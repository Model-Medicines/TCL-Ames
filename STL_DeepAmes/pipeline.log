2026-02-04 22:29:46.404146: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2026-02-04 22:29:46.407609: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100280000 Hz
2026-02-04 22:29:46.409977: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e10d025860 executing computations on platform Host. Devices:
2026-02-04 22:29:46.409994: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Using TensorFlow backend.
--- 0.2846033573150635 seconds ---
--- 3.457069396972656e-05 seconds ---
--- 2.956390380859375e-05 seconds ---
--- 3.0994415283203125e-05 seconds ---
--- 0.01782965660095215 seconds ---
--- 0.7303354740142822 seconds ---
DeepAmes prediction is completed
================================================================================
DeepAmes Multi-Dataset Pipeline
================================================================================

Found 16 dataset pair(s):
  - TA100_with_S9
  - TA100_without_S9
  - TA102_with_S9
  - TA102_without_S9
  - TA104_with_S9
  - TA104_without_S9
  - TA1535_with_S9
  - TA1535_without_S9
  - TA1537_with_S9
  - TA1537_without_S9
  - TA1538_with_S9
  - TA1538_without_S9
  - TA97_with_S9
  - TA97_without_S9
  - TA98_with_S9
  - TA98_without_S9


================================================================================
[1/16] Processing: TA100_with_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA100_with_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA100_with_S9_Test_mold2.csv
(4848, 777)
(3878, 777)
(567, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:33<10:37, 33.56s/it]KNN Seeds:  10%|█         | 2/20 [01:07<10:04, 33.58s/it]KNN Seeds:  15%|█▌        | 3/20 [01:40<09:29, 33.48s/it]KNN Seeds:  20%|██        | 4/20 [02:14<08:57, 33.58s/it]KNN Seeds:  25%|██▌       | 5/20 [02:47<08:23, 33.55s/it]KNN Seeds:  30%|███       | 6/20 [03:21<07:50, 33.58s/it]KNN Seeds:  35%|███▌      | 7/20 [03:55<07:18, 33.74s/it]KNN Seeds:  40%|████      | 8/20 [04:29<06:45, 33.80s/it]KNN Seeds:  45%|████▌     | 9/20 [05:02<06:10, 33.69s/it]KNN Seeds:  50%|█████     | 10/20 [05:36<05:35, 33.60s/it]KNN Seeds:  55%|█████▌    | 11/20 [06:09<05:02, 33.59s/it]KNN Seeds:  60%|██████    | 12/20 [06:43<04:29, 33.72s/it]KNN Seeds:  65%|██████▌   | 13/20 [07:17<03:56, 33.82s/it]KNN Seeds:  70%|███████   | 14/20 [07:51<03:22, 33.78s/it]KNN Seeds:  75%|███████▌  | 15/20 [08:25<02:48, 33.71s/it]KNN Seeds:  80%|████████  | 16/20 [08:58<02:14, 33.62s/it]KNN Seeds:  85%|████████▌ | 17/20 [09:32<01:41, 33.80s/it]KNN Seeds:  90%|█████████ | 18/20 [10:06<01:07, 33.76s/it]KNN Seeds:  95%|█████████▌| 19/20 [10:41<00:34, 34.07s/it]KNN Seeds: 100%|██████████| 20/20 [11:14<00:00, 33.98s/it]KNN Seeds: 100%|██████████| 20/20 [11:14<00:00, 33.75s/it]
24
(100, None, 'lbfgs')
(4848, 777)
(3878, 777)
(567, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:03<01:04,  3.38s/it]LR Seeds:  10%|█         | 2/20 [00:06<00:56,  3.15s/it]LR Seeds:  15%|█▌        | 3/20 [00:09<00:51,  3.04s/it]LR Seeds:  20%|██        | 4/20 [00:12<00:47,  3.00s/it]LR Seeds:  25%|██▌       | 5/20 [00:15<00:45,  3.03s/it]LR Seeds:  30%|███       | 6/20 [00:18<00:42,  3.03s/it]LR Seeds:  35%|███▌      | 7/20 [00:21<00:39,  3.05s/it]LR Seeds:  40%|████      | 8/20 [00:24<00:36,  3.05s/it]LR Seeds:  45%|████▌     | 9/20 [00:27<00:33,  3.06s/it]LR Seeds:  50%|█████     | 10/20 [00:30<00:30,  3.07s/it]LR Seeds:  55%|█████▌    | 11/20 [00:33<00:28,  3.12s/it]LR Seeds:  60%|██████    | 12/20 [00:36<00:24,  3.11s/it]LR Seeds:  65%|██████▌   | 13/20 [00:40<00:21,  3.12s/it]LR Seeds:  70%|███████   | 14/20 [00:43<00:18,  3.14s/it]LR Seeds:  75%|███████▌  | 15/20 [00:46<00:15,  3.16s/it]LR Seeds:  80%|████████  | 16/20 [00:49<00:12,  3.16s/it]LR Seeds:  85%|████████▌ | 17/20 [00:52<00:09,  3.16s/it]LR Seeds:  90%|█████████ | 18/20 [00:55<00:06,  3.16s/it]LR Seeds:  95%|█████████▌| 19/20 [00:59<00:03,  3.18s/it]LR Seeds: 100%|██████████| 20/20 [01:02<00:00,  3.18s/it]LR Seeds: 100%|██████████| 20/20 [01:02<00:00,  3.12s/it]
96
('rbf', 1, 1)
(4848, 777)
(3878, 777)
(567, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [03:51<1:13:19, 231.57s/it]SVM Seeds:  10%|█         | 2/20 [07:42<1:09:19, 231.08s/it]SVM Seeds:  15%|█▌        | 3/20 [11:32<1:05:24, 230.86s/it]SVM Seeds:  20%|██        | 4/20 [15:23<1:01:32, 230.76s/it]SVM Seeds:  25%|██▌       | 5/20 [19:14<57:41, 230.74s/it]  SVM Seeds:  30%|███       | 6/20 [23:04<53:49, 230.69s/it]SVM Seeds:  35%|███▌      | 7/20 [26:55<49:59, 230.70s/it]SVM Seeds:  40%|████      | 8/20 [30:46<46:08, 230.68s/it]SVM Seeds:  45%|████▌     | 9/20 [34:36<42:17, 230.67s/it]SVM Seeds:  50%|█████     | 10/20 [38:27<38:25, 230.53s/it]SVM Seeds:  55%|█████▌    | 11/20 [42:17<34:34, 230.54s/it]SVM Seeds:  60%|██████    | 12/20 [46:08<30:44, 230.51s/it]SVM Seeds:  65%|██████▌   | 13/20 [49:58<26:52, 230.42s/it]SVM Seeds:  70%|███████   | 14/20 [53:49<23:03, 230.58s/it]SVM Seeds:  75%|███████▌  | 15/20 [57:39<19:12, 230.48s/it]SVM Seeds:  80%|████████  | 16/20 [1:01:29<15:21, 230.38s/it]SVM Seeds:  85%|████████▌ | 17/20 [1:05:19<11:30, 230.30s/it]SVM Seeds:  90%|█████████ | 18/20 [1:09:10<07:40, 230.44s/it]SVM Seeds:  95%|█████████▌| 19/20 [1:13:00<03:50, 230.31s/it]SVM Seeds: 100%|██████████| 20/20 [1:16:50<00:00, 230.32s/it]SVM Seeds: 100%|██████████| 20/20 [1:16:50<00:00, 230.54s/it]
200
(500, None, 70, 1, 'balanced')
(4848, 777)
(3878, 777)
(567, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:17<05:27, 17.25s/it]RF Seeds:  10%|█         | 2/20 [00:34<05:11, 17.30s/it]RF Seeds:  15%|█▌        | 3/20 [00:51<04:53, 17.27s/it]RF Seeds:  20%|██        | 4/20 [01:09<04:36, 17.28s/it]RF Seeds:  25%|██▌       | 5/20 [01:26<04:18, 17.26s/it]RF Seeds:  30%|███       | 6/20 [01:43<04:01, 17.25s/it]RF Seeds:  35%|███▌      | 7/20 [02:00<03:44, 17.28s/it]RF Seeds:  40%|████      | 8/20 [02:18<03:27, 17.30s/it]RF Seeds:  45%|████▌     | 9/20 [02:35<03:10, 17.30s/it]RF Seeds:  50%|█████     | 10/20 [02:52<02:52, 17.30s/it]RF Seeds:  55%|█████▌    | 11/20 [03:10<02:35, 17.31s/it]RF Seeds:  60%|██████    | 12/20 [03:27<02:18, 17.33s/it]RF Seeds:  65%|██████▌   | 13/20 [03:44<02:01, 17.34s/it]RF Seeds:  70%|███████   | 14/20 [04:02<01:43, 17.32s/it]RF Seeds:  75%|███████▌  | 15/20 [04:19<01:26, 17.33s/it]RF Seeds:  80%|████████  | 16/20 [04:37<01:09, 17.40s/it]RF Seeds:  85%|████████▌ | 17/20 [04:54<00:52, 17.41s/it]RF Seeds:  90%|█████████ | 18/20 [05:12<00:35, 17.53s/it]RF Seeds:  95%|█████████▌| 19/20 [05:29<00:17, 17.51s/it]RF Seeds: 100%|██████████| 20/20 [05:47<00:00, 17.47s/it]RF Seeds: 100%|██████████| 20/20 [05:47<00:00, 17.36s/it]
400
(0.01, 900, 7, 0.8, 6)
(4848, 777)
(3878, 777)
(567, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [01:04<20:26, 64.57s/it]XGBoost Seeds:  10%|█         | 2/20 [02:08<19:19, 64.43s/it]XGBoost Seeds:  15%|█▌        | 3/20 [03:13<18:14, 64.36s/it]XGBoost Seeds:  20%|██        | 4/20 [04:17<17:10, 64.38s/it]XGBoost Seeds:  25%|██▌       | 5/20 [05:22<16:07, 64.49s/it]XGBoost Seeds:  30%|███       | 6/20 [06:26<15:03, 64.55s/it]XGBoost Seeds:  35%|███▌      | 7/20 [07:31<13:58, 64.53s/it]XGBoost Seeds:  40%|████      | 8/20 [08:35<12:53, 64.48s/it]XGBoost Seeds:  45%|████▌     | 9/20 [09:40<11:48, 64.45s/it]XGBoost Seeds:  50%|█████     | 10/20 [10:44<10:43, 64.40s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [11:48<09:39, 64.35s/it]XGBoost Seeds:  60%|██████    | 12/20 [12:52<08:34, 64.27s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [13:57<07:29, 64.25s/it]XGBoost Seeds:  70%|███████   | 14/20 [15:01<06:25, 64.25s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [16:05<05:21, 64.27s/it]XGBoost Seeds:  80%|████████  | 16/20 [17:09<04:17, 64.30s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [18:14<03:12, 64.27s/it]XGBoost Seeds:  90%|█████████ | 18/20 [19:18<02:08, 64.28s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [20:22<01:04, 64.35s/it]XGBoost Seeds: 100%|██████████| 20/20 [21:27<00:00, 64.33s/it]XGBoost Seeds: 100%|██████████| 20/20 [21:27<00:00, 64.36s/it]
knn:  95
lr:  85
svm:  100
rf:  92
xgboost:  74
Combining validation predictions is completed
knn:  95
lr:  85
svm:  100
rf:  92
xgboost:  74
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepames/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepames/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepames/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepames/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepames/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepames/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepames/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepames/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2026-02-05 00:26:51.415157: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 6s - loss: 3.7151 - acc: 0.4062
776/776 [==============================] - 0s 413us/step - loss: 1.9092 - acc: 0.7345 - val_loss: 1.2445 - val_acc: 0.6701

Epoch 00001: loss improved from inf to 1.90925, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9565 - acc: 0.6250
776/776 [==============================] - 0s 31us/step - loss: 1.6219 - acc: 0.7384 - val_loss: 1.3489 - val_acc: 0.4227

Epoch 00002: loss improved from 1.90925 to 1.62192, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0589 - acc: 0.6875
776/776 [==============================] - 0s 30us/step - loss: 1.5362 - acc: 0.7436 - val_loss: 1.1286 - val_acc: 0.7216

Epoch 00003: loss improved from 1.62192 to 1.53616, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 1.5991 - acc: 0.7500
776/776 [==============================] - 0s 30us/step - loss: 1.4856 - acc: 0.7461 - val_loss: 1.1495 - val_acc: 0.4742

Epoch 00004: loss improved from 1.53616 to 1.48557, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6847 - acc: 0.6250
776/776 [==============================] - 0s 30us/step - loss: 1.4265 - acc: 0.7552 - val_loss: 1.1239 - val_acc: 0.4639

Epoch 00005: loss improved from 1.48557 to 1.42649, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 1.5708 - acc: 0.7188
776/776 [==============================] - 0s 30us/step - loss: 1.3788 - acc: 0.7448 - val_loss: 1.0424 - val_acc: 0.5928

Epoch 00006: loss improved from 1.42649 to 1.37882, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 1.3885 - acc: 0.8125
776/776 [==============================] - 0s 30us/step - loss: 1.3184 - acc: 0.7590 - val_loss: 1.4283 - val_acc: 0.2320

Epoch 00007: loss improved from 1.37882 to 1.31835, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8853 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.3059 - acc: 0.7500 - val_loss: 1.5196 - val_acc: 0.4536

Epoch 00008: loss improved from 1.31835 to 1.30590, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7139 - acc: 0.7500
776/776 [==============================] - 0s 30us/step - loss: 1.2649 - acc: 0.7616 - val_loss: 1.2487 - val_acc: 0.3763

Epoch 00009: loss improved from 1.30590 to 1.26492, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7418 - acc: 0.5625
776/776 [==============================] - 0s 29us/step - loss: 1.2538 - acc: 0.7513 - val_loss: 1.1143 - val_acc: 0.4433

Epoch 00010: loss improved from 1.26492 to 1.25377, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6498 - acc: 0.6562
776/776 [==============================] - 0s 30us/step - loss: 1.2325 - acc: 0.7487 - val_loss: 0.8349 - val_acc: 0.7835

Epoch 00011: loss improved from 1.25377 to 1.23251, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 1.3492 - acc: 0.7188
776/776 [==============================] - 0s 30us/step - loss: 1.2223 - acc: 0.7526 - val_loss: 1.3124 - val_acc: 0.3608

Epoch 00012: loss improved from 1.23251 to 1.22225, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 1.4312 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.1825 - acc: 0.7616 - val_loss: 1.3853 - val_acc: 0.3660

Epoch 00013: loss improved from 1.22225 to 1.18253, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8530 - acc: 0.5312
776/776 [==============================] - 0s 29us/step - loss: 1.1804 - acc: 0.7796 - val_loss: 1.0458 - val_acc: 0.4433

Epoch 00014: loss improved from 1.18253 to 1.18044, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6952 - acc: 0.6562
776/776 [==============================] - 0s 29us/step - loss: 1.2105 - acc: 0.7332 - val_loss: 1.1388 - val_acc: 0.4691

Epoch 00015: loss did not improve from 1.18044
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 1.4942 - acc: 0.5625
776/776 [==============================] - 0s 29us/step - loss: 1.1577 - acc: 0.7577 - val_loss: 1.4205 - val_acc: 0.3299

Epoch 00016: loss improved from 1.18044 to 1.15773, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 1.2007 - acc: 0.6250
776/776 [==============================] - 0s 29us/step - loss: 1.1380 - acc: 0.7474 - val_loss: 1.0360 - val_acc: 0.4330

Epoch 00017: loss improved from 1.15773 to 1.13798, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 1.0729 - acc: 0.7500
776/776 [==============================] - 0s 30us/step - loss: 1.0707 - acc: 0.7655 - val_loss: 1.2666 - val_acc: 0.3505

Epoch 00018: loss improved from 1.13798 to 1.07069, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_6.h5
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 1.4122 - acc: 0.5938
776/776 [==============================] - 0s 29us/step - loss: 1.0748 - acc: 0.7771 - val_loss: 1.2162 - val_acc: 0.2938

Epoch 00019: loss did not improve from 1.07069
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 2.6620 - acc: 0.4062
776/776 [==============================] - 0s 29us/step - loss: 1.2046 - acc: 0.7564 - val_loss: 0.9911 - val_acc: 0.3557

Epoch 00020: loss did not improve from 1.07069
Epoch 21/100

 32/776 [>.............................] - ETA: 0s - loss: 1.0578 - acc: 0.6875
776/776 [==============================] - 0s 29us/step - loss: 1.0882 - acc: 0.7680 - val_loss: 1.0726 - val_acc: 0.2629

Epoch 00021: loss did not improve from 1.07069
Epoch 22/100

 32/776 [>.............................] - ETA: 0s - loss: 1.1022 - acc: 0.6875
776/776 [==============================] - 0s 29us/step - loss: 1.0736 - acc: 0.7887 - val_loss: 1.3569 - val_acc: 0.2010

Epoch 00022: loss did not improve from 1.07069
Epoch 23/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7879 - acc: 0.5000
776/776 [==============================] - 0s 29us/step - loss: 1.1455 - acc: 0.7616 - val_loss: 1.1963 - val_acc: 0.3351
DeepAmes+ Weights:   8%|▊         | 1/13 [00:02<00:26,  2.20s/it]
Epoch 00023: loss did not improve from 1.07069
Epoch 00023: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 1.8534 - acc: 0.7812
776/776 [==============================] - 0s 359us/step - loss: 1.8775 - acc: 0.7165 - val_loss: 1.5795 - val_acc: 0.3505

Epoch 00001: loss improved from inf to 1.87750, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2245 - acc: 0.4062
776/776 [==============================] - 0s 31us/step - loss: 1.7001 - acc: 0.6997 - val_loss: 1.5814 - val_acc: 0.3557

Epoch 00002: loss improved from 1.87750 to 1.70010, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3513 - acc: 0.4375
776/776 [==============================] - 0s 31us/step - loss: 1.6447 - acc: 0.7062 - val_loss: 1.3084 - val_acc: 0.3814

Epoch 00003: loss improved from 1.70010 to 1.64470, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8832 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.5441 - acc: 0.7255 - val_loss: 1.3095 - val_acc: 0.3711

Epoch 00004: loss improved from 1.64470 to 1.54413, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8597 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.4794 - acc: 0.7191 - val_loss: 1.1666 - val_acc: 0.5412

Epoch 00005: loss improved from 1.54413 to 1.47942, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6000 - acc: 0.7500
776/776 [==============================] - 0s 30us/step - loss: 1.4333 - acc: 0.7410 - val_loss: 1.3104 - val_acc: 0.3247

Epoch 00006: loss improved from 1.47942 to 1.43334, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0659 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.4171 - acc: 0.7255 - val_loss: 1.0324 - val_acc: 0.7010

Epoch 00007: loss improved from 1.43334 to 1.41712, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 1.3469 - acc: 0.7188
776/776 [==============================] - 0s 30us/step - loss: 1.3769 - acc: 0.7448 - val_loss: 1.2172 - val_acc: 0.2990

Epoch 00008: loss improved from 1.41712 to 1.37694, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 1.5525 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.3370 - acc: 0.7371 - val_loss: 1.1029 - val_acc: 0.4639

Epoch 00009: loss improved from 1.37694 to 1.33704, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6819 - acc: 0.6562
776/776 [==============================] - 0s 30us/step - loss: 1.2929 - acc: 0.7410 - val_loss: 1.1211 - val_acc: 0.3866

Epoch 00010: loss improved from 1.33704 to 1.29291, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8373 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.3052 - acc: 0.7345 - val_loss: 1.1111 - val_acc: 0.3402

Epoch 00011: loss did not improve from 1.29291
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 1.5337 - acc: 0.6250
776/776 [==============================] - 0s 30us/step - loss: 1.2546 - acc: 0.7358 - val_loss: 1.1950 - val_acc: 0.2835

Epoch 00012: loss improved from 1.29291 to 1.25463, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 1.4600 - acc: 0.6875
776/776 [==============================] - 0s 30us/step - loss: 1.2470 - acc: 0.7448 - val_loss: 1.8316 - val_acc: 0.1804

Epoch 00013: loss improved from 1.25463 to 1.24699, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3069 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.3108 - acc: 0.7088 - val_loss: 0.8502 - val_acc: 0.7165

Epoch 00014: loss did not improve from 1.24699
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 1.3235 - acc: 0.6562
776/776 [==============================] - 0s 30us/step - loss: 1.2529 - acc: 0.7178 - val_loss: 1.3404 - val_acc: 0.2732

Epoch 00015: loss did not improve from 1.24699
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2723 - acc: 0.4062
776/776 [==============================] - 0s 29us/step - loss: 1.3000 - acc: 0.7113 - val_loss: 1.3821 - val_acc: 0.3299

Epoch 00016: loss did not improve from 1.24699
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 1.5071 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.2096 - acc: 0.7358 - val_loss: 1.1559 - val_acc: 0.3351

Epoch 00017: loss improved from 1.24699 to 1.20962, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6165 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.2216 - acc: 0.7294 - val_loss: 1.7509 - val_acc: 0.2062

Epoch 00018: loss did not improve from 1.20962
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8293 - acc: 0.4375
776/776 [==============================] - 0s 29us/step - loss: 1.2545 - acc: 0.7010 - val_loss: 1.5807 - val_acc: 0.3402

Epoch 00019: loss did not improve from 1.20962
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 1.4943 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.2410 - acc: 0.7152 - val_loss: 1.1999 - val_acc: 0.3247

Epoch 00020: loss did not improve from 1.20962
Epoch 21/100

 32/776 [>.............................] - ETA: 0s - loss: 1.2368 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.1967 - acc: 0.7191 - val_loss: 4.1955 - val_acc: 0.2732

Epoch 00021: loss improved from 1.20962 to 1.19675, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_7.h5
Epoch 22/100

 32/776 [>.............................] - ETA: 0s - loss: 2.8383 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.2784 - acc: 0.7178 - val_loss: 2.9715 - val_acc: 0.2165

Epoch 00022: loss did not improve from 1.19675
Epoch 23/100

 32/776 [>.............................] - ETA: 0s - loss: 3.0141 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 1.2552 - acc: 0.7191 - val_loss: 2.1462 - val_acc: 0.2062

Epoch 00023: loss did not improve from 1.19675
Epoch 24/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2272 - acc: 0.4688
776/776 [==============================] - 0s 29us/step - loss: 1.2315 - acc: 0.7113 - val_loss: 1.6470 - val_acc: 0.2320

Epoch 00024: loss did not improve from 1.19675
Epoch 25/100

 32/776 [>.............................] - ETA: 0s - loss: 3.0645 - acc: 0.4688
776/776 [==============================] - 0s 29us/step - loss: 1.3509 - acc: 0.7139 - val_loss: 1.6406 - val_acc: 0.2990

Epoch 00025: loss did not improve from 1.19675
Epoch 26/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1965 - acc: 0.3750
776/776 [==============================] - 0s 29us/step - loss: 1.2387 - acc: 0.7307 - val_loss: 1.0741 - val_acc: 0.3351
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:04<00:24,  2.24s/it]
Epoch 00026: loss did not improve from 1.19675
Epoch 00026: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 1.7454 - acc: 0.8125
776/776 [==============================] - 0s 358us/step - loss: 1.9008 - acc: 0.7010 - val_loss: 1.8973 - val_acc: 0.3505

Epoch 00001: loss improved from inf to 1.90082, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1405 - acc: 0.4062
776/776 [==============================] - 0s 32us/step - loss: 1.8251 - acc: 0.6830 - val_loss: 1.7167 - val_acc: 0.3505

Epoch 00002: loss improved from 1.90082 to 1.82506, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 2.8710 - acc: 0.3438
776/776 [==============================] - 0s 31us/step - loss: 1.6978 - acc: 0.6869 - val_loss: 1.4772 - val_acc: 0.3608

Epoch 00003: loss improved from 1.82506 to 1.69783, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2280 - acc: 0.4688
776/776 [==============================] - 0s 31us/step - loss: 1.6282 - acc: 0.6959 - val_loss: 1.3619 - val_acc: 0.3454

Epoch 00004: loss improved from 1.69783 to 1.62820, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6782 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.5737 - acc: 0.6972 - val_loss: 1.7646 - val_acc: 0.2938

Epoch 00005: loss improved from 1.62820 to 1.57374, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.9236 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.5829 - acc: 0.6946 - val_loss: 1.3242 - val_acc: 0.3866

Epoch 00006: loss did not improve from 1.57374
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8181 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.4850 - acc: 0.7165 - val_loss: 1.3371 - val_acc: 0.2990

Epoch 00007: loss improved from 1.57374 to 1.48503, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2512 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.4499 - acc: 0.7075 - val_loss: 1.3009 - val_acc: 0.3402

Epoch 00008: loss improved from 1.48503 to 1.44986, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6132 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.4115 - acc: 0.7101 - val_loss: 1.4357 - val_acc: 0.2680

Epoch 00009: loss improved from 1.44986 to 1.41149, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2276 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.4138 - acc: 0.6946 - val_loss: 1.3093 - val_acc: 0.2680

Epoch 00010: loss did not improve from 1.41149
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1694 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.4527 - acc: 0.7165 - val_loss: 1.2066 - val_acc: 0.3608

Epoch 00011: loss did not improve from 1.41149
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7162 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.3628 - acc: 0.7191 - val_loss: 1.4525 - val_acc: 0.3454

Epoch 00012: loss improved from 1.41149 to 1.36284, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3697 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.3725 - acc: 0.6972 - val_loss: 1.8383 - val_acc: 0.3454

Epoch 00013: loss did not improve from 1.36284
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1585 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.3564 - acc: 0.6881 - val_loss: 1.5993 - val_acc: 0.3093

Epoch 00014: loss improved from 1.36284 to 1.35643, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5158 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.3999 - acc: 0.7036 - val_loss: 1.0562 - val_acc: 0.4278

Epoch 00015: loss did not improve from 1.35643
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9360 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.3139 - acc: 0.6972 - val_loss: 0.9267 - val_acc: 0.5412

Epoch 00016: loss improved from 1.35643 to 1.31392, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7238 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.2861 - acc: 0.7152 - val_loss: 0.9846 - val_acc: 0.4227

Epoch 00017: loss improved from 1.31392 to 1.28609, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 1.4804 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.2395 - acc: 0.7358 - val_loss: 1.1660 - val_acc: 0.2938

Epoch 00018: loss improved from 1.28609 to 1.23945, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2595 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.3237 - acc: 0.7294 - val_loss: 1.2593 - val_acc: 0.3196

Epoch 00019: loss did not improve from 1.23945
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7809 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.2857 - acc: 0.7216 - val_loss: 1.1377 - val_acc: 0.3196

Epoch 00020: loss did not improve from 1.23945
Epoch 21/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7631 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.2938 - acc: 0.6959 - val_loss: 1.2492 - val_acc: 0.3402

Epoch 00021: loss did not improve from 1.23945
Epoch 22/100

 32/776 [>.............................] - ETA: 0s - loss: 1.1387 - acc: 0.6875
776/776 [==============================] - 0s 30us/step - loss: 1.2031 - acc: 0.7487 - val_loss: 1.5510 - val_acc: 0.2784

Epoch 00022: loss improved from 1.23945 to 1.20308, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_8.h5
Epoch 23/100

 32/776 [>.............................] - ETA: 0s - loss: 3.3781 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.4476 - acc: 0.6920 - val_loss: 1.2765 - val_acc: 0.3454

Epoch 00023: loss did not improve from 1.20308
Epoch 24/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0242 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.2743 - acc: 0.6933 - val_loss: 1.9095 - val_acc: 0.1959

Epoch 00024: loss did not improve from 1.20308
Epoch 25/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0915 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.2723 - acc: 0.7191 - val_loss: 1.4066 - val_acc: 0.2629

Epoch 00025: loss did not improve from 1.20308
Epoch 26/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8307 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.2772 - acc: 0.7062 - val_loss: 1.2819 - val_acc: 0.3763

Epoch 00026: loss did not improve from 1.20308
Epoch 27/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6877 - acc: 0.6250
776/776 [==============================] - 0s 30us/step - loss: 1.2840 - acc: 0.7049 - val_loss: 1.4292 - val_acc: 0.3351
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:06<00:22,  2.28s/it]
Epoch 00027: loss did not improve from 1.20308
Epoch 00027: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.0299 - acc: 0.7500
776/776 [==============================] - 0s 363us/step - loss: 2.0424 - acc: 0.7165 - val_loss: 2.0185 - val_acc: 0.2629

Epoch 00001: loss improved from inf to 2.04245, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 2.8201 - acc: 0.4062
776/776 [==============================] - 0s 32us/step - loss: 1.8342 - acc: 0.6714 - val_loss: 1.9157 - val_acc: 0.2423

Epoch 00002: loss improved from 2.04245 to 1.83423, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1793 - acc: 0.2812
776/776 [==============================] - 0s 31us/step - loss: 1.8153 - acc: 0.6469 - val_loss: 1.6059 - val_acc: 0.3144

Epoch 00003: loss improved from 1.83423 to 1.81533, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0785 - acc: 0.4062
776/776 [==============================] - 0s 31us/step - loss: 1.6946 - acc: 0.6624 - val_loss: 1.4185 - val_acc: 0.3196

Epoch 00004: loss improved from 1.81533 to 1.69461, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8874 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.6068 - acc: 0.6675 - val_loss: 1.2562 - val_acc: 0.3814

Epoch 00005: loss improved from 1.69461 to 1.60682, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7962 - acc: 0.6250
776/776 [==============================] - 0s 30us/step - loss: 1.5864 - acc: 0.6817 - val_loss: 1.6516 - val_acc: 0.2423

Epoch 00006: loss improved from 1.60682 to 1.58641, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2263 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.5539 - acc: 0.6791 - val_loss: 1.4171 - val_acc: 0.3505

Epoch 00007: loss improved from 1.58641 to 1.55388, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0996 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.5544 - acc: 0.6675 - val_loss: 1.7838 - val_acc: 0.1959

Epoch 00008: loss did not improve from 1.55388
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3215 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.4874 - acc: 0.6843 - val_loss: 1.3034 - val_acc: 0.3763

Epoch 00009: loss improved from 1.55388 to 1.48744, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.4387 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.4800 - acc: 0.6856 - val_loss: 1.5096 - val_acc: 0.2784

Epoch 00010: loss improved from 1.48744 to 1.47998, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1883 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.4664 - acc: 0.6972 - val_loss: 1.8419 - val_acc: 0.3144

Epoch 00011: loss improved from 1.47998 to 1.46638, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1201 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.4427 - acc: 0.6714 - val_loss: 1.2845 - val_acc: 0.3557

Epoch 00012: loss improved from 1.46638 to 1.44272, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7309 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.4116 - acc: 0.6778 - val_loss: 1.0707 - val_acc: 0.3505

Epoch 00013: loss improved from 1.44272 to 1.41156, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7310 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.4056 - acc: 0.7010 - val_loss: 1.7787 - val_acc: 0.2165

Epoch 00014: loss improved from 1.41156 to 1.40562, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5370 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.3766 - acc: 0.6985 - val_loss: 2.0510 - val_acc: 0.2320

Epoch 00015: loss improved from 1.40562 to 1.37665, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 3.9568 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.4726 - acc: 0.6662 - val_loss: 1.2387 - val_acc: 0.2887

Epoch 00016: loss did not improve from 1.37665
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 2.4608 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.4144 - acc: 0.6714 - val_loss: 1.5921 - val_acc: 0.3557

Epoch 00017: loss did not improve from 1.37665
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7595 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.3865 - acc: 0.6778 - val_loss: 1.2804 - val_acc: 0.3711

Epoch 00018: loss did not improve from 1.37665
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8628 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.3649 - acc: 0.6920 - val_loss: 1.0859 - val_acc: 0.3969

Epoch 00019: loss improved from 1.37665 to 1.36485, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 1.5189 - acc: 0.6250
776/776 [==============================] - 0s 30us/step - loss: 1.3239 - acc: 0.6972 - val_loss: 1.1943 - val_acc: 0.3351

Epoch 00020: loss improved from 1.36485 to 1.32393, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 21/100

 32/776 [>.............................] - ETA: 0s - loss: 1.2508 - acc: 0.6250
776/776 [==============================] - 0s 30us/step - loss: 1.3267 - acc: 0.7126 - val_loss: 1.0394 - val_acc: 0.4381

Epoch 00021: loss did not improve from 1.32393
Epoch 22/100

 32/776 [>.............................] - ETA: 0s - loss: 1.3426 - acc: 0.6875
776/776 [==============================] - 0s 30us/step - loss: 1.3247 - acc: 0.6985 - val_loss: 1.6217 - val_acc: 0.2474

Epoch 00022: loss did not improve from 1.32393
Epoch 23/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1019 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.3090 - acc: 0.7242 - val_loss: 1.4760 - val_acc: 0.3454

Epoch 00023: loss improved from 1.32393 to 1.30904, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_9.h5
Epoch 24/100

 32/776 [>.............................] - ETA: 0s - loss: 1.0766 - acc: 0.6250
776/776 [==============================] - 0s 30us/step - loss: 1.3553 - acc: 0.7062 - val_loss: 1.7201 - val_acc: 0.2113

Epoch 00024: loss did not improve from 1.30904
Epoch 25/100

 32/776 [>.............................] - ETA: 0s - loss: 1.5493 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.3330 - acc: 0.6856 - val_loss: 1.2566 - val_acc: 0.3196

Epoch 00025: loss did not improve from 1.30904
Epoch 26/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9231 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.3824 - acc: 0.6740 - val_loss: 2.8526 - val_acc: 0.1495

Epoch 00026: loss did not improve from 1.30904
Epoch 27/100

 32/776 [>.............................] - ETA: 0s - loss: 4.1308 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.5870 - acc: 0.6211 - val_loss: 0.8899 - val_acc: 0.5722

Epoch 00027: loss did not improve from 1.30904
Epoch 28/100

 32/776 [>.............................] - ETA: 0s - loss: 1.3507 - acc: 0.6875
776/776 [==============================] - 0s 30us/step - loss: 1.4070 - acc: 0.6920 - val_loss: 1.2208 - val_acc: 0.3557
DeepAmes+ Weights:  31%|███       | 4/13 [00:09<00:20,  2.29s/it]
Epoch 00028: loss did not improve from 1.30904
Epoch 00028: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.1034 - acc: 0.6875
776/776 [==============================] - 0s 364us/step - loss: 2.0846 - acc: 0.6817 - val_loss: 2.4801 - val_acc: 0.1598

Epoch 00001: loss improved from inf to 2.08458, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 2.9711 - acc: 0.3438
776/776 [==============================] - 0s 32us/step - loss: 1.9252 - acc: 0.6495 - val_loss: 1.9303 - val_acc: 0.2320

Epoch 00002: loss improved from 2.08458 to 1.92518, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 4.3282 - acc: 0.2812
776/776 [==============================] - 0s 31us/step - loss: 1.9677 - acc: 0.6482 - val_loss: 1.7502 - val_acc: 0.3402

Epoch 00003: loss did not improve from 1.92518
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3832 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.7569 - acc: 0.6637 - val_loss: 1.5224 - val_acc: 0.2938

Epoch 00004: loss improved from 1.92518 to 1.75694, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3577 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.7016 - acc: 0.6740 - val_loss: 1.4414 - val_acc: 0.2680

Epoch 00005: loss improved from 1.75694 to 1.70158, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1729 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.6425 - acc: 0.6572 - val_loss: 1.2670 - val_acc: 0.3918

Epoch 00006: loss improved from 1.70158 to 1.64250, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9875 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.5954 - acc: 0.6611 - val_loss: 1.2399 - val_acc: 0.3557

Epoch 00007: loss improved from 1.64250 to 1.59545, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6543 - acc: 0.7188
776/776 [==============================] - 0s 30us/step - loss: 1.5575 - acc: 0.6727 - val_loss: 1.1669 - val_acc: 0.3660

Epoch 00008: loss improved from 1.59545 to 1.55748, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6412 - acc: 0.6875
776/776 [==============================] - 0s 30us/step - loss: 1.5365 - acc: 0.6701 - val_loss: 2.1734 - val_acc: 0.2165

Epoch 00009: loss improved from 1.55748 to 1.53651, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 5.2133 - acc: 0.2500
776/776 [==============================] - 0s 30us/step - loss: 1.7102 - acc: 0.6443 - val_loss: 2.0944 - val_acc: 0.2629

Epoch 00010: loss did not improve from 1.53651
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7713 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.5911 - acc: 0.6224 - val_loss: 2.1405 - val_acc: 0.1907

Epoch 00011: loss did not improve from 1.53651
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5187 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 1.5230 - acc: 0.6340 - val_loss: 1.4524 - val_acc: 0.2887

Epoch 00012: loss improved from 1.53651 to 1.52303, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9885 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.5238 - acc: 0.6405 - val_loss: 1.3606 - val_acc: 0.3196

Epoch 00013: loss did not improve from 1.52303
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1325 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.4541 - acc: 0.6521 - val_loss: 1.3555 - val_acc: 0.3144

Epoch 00014: loss improved from 1.52303 to 1.45408, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5822 - acc: 0.4062
776/776 [==============================] - 0s 29us/step - loss: 1.5709 - acc: 0.6314 - val_loss: 1.3934 - val_acc: 0.2938

Epoch 00015: loss did not improve from 1.45408
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8287 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.4594 - acc: 0.6469 - val_loss: 1.0502 - val_acc: 0.4072

Epoch 00016: loss did not improve from 1.45408
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 1.3331 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.3970 - acc: 0.6624 - val_loss: 1.4452 - val_acc: 0.2216

Epoch 00017: loss improved from 1.45408 to 1.39699, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_10.h5
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 2.9148 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.5323 - acc: 0.6637 - val_loss: 1.4224 - val_acc: 0.2732

Epoch 00018: loss did not improve from 1.39699
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9965 - acc: 0.4062
776/776 [==============================] - 0s 29us/step - loss: 1.4726 - acc: 0.6572 - val_loss: 1.8909 - val_acc: 0.2423

Epoch 00019: loss did not improve from 1.39699
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7964 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 1.5473 - acc: 0.6379 - val_loss: 1.4483 - val_acc: 0.3041

Epoch 00020: loss did not improve from 1.39699
Epoch 21/100

 32/776 [>.............................] - ETA: 0s - loss: 1.5865 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.4411 - acc: 0.6495 - val_loss: 1.3107 - val_acc: 0.2526

Epoch 00021: loss did not improve from 1.39699
Epoch 22/100

 32/776 [>.............................] - ETA: 0s - loss: 2.4636 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.4414 - acc: 0.6624 - val_loss: 1.5758 - val_acc: 0.2990
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:11<00:18,  2.26s/it]
Epoch 00022: loss did not improve from 1.39699
Epoch 00022: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.3916 - acc: 0.7812
776/776 [==============================] - 0s 358us/step - loss: 2.1396 - acc: 0.6675 - val_loss: 2.7059 - val_acc: 0.2062

Epoch 00001: loss improved from inf to 2.13961, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 5.3860 - acc: 0.3125
776/776 [==============================] - 0s 31us/step - loss: 2.1262 - acc: 0.6031 - val_loss: 1.9041 - val_acc: 0.3196

Epoch 00002: loss improved from 2.13961 to 2.12623, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1006 - acc: 0.3750
776/776 [==============================] - 0s 31us/step - loss: 1.8816 - acc: 0.6314 - val_loss: 1.7651 - val_acc: 0.3196

Epoch 00003: loss improved from 2.12623 to 1.88158, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7479 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.8358 - acc: 0.6198 - val_loss: 1.4825 - val_acc: 0.3402

Epoch 00004: loss improved from 1.88158 to 1.83584, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2411 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.7520 - acc: 0.6353 - val_loss: 1.6514 - val_acc: 0.3299

Epoch 00005: loss improved from 1.83584 to 1.75204, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7174 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.7306 - acc: 0.6250 - val_loss: 1.3457 - val_acc: 0.3093

Epoch 00006: loss improved from 1.75204 to 1.73056, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8236 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.6552 - acc: 0.6314 - val_loss: 1.2114 - val_acc: 0.3093

Epoch 00007: loss improved from 1.73056 to 1.65517, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6339 - acc: 0.7188
776/776 [==============================] - 0s 30us/step - loss: 1.6099 - acc: 0.6521 - val_loss: 1.5210 - val_acc: 0.3093

Epoch 00008: loss improved from 1.65517 to 1.60985, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2064 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.5920 - acc: 0.6534 - val_loss: 1.5287 - val_acc: 0.2577

Epoch 00009: loss improved from 1.60985 to 1.59198, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5998 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.5984 - acc: 0.6456 - val_loss: 1.4273 - val_acc: 0.2526

Epoch 00010: loss did not improve from 1.59198
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7164 - acc: 0.4375
776/776 [==============================] - 0s 29us/step - loss: 1.5762 - acc: 0.6147 - val_loss: 1.4752 - val_acc: 0.2474

Epoch 00011: loss improved from 1.59198 to 1.57623, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1754 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.6809 - acc: 0.6095 - val_loss: 2.2040 - val_acc: 0.2629

Epoch 00012: loss did not improve from 1.57623
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 4.2928 - acc: 0.3438
776/776 [==============================] - 0s 29us/step - loss: 1.7024 - acc: 0.6160 - val_loss: 1.6184 - val_acc: 0.3144

Epoch 00013: loss did not improve from 1.57623
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0272 - acc: 0.5000
776/776 [==============================] - 0s 29us/step - loss: 1.5114 - acc: 0.6082 - val_loss: 1.7078 - val_acc: 0.3196

Epoch 00014: loss improved from 1.57623 to 1.51144, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3895 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.4721 - acc: 0.6559 - val_loss: 1.8927 - val_acc: 0.2010

Epoch 00015: loss improved from 1.51144 to 1.47207, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3555 - acc: 0.4688
776/776 [==============================] - 0s 36us/step - loss: 1.5105 - acc: 0.6430 - val_loss: 1.7468 - val_acc: 0.2629

Epoch 00016: loss did not improve from 1.47207
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6500 - acc: 0.5312
776/776 [==============================] - 0s 29us/step - loss: 1.4939 - acc: 0.6057 - val_loss: 1.5068 - val_acc: 0.3144

Epoch 00017: loss did not improve from 1.47207
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 2.4259 - acc: 0.4062
776/776 [==============================] - 0s 29us/step - loss: 1.5464 - acc: 0.6263 - val_loss: 2.3535 - val_acc: 0.3144

Epoch 00018: loss did not improve from 1.47207
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3544 - acc: 0.4375
776/776 [==============================] - 0s 29us/step - loss: 1.4531 - acc: 0.6276 - val_loss: 2.0749 - val_acc: 0.2165

Epoch 00019: loss improved from 1.47207 to 1.45310, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_11.h5
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 3.0878 - acc: 0.2812
776/776 [==============================] - 0s 30us/step - loss: 1.5359 - acc: 0.6340 - val_loss: 2.0738 - val_acc: 0.2320

Epoch 00020: loss did not improve from 1.45310
Epoch 21/100

 32/776 [>.............................] - ETA: 0s - loss: 2.9334 - acc: 0.3438
776/776 [==============================] - 0s 29us/step - loss: 1.5593 - acc: 0.6237 - val_loss: 1.8660 - val_acc: 0.2423

Epoch 00021: loss did not improve from 1.45310
Epoch 22/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7095 - acc: 0.3438
776/776 [==============================] - 0s 29us/step - loss: 1.4940 - acc: 0.6430 - val_loss: 1.4229 - val_acc: 0.3299

Epoch 00022: loss did not improve from 1.45310
Epoch 23/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2815 - acc: 0.5000
776/776 [==============================] - 0s 29us/step - loss: 1.4562 - acc: 0.6598 - val_loss: 2.2475 - val_acc: 0.3196

Epoch 00023: loss did not improve from 1.45310
Epoch 24/100

 32/776 [>.............................] - ETA: 0s - loss: 3.8146 - acc: 0.4062
776/776 [==============================] - 0s 29us/step - loss: 1.6571 - acc: 0.6456 - val_loss: 2.8824 - val_acc: 0.1753
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:13<00:15,  2.26s/it]
Epoch 00024: loss did not improve from 1.45310
Epoch 00024: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 1.9143 - acc: 0.8125
776/776 [==============================] - 0s 361us/step - loss: 2.3043 - acc: 0.6443 - val_loss: 2.7057 - val_acc: 0.2062

Epoch 00001: loss improved from inf to 2.30433, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 5.6210 - acc: 0.1875
776/776 [==============================] - 0s 32us/step - loss: 2.1905 - acc: 0.5992 - val_loss: 1.7673 - val_acc: 0.3093

Epoch 00002: loss improved from 2.30433 to 2.19054, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7409 - acc: 0.3438
776/776 [==============================] - 0s 31us/step - loss: 1.9072 - acc: 0.6070 - val_loss: 1.4845 - val_acc: 0.3196

Epoch 00003: loss improved from 2.19054 to 1.90721, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9273 - acc: 0.5000
776/776 [==============================] - 0s 31us/step - loss: 1.8197 - acc: 0.6314 - val_loss: 1.6683 - val_acc: 0.2474

Epoch 00004: loss improved from 1.90721 to 1.81966, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 2.4586 - acc: 0.3438
776/776 [==============================] - 0s 31us/step - loss: 1.7795 - acc: 0.6044 - val_loss: 1.5664 - val_acc: 0.3144

Epoch 00005: loss improved from 1.81966 to 1.77950, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0697 - acc: 0.4375
776/776 [==============================] - 0s 31us/step - loss: 1.7414 - acc: 0.6173 - val_loss: 1.6646 - val_acc: 0.2887

Epoch 00006: loss improved from 1.77950 to 1.74142, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 2.8653 - acc: 0.4375
776/776 [==============================] - 0s 31us/step - loss: 1.7265 - acc: 0.6224 - val_loss: 1.4618 - val_acc: 0.3299

Epoch 00007: loss improved from 1.74142 to 1.72649, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 2.8258 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.7040 - acc: 0.6082 - val_loss: 1.9973 - val_acc: 0.2784

Epoch 00008: loss improved from 1.72649 to 1.70399, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 2.4567 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.6694 - acc: 0.5889 - val_loss: 1.8082 - val_acc: 0.2526

Epoch 00009: loss improved from 1.70399 to 1.66944, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.8204 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.6663 - acc: 0.6031 - val_loss: 1.7475 - val_acc: 0.2732

Epoch 00010: loss improved from 1.66944 to 1.66630, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1905 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.7078 - acc: 0.5928 - val_loss: 1.5991 - val_acc: 0.2268

Epoch 00011: loss did not improve from 1.66630
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3814 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.6405 - acc: 0.5941 - val_loss: 1.6253 - val_acc: 0.2320

Epoch 00012: loss improved from 1.66630 to 1.64053, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 2.6561 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.6486 - acc: 0.5915 - val_loss: 2.1170 - val_acc: 0.2268

Epoch 00013: loss did not improve from 1.64053
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 4.3905 - acc: 0.2812
776/776 [==============================] - 0s 30us/step - loss: 1.8203 - acc: 0.6121 - val_loss: 2.1243 - val_acc: 0.2371

Epoch 00014: loss did not improve from 1.64053
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 3.5801 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.6888 - acc: 0.5915 - val_loss: 1.9422 - val_acc: 0.2371

Epoch 00015: loss did not improve from 1.64053
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 3.8250 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.7456 - acc: 0.5799 - val_loss: 1.9646 - val_acc: 0.2320

Epoch 00016: loss did not improve from 1.64053
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 6.1186 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9475 - acc: 0.5683 - val_loss: 4.0511 - val_acc: 0.2423
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:15<00:13,  2.21s/it]
Epoch 00017: loss did not improve from 1.64053
Epoch 00017: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.1363 - acc: 0.7812
776/776 [==============================] - 0s 359us/step - loss: 2.3186 - acc: 0.6598 - val_loss: 2.3351 - val_acc: 0.2577

Epoch 00001: loss improved from inf to 2.31857, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 4.6401 - acc: 0.3125
776/776 [==============================] - 0s 31us/step - loss: 2.1876 - acc: 0.5966 - val_loss: 2.8189 - val_acc: 0.1392

Epoch 00002: loss improved from 2.31857 to 2.18764, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 4.0874 - acc: 0.2812
776/776 [==============================] - 0s 31us/step - loss: 2.0699 - acc: 0.5683 - val_loss: 1.7674 - val_acc: 0.2990

Epoch 00003: loss improved from 2.18764 to 2.06987, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7662 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9214 - acc: 0.5812 - val_loss: 1.5440 - val_acc: 0.3144

Epoch 00004: loss improved from 2.06987 to 1.92140, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0165 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.8158 - acc: 0.5786 - val_loss: 2.3122 - val_acc: 0.2990

Epoch 00005: loss improved from 1.92140 to 1.81578, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7158 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.8727 - acc: 0.5593 - val_loss: 1.7389 - val_acc: 0.2938

Epoch 00006: loss did not improve from 1.81578
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3969 - acc: 0.4062
776/776 [==============================] - 0s 29us/step - loss: 1.7492 - acc: 0.5915 - val_loss: 1.1661 - val_acc: 0.5825

Epoch 00007: loss improved from 1.81578 to 1.74921, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2526 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.7346 - acc: 0.6018 - val_loss: 1.5426 - val_acc: 0.3247

Epoch 00008: loss improved from 1.74921 to 1.73459, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0072 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.6700 - acc: 0.5966 - val_loss: 1.4121 - val_acc: 0.3247

Epoch 00009: loss improved from 1.73459 to 1.67005, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1158 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.6803 - acc: 0.6082 - val_loss: 2.2017 - val_acc: 0.2371

Epoch 00010: loss did not improve from 1.67005
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 4.2789 - acc: 0.3125
776/776 [==============================] - 0s 29us/step - loss: 1.8793 - acc: 0.5709 - val_loss: 1.4713 - val_acc: 0.3196

Epoch 00011: loss did not improve from 1.67005
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7140 - acc: 0.4688
776/776 [==============================] - 0s 29us/step - loss: 1.6123 - acc: 0.6095 - val_loss: 1.3652 - val_acc: 0.3196

Epoch 00012: loss improved from 1.67005 to 1.61226, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 1.8470 - acc: 0.5625
776/776 [==============================] - 0s 30us/step - loss: 1.6236 - acc: 0.6186 - val_loss: 1.8613 - val_acc: 0.2990

Epoch 00013: loss did not improve from 1.61226
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5591 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.6282 - acc: 0.6173 - val_loss: 1.4605 - val_acc: 0.2990

Epoch 00014: loss did not improve from 1.61226
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1435 - acc: 0.4688
776/776 [==============================] - 0s 29us/step - loss: 1.5332 - acc: 0.6379 - val_loss: 1.4092 - val_acc: 0.2990

Epoch 00015: loss improved from 1.61226 to 1.53323, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 1.7291 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.6472 - acc: 0.6250 - val_loss: 1.8947 - val_acc: 0.2320

Epoch 00016: loss did not improve from 1.53323
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 6.2740 - acc: 0.2500
776/776 [==============================] - 0s 30us/step - loss: 2.0700 - acc: 0.5889 - val_loss: 1.0470 - val_acc: 0.4433

Epoch 00017: loss did not improve from 1.53323
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0728 - acc: 0.5938
776/776 [==============================] - 0s 30us/step - loss: 1.6388 - acc: 0.6160 - val_loss: 2.2171 - val_acc: 0.1959

Epoch 00018: loss did not improve from 1.53323
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 5.5384 - acc: 0.3125
776/776 [==============================] - 0s 29us/step - loss: 2.3053 - acc: 0.5399 - val_loss: 2.7825 - val_acc: 0.1907

Epoch 00019: loss did not improve from 1.53323
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 4.3889 - acc: 0.4375
776/776 [==============================] - 0s 29us/step - loss: 2.0904 - acc: 0.5735 - val_loss: 3.4863 - val_acc: 0.1495
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:17<00:10,  2.15s/it]
Epoch 00020: loss did not improve from 1.53323
Epoch 00020: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.3119 - acc: 0.7812
776/776 [==============================] - 0s 366us/step - loss: 2.2261 - acc: 0.6237 - val_loss: 1.9728 - val_acc: 0.2887

Epoch 00001: loss improved from inf to 2.22612, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 3.8577 - acc: 0.3750
776/776 [==============================] - 0s 31us/step - loss: 2.2101 - acc: 0.5825 - val_loss: 2.1404 - val_acc: 0.3196

Epoch 00002: loss improved from 2.22612 to 2.21010, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 3.2010 - acc: 0.4375
776/776 [==============================] - 0s 31us/step - loss: 2.1044 - acc: 0.5619 - val_loss: 2.2695 - val_acc: 0.3402

Epoch 00003: loss improved from 2.21010 to 2.10442, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 3.8935 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 2.0396 - acc: 0.5709 - val_loss: 1.8813 - val_acc: 0.3093

Epoch 00004: loss improved from 2.10442 to 2.03961, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5572 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.8866 - acc: 0.5799 - val_loss: 2.1165 - val_acc: 0.3144

Epoch 00005: loss improved from 2.03961 to 1.88657, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7350 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.8493 - acc: 0.5735 - val_loss: 2.0693 - val_acc: 0.2062

Epoch 00006: loss improved from 1.88657 to 1.84930, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 3.0485 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.8553 - acc: 0.5528 - val_loss: 1.6210 - val_acc: 0.3711

Epoch 00007: loss did not improve from 1.84930
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7845 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.8352 - acc: 0.5747 - val_loss: 2.1198 - val_acc: 0.2938

Epoch 00008: loss improved from 1.84930 to 1.83516, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3178 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.7673 - acc: 0.5812 - val_loss: 1.8349 - val_acc: 0.2990

Epoch 00009: loss improved from 1.83516 to 1.76731, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1802 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.6950 - acc: 0.6134 - val_loss: 2.2100 - val_acc: 0.3041

Epoch 00010: loss improved from 1.76731 to 1.69502, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7624 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.7816 - acc: 0.5683 - val_loss: 1.8103 - val_acc: 0.3299

Epoch 00011: loss did not improve from 1.69502
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 2.9843 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.8184 - acc: 0.5593 - val_loss: 2.9584 - val_acc: 0.2938

Epoch 00012: loss did not improve from 1.69502
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1820 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.7712 - acc: 0.5631 - val_loss: 2.3463 - val_acc: 0.2010

Epoch 00013: loss did not improve from 1.69502
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 4.2957 - acc: 0.3125
776/776 [==============================] - 0s 29us/step - loss: 1.8740 - acc: 0.5851 - val_loss: 2.4569 - val_acc: 0.2680

Epoch 00014: loss did not improve from 1.69502
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 6.0817 - acc: 0.2812
776/776 [==============================] - 0s 29us/step - loss: 2.3468 - acc: 0.5606 - val_loss: 2.3685 - val_acc: 0.1907
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:19<00:08,  2.10s/it]
Epoch 00015: loss did not improve from 1.69502
Epoch 00015: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.8289 - acc: 0.7812
776/776 [==============================] - 0s 359us/step - loss: 2.4925 - acc: 0.6353 - val_loss: 2.7276 - val_acc: 0.2268

Epoch 00001: loss improved from inf to 2.49250, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 4.8463 - acc: 0.2500
776/776 [==============================] - 0s 32us/step - loss: 2.3937 - acc: 0.5464 - val_loss: 2.4530 - val_acc: 0.2938

Epoch 00002: loss improved from 2.49250 to 2.39373, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 4.9851 - acc: 0.3438
776/776 [==============================] - 0s 31us/step - loss: 2.3084 - acc: 0.5515 - val_loss: 1.8818 - val_acc: 0.2938

Epoch 00003: loss improved from 2.39373 to 2.30839, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 2.6229 - acc: 0.3438
776/776 [==============================] - 0s 31us/step - loss: 2.0398 - acc: 0.5258 - val_loss: 1.6482 - val_acc: 0.2938

Epoch 00004: loss improved from 2.30839 to 2.03982, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3748 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.9637 - acc: 0.5554 - val_loss: 1.7118 - val_acc: 0.2938

Epoch 00005: loss improved from 2.03982 to 1.96374, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.8502 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9077 - acc: 0.5747 - val_loss: 1.9223 - val_acc: 0.2938

Epoch 00006: loss improved from 1.96374 to 1.90773, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7901 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9161 - acc: 0.5451 - val_loss: 1.7746 - val_acc: 0.2938

Epoch 00007: loss did not improve from 1.90773
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 2.4983 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.8067 - acc: 0.5670 - val_loss: 1.7293 - val_acc: 0.2990

Epoch 00008: loss improved from 1.90773 to 1.80668, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 2.8232 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.8000 - acc: 0.5580 - val_loss: 1.7147 - val_acc: 0.3402

Epoch 00009: loss improved from 1.80668 to 1.80003, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3884 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.7680 - acc: 0.5747 - val_loss: 1.4692 - val_acc: 0.2680

Epoch 00010: loss improved from 1.80003 to 1.76801, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9504 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.7354 - acc: 0.5747 - val_loss: 1.5619 - val_acc: 0.3093

Epoch 00011: loss improved from 1.76801 to 1.73545, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 1.6921 - acc: 0.5312
776/776 [==============================] - 0s 30us/step - loss: 1.8021 - acc: 0.5593 - val_loss: 1.5997 - val_acc: 0.3299

Epoch 00012: loss did not improve from 1.73545
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1134 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.7374 - acc: 0.5644 - val_loss: 2.2277 - val_acc: 0.1856

Epoch 00013: loss did not improve from 1.73545
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 3.5148 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 1.8352 - acc: 0.5515 - val_loss: 2.9461 - val_acc: 0.2320

Epoch 00014: loss did not improve from 1.73545
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 6.3302 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 2.2219 - acc: 0.5528 - val_loss: 1.8746 - val_acc: 0.3196

Epoch 00015: loss did not improve from 1.73545
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5825 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.7048 - acc: 0.5889 - val_loss: 2.2210 - val_acc: 0.2732

Epoch 00016: loss improved from 1.73545 to 1.70477, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_15.h5
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 5.1618 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9962 - acc: 0.5838 - val_loss: 1.8164 - val_acc: 0.2784

Epoch 00017: loss did not improve from 1.70477
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 3.2738 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.9284 - acc: 0.5786 - val_loss: 3.5695 - val_acc: 0.2062

Epoch 00018: loss did not improve from 1.70477
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 10.2747 - acc: 0.1875
776/776 [==============================] - 0s 30us/step - loss: 3.3219 - acc: 0.5735 - val_loss: 2.3684 - val_acc: 0.3041

Epoch 00019: loss did not improve from 1.70477
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2181 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 2.0096 - acc: 0.5206 - val_loss: 1.8360 - val_acc: 0.2577

Epoch 00020: loss did not improve from 1.70477
Epoch 21/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5975 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.9808 - acc: 0.5851 - val_loss: 1.7445 - val_acc: 0.3402
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:21<00:06,  2.12s/it]
Epoch 00021: loss did not improve from 1.70477
Epoch 00021: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.8379 - acc: 0.7500
776/776 [==============================] - 0s 362us/step - loss: 2.5218 - acc: 0.5928 - val_loss: 2.7356 - val_acc: 0.2474

Epoch 00001: loss improved from inf to 2.52183, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 4.3926 - acc: 0.4062
776/776 [==============================] - 0s 32us/step - loss: 2.3540 - acc: 0.5451 - val_loss: 2.1062 - val_acc: 0.3196

Epoch 00002: loss improved from 2.52183 to 2.35399, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 3.7151 - acc: 0.3750
776/776 [==============================] - 0s 31us/step - loss: 2.2259 - acc: 0.5309 - val_loss: 2.0423 - val_acc: 0.3093

Epoch 00003: loss improved from 2.35399 to 2.22592, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1902 - acc: 0.3750
776/776 [==============================] - 0s 31us/step - loss: 2.1380 - acc: 0.5451 - val_loss: 1.9108 - val_acc: 0.3093

Epoch 00004: loss improved from 2.22592 to 2.13804, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1020 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 2.0083 - acc: 0.5425 - val_loss: 1.9088 - val_acc: 0.3093

Epoch 00005: loss improved from 2.13804 to 2.00825, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.6349 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.9793 - acc: 0.5580 - val_loss: 2.1645 - val_acc: 0.2577

Epoch 00006: loss improved from 2.00825 to 1.97930, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 3.5117 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.9487 - acc: 0.5451 - val_loss: 1.9432 - val_acc: 0.3608

Epoch 00007: loss improved from 1.97930 to 1.94872, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 3.9084 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.9576 - acc: 0.5593 - val_loss: 1.7947 - val_acc: 0.3299

Epoch 00008: loss did not improve from 1.94872
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1326 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.9275 - acc: 0.5464 - val_loss: 1.4730 - val_acc: 0.3402

Epoch 00009: loss improved from 1.94872 to 1.92751, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2264 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.8579 - acc: 0.5735 - val_loss: 2.5048 - val_acc: 0.3144

Epoch 00010: loss improved from 1.92751 to 1.85787, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 4.1376 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.8984 - acc: 0.5296 - val_loss: 1.7778 - val_acc: 0.3402

Epoch 00011: loss did not improve from 1.85787
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 4.0217 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 2.0455 - acc: 0.5631 - val_loss: 2.2069 - val_acc: 0.2113

Epoch 00012: loss did not improve from 1.85787
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 8.0083 - acc: 0.2188
776/776 [==============================] - 0s 30us/step - loss: 2.6232 - acc: 0.5490 - val_loss: 2.1484 - val_acc: 0.1907

Epoch 00013: loss did not improve from 1.85787
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 2.6281 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9355 - acc: 0.5103 - val_loss: 1.8726 - val_acc: 0.2010

Epoch 00014: loss did not improve from 1.85787
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 3.4613 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 2.1065 - acc: 0.5193 - val_loss: 1.3170 - val_acc: 0.3351
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:23<00:04,  2.05s/it]
Epoch 00015: loss did not improve from 1.85787
Epoch 00015: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.9290 - acc: 0.7500
776/776 [==============================] - 0s 363us/step - loss: 2.5970 - acc: 0.6121 - val_loss: 3.5278 - val_acc: 0.1907

Epoch 00001: loss improved from inf to 2.59700, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 7.7520 - acc: 0.2188
776/776 [==============================] - 0s 31us/step - loss: 2.7362 - acc: 0.5541 - val_loss: 2.3672 - val_acc: 0.2990

Epoch 00002: loss did not improve from 2.59700
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 3.7591 - acc: 0.3438
776/776 [==============================] - 0s 31us/step - loss: 2.2397 - acc: 0.4936 - val_loss: 2.2766 - val_acc: 0.2938

Epoch 00003: loss improved from 2.59700 to 2.23974, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 3.4282 - acc: 0.3438
776/776 [==============================] - 0s 31us/step - loss: 2.1642 - acc: 0.4936 - val_loss: 1.9669 - val_acc: 0.2938

Epoch 00004: loss improved from 2.23974 to 2.16422, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5589 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 2.0546 - acc: 0.5155 - val_loss: 2.0207 - val_acc: 0.2938

Epoch 00005: loss improved from 2.16422 to 2.05462, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 2.6567 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9868 - acc: 0.5090 - val_loss: 1.8693 - val_acc: 0.2938

Epoch 00006: loss improved from 2.05462 to 1.98679, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 2.2315 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.9063 - acc: 0.5515 - val_loss: 2.0926 - val_acc: 0.2113

Epoch 00007: loss improved from 1.98679 to 1.90629, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_17.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 4.1161 - acc: 0.2812
776/776 [==============================] - 0s 30us/step - loss: 2.0677 - acc: 0.5451 - val_loss: 3.1113 - val_acc: 0.2423

Epoch 00008: loss did not improve from 1.90629
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 3.4389 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.9434 - acc: 0.5219 - val_loss: 2.2274 - val_acc: 0.2268

Epoch 00009: loss did not improve from 1.90629
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 4.4974 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 2.1501 - acc: 0.5077 - val_loss: 2.0264 - val_acc: 0.2938

Epoch 00010: loss did not improve from 1.90629
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5685 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.8917 - acc: 0.5116 - val_loss: 2.9635 - val_acc: 0.1546

Epoch 00011: loss improved from 1.90629 to 1.89171, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_17.h5
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 5.3481 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 2.3302 - acc: 0.4948 - val_loss: 3.9947 - val_acc: 0.2062

Epoch 00012: loss did not improve from 1.89171
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 5.9026 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 2.3185 - acc: 0.5077 - val_loss: 2.1452 - val_acc: 0.2938

Epoch 00013: loss did not improve from 1.89171
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1430 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.9940 - acc: 0.5644 - val_loss: 2.7092 - val_acc: 0.2784

Epoch 00014: loss did not improve from 1.89171
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 4.7428 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 2.3140 - acc: 0.5142 - val_loss: 1.5628 - val_acc: 0.2938

Epoch 00015: loss did not improve from 1.89171
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 2.0795 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 1.8739 - acc: 0.5619 - val_loss: 1.5898 - val_acc: 0.2990

Epoch 00016: loss improved from 1.89171 to 1.87385, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_17.h5
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3469 - acc: 0.5000
776/776 [==============================] - 0s 30us/step - loss: 1.8756 - acc: 0.5915 - val_loss: 1.8204 - val_acc: 0.2887

Epoch 00017: loss did not improve from 1.87385
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 1.9845 - acc: 0.4375
776/776 [==============================] - 0s 30us/step - loss: 2.0961 - acc: 0.5683 - val_loss: 2.3798 - val_acc: 0.2474

Epoch 00018: loss did not improve from 1.87385
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 6.3397 - acc: 0.2812
776/776 [==============================] - 0s 30us/step - loss: 3.3055 - acc: 0.5374 - val_loss: 3.1069 - val_acc: 0.2371

Epoch 00019: loss did not improve from 1.87385
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 6.7623 - acc: 0.2500
776/776 [==============================] - 0s 30us/step - loss: 2.9592 - acc: 0.4948 - val_loss: 4.0886 - val_acc: 0.2526

Epoch 00020: loss did not improve from 1.87385
Epoch 21/100

 32/776 [>.............................] - ETA: 0s - loss: 14.5199 - acc: 0.1875
776/776 [==============================] - 0s 30us/step - loss: 4.4175 - acc: 0.5477 - val_loss: 7.7635 - val_acc: 0.3299
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:25<00:02,  2.08s/it]
Epoch 00021: loss did not improve from 1.87385
Epoch 00021: early stopping
Train on 776 samples, validate on 194 samples
Epoch 1/100

 32/776 [>.............................] - ETA: 5s - loss: 2.6587 - acc: 0.8125
776/776 [==============================] - 0s 356us/step - loss: 2.6170 - acc: 0.6430 - val_loss: 4.1516 - val_acc: 0.1340

Epoch 00001: loss improved from inf to 2.61699, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/776 [>.............................] - ETA: 0s - loss: 10.0664 - acc: 0.2500
776/776 [==============================] - 0s 31us/step - loss: 2.9967 - acc: 0.5052 - val_loss: 2.8225 - val_acc: 0.3041

Epoch 00002: loss did not improve from 2.61699
Epoch 3/100

 32/776 [>.............................] - ETA: 0s - loss: 3.6813 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 2.3930 - acc: 0.4601 - val_loss: 2.0647 - val_acc: 0.2938

Epoch 00003: loss improved from 2.61699 to 2.39295, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/776 [>.............................] - ETA: 0s - loss: 3.0658 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 2.2150 - acc: 0.4549 - val_loss: 1.8032 - val_acc: 0.2938

Epoch 00004: loss improved from 2.39295 to 2.21499, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/776 [>.............................] - ETA: 0s - loss: 2.1469 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 2.1553 - acc: 0.4858 - val_loss: 1.8688 - val_acc: 0.2938

Epoch 00005: loss improved from 2.21499 to 2.15534, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/776 [>.............................] - ETA: 0s - loss: 3.0181 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 2.0365 - acc: 0.4910 - val_loss: 1.8838 - val_acc: 0.2938

Epoch 00006: loss improved from 2.15534 to 2.03654, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/776 [>.............................] - ETA: 0s - loss: 2.6833 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 2.0004 - acc: 0.5296 - val_loss: 1.8707 - val_acc: 0.2938

Epoch 00007: loss improved from 2.03654 to 2.00038, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7395 - acc: 0.4062
776/776 [==============================] - 0s 30us/step - loss: 1.9949 - acc: 0.5064 - val_loss: 1.5690 - val_acc: 0.2938

Epoch 00008: loss improved from 2.00038 to 1.99495, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/776 [>.............................] - ETA: 0s - loss: 2.7176 - acc: 0.3125
776/776 [==============================] - 0s 30us/step - loss: 1.9786 - acc: 0.4871 - val_loss: 1.5244 - val_acc: 0.3041

Epoch 00009: loss improved from 1.99495 to 1.97862, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3764 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9474 - acc: 0.5064 - val_loss: 1.2411 - val_acc: 0.4381

Epoch 00010: loss improved from 1.97862 to 1.94741, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

 32/776 [>.............................] - ETA: 0s - loss: 2.3624 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.9322 - acc: 0.5219 - val_loss: 2.0157 - val_acc: 0.2990

Epoch 00011: loss improved from 1.94741 to 1.93224, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

 32/776 [>.............................] - ETA: 0s - loss: 3.6154 - acc: 0.3750
776/776 [==============================] - 0s 30us/step - loss: 1.9505 - acc: 0.5052 - val_loss: 2.2462 - val_acc: 0.2784

Epoch 00012: loss did not improve from 1.93224
Epoch 13/100

 32/776 [>.............................] - ETA: 0s - loss: 4.8501 - acc: 0.2188
776/776 [==============================] - 0s 29us/step - loss: 2.2334 - acc: 0.5013 - val_loss: 2.0251 - val_acc: 0.2938

Epoch 00013: loss did not improve from 1.93224
Epoch 14/100

 32/776 [>.............................] - ETA: 0s - loss: 3.1107 - acc: 0.3125
776/776 [==============================] - 0s 29us/step - loss: 1.8697 - acc: 0.5374 - val_loss: 1.7701 - val_acc: 0.3041

Epoch 00014: loss improved from 1.93224 to 1.86972, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 15/100

 32/776 [>.............................] - ETA: 0s - loss: 2.5239 - acc: 0.3438
776/776 [==============================] - 0s 30us/step - loss: 1.8037 - acc: 0.5554 - val_loss: 1.4981 - val_acc: 0.3247

Epoch 00015: loss improved from 1.86972 to 1.80370, saving model to ./results_TA100_with_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

 32/776 [>.............................] - ETA: 0s - loss: 3.0214 - acc: 0.4688
776/776 [==============================] - 0s 30us/step - loss: 1.8399 - acc: 0.5399 - val_loss: 2.3783 - val_acc: 0.2268

Epoch 00016: loss did not improve from 1.80370
Epoch 17/100

 32/776 [>.............................] - ETA: 0s - loss: 5.2023 - acc: 0.4375
776/776 [==============================] - 0s 29us/step - loss: 2.1090 - acc: 0.5271 - val_loss: 2.8162 - val_acc: 0.2216

Epoch 00017: loss did not improve from 1.80370
Epoch 18/100

 32/776 [>.............................] - ETA: 0s - loss: 7.7729 - acc: 0.3750
776/776 [==============================] - 0s 29us/step - loss: 2.4660 - acc: 0.5232 - val_loss: 2.9916 - val_acc: 0.2423

Epoch 00018: loss did not improve from 1.80370
Epoch 19/100

 32/776 [>.............................] - ETA: 0s - loss: 12.3231 - acc: 0.2812
776/776 [==============================] - 0s 29us/step - loss: 3.6812 - acc: 0.5773 - val_loss: 6.4785 - val_acc: 0.3196

Epoch 00019: loss did not improve from 1.80370
Epoch 20/100

 32/776 [>.............................] - ETA: 0s - loss: 6.4526 - acc: 0.3750
776/776 [==============================] - 0s 29us/step - loss: 2.9269 - acc: 0.4716 - val_loss: 3.0543 - val_acc: 0.3454
DeepAmes+ Weights: 100%|██████████| 13/13 [00:28<00:00,  2.09s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:28<00:00,  2.16s/it]

Epoch 00020: loss did not improve from 1.80370
Epoch 00020: early stopping
--- 7052.413728237152 seconds ---

Generating metrics report for TA100_with_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 567 samples.
Processing weight 7...
  Done. 567 samples.
Processing weight 8...
  Done. 567 samples.
Processing weight 9...
  Done. 567 samples.
Processing weight 10...
  Done. 567 samples.
Processing weight 11...
  Done. 567 samples.
Processing weight 12...
  Done. 567 samples.
Processing weight 13...
  Done. 567 samples.
Processing weight 14...
  Done. 567 samples.
Processing weight 15...
  Done. 567 samples.
Processing weight 16...
  Done. 567 samples.
Processing weight 17...
  Done. 567 samples.
Processing weight 18...
  Done. 567 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA100_with_S9/metrics_report_TA100_with_S9.txt

Done!

Completed TA100_with_S9 in 7052.41 seconds

================================================================================
[2/16] Processing: TA100_without_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA100_without_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA100_without_S9_Test_mold2.csv
(5316, 777)
(4252, 777)
(591, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:39<12:37, 39.86s/it]KNN Seeds:  10%|█         | 2/20 [01:18<11:48, 39.38s/it]KNN Seeds:  15%|█▌        | 3/20 [01:57<11:05, 39.16s/it]KNN Seeds:  20%|██        | 4/20 [02:36<10:25, 39.08s/it]KNN Seeds:  25%|██▌       | 5/20 [03:16<09:47, 39.17s/it]KNN Seeds:  30%|███       | 6/20 [03:55<09:07, 39.12s/it]KNN Seeds:  35%|███▌      | 7/20 [04:34<08:29, 39.22s/it]KNN Seeds:  40%|████      | 8/20 [05:13<07:51, 39.27s/it]KNN Seeds:  45%|████▌     | 9/20 [05:53<07:12, 39.29s/it]KNN Seeds:  50%|█████     | 10/20 [06:32<06:32, 39.23s/it]KNN Seeds:  55%|█████▌    | 11/20 [07:12<05:54, 39.39s/it]KNN Seeds:  60%|██████    | 12/20 [07:52<05:16, 39.54s/it]KNN Seeds:  65%|██████▌   | 13/20 [08:31<04:36, 39.50s/it]KNN Seeds:  70%|███████   | 14/20 [09:10<03:56, 39.44s/it]KNN Seeds:  75%|███████▌  | 15/20 [09:49<03:16, 39.37s/it]KNN Seeds:  80%|████████  | 16/20 [10:29<02:37, 39.46s/it]KNN Seeds:  85%|████████▌ | 17/20 [11:09<01:58, 39.49s/it]KNN Seeds:  90%|█████████ | 18/20 [11:48<01:18, 39.50s/it]KNN Seeds:  95%|█████████▌| 19/20 [12:28<00:39, 39.47s/it]KNN Seeds: 100%|██████████| 20/20 [13:07<00:00, 39.51s/it]KNN Seeds: 100%|██████████| 20/20 [13:07<00:00, 39.38s/it]
24
(100, None, 'lbfgs')
(5316, 777)
(4252, 777)
(591, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:03<01:00,  3.20s/it]LR Seeds:  10%|█         | 2/20 [00:06<00:55,  3.11s/it]LR Seeds:  15%|█▌        | 3/20 [00:09<00:51,  3.05s/it]LR Seeds:  20%|██        | 4/20 [00:12<00:48,  3.05s/it]LR Seeds:  25%|██▌       | 5/20 [00:15<00:45,  3.06s/it]LR Seeds:  30%|███       | 6/20 [00:18<00:42,  3.04s/it]LR Seeds:  35%|███▌      | 7/20 [00:21<00:39,  3.04s/it]LR Seeds:  40%|████      | 8/20 [00:24<00:36,  3.06s/it]LR Seeds:  45%|████▌     | 9/20 [00:27<00:33,  3.07s/it]LR Seeds:  50%|█████     | 10/20 [00:30<00:30,  3.06s/it]LR Seeds:  55%|█████▌    | 11/20 [00:33<00:27,  3.07s/it]LR Seeds:  60%|██████    | 12/20 [00:36<00:24,  3.07s/it]LR Seeds:  65%|██████▌   | 13/20 [00:39<00:21,  3.08s/it]LR Seeds:  70%|███████   | 14/20 [00:43<00:18,  3.10s/it]LR Seeds:  75%|███████▌  | 15/20 [00:46<00:15,  3.09s/it]LR Seeds:  80%|████████  | 16/20 [00:49<00:12,  3.10s/it]LR Seeds:  85%|████████▌ | 17/20 [00:52<00:09,  3.12s/it]LR Seeds:  90%|█████████ | 18/20 [00:55<00:06,  3.16s/it]LR Seeds:  95%|█████████▌| 19/20 [00:58<00:03,  3.20s/it]LR Seeds: 100%|██████████| 20/20 [01:02<00:00,  3.24s/it]LR Seeds: 100%|██████████| 20/20 [01:02<00:00,  3.11s/it]
96
('rbf', 1, 1)
(5316, 777)
(4252, 777)
(591, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [04:28<1:25:02, 268.56s/it]SVM Seeds:  10%|█         | 2/20 [08:56<1:20:26, 268.15s/it]SVM Seeds:  15%|█▌        | 3/20 [13:25<1:16:05, 268.54s/it]SVM Seeds:  20%|██        | 4/20 [17:58<1:12:07, 270.47s/it]SVM Seeds:  25%|██▌       | 5/20 [22:32<1:07:56, 271.77s/it]SVM Seeds:  30%|███       | 6/20 [27:06<1:03:31, 272.23s/it]SVM Seeds:  35%|███▌      | 7/20 [31:38<59:01, 272.40s/it]  SVM Seeds:  40%|████      | 8/20 [36:11<54:31, 272.63s/it]SVM Seeds:  45%|████▌     | 9/20 [40:45<50:02, 272.98s/it]SVM Seeds:  50%|█████     | 10/20 [45:18<45:29, 272.96s/it]SVM Seeds:  55%|█████▌    | 11/20 [49:52<40:58, 273.17s/it]SVM Seeds:  60%|██████    | 12/20 [54:26<36:27, 273.43s/it]SVM Seeds:  65%|██████▌   | 13/20 [58:59<31:54, 273.46s/it]SVM Seeds:  70%|███████   | 14/20 [1:03:33<27:20, 273.39s/it]SVM Seeds:  75%|███████▌  | 15/20 [1:08:06<22:47, 273.44s/it]SVM Seeds:  80%|████████  | 16/20 [1:12:40<18:14, 273.52s/it]SVM Seeds:  85%|████████▌ | 17/20 [1:17:12<13:39, 273.10s/it]SVM Seeds:  90%|█████████ | 18/20 [1:21:46<09:06, 273.49s/it]SVM Seeds:  95%|█████████▌| 19/20 [1:26:18<04:32, 272.89s/it]SVM Seeds: 100%|██████████| 20/20 [1:30:51<00:00, 272.98s/it]SVM Seeds: 100%|██████████| 20/20 [1:30:51<00:00, 272.57s/it]
200
(500, None, 70, 1, 'balanced')
(5316, 777)
(4252, 777)
(591, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:19<06:19, 19.97s/it]RF Seeds:  10%|█         | 2/20 [00:39<05:59, 19.96s/it]RF Seeds:  15%|█▌        | 3/20 [00:59<05:39, 19.95s/it]RF Seeds:  20%|██        | 4/20 [01:19<05:18, 19.94s/it]RF Seeds:  25%|██▌       | 5/20 [01:39<04:59, 19.94s/it]RF Seeds:  30%|███       | 6/20 [01:59<04:39, 19.95s/it]RF Seeds:  35%|███▌      | 7/20 [02:19<04:19, 19.96s/it]RF Seeds:  40%|████      | 8/20 [02:39<03:59, 19.98s/it]RF Seeds:  45%|████▌     | 9/20 [02:59<03:39, 19.95s/it]RF Seeds:  50%|█████     | 10/20 [03:19<03:19, 19.96s/it]RF Seeds:  55%|█████▌    | 11/20 [03:39<02:59, 20.00s/it]RF Seeds:  60%|██████    | 12/20 [03:59<02:40, 20.02s/it]RF Seeds:  65%|██████▌   | 13/20 [04:19<02:20, 20.03s/it]RF Seeds:  70%|███████   | 14/20 [04:39<02:00, 20.05s/it]RF Seeds:  75%|███████▌  | 15/20 [05:00<01:40, 20.14s/it]RF Seeds:  80%|████████  | 16/20 [05:20<01:20, 20.15s/it]RF Seeds:  85%|████████▌ | 17/20 [05:40<01:00, 20.12s/it]RF Seeds:  90%|█████████ | 18/20 [06:00<00:40, 20.14s/it]RF Seeds:  95%|█████████▌| 19/20 [06:20<00:20, 20.14s/it]RF Seeds: 100%|██████████| 20/20 [06:40<00:00, 20.13s/it]RF Seeds: 100%|██████████| 20/20 [06:40<00:00, 20.04s/it]
400
(0.01, 900, 7, 0.8, 6)
(5316, 777)
(4252, 777)
(591, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [01:16<24:14, 76.55s/it]XGBoost Seeds:  10%|█         | 2/20 [02:24<21:26, 71.48s/it]XGBoost Seeds:  15%|█▌        | 3/20 [03:32<19:46, 69.82s/it]XGBoost Seeds:  20%|██        | 4/20 [04:40<18:29, 69.32s/it]XGBoost Seeds:  25%|██▌       | 5/20 [05:48<17:13, 68.88s/it]XGBoost Seeds:  30%|███       | 6/20 [06:56<15:59, 68.55s/it]XGBoost Seeds:  35%|███▌      | 7/20 [08:04<14:47, 68.24s/it]XGBoost Seeds:  40%|████      | 8/20 [09:12<13:36, 68.03s/it]XGBoost Seeds:  45%|████▌     | 9/20 [10:19<12:27, 67.98s/it]XGBoost Seeds:  50%|█████     | 10/20 [11:28<11:22, 68.24s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [12:36<10:12, 68.05s/it]XGBoost Seeds:  60%|██████    | 12/20 [13:44<09:04, 68.02s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [14:52<07:55, 67.93s/it]XGBoost Seeds:  70%|███████   | 14/20 [16:00<06:48, 68.05s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [17:08<05:39, 67.92s/it]XGBoost Seeds:  80%|████████  | 16/20 [18:16<04:31, 67.97s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [19:23<03:23, 67.92s/it]XGBoost Seeds:  90%|█████████ | 18/20 [20:31<02:15, 67.87s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [21:40<01:08, 68.17s/it]XGBoost Seeds: 100%|██████████| 20/20 [22:50<00:00, 68.63s/it]XGBoost Seeds: 100%|██████████| 20/20 [22:50<00:00, 68.51s/it]
knn:  96
lr:  81
svm:  100
rf:  98
xgboost:  71
Combining validation predictions is completed
knn:  96
lr:  81
svm:  100
rf:  98
xgboost:  71
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 6s - loss: 1.3776 - acc: 0.6875
851/851 [==============================] - 0s 343us/step - loss: 1.4705 - acc: 0.7861 - val_loss: 1.1801 - val_acc: 0.7887

Epoch 00001: loss improved from inf to 1.47051, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1428 - acc: 0.7812
851/851 [==============================] - 0s 32us/step - loss: 1.3295 - acc: 0.8038 - val_loss: 1.0630 - val_acc: 0.7793

Epoch 00002: loss improved from 1.47051 to 1.32950, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0689 - acc: 0.8438
851/851 [==============================] - 0s 31us/step - loss: 1.2474 - acc: 0.8049 - val_loss: 1.0036 - val_acc: 0.7793

Epoch 00003: loss improved from 1.32950 to 1.24738, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9272 - acc: 0.8438
851/851 [==============================] - 0s 31us/step - loss: 1.1718 - acc: 0.8120 - val_loss: 0.9730 - val_acc: 0.7840

Epoch 00004: loss improved from 1.24738 to 1.17178, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9490 - acc: 0.8125
851/851 [==============================] - 0s 31us/step - loss: 1.1153 - acc: 0.8108 - val_loss: 0.8872 - val_acc: 0.7981

Epoch 00005: loss improved from 1.17178 to 1.11532, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8871 - acc: 0.8125
851/851 [==============================] - 0s 31us/step - loss: 1.0959 - acc: 0.8190 - val_loss: 0.8727 - val_acc: 0.7887

Epoch 00006: loss improved from 1.11532 to 1.09589, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9288 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 1.0466 - acc: 0.8143 - val_loss: 0.7818 - val_acc: 0.8075

Epoch 00007: loss improved from 1.09589 to 1.04656, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7831 - acc: 0.8750
851/851 [==============================] - 0s 31us/step - loss: 1.0004 - acc: 0.8284 - val_loss: 0.7233 - val_acc: 0.8122

Epoch 00008: loss improved from 1.04656 to 1.00043, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7743 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 0.9479 - acc: 0.8308 - val_loss: 0.6875 - val_acc: 0.8075

Epoch 00009: loss improved from 1.00043 to 0.94793, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8460 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.9201 - acc: 0.8308 - val_loss: 0.6431 - val_acc: 0.8122

Epoch 00010: loss improved from 0.94793 to 0.92008, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7335 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.9452 - acc: 0.8273 - val_loss: 0.7161 - val_acc: 0.8122

Epoch 00011: loss did not improve from 0.92008
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7465 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.8911 - acc: 0.8249 - val_loss: 0.6725 - val_acc: 0.8122

Epoch 00012: loss improved from 0.92008 to 0.89108, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6601 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.8739 - acc: 0.8414 - val_loss: 0.6806 - val_acc: 0.8169

Epoch 00013: loss improved from 0.89108 to 0.87387, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6599 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8315 - acc: 0.8508 - val_loss: 0.7545 - val_acc: 0.8216

Epoch 00014: loss improved from 0.87387 to 0.83145, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7500 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.7682 - acc: 0.8613 - val_loss: 0.5898 - val_acc: 0.8169

Epoch 00015: loss improved from 0.83145 to 0.76821, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5598 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.8239 - acc: 0.8414 - val_loss: 0.8113 - val_acc: 0.8357

Epoch 00016: loss did not improve from 0.76821
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6333 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.8044 - acc: 0.8402 - val_loss: 0.7073 - val_acc: 0.8216

Epoch 00017: loss did not improve from 0.76821
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6509 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 0.7925 - acc: 0.8508 - val_loss: 0.6631 - val_acc: 0.8263

Epoch 00018: loss did not improve from 0.76821
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6332 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.7374 - acc: 0.8543 - val_loss: 0.6903 - val_acc: 0.8169

Epoch 00019: loss improved from 0.76821 to 0.73740, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6495 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.7838 - acc: 0.8331 - val_loss: 0.6860 - val_acc: 0.8169

Epoch 00020: loss did not improve from 0.73740
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5715 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.7858 - acc: 0.8320 - val_loss: 0.5800 - val_acc: 0.8169

Epoch 00021: loss did not improve from 0.73740
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6783 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.7106 - acc: 0.8590 - val_loss: 0.5387 - val_acc: 0.8451

Epoch 00022: loss improved from 0.73740 to 0.71059, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_6.h5
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.4960 - acc: 0.9062
851/851 [==============================] - 0s 30us/step - loss: 0.7711 - acc: 0.8461 - val_loss: 0.5631 - val_acc: 0.8263

Epoch 00023: loss did not improve from 0.71059
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5928 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.7815 - acc: 0.8226 - val_loss: 0.5717 - val_acc: 0.8451

Epoch 00024: loss did not improve from 0.71059
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5512 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 0.7201 - acc: 0.8637 - val_loss: 0.6281 - val_acc: 0.8357

Epoch 00025: loss did not improve from 0.71059
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6015 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.8003 - acc: 0.8519 - val_loss: 0.6121 - val_acc: 0.8263

Epoch 00026: loss did not improve from 0.71059
Epoch 27/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7120 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.7405 - acc: 0.8484 - val_loss: 0.5764 - val_acc: 0.8404
DeepAmes+ Weights:   8%|▊         | 1/13 [00:02<00:28,  2.37s/it]
Epoch 00027: loss did not improve from 0.71059
Epoch 00027: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 6s - loss: 1.3531 - acc: 0.7812
851/851 [==============================] - 0s 342us/step - loss: 1.5550 - acc: 0.7756 - val_loss: 1.1446 - val_acc: 0.7793

Epoch 00001: loss improved from inf to 1.55501, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2026 - acc: 0.8125
851/851 [==============================] - 0s 32us/step - loss: 1.3555 - acc: 0.7967 - val_loss: 1.1196 - val_acc: 0.7465

Epoch 00002: loss improved from 1.55501 to 1.35548, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0918 - acc: 0.8125
851/851 [==============================] - 0s 31us/step - loss: 1.3078 - acc: 0.7885 - val_loss: 1.0180 - val_acc: 0.7793

Epoch 00003: loss improved from 1.35548 to 1.30777, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0299 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 1.2333 - acc: 0.8085 - val_loss: 1.0313 - val_acc: 0.7653

Epoch 00004: loss improved from 1.30777 to 1.23330, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0039 - acc: 0.8125
851/851 [==============================] - 0s 31us/step - loss: 1.1747 - acc: 0.7979 - val_loss: 0.9631 - val_acc: 0.7793

Epoch 00005: loss improved from 1.23330 to 1.17468, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9814 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 1.1207 - acc: 0.7967 - val_loss: 0.9027 - val_acc: 0.7606

Epoch 00006: loss improved from 1.17468 to 1.12075, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8637 - acc: 0.8438
851/851 [==============================] - 0s 32us/step - loss: 1.1033 - acc: 0.8049 - val_loss: 0.8476 - val_acc: 0.7512

Epoch 00007: loss improved from 1.12075 to 1.10333, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7778 - acc: 0.8438
851/851 [==============================] - 0s 31us/step - loss: 1.0274 - acc: 0.8096 - val_loss: 0.7725 - val_acc: 0.8028

Epoch 00008: loss improved from 1.10333 to 1.02741, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8446 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 0.9590 - acc: 0.8308 - val_loss: 0.7822 - val_acc: 0.8169

Epoch 00009: loss improved from 1.02741 to 0.95895, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7613 - acc: 0.8750
851/851 [==============================] - 0s 31us/step - loss: 0.9310 - acc: 0.8261 - val_loss: 0.7504 - val_acc: 0.7700

Epoch 00010: loss improved from 0.95895 to 0.93104, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7456 - acc: 0.8125
851/851 [==============================] - 0s 31us/step - loss: 0.9931 - acc: 0.8273 - val_loss: 0.8283 - val_acc: 0.8122

Epoch 00011: loss did not improve from 0.93104
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8879 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9660 - acc: 0.8308 - val_loss: 0.7033 - val_acc: 0.8075

Epoch 00012: loss did not improve from 0.93104
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8911 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9383 - acc: 0.8261 - val_loss: 0.6457 - val_acc: 0.8169

Epoch 00013: loss did not improve from 0.93104
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6304 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9196 - acc: 0.8308 - val_loss: 0.8159 - val_acc: 0.8075

Epoch 00014: loss improved from 0.93104 to 0.91955, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6215 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 0.8753 - acc: 0.8296 - val_loss: 0.6994 - val_acc: 0.8122

Epoch 00015: loss improved from 0.91955 to 0.87526, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5937 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.8789 - acc: 0.8355 - val_loss: 0.7922 - val_acc: 0.8028

Epoch 00016: loss did not improve from 0.87526
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6379 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.8820 - acc: 0.8331 - val_loss: 0.7256 - val_acc: 0.8404

Epoch 00017: loss did not improve from 0.87526
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5743 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 0.8234 - acc: 0.8390 - val_loss: 0.6524 - val_acc: 0.8310

Epoch 00018: loss improved from 0.87526 to 0.82341, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6707 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8642 - acc: 0.8320 - val_loss: 0.6392 - val_acc: 0.8310

Epoch 00019: loss did not improve from 0.82341
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5644 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8607 - acc: 0.8273 - val_loss: 0.5657 - val_acc: 0.8357

Epoch 00020: loss did not improve from 0.82341
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7316 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.8665 - acc: 0.8214 - val_loss: 0.5981 - val_acc: 0.8169

Epoch 00021: loss did not improve from 0.82341
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5417 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 0.8094 - acc: 0.8449 - val_loss: 0.6241 - val_acc: 0.8357

Epoch 00022: loss improved from 0.82341 to 0.80936, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5034 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.8031 - acc: 0.8414 - val_loss: 0.7284 - val_acc: 0.8357

Epoch 00023: loss improved from 0.80936 to 0.80306, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6638 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.7923 - acc: 0.8425 - val_loss: 0.5864 - val_acc: 0.8357

Epoch 00024: loss improved from 0.80306 to 0.79234, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5068 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 0.7525 - acc: 0.8519 - val_loss: 0.6380 - val_acc: 0.8310

Epoch 00025: loss improved from 0.79234 to 0.75253, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7310 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.7164 - acc: 0.8543 - val_loss: 0.6853 - val_acc: 0.8122

Epoch 00026: loss improved from 0.75253 to 0.71642, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_7.h5
Epoch 27/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6631 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8205 - acc: 0.8249 - val_loss: 0.7215 - val_acc: 0.8357

Epoch 00027: loss did not improve from 0.71642
Epoch 28/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6216 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.8919 - acc: 0.8284 - val_loss: 0.6190 - val_acc: 0.8122

Epoch 00028: loss did not improve from 0.71642
Epoch 29/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7539 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.8034 - acc: 0.8496 - val_loss: 0.6427 - val_acc: 0.8357

Epoch 00029: loss did not improve from 0.71642
Epoch 30/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5469 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8598 - acc: 0.8226 - val_loss: 0.6999 - val_acc: 0.8216

Epoch 00030: loss did not improve from 0.71642
Epoch 31/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5594 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.7699 - acc: 0.8355 - val_loss: 0.6438 - val_acc: 0.8404
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:04<00:27,  2.50s/it]
Epoch 00031: loss did not improve from 0.71642
Epoch 00031: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 1.8279 - acc: 0.7188
851/851 [==============================] - 0s 329us/step - loss: 1.6403 - acc: 0.7685 - val_loss: 1.2280 - val_acc: 0.7700

Epoch 00001: loss improved from inf to 1.64025, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2811 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 1.4063 - acc: 0.7779 - val_loss: 1.1171 - val_acc: 0.7793

Epoch 00002: loss improved from 1.64025 to 1.40628, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1538 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.3432 - acc: 0.7991 - val_loss: 1.1281 - val_acc: 0.7840

Epoch 00003: loss improved from 1.40628 to 1.34322, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1413 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.3207 - acc: 0.7767 - val_loss: 1.0473 - val_acc: 0.7371

Epoch 00004: loss improved from 1.34322 to 1.32066, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9270 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 1.2387 - acc: 0.8049 - val_loss: 0.9133 - val_acc: 0.7934

Epoch 00005: loss improved from 1.32066 to 1.23867, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0092 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1860 - acc: 0.8038 - val_loss: 0.9081 - val_acc: 0.7887

Epoch 00006: loss improved from 1.23867 to 1.18603, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9444 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1269 - acc: 0.8108 - val_loss: 0.9172 - val_acc: 0.7418

Epoch 00007: loss improved from 1.18603 to 1.12690, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8805 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0922 - acc: 0.8073 - val_loss: 0.8713 - val_acc: 0.7512

Epoch 00008: loss improved from 1.12690 to 1.09217, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8751 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.0567 - acc: 0.8179 - val_loss: 0.8153 - val_acc: 0.7418

Epoch 00009: loss improved from 1.09217 to 1.05670, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8743 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.0160 - acc: 0.8155 - val_loss: 0.8230 - val_acc: 0.7653

Epoch 00010: loss improved from 1.05670 to 1.01597, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8462 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9680 - acc: 0.8155 - val_loss: 0.7995 - val_acc: 0.7793

Epoch 00011: loss improved from 1.01597 to 0.96799, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7839 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9482 - acc: 0.8237 - val_loss: 0.7614 - val_acc: 0.8169

Epoch 00012: loss improved from 0.96799 to 0.94823, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8362 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9947 - acc: 0.8038 - val_loss: 0.7039 - val_acc: 0.8122

Epoch 00013: loss did not improve from 0.94823
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7773 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9340 - acc: 0.8343 - val_loss: 0.6281 - val_acc: 0.8169

Epoch 00014: loss improved from 0.94823 to 0.93395, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7322 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.9090 - acc: 0.8425 - val_loss: 0.7252 - val_acc: 0.8075

Epoch 00015: loss improved from 0.93395 to 0.90898, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8223 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9227 - acc: 0.8167 - val_loss: 0.6587 - val_acc: 0.8169

Epoch 00016: loss did not improve from 0.90898
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6367 - acc: 0.8438
851/851 [==============================] - 0s 29us/step - loss: 0.9033 - acc: 0.8226 - val_loss: 0.6734 - val_acc: 0.8075

Epoch 00017: loss improved from 0.90898 to 0.90328, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7171 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8638 - acc: 0.8308 - val_loss: 0.7939 - val_acc: 0.8122

Epoch 00018: loss improved from 0.90328 to 0.86384, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8601 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 0.8983 - acc: 0.8202 - val_loss: 0.6669 - val_acc: 0.8263

Epoch 00019: loss did not improve from 0.86384
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7533 - acc: 0.8750
851/851 [==============================] - 0s 29us/step - loss: 0.9143 - acc: 0.8167 - val_loss: 0.7043 - val_acc: 0.8169

Epoch 00020: loss did not improve from 0.86384
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6475 - acc: 0.7812
851/851 [==============================] - 0s 29us/step - loss: 0.9222 - acc: 0.8155 - val_loss: 0.6894 - val_acc: 0.7934

Epoch 00021: loss did not improve from 0.86384
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7695 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9067 - acc: 0.8108 - val_loss: 0.6261 - val_acc: 0.7934

Epoch 00022: loss did not improve from 0.86384
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6353 - acc: 0.8438
851/851 [==============================] - 0s 29us/step - loss: 0.8310 - acc: 0.8296 - val_loss: 0.6440 - val_acc: 0.8263

Epoch 00023: loss improved from 0.86384 to 0.83097, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6498 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8457 - acc: 0.8190 - val_loss: 0.6515 - val_acc: 0.8263

Epoch 00024: loss did not improve from 0.83097
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8353 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.8418 - acc: 0.8320 - val_loss: 0.5940 - val_acc: 0.8122

Epoch 00025: loss did not improve from 0.83097
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6989 - acc: 0.8125
851/851 [==============================] - 0s 29us/step - loss: 0.8358 - acc: 0.8249 - val_loss: 0.6094 - val_acc: 0.8310

Epoch 00026: loss did not improve from 0.83097
Epoch 27/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6999 - acc: 0.8750
851/851 [==============================] - 0s 29us/step - loss: 0.7847 - acc: 0.8578 - val_loss: 0.8012 - val_acc: 0.8028

Epoch 00027: loss improved from 0.83097 to 0.78470, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 28/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5254 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.7665 - acc: 0.8425 - val_loss: 0.6532 - val_acc: 0.8075

Epoch 00028: loss improved from 0.78470 to 0.76654, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_8.h5
Epoch 29/100

 32/851 [>.............................] - ETA: 0s - loss: 0.5829 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 0.8519 - acc: 0.8378 - val_loss: 0.6308 - val_acc: 0.8075

Epoch 00029: loss did not improve from 0.76654
Epoch 30/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6516 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.8227 - acc: 0.8449 - val_loss: 0.6782 - val_acc: 0.8310

Epoch 00030: loss did not improve from 0.76654
Epoch 31/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8240 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.8472 - acc: 0.8214 - val_loss: 0.6525 - val_acc: 0.8216

Epoch 00031: loss did not improve from 0.76654
Epoch 32/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8522 - acc: 0.7812
851/851 [==============================] - 0s 29us/step - loss: 0.8712 - acc: 0.8214 - val_loss: 0.6690 - val_acc: 0.8028

Epoch 00032: loss did not improve from 0.76654
Epoch 33/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7116 - acc: 0.8125
851/851 [==============================] - 0s 29us/step - loss: 0.8329 - acc: 0.8261 - val_loss: 0.7728 - val_acc: 0.8122
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:07<00:25,  2.55s/it]
Epoch 00033: loss did not improve from 0.76654
Epoch 00033: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 1.4468 - acc: 0.7500
851/851 [==============================] - 0s 338us/step - loss: 1.5798 - acc: 0.7685 - val_loss: 1.2099 - val_acc: 0.7746

Epoch 00001: loss improved from inf to 1.57977, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.3563 - acc: 0.7500
851/851 [==============================] - 0s 32us/step - loss: 1.4754 - acc: 0.7626 - val_loss: 1.1169 - val_acc: 0.7793

Epoch 00002: loss improved from 1.57977 to 1.47544, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0845 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 1.3659 - acc: 0.7756 - val_loss: 1.0923 - val_acc: 0.7512

Epoch 00003: loss improved from 1.47544 to 1.36589, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1287 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.3069 - acc: 0.7744 - val_loss: 1.0393 - val_acc: 0.7465

Epoch 00004: loss improved from 1.36589 to 1.30689, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9939 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.2536 - acc: 0.7861 - val_loss: 0.9878 - val_acc: 0.7559

Epoch 00005: loss improved from 1.30689 to 1.25363, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9231 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1765 - acc: 0.7908 - val_loss: 0.9524 - val_acc: 0.7512

Epoch 00006: loss improved from 1.25363 to 1.17648, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0027 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.1523 - acc: 0.8108 - val_loss: 0.9697 - val_acc: 0.7277

Epoch 00007: loss improved from 1.17648 to 1.15231, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8300 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.1257 - acc: 0.8002 - val_loss: 0.8594 - val_acc: 0.7793

Epoch 00008: loss improved from 1.15231 to 1.12572, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8670 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0874 - acc: 0.7955 - val_loss: 0.8499 - val_acc: 0.7465

Epoch 00009: loss improved from 1.12572 to 1.08738, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8823 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0010 - acc: 0.8155 - val_loss: 0.7929 - val_acc: 0.7934

Epoch 00010: loss improved from 1.08738 to 1.00097, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9208 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0515 - acc: 0.7979 - val_loss: 0.8795 - val_acc: 0.7840

Epoch 00011: loss did not improve from 1.00097
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7413 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0006 - acc: 0.8155 - val_loss: 0.8296 - val_acc: 0.7793

Epoch 00012: loss improved from 1.00097 to 1.00057, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8340 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9803 - acc: 0.8190 - val_loss: 0.8151 - val_acc: 0.8122

Epoch 00013: loss improved from 1.00057 to 0.98029, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7435 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0480 - acc: 0.8073 - val_loss: 0.7478 - val_acc: 0.7981

Epoch 00014: loss did not improve from 0.98029
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8510 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0256 - acc: 0.7967 - val_loss: 0.7946 - val_acc: 0.7840

Epoch 00015: loss did not improve from 0.98029
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7696 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9641 - acc: 0.8167 - val_loss: 0.6654 - val_acc: 0.7793

Epoch 00016: loss improved from 0.98029 to 0.96410, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8554 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9552 - acc: 0.8237 - val_loss: 0.6818 - val_acc: 0.8263

Epoch 00017: loss improved from 0.96410 to 0.95518, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6657 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9388 - acc: 0.8190 - val_loss: 0.7226 - val_acc: 0.8122

Epoch 00018: loss improved from 0.95518 to 0.93877, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7347 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9634 - acc: 0.8002 - val_loss: 0.6920 - val_acc: 0.7981

Epoch 00019: loss did not improve from 0.93877
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6966 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9217 - acc: 0.7991 - val_loss: 0.6477 - val_acc: 0.7934

Epoch 00020: loss improved from 0.93877 to 0.92168, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7809 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8765 - acc: 0.8226 - val_loss: 0.7423 - val_acc: 0.7934

Epoch 00021: loss improved from 0.92168 to 0.87647, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_9.h5
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6218 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.8821 - acc: 0.8273 - val_loss: 0.6259 - val_acc: 0.7887

Epoch 00022: loss did not improve from 0.87647
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9018 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 0.8962 - acc: 0.8284 - val_loss: 0.6343 - val_acc: 0.8169

Epoch 00023: loss did not improve from 0.87647
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7834 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9132 - acc: 0.8202 - val_loss: 0.6620 - val_acc: 0.8310

Epoch 00024: loss did not improve from 0.87647
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6674 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9248 - acc: 0.8355 - val_loss: 0.6259 - val_acc: 0.8169

Epoch 00025: loss did not improve from 0.87647
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6534 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.9359 - acc: 0.8202 - val_loss: 0.6927 - val_acc: 0.7746
DeepAmes+ Weights:  31%|███       | 4/13 [00:09<00:22,  2.46s/it]
Epoch 00026: loss did not improve from 0.87647
Epoch 00026: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 1.3143 - acc: 0.7500
851/851 [==============================] - 0s 339us/step - loss: 1.6194 - acc: 0.7532 - val_loss: 1.2536 - val_acc: 0.7418

Epoch 00001: loss improved from inf to 1.61935, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2536 - acc: 0.7188
851/851 [==============================] - 0s 32us/step - loss: 1.4814 - acc: 0.7615 - val_loss: 1.1401 - val_acc: 0.7559

Epoch 00002: loss improved from 1.61935 to 1.48137, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2917 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.4181 - acc: 0.7744 - val_loss: 1.0961 - val_acc: 0.7793

Epoch 00003: loss improved from 1.48137 to 1.41807, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0388 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 1.3799 - acc: 0.7732 - val_loss: 1.0338 - val_acc: 0.7606

Epoch 00004: loss improved from 1.41807 to 1.37994, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0325 - acc: 0.8438
851/851 [==============================] - 0s 31us/step - loss: 1.3124 - acc: 0.7732 - val_loss: 0.9654 - val_acc: 0.7606

Epoch 00005: loss improved from 1.37994 to 1.31237, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9322 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.2317 - acc: 0.7873 - val_loss: 0.9759 - val_acc: 0.7371

Epoch 00006: loss improved from 1.31237 to 1.23175, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9743 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1897 - acc: 0.7814 - val_loss: 0.9149 - val_acc: 0.7512

Epoch 00007: loss improved from 1.23175 to 1.18969, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8741 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1111 - acc: 0.7967 - val_loss: 0.9160 - val_acc: 0.7746

Epoch 00008: loss improved from 1.18969 to 1.11112, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8375 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.1577 - acc: 0.7908 - val_loss: 0.7984 - val_acc: 0.7934

Epoch 00009: loss did not improve from 1.11112
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9072 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1197 - acc: 0.7897 - val_loss: 0.8148 - val_acc: 0.7793

Epoch 00010: loss did not improve from 1.11112
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8986 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0672 - acc: 0.7967 - val_loss: 0.7881 - val_acc: 0.7840

Epoch 00011: loss improved from 1.11112 to 1.06719, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7832 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0141 - acc: 0.8143 - val_loss: 0.8294 - val_acc: 0.7746

Epoch 00012: loss improved from 1.06719 to 1.01410, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9689 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0610 - acc: 0.8061 - val_loss: 0.8971 - val_acc: 0.8075

Epoch 00013: loss did not improve from 1.01410
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9326 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0707 - acc: 0.7908 - val_loss: 0.8957 - val_acc: 0.8122

Epoch 00014: loss did not improve from 1.01410
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9174 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0470 - acc: 0.7991 - val_loss: 0.6944 - val_acc: 0.7981

Epoch 00015: loss did not improve from 1.01410
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8018 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 0.9829 - acc: 0.8179 - val_loss: 0.6428 - val_acc: 0.8169

Epoch 00016: loss improved from 1.01410 to 0.98286, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7864 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.0162 - acc: 0.8014 - val_loss: 0.7705 - val_acc: 0.7840

Epoch 00017: loss did not improve from 0.98286
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8312 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0332 - acc: 0.7991 - val_loss: 0.7655 - val_acc: 0.7887

Epoch 00018: loss did not improve from 0.98286
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6815 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9847 - acc: 0.8143 - val_loss: 0.7896 - val_acc: 0.7606

Epoch 00019: loss did not improve from 0.98286
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6435 - acc: 0.8750
851/851 [==============================] - 0s 30us/step - loss: 0.9258 - acc: 0.8190 - val_loss: 0.9026 - val_acc: 0.7606

Epoch 00020: loss improved from 0.98286 to 0.92576, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6493 - acc: 0.8438
851/851 [==============================] - 0s 31us/step - loss: 0.8885 - acc: 0.8284 - val_loss: 0.6878 - val_acc: 0.7887

Epoch 00021: loss improved from 0.92576 to 0.88853, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_10.h5
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7897 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9402 - acc: 0.8096 - val_loss: 0.6510 - val_acc: 0.7934

Epoch 00022: loss did not improve from 0.88853
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7688 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 0.9604 - acc: 0.8202 - val_loss: 0.9063 - val_acc: 0.8075

Epoch 00023: loss did not improve from 0.88853
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9421 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0454 - acc: 0.7967 - val_loss: 0.7613 - val_acc: 0.8075

Epoch 00024: loss did not improve from 0.88853
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8021 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 0.9570 - acc: 0.8226 - val_loss: 0.7575 - val_acc: 0.8028

Epoch 00025: loss did not improve from 0.88853
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6360 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9909 - acc: 0.8108 - val_loss: 0.7552 - val_acc: 0.7981
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:12<00:19,  2.45s/it]
Epoch 00026: loss did not improve from 0.88853
Epoch 00026: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 1.4603 - acc: 0.7812
851/851 [==============================] - 0s 329us/step - loss: 1.7444 - acc: 0.7544 - val_loss: 1.2916 - val_acc: 0.7230

Epoch 00001: loss improved from inf to 1.74441, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2715 - acc: 0.7188
851/851 [==============================] - 0s 32us/step - loss: 1.5393 - acc: 0.7450 - val_loss: 1.1958 - val_acc: 0.7089

Epoch 00002: loss improved from 1.74441 to 1.53925, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2948 - acc: 0.8125
851/851 [==============================] - 0s 31us/step - loss: 1.4644 - acc: 0.7591 - val_loss: 1.1302 - val_acc: 0.7230

Epoch 00003: loss improved from 1.53925 to 1.46436, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1184 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.3832 - acc: 0.7650 - val_loss: 1.1217 - val_acc: 0.6995

Epoch 00004: loss improved from 1.46436 to 1.38318, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1335 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.3176 - acc: 0.7720 - val_loss: 1.0731 - val_acc: 0.7136

Epoch 00005: loss improved from 1.38318 to 1.31763, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1041 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2653 - acc: 0.7638 - val_loss: 1.0024 - val_acc: 0.7183

Epoch 00006: loss improved from 1.31763 to 1.26533, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9480 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2078 - acc: 0.7756 - val_loss: 0.9720 - val_acc: 0.7418

Epoch 00007: loss improved from 1.26533 to 1.20777, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9309 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1432 - acc: 0.7991 - val_loss: 0.9142 - val_acc: 0.7559

Epoch 00008: loss improved from 1.20777 to 1.14315, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8330 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1512 - acc: 0.7850 - val_loss: 0.8052 - val_acc: 0.8028

Epoch 00009: loss did not improve from 1.14315
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8525 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1085 - acc: 0.7920 - val_loss: 0.8546 - val_acc: 0.7887

Epoch 00010: loss improved from 1.14315 to 1.10845, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9042 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1341 - acc: 0.8002 - val_loss: 0.9514 - val_acc: 0.7981

Epoch 00011: loss did not improve from 1.10845
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1771 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0643 - acc: 0.7967 - val_loss: 0.7660 - val_acc: 0.7887

Epoch 00012: loss improved from 1.10845 to 1.06429, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8200 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0537 - acc: 0.8049 - val_loss: 0.8141 - val_acc: 0.7934

Epoch 00013: loss improved from 1.06429 to 1.05370, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8285 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9948 - acc: 0.8096 - val_loss: 0.8462 - val_acc: 0.7653

Epoch 00014: loss improved from 1.05370 to 0.99480, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7270 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0515 - acc: 0.8026 - val_loss: 0.8337 - val_acc: 0.8028

Epoch 00015: loss did not improve from 0.99480
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9045 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0369 - acc: 0.7850 - val_loss: 0.8003 - val_acc: 0.7934

Epoch 00016: loss did not improve from 0.99480
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7174 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9793 - acc: 0.8049 - val_loss: 0.7989 - val_acc: 0.7700

Epoch 00017: loss improved from 0.99480 to 0.97931, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7469 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9784 - acc: 0.8132 - val_loss: 0.7788 - val_acc: 0.7653

Epoch 00018: loss improved from 0.97931 to 0.97845, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_11.h5
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7997 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0354 - acc: 0.8108 - val_loss: 0.7472 - val_acc: 0.7981

Epoch 00019: loss did not improve from 0.97845
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7809 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.0562 - acc: 0.8132 - val_loss: 0.7769 - val_acc: 0.7746

Epoch 00020: loss did not improve from 0.97845
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8109 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 0.9893 - acc: 0.8049 - val_loss: 0.7461 - val_acc: 0.7559

Epoch 00021: loss did not improve from 0.97845
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7742 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.0291 - acc: 0.7932 - val_loss: 0.7279 - val_acc: 0.8122

Epoch 00022: loss did not improve from 0.97845
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8938 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0187 - acc: 0.8061 - val_loss: 0.7584 - val_acc: 0.8028
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:14<00:16,  2.40s/it]
Epoch 00023: loss did not improve from 0.97845
Epoch 00023: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 1.8160 - acc: 0.7188
851/851 [==============================] - 0s 330us/step - loss: 1.8145 - acc: 0.7532 - val_loss: 1.3326 - val_acc: 0.7277

Epoch 00001: loss improved from inf to 1.81453, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4165 - acc: 0.7188
851/851 [==============================] - 0s 32us/step - loss: 1.6435 - acc: 0.7462 - val_loss: 1.2747 - val_acc: 0.7559

Epoch 00002: loss improved from 1.81453 to 1.64346, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.3079 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.5336 - acc: 0.7603 - val_loss: 1.1942 - val_acc: 0.7230

Epoch 00003: loss improved from 1.64346 to 1.53356, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2407 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.4947 - acc: 0.7556 - val_loss: 1.1340 - val_acc: 0.7277

Epoch 00004: loss improved from 1.53356 to 1.49466, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1880 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.4178 - acc: 0.7497 - val_loss: 1.1365 - val_acc: 0.7230

Epoch 00005: loss improved from 1.49466 to 1.41777, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1386 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.3652 - acc: 0.7638 - val_loss: 1.0753 - val_acc: 0.7089

Epoch 00006: loss improved from 1.41777 to 1.36524, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1043 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.3111 - acc: 0.7685 - val_loss: 0.9952 - val_acc: 0.7183

Epoch 00007: loss improved from 1.36524 to 1.31112, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0567 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2375 - acc: 0.7720 - val_loss: 0.9962 - val_acc: 0.7418

Epoch 00008: loss improved from 1.31112 to 1.23746, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0121 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2575 - acc: 0.7673 - val_loss: 0.9662 - val_acc: 0.7324

Epoch 00009: loss did not improve from 1.23746
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9278 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.2370 - acc: 0.7650 - val_loss: 0.8819 - val_acc: 0.7418

Epoch 00010: loss improved from 1.23746 to 1.23703, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0094 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.1626 - acc: 0.7861 - val_loss: 0.8925 - val_acc: 0.7465

Epoch 00011: loss improved from 1.23703 to 1.16256, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9222 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1300 - acc: 0.7885 - val_loss: 0.9103 - val_acc: 0.7136

Epoch 00012: loss improved from 1.16256 to 1.13003, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7613 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1356 - acc: 0.7767 - val_loss: 0.8560 - val_acc: 0.7418

Epoch 00013: loss did not improve from 1.13003
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6881 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1261 - acc: 0.7873 - val_loss: 0.8782 - val_acc: 0.7465

Epoch 00014: loss improved from 1.13003 to 1.12606, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8187 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1023 - acc: 0.7709 - val_loss: 0.7099 - val_acc: 0.7981

Epoch 00015: loss improved from 1.12606 to 1.10229, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8689 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1462 - acc: 0.7767 - val_loss: 0.7866 - val_acc: 0.7653

Epoch 00016: loss did not improve from 1.10229
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7935 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1000 - acc: 0.7756 - val_loss: 0.8073 - val_acc: 0.7653

Epoch 00017: loss improved from 1.10229 to 1.09999, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8313 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0692 - acc: 0.7838 - val_loss: 0.8201 - val_acc: 0.7371

Epoch 00018: loss improved from 1.09999 to 1.06916, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8619 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0041 - acc: 0.8085 - val_loss: 0.7700 - val_acc: 0.7840

Epoch 00019: loss improved from 1.06916 to 1.00411, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7618 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1247 - acc: 0.8038 - val_loss: 0.7216 - val_acc: 0.7887

Epoch 00020: loss did not improve from 1.00411
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7763 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0918 - acc: 0.7873 - val_loss: 0.7257 - val_acc: 0.7793

Epoch 00021: loss did not improve from 1.00411
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8175 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1278 - acc: 0.7920 - val_loss: 0.8491 - val_acc: 0.7465

Epoch 00022: loss did not improve from 1.00411
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7621 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0407 - acc: 0.7850 - val_loss: 0.7852 - val_acc: 0.7606

Epoch 00023: loss did not improve from 1.00411
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8335 - acc: 0.6875
851/851 [==============================] - 0s 30us/step - loss: 0.9923 - acc: 0.8155 - val_loss: 0.9995 - val_acc: 0.8028

Epoch 00024: loss improved from 1.00411 to 0.99233, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0460 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0644 - acc: 0.7908 - val_loss: 0.6869 - val_acc: 0.7793

Epoch 00025: loss did not improve from 0.99233
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7041 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.0232 - acc: 0.7967 - val_loss: 0.7222 - val_acc: 0.7887

Epoch 00026: loss did not improve from 0.99233
Epoch 27/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7164 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9522 - acc: 0.8026 - val_loss: 0.6546 - val_acc: 0.7934

Epoch 00027: loss improved from 0.99233 to 0.95220, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 28/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8243 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0041 - acc: 0.7920 - val_loss: 0.7543 - val_acc: 0.7559

Epoch 00028: loss did not improve from 0.95220
Epoch 29/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6726 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 0.9252 - acc: 0.8002 - val_loss: 0.7129 - val_acc: 0.7746

Epoch 00029: loss improved from 0.95220 to 0.92523, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 30/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8211 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8745 - acc: 0.8143 - val_loss: 0.6349 - val_acc: 0.8028

Epoch 00030: loss improved from 0.92523 to 0.87445, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_12.h5
Epoch 31/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7033 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.8914 - acc: 0.8249 - val_loss: 0.7408 - val_acc: 0.7934

Epoch 00031: loss did not improve from 0.87445
Epoch 32/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7674 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0513 - acc: 0.7979 - val_loss: 0.8183 - val_acc: 0.7887

Epoch 00032: loss did not improve from 0.87445
Epoch 33/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6971 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0402 - acc: 0.8132 - val_loss: 0.7578 - val_acc: 0.7793

Epoch 00033: loss did not improve from 0.87445
Epoch 34/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7508 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0308 - acc: 0.8002 - val_loss: 0.8091 - val_acc: 0.7559

Epoch 00034: loss did not improve from 0.87445
Epoch 35/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7341 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0066 - acc: 0.8061 - val_loss: 0.7134 - val_acc: 0.7981
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:17<00:14,  2.46s/it]
Epoch 00035: loss did not improve from 0.87445
Epoch 00035: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 2.1420 - acc: 0.7500
851/851 [==============================] - 0s 337us/step - loss: 1.9160 - acc: 0.7521 - val_loss: 1.3760 - val_acc: 0.7230

Epoch 00001: loss improved from inf to 1.91598, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4743 - acc: 0.7188
851/851 [==============================] - 0s 32us/step - loss: 1.7600 - acc: 0.7427 - val_loss: 1.4132 - val_acc: 0.7230

Epoch 00002: loss improved from 1.91598 to 1.75996, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4692 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.6151 - acc: 0.7380 - val_loss: 1.2726 - val_acc: 0.7089

Epoch 00003: loss improved from 1.75996 to 1.61508, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.3046 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.5519 - acc: 0.7568 - val_loss: 1.2018 - val_acc: 0.7183

Epoch 00004: loss improved from 1.61508 to 1.55192, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2519 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.4934 - acc: 0.7603 - val_loss: 1.1536 - val_acc: 0.7277

Epoch 00005: loss improved from 1.55192 to 1.49338, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1417 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.4320 - acc: 0.7485 - val_loss: 1.0762 - val_acc: 0.7136

Epoch 00006: loss improved from 1.49338 to 1.43201, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1039 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 1.4112 - acc: 0.7650 - val_loss: 1.0871 - val_acc: 0.7418

Epoch 00007: loss improved from 1.43201 to 1.41117, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1465 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.3301 - acc: 0.7615 - val_loss: 1.0042 - val_acc: 0.7559

Epoch 00008: loss improved from 1.41117 to 1.33010, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0107 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.3499 - acc: 0.7591 - val_loss: 0.9072 - val_acc: 0.7559

Epoch 00009: loss did not improve from 1.33010
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0931 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.3116 - acc: 0.7579 - val_loss: 0.9822 - val_acc: 0.7230

Epoch 00010: loss improved from 1.33010 to 1.31156, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9581 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1979 - acc: 0.7732 - val_loss: 0.9519 - val_acc: 0.7324

Epoch 00011: loss improved from 1.31156 to 1.19794, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1077 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.1532 - acc: 0.7850 - val_loss: 0.9607 - val_acc: 0.7887

Epoch 00012: loss improved from 1.19794 to 1.15315, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9632 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1629 - acc: 0.7838 - val_loss: 1.0124 - val_acc: 0.7371

Epoch 00013: loss did not improve from 1.15315
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8723 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1971 - acc: 0.7697 - val_loss: 0.8657 - val_acc: 0.7700

Epoch 00014: loss did not improve from 1.15315
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8326 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1201 - acc: 0.7861 - val_loss: 0.8971 - val_acc: 0.7136

Epoch 00015: loss improved from 1.15315 to 1.12012, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8172 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1916 - acc: 0.7920 - val_loss: 0.9042 - val_acc: 0.7606

Epoch 00016: loss did not improve from 1.12012
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0904 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1373 - acc: 0.7662 - val_loss: 0.7948 - val_acc: 0.7700

Epoch 00017: loss did not improve from 1.12012
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8550 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1230 - acc: 0.7744 - val_loss: 0.7306 - val_acc: 0.7887

Epoch 00018: loss did not improve from 1.12012
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8337 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0998 - acc: 0.7885 - val_loss: 0.7575 - val_acc: 0.7746

Epoch 00019: loss improved from 1.12012 to 1.09975, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8026 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0737 - acc: 0.7991 - val_loss: 0.8095 - val_acc: 0.7746

Epoch 00020: loss improved from 1.09975 to 1.07367, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7496 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.0101 - acc: 0.7979 - val_loss: 0.7291 - val_acc: 0.7746

Epoch 00021: loss improved from 1.07367 to 1.01014, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.6845 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0124 - acc: 0.8096 - val_loss: 0.8338 - val_acc: 0.7512

Epoch 00022: loss did not improve from 1.01014
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9619 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0952 - acc: 0.7967 - val_loss: 0.8451 - val_acc: 0.7277

Epoch 00023: loss did not improve from 1.01014
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0582 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9673 - acc: 0.8132 - val_loss: 0.7027 - val_acc: 0.7746

Epoch 00024: loss improved from 1.01014 to 0.96726, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_13.h5
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7637 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9966 - acc: 0.8155 - val_loss: 0.8759 - val_acc: 0.7934

Epoch 00025: loss did not improve from 0.96726
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8678 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 0.9983 - acc: 0.8120 - val_loss: 0.9285 - val_acc: 0.8075

Epoch 00026: loss did not improve from 0.96726
Epoch 27/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8009 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.0238 - acc: 0.8132 - val_loss: 0.9577 - val_acc: 0.7371

Epoch 00027: loss did not improve from 0.96726
Epoch 28/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7310 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 0.9715 - acc: 0.8273 - val_loss: 0.7718 - val_acc: 0.8216

Epoch 00028: loss did not improve from 0.96726
Epoch 29/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8363 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0921 - acc: 0.8061 - val_loss: 0.6910 - val_acc: 0.7934
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:19<00:12,  2.48s/it]
Epoch 00029: loss did not improve from 0.96726
Epoch 00029: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 1.5019 - acc: 0.7812
851/851 [==============================] - 0s 341us/step - loss: 1.8804 - acc: 0.7427 - val_loss: 1.3370 - val_acc: 0.7277

Epoch 00001: loss improved from inf to 1.88036, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4250 - acc: 0.6875
851/851 [==============================] - 0s 32us/step - loss: 1.6852 - acc: 0.7239 - val_loss: 1.2550 - val_acc: 0.7183

Epoch 00002: loss improved from 1.88036 to 1.68521, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2622 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.5457 - acc: 0.7403 - val_loss: 1.2188 - val_acc: 0.7183

Epoch 00003: loss improved from 1.68521 to 1.54569, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2536 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.5161 - acc: 0.7321 - val_loss: 1.1434 - val_acc: 0.7042

Epoch 00004: loss improved from 1.54569 to 1.51610, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1050 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.4355 - acc: 0.7438 - val_loss: 1.1114 - val_acc: 0.7230

Epoch 00005: loss improved from 1.51610 to 1.43555, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1257 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.3993 - acc: 0.7638 - val_loss: 1.0388 - val_acc: 0.7324

Epoch 00006: loss improved from 1.43555 to 1.39935, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0881 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.3322 - acc: 0.7591 - val_loss: 1.0383 - val_acc: 0.7230

Epoch 00007: loss improved from 1.39935 to 1.33222, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9756 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.2767 - acc: 0.7673 - val_loss: 1.0452 - val_acc: 0.7136

Epoch 00008: loss improved from 1.33222 to 1.27671, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0274 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.2646 - acc: 0.7685 - val_loss: 0.9009 - val_acc: 0.7700

Epoch 00009: loss improved from 1.27671 to 1.26459, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9892 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.2396 - acc: 0.7756 - val_loss: 0.9848 - val_acc: 0.7746

Epoch 00010: loss improved from 1.26459 to 1.23959, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9326 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2006 - acc: 0.7756 - val_loss: 0.8924 - val_acc: 0.7653

Epoch 00011: loss improved from 1.23959 to 1.20062, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9799 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1681 - acc: 0.7744 - val_loss: 0.9688 - val_acc: 0.7840

Epoch 00012: loss improved from 1.20062 to 1.16807, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0855 - acc: 0.6875
851/851 [==============================] - 0s 30us/step - loss: 1.1591 - acc: 0.7697 - val_loss: 0.8840 - val_acc: 0.7700

Epoch 00013: loss improved from 1.16807 to 1.15911, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9446 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1171 - acc: 0.7803 - val_loss: 0.8448 - val_acc: 0.7793

Epoch 00014: loss improved from 1.15911 to 1.11710, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8529 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1112 - acc: 0.7791 - val_loss: 0.7967 - val_acc: 0.7887

Epoch 00015: loss improved from 1.11710 to 1.11116, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7179 - acc: 0.8438
851/851 [==============================] - 0s 30us/step - loss: 1.1109 - acc: 0.7885 - val_loss: 0.7772 - val_acc: 0.7746

Epoch 00016: loss improved from 1.11116 to 1.11093, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8632 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1177 - acc: 0.7873 - val_loss: 0.7895 - val_acc: 0.7887

Epoch 00017: loss did not improve from 1.11093
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8504 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0901 - acc: 0.8002 - val_loss: 0.8092 - val_acc: 0.7840

Epoch 00018: loss improved from 1.11093 to 1.09013, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8029 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1309 - acc: 0.7967 - val_loss: 0.7861 - val_acc: 0.7746

Epoch 00019: loss did not improve from 1.09013
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1312 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0791 - acc: 0.7885 - val_loss: 0.9206 - val_acc: 0.7700

Epoch 00020: loss improved from 1.09013 to 1.07908, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9161 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0639 - acc: 0.7908 - val_loss: 0.8375 - val_acc: 0.7606

Epoch 00021: loss improved from 1.07908 to 1.06394, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7902 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 0.9580 - acc: 0.8190 - val_loss: 0.7792 - val_acc: 0.7793

Epoch 00022: loss improved from 1.06394 to 0.95800, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_14.h5
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9390 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0293 - acc: 0.8108 - val_loss: 0.8020 - val_acc: 0.8216

Epoch 00023: loss did not improve from 0.95800
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9473 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0756 - acc: 0.7908 - val_loss: 0.7739 - val_acc: 0.7653

Epoch 00024: loss did not improve from 0.95800
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7931 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1074 - acc: 0.7944 - val_loss: 0.7893 - val_acc: 0.7981

Epoch 00025: loss did not improve from 0.95800
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7645 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.1582 - acc: 0.7826 - val_loss: 0.9873 - val_acc: 0.7512

Epoch 00026: loss did not improve from 0.95800
Epoch 27/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9526 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0145 - acc: 0.7873 - val_loss: 0.8018 - val_acc: 0.7559
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:22<00:09,  2.48s/it]
Epoch 00027: loss did not improve from 0.95800
Epoch 00027: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 2.1839 - acc: 0.6875
851/851 [==============================] - 0s 335us/step - loss: 2.1207 - acc: 0.7250 - val_loss: 1.5616 - val_acc: 0.7183

Epoch 00001: loss improved from inf to 2.12069, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.6585 - acc: 0.7188
851/851 [==============================] - 0s 32us/step - loss: 1.8279 - acc: 0.7262 - val_loss: 1.4823 - val_acc: 0.7183

Epoch 00002: loss improved from 2.12069 to 1.82795, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.5341 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.7437 - acc: 0.7368 - val_loss: 1.3675 - val_acc: 0.7042

Epoch 00003: loss improved from 1.82795 to 1.74367, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4429 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.6485 - acc: 0.7474 - val_loss: 1.3759 - val_acc: 0.6714

Epoch 00004: loss improved from 1.74367 to 1.64854, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.3346 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.5597 - acc: 0.7497 - val_loss: 1.3483 - val_acc: 0.6667

Epoch 00005: loss improved from 1.64854 to 1.55973, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2706 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.5322 - acc: 0.7415 - val_loss: 1.2331 - val_acc: 0.6948

Epoch 00006: loss improved from 1.55973 to 1.53222, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2234 - acc: 0.6875
851/851 [==============================] - 0s 30us/step - loss: 1.4477 - acc: 0.7485 - val_loss: 1.1594 - val_acc: 0.6901

Epoch 00007: loss improved from 1.53222 to 1.44766, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1063 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.3995 - acc: 0.7568 - val_loss: 1.0514 - val_acc: 0.7512

Epoch 00008: loss improved from 1.44766 to 1.39948, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1637 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.3612 - acc: 0.7544 - val_loss: 1.0375 - val_acc: 0.7042

Epoch 00009: loss improved from 1.39948 to 1.36122, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0776 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.3217 - acc: 0.7603 - val_loss: 1.1007 - val_acc: 0.6948

Epoch 00010: loss improved from 1.36122 to 1.32166, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1108 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2990 - acc: 0.7638 - val_loss: 0.9474 - val_acc: 0.7324

Epoch 00011: loss improved from 1.32166 to 1.29900, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0522 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.2250 - acc: 0.7720 - val_loss: 0.9567 - val_acc: 0.7371

Epoch 00012: loss improved from 1.29900 to 1.22496, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9621 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2483 - acc: 0.7732 - val_loss: 0.9427 - val_acc: 0.6901

Epoch 00013: loss did not improve from 1.22496
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9538 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2497 - acc: 0.7709 - val_loss: 0.9365 - val_acc: 0.7512

Epoch 00014: loss did not improve from 1.22496
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9541 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.2179 - acc: 0.7603 - val_loss: 0.8914 - val_acc: 0.7653

Epoch 00015: loss improved from 1.22496 to 1.21794, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0610 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.1974 - acc: 0.7814 - val_loss: 0.9662 - val_acc: 0.7371

Epoch 00016: loss improved from 1.21794 to 1.19736, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0081 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0951 - acc: 0.7897 - val_loss: 0.9589 - val_acc: 0.7371

Epoch 00017: loss improved from 1.19736 to 1.09514, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9414 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1516 - acc: 0.7873 - val_loss: 0.8416 - val_acc: 0.7887

Epoch 00018: loss did not improve from 1.09514
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9408 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1161 - acc: 0.7803 - val_loss: 0.7892 - val_acc: 0.7746

Epoch 00019: loss did not improve from 1.09514
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8097 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1221 - acc: 0.7850 - val_loss: 0.9270 - val_acc: 0.7653

Epoch 00020: loss did not improve from 1.09514
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9689 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.1722 - acc: 0.7720 - val_loss: 0.7912 - val_acc: 0.7700

Epoch 00021: loss did not improve from 1.09514
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7958 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.0905 - acc: 0.7826 - val_loss: 0.7425 - val_acc: 0.7934

Epoch 00022: loss improved from 1.09514 to 1.09053, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7823 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0509 - acc: 0.7932 - val_loss: 0.6874 - val_acc: 0.7887

Epoch 00023: loss improved from 1.09053 to 1.05094, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_15.h5
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7732 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2525 - acc: 0.7814 - val_loss: 1.3656 - val_acc: 0.7042

Epoch 00024: loss did not improve from 1.05094
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0766 - acc: 0.6875
851/851 [==============================] - 0s 30us/step - loss: 1.1535 - acc: 0.7814 - val_loss: 0.9303 - val_acc: 0.7606

Epoch 00025: loss did not improve from 1.05094
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7580 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.2059 - acc: 0.7709 - val_loss: 0.8416 - val_acc: 0.7606

Epoch 00026: loss did not improve from 1.05094
Epoch 27/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9668 - acc: 0.7188
851/851 [==============================] - 0s 29us/step - loss: 1.1204 - acc: 0.7615 - val_loss: 0.7539 - val_acc: 0.7606

Epoch 00027: loss did not improve from 1.05094
Epoch 28/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0414 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.0679 - acc: 0.7873 - val_loss: 1.1274 - val_acc: 0.6714
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:24<00:07,  2.48s/it]
Epoch 00028: loss did not improve from 1.05094
Epoch 00028: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 1.5522 - acc: 0.7188
851/851 [==============================] - 0s 332us/step - loss: 1.9711 - acc: 0.7321 - val_loss: 1.3505 - val_acc: 0.7230

Epoch 00001: loss improved from inf to 1.97109, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4877 - acc: 0.6875
851/851 [==============================] - 0s 32us/step - loss: 1.7423 - acc: 0.7239 - val_loss: 1.3016 - val_acc: 0.7136

Epoch 00002: loss improved from 1.97109 to 1.74229, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2652 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.6505 - acc: 0.7286 - val_loss: 1.2243 - val_acc: 0.7183

Epoch 00003: loss improved from 1.74229 to 1.65045, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2686 - acc: 0.6875
851/851 [==============================] - 0s 31us/step - loss: 1.5703 - acc: 0.7333 - val_loss: 1.1812 - val_acc: 0.7089

Epoch 00004: loss improved from 1.65045 to 1.57034, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2725 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.4900 - acc: 0.7356 - val_loss: 1.1856 - val_acc: 0.6667

Epoch 00005: loss improved from 1.57034 to 1.48996, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1714 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.4688 - acc: 0.7462 - val_loss: 1.1141 - val_acc: 0.7418

Epoch 00006: loss improved from 1.48996 to 1.46882, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1843 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.3910 - acc: 0.7485 - val_loss: 1.1661 - val_acc: 0.6854

Epoch 00007: loss improved from 1.46882 to 1.39103, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0830 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.3813 - acc: 0.7509 - val_loss: 1.0946 - val_acc: 0.7042

Epoch 00008: loss improved from 1.39103 to 1.38132, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0578 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.3085 - acc: 0.7626 - val_loss: 1.0474 - val_acc: 0.7512

Epoch 00009: loss improved from 1.38132 to 1.30854, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0384 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.3031 - acc: 0.7579 - val_loss: 0.9665 - val_acc: 0.7653

Epoch 00010: loss improved from 1.30854 to 1.30306, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9404 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2430 - acc: 0.7556 - val_loss: 0.9585 - val_acc: 0.7230

Epoch 00011: loss improved from 1.30306 to 1.24299, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8730 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2234 - acc: 0.7591 - val_loss: 0.8644 - val_acc: 0.7230

Epoch 00012: loss improved from 1.24299 to 1.22337, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8588 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2419 - acc: 0.7568 - val_loss: 0.9073 - val_acc: 0.7042

Epoch 00013: loss did not improve from 1.22337
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8675 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1977 - acc: 0.7673 - val_loss: 0.8646 - val_acc: 0.7559

Epoch 00014: loss improved from 1.22337 to 1.19770, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9238 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1852 - acc: 0.7685 - val_loss: 0.8392 - val_acc: 0.7277

Epoch 00015: loss improved from 1.19770 to 1.18517, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0537 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.2709 - acc: 0.7556 - val_loss: 0.8497 - val_acc: 0.7559

Epoch 00016: loss did not improve from 1.18517
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8615 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1567 - acc: 0.7615 - val_loss: 0.7688 - val_acc: 0.7559

Epoch 00017: loss improved from 1.18517 to 1.15674, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0047 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.1275 - acc: 0.7944 - val_loss: 0.7745 - val_acc: 0.7840

Epoch 00018: loss improved from 1.15674 to 1.12753, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.7662 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1155 - acc: 0.8014 - val_loss: 0.8434 - val_acc: 0.7653

Epoch 00019: loss improved from 1.12753 to 1.11546, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_16.h5
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8452 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1314 - acc: 0.7826 - val_loss: 0.8432 - val_acc: 0.7606

Epoch 00020: loss did not improve from 1.11546
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0318 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1651 - acc: 0.7744 - val_loss: 0.7640 - val_acc: 0.7371

Epoch 00021: loss did not improve from 1.11546
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9094 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1223 - acc: 0.7779 - val_loss: 0.8201 - val_acc: 0.7559

Epoch 00022: loss did not improve from 1.11546
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8128 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.2187 - acc: 0.7955 - val_loss: 1.0826 - val_acc: 0.7277

Epoch 00023: loss did not improve from 1.11546
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9640 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1357 - acc: 0.7744 - val_loss: 0.8561 - val_acc: 0.7700
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:26<00:04,  2.42s/it]
Epoch 00024: loss did not improve from 1.11546
Epoch 00024: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 6s - loss: 1.6093 - acc: 0.7500
851/851 [==============================] - 0s 342us/step - loss: 2.0408 - acc: 0.7133 - val_loss: 1.3765 - val_acc: 0.7089

Epoch 00001: loss improved from inf to 2.04075, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4322 - acc: 0.6875
851/851 [==============================] - 0s 32us/step - loss: 1.7840 - acc: 0.7286 - val_loss: 1.3292 - val_acc: 0.7089

Epoch 00002: loss improved from 2.04075 to 1.78400, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4136 - acc: 0.6875
851/851 [==============================] - 0s 31us/step - loss: 1.6721 - acc: 0.7227 - val_loss: 1.2132 - val_acc: 0.7136

Epoch 00003: loss improved from 1.78400 to 1.67214, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2706 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.6132 - acc: 0.7309 - val_loss: 1.1899 - val_acc: 0.7183

Epoch 00004: loss improved from 1.67214 to 1.61318, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2509 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.5606 - acc: 0.7297 - val_loss: 1.4739 - val_acc: 0.4131

Epoch 00005: loss improved from 1.61318 to 1.56058, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2070 - acc: 0.6875
851/851 [==============================] - 0s 30us/step - loss: 1.4465 - acc: 0.7380 - val_loss: 1.2722 - val_acc: 0.6667

Epoch 00006: loss improved from 1.56058 to 1.44648, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1515 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.4476 - acc: 0.7368 - val_loss: 1.1437 - val_acc: 0.6948

Epoch 00007: loss did not improve from 1.44648
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1350 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.3979 - acc: 0.7615 - val_loss: 1.0080 - val_acc: 0.7183

Epoch 00008: loss improved from 1.44648 to 1.39792, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0306 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.2951 - acc: 0.7697 - val_loss: 1.0026 - val_acc: 0.7606

Epoch 00009: loss improved from 1.39792 to 1.29505, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9759 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2973 - acc: 0.7626 - val_loss: 0.9106 - val_acc: 0.7606

Epoch 00010: loss did not improve from 1.29505
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1983 - acc: 0.6562
851/851 [==============================] - 0s 30us/step - loss: 1.2440 - acc: 0.7579 - val_loss: 0.8978 - val_acc: 0.7559

Epoch 00011: loss improved from 1.29505 to 1.24401, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9290 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2853 - acc: 0.7603 - val_loss: 0.9016 - val_acc: 0.7746

Epoch 00012: loss did not improve from 1.24401
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1303 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2242 - acc: 0.7779 - val_loss: 0.9176 - val_acc: 0.7606

Epoch 00013: loss improved from 1.24401 to 1.22418, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9280 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2222 - acc: 0.7685 - val_loss: 0.9273 - val_acc: 0.7230

Epoch 00014: loss improved from 1.22418 to 1.22224, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0572 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.1899 - acc: 0.7850 - val_loss: 1.0994 - val_acc: 0.7700

Epoch 00015: loss improved from 1.22224 to 1.18992, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0846 - acc: 0.6875
851/851 [==============================] - 0s 30us/step - loss: 1.1726 - acc: 0.7838 - val_loss: 0.8666 - val_acc: 0.7559

Epoch 00016: loss improved from 1.18992 to 1.17264, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9106 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1907 - acc: 0.7920 - val_loss: 0.8437 - val_acc: 0.7653

Epoch 00017: loss did not improve from 1.17264
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9473 - acc: 0.7812
851/851 [==============================] - 0s 31us/step - loss: 1.2056 - acc: 0.7814 - val_loss: 0.8380 - val_acc: 0.7700

Epoch 00018: loss did not improve from 1.17264
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8701 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.2130 - acc: 0.7662 - val_loss: 0.7844 - val_acc: 0.7559

Epoch 00019: loss did not improve from 1.17264
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9871 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1325 - acc: 0.7838 - val_loss: 0.7832 - val_acc: 0.7700

Epoch 00020: loss improved from 1.17264 to 1.13253, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 21/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0024 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.2118 - acc: 0.7591 - val_loss: 0.8628 - val_acc: 0.7934

Epoch 00021: loss did not improve from 1.13253
Epoch 22/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0067 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1152 - acc: 0.7744 - val_loss: 0.7520 - val_acc: 0.7840

Epoch 00022: loss improved from 1.13253 to 1.11520, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_17.h5
Epoch 23/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9169 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.1458 - acc: 0.7791 - val_loss: 0.7322 - val_acc: 0.7700

Epoch 00023: loss did not improve from 1.11520
Epoch 24/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9249 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.1817 - acc: 0.7744 - val_loss: 0.8711 - val_acc: 0.7512

Epoch 00024: loss did not improve from 1.11520
Epoch 25/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8976 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.2085 - acc: 0.7756 - val_loss: 0.9056 - val_acc: 0.7512

Epoch 00025: loss did not improve from 1.11520
Epoch 26/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9587 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.1511 - acc: 0.7720 - val_loss: 0.8387 - val_acc: 0.7606

Epoch 00026: loss did not improve from 1.11520
Epoch 27/100

 32/851 [>.............................] - ETA: 0s - loss: 0.8719 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2738 - acc: 0.7779 - val_loss: 0.9885 - val_acc: 0.7183
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:29<00:02,  2.44s/it]
Epoch 00027: loss did not improve from 1.11520
Epoch 00027: early stopping
Train on 851 samples, validate on 213 samples
Epoch 1/100

 32/851 [>.............................] - ETA: 5s - loss: 2.2788 - acc: 0.7188
851/851 [==============================] - 0s 336us/step - loss: 2.2692 - acc: 0.7168 - val_loss: 1.5638 - val_acc: 0.7136

Epoch 00001: loss improved from inf to 2.26923, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/851 [>.............................] - ETA: 0s - loss: 1.6117 - acc: 0.6875
851/851 [==============================] - 0s 32us/step - loss: 1.9699 - acc: 0.7180 - val_loss: 1.5098 - val_acc: 0.7136

Epoch 00002: loss improved from 2.26923 to 1.96988, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/851 [>.............................] - ETA: 0s - loss: 1.6333 - acc: 0.6562
851/851 [==============================] - 0s 31us/step - loss: 1.8587 - acc: 0.7145 - val_loss: 1.4888 - val_acc: 0.6854

Epoch 00003: loss improved from 1.96988 to 1.85870, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/851 [>.............................] - ETA: 0s - loss: 1.4415 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.7453 - acc: 0.7227 - val_loss: 1.4043 - val_acc: 0.7042

Epoch 00004: loss improved from 1.85870 to 1.74533, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2751 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.6852 - acc: 0.7368 - val_loss: 1.2734 - val_acc: 0.7230

Epoch 00005: loss improved from 1.74533 to 1.68521, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/851 [>.............................] - ETA: 0s - loss: 1.3157 - acc: 0.7500
851/851 [==============================] - 0s 31us/step - loss: 1.5961 - acc: 0.7356 - val_loss: 1.2055 - val_acc: 0.7136

Epoch 00006: loss improved from 1.68521 to 1.59614, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2648 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.5524 - acc: 0.7474 - val_loss: 1.1462 - val_acc: 0.7277

Epoch 00007: loss improved from 1.59614 to 1.55238, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/851 [>.............................] - ETA: 0s - loss: 1.2207 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.4760 - acc: 0.7485 - val_loss: 1.1354 - val_acc: 0.7371

Epoch 00008: loss improved from 1.55238 to 1.47603, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1690 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.3535 - acc: 0.7568 - val_loss: 1.0022 - val_acc: 0.7653

Epoch 00009: loss improved from 1.47603 to 1.35349, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9280 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.3388 - acc: 0.7673 - val_loss: 1.1909 - val_acc: 0.6948

Epoch 00010: loss improved from 1.35349 to 1.33882, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1181 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.3352 - acc: 0.7673 - val_loss: 1.1332 - val_acc: 0.6995

Epoch 00011: loss improved from 1.33882 to 1.33517, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0674 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.2563 - acc: 0.7615 - val_loss: 1.0513 - val_acc: 0.7277

Epoch 00012: loss improved from 1.33517 to 1.25626, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 13/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9589 - acc: 0.7188
851/851 [==============================] - 0s 31us/step - loss: 1.2505 - acc: 0.7756 - val_loss: 0.9567 - val_acc: 0.7700

Epoch 00013: loss improved from 1.25626 to 1.25055, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 14/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0591 - acc: 0.7812
851/851 [==============================] - 0s 30us/step - loss: 1.3890 - acc: 0.7380 - val_loss: 1.0375 - val_acc: 0.6901

Epoch 00014: loss did not improve from 1.25055
Epoch 15/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1249 - acc: 0.7500
851/851 [==============================] - 0s 30us/step - loss: 1.2042 - acc: 0.7850 - val_loss: 0.9003 - val_acc: 0.7653

Epoch 00015: loss improved from 1.25055 to 1.20422, saving model to ./results_TA100_without_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9426 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.3675 - acc: 0.7485 - val_loss: 0.9541 - val_acc: 0.7606

Epoch 00016: loss did not improve from 1.20422
Epoch 17/100

 32/851 [>.............................] - ETA: 0s - loss: 1.0711 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.2543 - acc: 0.7626 - val_loss: 0.7714 - val_acc: 0.7606

Epoch 00017: loss did not improve from 1.20422
Epoch 18/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9528 - acc: 0.8125
851/851 [==============================] - 0s 30us/step - loss: 1.2174 - acc: 0.7673 - val_loss: 0.8083 - val_acc: 0.7559

Epoch 00018: loss did not improve from 1.20422
Epoch 19/100

 32/851 [>.............................] - ETA: 0s - loss: 0.9614 - acc: 0.7188
851/851 [==============================] - 0s 30us/step - loss: 1.3492 - acc: 0.7474 - val_loss: 1.2752 - val_acc: 0.7887

Epoch 00019: loss did not improve from 1.20422
Epoch 20/100

 32/851 [>.............................] - ETA: 0s - loss: 1.1765 - acc: 0.6875
851/851 [==============================] - 0s 30us/step - loss: 1.3312 - acc: 0.7462 - val_loss: 0.9585 - val_acc: 0.7418
DeepAmes+ Weights: 100%|██████████| 13/13 [00:31<00:00,  2.39s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:31<00:00,  2.44s/it]

Epoch 00020: loss did not improve from 1.20422
Epoch 00020: early stopping
--- 8159.426089286804 seconds ---

Generating metrics report for TA100_without_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 591 samples.
Processing weight 7...
  Done. 591 samples.
Processing weight 8...
  Done. 591 samples.
Processing weight 9...
  Done. 591 samples.
Processing weight 10...
  Done. 591 samples.
Processing weight 11...
  Done. 591 samples.
Processing weight 12...
  Done. 591 samples.
Processing weight 13...
  Done. 591 samples.
Processing weight 14...
  Done. 591 samples.
Processing weight 15...
  Done. 591 samples.
Processing weight 16...
  Done. 591 samples.
Processing weight 17...
  Done. 591 samples.
Processing weight 18...
  Done. 591 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA100_without_S9/metrics_report_TA100_without_S9.txt

Done!

Completed TA100_without_S9 in 8159.43 seconds

================================================================================
[3/16] Processing: TA102_with_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA102_with_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA102_with_S9_Test_mold2.csv
(757, 777)
(605, 777)
(98, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:01<00:23,  1.25s/it]KNN Seeds:  10%|█         | 2/20 [00:02<00:22,  1.25s/it]KNN Seeds:  15%|█▌        | 3/20 [00:03<00:21,  1.26s/it]KNN Seeds:  20%|██        | 4/20 [00:05<00:20,  1.27s/it]KNN Seeds:  25%|██▌       | 5/20 [00:06<00:19,  1.28s/it]KNN Seeds:  30%|███       | 6/20 [00:07<00:18,  1.29s/it]KNN Seeds:  35%|███▌      | 7/20 [00:08<00:16,  1.30s/it]KNN Seeds:  40%|████      | 8/20 [00:10<00:15,  1.31s/it]KNN Seeds:  45%|████▌     | 9/20 [00:11<00:14,  1.32s/it]KNN Seeds:  50%|█████     | 10/20 [00:12<00:13,  1.33s/it]KNN Seeds:  55%|█████▌    | 11/20 [00:14<00:12,  1.34s/it]KNN Seeds:  60%|██████    | 12/20 [00:15<00:10,  1.35s/it]KNN Seeds:  65%|██████▌   | 13/20 [00:17<00:09,  1.36s/it]KNN Seeds:  70%|███████   | 14/20 [00:18<00:08,  1.37s/it]KNN Seeds:  75%|███████▌  | 15/20 [00:19<00:06,  1.38s/it]KNN Seeds:  80%|████████  | 16/20 [00:21<00:05,  1.39s/it]KNN Seeds:  85%|████████▌ | 17/20 [00:22<00:04,  1.40s/it]KNN Seeds:  90%|█████████ | 18/20 [00:24<00:02,  1.41s/it]KNN Seeds:  95%|█████████▌| 19/20 [00:25<00:01,  1.41s/it]KNN Seeds: 100%|██████████| 20/20 [00:27<00:00,  1.42s/it]KNN Seeds: 100%|██████████| 20/20 [00:27<00:00,  1.35s/it]
24
(100, None, 'lbfgs')
(757, 777)
(605, 777)
(98, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:01<00:19,  1.02s/it]LR Seeds:  10%|█         | 2/20 [00:02<00:24,  1.35s/it]LR Seeds:  15%|█▌        | 3/20 [00:04<00:24,  1.47s/it]LR Seeds:  20%|██        | 4/20 [00:05<00:24,  1.53s/it]LR Seeds:  25%|██▌       | 5/20 [00:07<00:23,  1.58s/it]LR Seeds:  30%|███       | 6/20 [00:09<00:22,  1.63s/it]LR Seeds:  35%|███▌      | 7/20 [00:10<00:21,  1.65s/it]LR Seeds:  40%|████      | 8/20 [00:12<00:19,  1.67s/it]LR Seeds:  45%|████▌     | 9/20 [00:14<00:18,  1.68s/it]LR Seeds:  50%|█████     | 10/20 [00:16<00:17,  1.71s/it]LR Seeds:  55%|█████▌    | 11/20 [00:17<00:15,  1.72s/it]LR Seeds:  60%|██████    | 12/20 [00:19<00:13,  1.74s/it]LR Seeds:  65%|██████▌   | 13/20 [00:21<00:12,  1.75s/it]LR Seeds:  70%|███████   | 14/20 [00:23<00:10,  1.76s/it]LR Seeds:  75%|███████▌  | 15/20 [00:25<00:08,  1.77s/it]LR Seeds:  80%|████████  | 16/20 [00:26<00:07,  1.80s/it]LR Seeds:  85%|████████▌ | 17/20 [00:28<00:05,  1.82s/it]LR Seeds:  90%|█████████ | 18/20 [00:30<00:03,  1.84s/it]LR Seeds:  95%|█████████▌| 19/20 [00:32<00:01,  1.89s/it]LR Seeds: 100%|██████████| 20/20 [00:34<00:00,  1.89s/it]LR Seeds: 100%|██████████| 20/20 [00:34<00:00,  1.73s/it]
96
('rbf', 1, 1)
(757, 777)
(605, 777)
(98, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [00:05<01:51,  5.87s/it]SVM Seeds:  10%|█         | 2/20 [00:11<01:45,  5.88s/it]SVM Seeds:  15%|█▌        | 3/20 [00:17<01:40,  5.89s/it]SVM Seeds:  20%|██        | 4/20 [00:23<01:34,  5.89s/it]SVM Seeds:  25%|██▌       | 5/20 [00:29<01:28,  5.90s/it]SVM Seeds:  30%|███       | 6/20 [00:35<01:22,  5.91s/it]SVM Seeds:  35%|███▌      | 7/20 [00:41<01:16,  5.92s/it]SVM Seeds:  40%|████      | 8/20 [00:47<01:11,  5.93s/it]SVM Seeds:  45%|████▌     | 9/20 [00:53<01:05,  5.94s/it]SVM Seeds:  50%|█████     | 10/20 [00:59<00:59,  5.94s/it]SVM Seeds:  55%|█████▌    | 11/20 [01:05<00:53,  5.95s/it]SVM Seeds:  60%|██████    | 12/20 [01:11<00:47,  5.96s/it]SVM Seeds:  65%|██████▌   | 13/20 [01:17<00:41,  5.97s/it]SVM Seeds:  70%|███████   | 14/20 [01:23<00:35,  5.98s/it]SVM Seeds:  75%|███████▌  | 15/20 [01:29<00:29,  5.99s/it]SVM Seeds:  80%|████████  | 16/20 [01:35<00:23,  6.00s/it]SVM Seeds:  85%|████████▌ | 17/20 [01:41<00:18,  6.01s/it]SVM Seeds:  90%|█████████ | 18/20 [01:47<00:12,  6.02s/it]SVM Seeds:  95%|█████████▌| 19/20 [01:53<00:06,  6.03s/it]SVM Seeds: 100%|██████████| 20/20 [01:59<00:00,  6.04s/it]SVM Seeds: 100%|██████████| 20/20 [01:59<00:00,  5.97s/it]
200
(500, None, 70, 1, 'balanced')
(757, 777)
(605, 777)
(98, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:02<00:46,  2.45s/it]RF Seeds:  10%|█         | 2/20 [00:05<00:46,  2.57s/it]RF Seeds:  15%|█▌        | 3/20 [00:07<00:42,  2.52s/it]RF Seeds:  20%|██        | 4/20 [00:10<00:41,  2.62s/it]RF Seeds:  25%|██▌       | 5/20 [00:12<00:38,  2.57s/it]RF Seeds:  30%|███       | 6/20 [00:15<00:35,  2.54s/it]RF Seeds:  35%|███▌      | 7/20 [00:17<00:32,  2.53s/it]RF Seeds:  40%|████      | 8/20 [00:20<00:30,  2.52s/it]RF Seeds:  45%|████▌     | 9/20 [00:22<00:27,  2.52s/it]RF Seeds:  50%|█████     | 10/20 [00:25<00:25,  2.52s/it]RF Seeds:  55%|█████▌    | 11/20 [00:27<00:22,  2.53s/it]RF Seeds:  60%|██████    | 12/20 [00:30<00:20,  2.53s/it]RF Seeds:  65%|██████▌   | 13/20 [00:32<00:17,  2.53s/it]RF Seeds:  70%|███████   | 14/20 [00:35<00:15,  2.55s/it]RF Seeds:  75%|███████▌  | 15/20 [00:38<00:12,  2.55s/it]RF Seeds:  80%|████████  | 16/20 [00:40<00:10,  2.56s/it]RF Seeds:  85%|████████▌ | 17/20 [00:43<00:07,  2.60s/it]RF Seeds:  90%|█████████ | 18/20 [00:46<00:05,  2.61s/it]RF Seeds:  95%|█████████▌| 19/20 [00:48<00:02,  2.61s/it]RF Seeds: 100%|██████████| 20/20 [00:51<00:00,  2.62s/it]RF Seeds: 100%|██████████| 20/20 [00:51<00:00,  2.56s/it]
400
(0.01, 900, 7, 0.8, 6)
(757, 777)
(605, 777)
(98, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:27<08:48, 27.83s/it]XGBoost Seeds:  10%|█         | 2/20 [00:55<08:18, 27.70s/it]XGBoost Seeds:  15%|█▌        | 3/20 [01:22<07:49, 27.61s/it]XGBoost Seeds:  20%|██        | 4/20 [01:50<07:20, 27.53s/it]XGBoost Seeds:  25%|██▌       | 5/20 [02:17<06:51, 27.42s/it]XGBoost Seeds:  30%|███       | 6/20 [02:44<06:21, 27.25s/it]XGBoost Seeds:  35%|███▌      | 7/20 [03:12<05:59, 27.66s/it]XGBoost Seeds:  40%|████      | 8/20 [03:40<05:29, 27.49s/it]XGBoost Seeds:  45%|████▌     | 9/20 [04:07<05:00, 27.36s/it]XGBoost Seeds:  50%|█████     | 10/20 [04:34<04:33, 27.33s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [05:01<04:05, 27.30s/it]XGBoost Seeds:  60%|██████    | 12/20 [05:29<03:38, 27.34s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [05:56<03:11, 27.37s/it]XGBoost Seeds:  70%|███████   | 14/20 [06:24<02:44, 27.46s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [06:51<02:16, 27.40s/it]XGBoost Seeds:  80%|████████  | 16/20 [07:18<01:49, 27.34s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [07:45<01:21, 27.25s/it]XGBoost Seeds:  90%|█████████ | 18/20 [08:12<00:54, 27.20s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [08:39<00:27, 27.14s/it]XGBoost Seeds: 100%|██████████| 20/20 [09:08<00:00, 27.49s/it]XGBoost Seeds: 100%|██████████| 20/20 [09:08<00:00, 27.40s/it]
knn:  88
lr:  73
svm:  97
rf:  89
xgboost:  98
Combining validation predictions is completed
knn:  88
lr:  73
svm:  97
rf:  89
xgboost:  98
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.3098 - acc: 0.5000
121/121 [==============================] - 0s 2ms/step - loss: 1.8872 - acc: 0.6364 - val_loss: 1.4132 - val_acc: 0.7419

Epoch 00001: loss improved from inf to 1.88716, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3724 - acc: 0.8438
121/121 [==============================] - 0s 38us/step - loss: 1.4144 - acc: 0.7934 - val_loss: 1.4873 - val_acc: 0.7419

Epoch 00002: loss improved from 1.88716 to 1.41442, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2968 - acc: 0.7812
121/121 [==============================] - 0s 34us/step - loss: 1.3031 - acc: 0.8430 - val_loss: 1.3855 - val_acc: 0.7742

Epoch 00003: loss improved from 1.41442 to 1.30307, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3043 - acc: 0.7812
121/121 [==============================] - 0s 34us/step - loss: 1.2780 - acc: 0.8264 - val_loss: 1.3851 - val_acc: 0.7742

Epoch 00004: loss improved from 1.30307 to 1.27800, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0431 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.1138 - acc: 0.9091 - val_loss: 1.4514 - val_acc: 0.6774

Epoch 00005: loss improved from 1.27800 to 1.11381, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1961 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.0911 - acc: 0.8926 - val_loss: 1.3435 - val_acc: 0.7419

Epoch 00006: loss improved from 1.11381 to 1.09115, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8535 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.9274 - acc: 0.9339 - val_loss: 1.3264 - val_acc: 0.7419

Epoch 00007: loss improved from 1.09115 to 0.92739, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9250 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.8746 - acc: 0.9504 - val_loss: 1.2224 - val_acc: 0.8387

Epoch 00008: loss improved from 0.92739 to 0.87465, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8673 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.9571 - acc: 0.9504 - val_loss: 1.1717 - val_acc: 0.7419

Epoch 00009: loss did not improve from 0.87465
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1192 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.1302 - acc: 0.8926 - val_loss: 1.2478 - val_acc: 0.7419

Epoch 00010: loss did not improve from 0.87465
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0447 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 0.9245 - acc: 0.9174 - val_loss: 1.1860 - val_acc: 0.7742

Epoch 00011: loss did not improve from 0.87465
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8415 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 1.0004 - acc: 0.9421 - val_loss: 1.2857 - val_acc: 0.7419

Epoch 00012: loss did not improve from 0.87465
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8340 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.0149 - acc: 0.8926 - val_loss: 1.3366 - val_acc: 0.7742
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:17,  1.48s/it]
Epoch 00013: loss did not improve from 0.87465
Epoch 00013: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.7644 - acc: 0.4688
121/121 [==============================] - 0s 2ms/step - loss: 2.1041 - acc: 0.6033 - val_loss: 1.6670 - val_acc: 0.7419

Epoch 00001: loss improved from inf to 2.10412, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6875 - acc: 0.6875
121/121 [==============================] - 0s 39us/step - loss: 1.5502 - acc: 0.7686 - val_loss: 1.5224 - val_acc: 0.7097

Epoch 00002: loss improved from 2.10412 to 1.55021, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3446 - acc: 0.7500
121/121 [==============================] - 0s 35us/step - loss: 1.6998 - acc: 0.7769 - val_loss: 1.5436 - val_acc: 0.7097

Epoch 00003: loss did not improve from 1.55021
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3869 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.4682 - acc: 0.7934 - val_loss: 1.4430 - val_acc: 0.7097

Epoch 00004: loss improved from 1.55021 to 1.46819, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3847 - acc: 0.8125
121/121 [==============================] - 0s 34us/step - loss: 1.2632 - acc: 0.8678 - val_loss: 1.4514 - val_acc: 0.7419

Epoch 00005: loss improved from 1.46819 to 1.26321, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1602 - acc: 0.8125
121/121 [==============================] - 0s 34us/step - loss: 1.2747 - acc: 0.8678 - val_loss: 1.4604 - val_acc: 0.7097

Epoch 00006: loss did not improve from 1.26321
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3062 - acc: 0.7188
121/121 [==============================] - 0s 33us/step - loss: 1.1546 - acc: 0.8347 - val_loss: 1.4534 - val_acc: 0.7097

Epoch 00007: loss improved from 1.26321 to 1.15456, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5670 - acc: 0.7188
121/121 [==============================] - 0s 34us/step - loss: 1.2795 - acc: 0.8430 - val_loss: 1.5203 - val_acc: 0.6452

Epoch 00008: loss did not improve from 1.15456
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1156 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.3807 - acc: 0.8678 - val_loss: 1.4018 - val_acc: 0.7097

Epoch 00009: loss did not improve from 1.15456
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9998 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.0676 - acc: 0.9174 - val_loss: 1.3576 - val_acc: 0.7097

Epoch 00010: loss improved from 1.15456 to 1.06760, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0573 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.0137 - acc: 0.9174 - val_loss: 1.3836 - val_acc: 0.6774

Epoch 00011: loss improved from 1.06760 to 1.01369, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9409 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.9256 - acc: 0.9587 - val_loss: 1.3179 - val_acc: 0.7097

Epoch 00012: loss improved from 1.01369 to 0.92562, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7950 - acc: 1.0000
121/121 [==============================] - 0s 34us/step - loss: 0.9849 - acc: 0.9421 - val_loss: 1.5819 - val_acc: 0.7097

Epoch 00013: loss did not improve from 0.92562
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9104 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 0.9701 - acc: 0.9174 - val_loss: 1.8916 - val_acc: 0.3871

Epoch 00014: loss did not improve from 0.92562
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2158 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 0.9758 - acc: 0.9339 - val_loss: 1.3724 - val_acc: 0.7742

Epoch 00015: loss did not improve from 0.92562
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0031 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 0.8610 - acc: 0.9421 - val_loss: 1.3220 - val_acc: 0.7742

Epoch 00016: loss improved from 0.92562 to 0.86096, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8225 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 1.1872 - acc: 0.9174 - val_loss: 1.4508 - val_acc: 0.7097

Epoch 00017: loss did not improve from 0.86096
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1853 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 0.9981 - acc: 0.8926 - val_loss: 1.2606 - val_acc: 0.7742

Epoch 00018: loss did not improve from 0.86096
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8072 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.7583 - acc: 0.9669 - val_loss: 1.3512 - val_acc: 0.7419

Epoch 00019: loss improved from 0.86096 to 0.75830, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 20/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8163 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.7857 - acc: 0.9504 - val_loss: 1.2331 - val_acc: 0.7742

Epoch 00020: loss did not improve from 0.75830
Epoch 21/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6752 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.7468 - acc: 0.9752 - val_loss: 1.3761 - val_acc: 0.7097

Epoch 00021: loss improved from 0.75830 to 0.74681, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 22/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8652 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.7066 - acc: 0.9835 - val_loss: 1.2791 - val_acc: 0.7097

Epoch 00022: loss improved from 0.74681 to 0.70662, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 23/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6789 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.7018 - acc: 0.9917 - val_loss: 1.3691 - val_acc: 0.7419

Epoch 00023: loss improved from 0.70662 to 0.70178, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 24/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6745 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.7626 - acc: 0.9669 - val_loss: 1.2753 - val_acc: 0.7097

Epoch 00024: loss did not improve from 0.70178
Epoch 25/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6361 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.6281 - acc: 0.9835 - val_loss: 1.2224 - val_acc: 0.7097

Epoch 00025: loss improved from 0.70178 to 0.62806, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 26/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5819 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.6534 - acc: 0.9752 - val_loss: 1.2872 - val_acc: 0.7419

Epoch 00026: loss did not improve from 0.62806
Epoch 27/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7390 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.6364 - acc: 0.9917 - val_loss: 1.2888 - val_acc: 0.7742

Epoch 00027: loss did not improve from 0.62806
Epoch 28/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7452 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.6615 - acc: 0.9504 - val_loss: 1.2338 - val_acc: 0.7419

Epoch 00028: loss did not improve from 0.62806
Epoch 29/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8646 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.6949 - acc: 0.9669 - val_loss: 1.5155 - val_acc: 0.7742

Epoch 00029: loss did not improve from 0.62806
Epoch 30/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5413 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.5914 - acc: 0.9917 - val_loss: 1.3956 - val_acc: 0.7742

Epoch 00030: loss improved from 0.62806 to 0.59143, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 31/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5328 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.6033 - acc: 0.9752 - val_loss: 1.2789 - val_acc: 0.7742

Epoch 00031: loss did not improve from 0.59143
Epoch 32/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5439 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.6027 - acc: 0.9669 - val_loss: 1.2780 - val_acc: 0.8065

Epoch 00032: loss did not improve from 0.59143
Epoch 33/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5391 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.5558 - acc: 0.9917 - val_loss: 1.2060 - val_acc: 0.7097

Epoch 00033: loss improved from 0.59143 to 0.55581, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 34/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6017 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.5552 - acc: 0.9752 - val_loss: 1.2902 - val_acc: 0.7742

Epoch 00034: loss improved from 0.55581 to 0.55517, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_7.h5
Epoch 35/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5857 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.7110 - acc: 0.9421 - val_loss: 1.0942 - val_acc: 0.7742

Epoch 00035: loss did not improve from 0.55517
Epoch 36/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6243 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.5971 - acc: 0.9587 - val_loss: 1.0011 - val_acc: 0.8387

Epoch 00036: loss did not improve from 0.55517
Epoch 37/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6145 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.7748 - acc: 0.9669 - val_loss: 1.2293 - val_acc: 0.8065

Epoch 00037: loss did not improve from 0.55517
Epoch 38/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7533 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 0.6558 - acc: 0.9256 - val_loss: 0.9628 - val_acc: 0.8065

Epoch 00038: loss did not improve from 0.55517
Epoch 39/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5505 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.6150 - acc: 0.9752 - val_loss: 1.0445 - val_acc: 0.7742
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:03<00:18,  1.66s/it]
Epoch 00039: loss did not improve from 0.55517
Epoch 00039: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 3.5266 - acc: 0.4688
121/121 [==============================] - 0s 2ms/step - loss: 2.3664 - acc: 0.6612 - val_loss: 1.6665 - val_acc: 0.6452

Epoch 00001: loss improved from inf to 2.36643, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5757 - acc: 0.6875
121/121 [==============================] - 0s 37us/step - loss: 1.5115 - acc: 0.7851 - val_loss: 1.3970 - val_acc: 0.6774

Epoch 00002: loss improved from 2.36643 to 1.51149, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2585 - acc: 0.8125
121/121 [==============================] - 0s 34us/step - loss: 1.5673 - acc: 0.7686 - val_loss: 1.5404 - val_acc: 0.7419

Epoch 00003: loss did not improve from 1.51149
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3056 - acc: 0.7812
121/121 [==============================] - 0s 33us/step - loss: 1.3214 - acc: 0.8182 - val_loss: 1.3525 - val_acc: 0.7419

Epoch 00004: loss improved from 1.51149 to 1.32140, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2388 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.3413 - acc: 0.8347 - val_loss: 1.4239 - val_acc: 0.7742

Epoch 00005: loss did not improve from 1.32140
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3184 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.4405 - acc: 0.8430 - val_loss: 1.3836 - val_acc: 0.7742

Epoch 00006: loss did not improve from 1.32140
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1481 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.4017 - acc: 0.8512 - val_loss: 1.2939 - val_acc: 0.7419

Epoch 00007: loss did not improve from 1.32140
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1260 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.1827 - acc: 0.8843 - val_loss: 1.3013 - val_acc: 0.7419

Epoch 00008: loss improved from 1.32140 to 1.18273, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1126 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.2047 - acc: 0.8843 - val_loss: 1.2147 - val_acc: 0.7742

Epoch 00009: loss did not improve from 1.18273
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9575 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.2947 - acc: 0.8512 - val_loss: 1.2918 - val_acc: 0.7097

Epoch 00010: loss did not improve from 1.18273
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8988 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.0646 - acc: 0.9174 - val_loss: 1.3373 - val_acc: 0.6774

Epoch 00011: loss improved from 1.18273 to 1.06463, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0988 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.2235 - acc: 0.8430 - val_loss: 1.5300 - val_acc: 0.6774

Epoch 00012: loss did not improve from 1.06463
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0933 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.0849 - acc: 0.8760 - val_loss: 1.3519 - val_acc: 0.6774

Epoch 00013: loss did not improve from 1.06463
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8689 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 0.9116 - acc: 0.9091 - val_loss: 1.3138 - val_acc: 0.6774

Epoch 00014: loss improved from 1.06463 to 0.91157, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8429 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.9243 - acc: 0.9421 - val_loss: 1.2993 - val_acc: 0.6129

Epoch 00015: loss did not improve from 0.91157
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8006 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.8910 - acc: 0.9752 - val_loss: 1.3594 - val_acc: 0.6452

Epoch 00016: loss improved from 0.91157 to 0.89103, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8363 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 0.8870 - acc: 0.9504 - val_loss: 1.4253 - val_acc: 0.6129

Epoch 00017: loss improved from 0.89103 to 0.88703, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7426 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.7582 - acc: 0.9669 - val_loss: 1.3326 - val_acc: 0.6774

Epoch 00018: loss improved from 0.88703 to 0.75818, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6911 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.7577 - acc: 0.9669 - val_loss: 1.2761 - val_acc: 0.7097

Epoch 00019: loss improved from 0.75818 to 0.75773, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 20/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6852 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.6876 - acc: 0.9835 - val_loss: 1.2076 - val_acc: 0.6452

Epoch 00020: loss improved from 0.75773 to 0.68759, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 21/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7254 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.7046 - acc: 0.9917 - val_loss: 1.0806 - val_acc: 0.7419

Epoch 00021: loss did not improve from 0.68759
Epoch 22/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7512 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.6735 - acc: 0.9835 - val_loss: 1.3132 - val_acc: 0.7742

Epoch 00022: loss improved from 0.68759 to 0.67349, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 23/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6287 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.6636 - acc: 0.9669 - val_loss: 1.1567 - val_acc: 0.6774

Epoch 00023: loss improved from 0.67349 to 0.66363, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_8.h5
Epoch 24/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7079 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.6685 - acc: 0.9835 - val_loss: 1.2053 - val_acc: 0.7742

Epoch 00024: loss did not improve from 0.66363
Epoch 25/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5945 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.8154 - acc: 0.9587 - val_loss: 1.0306 - val_acc: 0.7419

Epoch 00025: loss did not improve from 0.66363
Epoch 26/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6343 - acc: 0.9688
121/121 [==============================] - 0s 31us/step - loss: 0.6730 - acc: 0.9669 - val_loss: 1.2054 - val_acc: 0.6452

Epoch 00026: loss did not improve from 0.66363
Epoch 27/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7013 - acc: 0.9688
121/121 [==============================] - 0s 31us/step - loss: 0.6985 - acc: 0.9669 - val_loss: 1.1417 - val_acc: 0.6774

Epoch 00027: loss did not improve from 0.66363
Epoch 28/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6461 - acc: 0.9688
121/121 [==============================] - 0s 31us/step - loss: 0.9105 - acc: 0.9421 - val_loss: 1.5918 - val_acc: 0.6452
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:04<00:16,  1.67s/it]
Epoch 00028: loss did not improve from 0.66363
Epoch 00028: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.7473 - acc: 0.5000
121/121 [==============================] - 0s 2ms/step - loss: 2.1391 - acc: 0.6612 - val_loss: 1.5747 - val_acc: 0.7097

Epoch 00001: loss improved from inf to 2.13915, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.7690 - acc: 0.6562
121/121 [==============================] - 0s 38us/step - loss: 1.7849 - acc: 0.7107 - val_loss: 1.5996 - val_acc: 0.7097

Epoch 00002: loss improved from 2.13915 to 1.78492, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3531 - acc: 0.7812
121/121 [==============================] - 0s 34us/step - loss: 1.6968 - acc: 0.7686 - val_loss: 1.5519 - val_acc: 0.7097

Epoch 00003: loss improved from 1.78492 to 1.69681, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5983 - acc: 0.7188
121/121 [==============================] - 0s 34us/step - loss: 1.5509 - acc: 0.7769 - val_loss: 1.5431 - val_acc: 0.7097

Epoch 00004: loss improved from 1.69681 to 1.55090, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4056 - acc: 0.7812
121/121 [==============================] - 0s 34us/step - loss: 1.4540 - acc: 0.7934 - val_loss: 1.4674 - val_acc: 0.7097

Epoch 00005: loss improved from 1.55090 to 1.45400, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1866 - acc: 0.8438
121/121 [==============================] - 0s 33us/step - loss: 1.2239 - acc: 0.8595 - val_loss: 1.4328 - val_acc: 0.7097

Epoch 00006: loss improved from 1.45400 to 1.22389, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1068 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.0579 - acc: 0.9174 - val_loss: 1.4009 - val_acc: 0.6452

Epoch 00007: loss improved from 1.22389 to 1.05794, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9815 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 0.9896 - acc: 0.9174 - val_loss: 1.4464 - val_acc: 0.6452

Epoch 00008: loss improved from 1.05794 to 0.98964, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9378 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.0237 - acc: 0.9091 - val_loss: 1.5831 - val_acc: 0.6774

Epoch 00009: loss did not improve from 0.98964
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9131 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 1.0300 - acc: 0.9504 - val_loss: 1.4468 - val_acc: 0.6774

Epoch 00010: loss did not improve from 0.98964
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2244 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 1.0027 - acc: 0.9256 - val_loss: 1.2597 - val_acc: 0.7097

Epoch 00011: loss did not improve from 0.98964
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9336 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 0.9506 - acc: 0.9421 - val_loss: 1.7242 - val_acc: 0.7742

Epoch 00012: loss improved from 0.98964 to 0.95061, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2657 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.1048 - acc: 0.9339 - val_loss: 1.5406 - val_acc: 0.6774

Epoch 00013: loss did not improve from 0.95061
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0341 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.0880 - acc: 0.9421 - val_loss: 1.5762 - val_acc: 0.6774

Epoch 00014: loss did not improve from 0.95061
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8758 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.9343 - acc: 0.9421 - val_loss: 1.5347 - val_acc: 0.6774

Epoch 00015: loss improved from 0.95061 to 0.93427, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8776 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.9658 - acc: 0.9587 - val_loss: 1.6532 - val_acc: 0.4839

Epoch 00016: loss did not improve from 0.93427
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2320 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.9878 - acc: 0.9504 - val_loss: 1.3753 - val_acc: 0.7097

Epoch 00017: loss did not improve from 0.93427
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8656 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.8827 - acc: 0.9669 - val_loss: 1.3379 - val_acc: 0.7097

Epoch 00018: loss improved from 0.93427 to 0.88268, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8533 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.8737 - acc: 0.9669 - val_loss: 1.3332 - val_acc: 0.7097

Epoch 00019: loss improved from 0.88268 to 0.87372, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 20/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7601 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.7402 - acc: 0.9835 - val_loss: 1.2871 - val_acc: 0.7097

Epoch 00020: loss improved from 0.87372 to 0.74023, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 21/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8114 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.7901 - acc: 0.9752 - val_loss: 1.7534 - val_acc: 0.7097

Epoch 00021: loss did not improve from 0.74023
Epoch 22/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8714 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 0.8341 - acc: 0.9504 - val_loss: 1.5029 - val_acc: 0.7097

Epoch 00022: loss did not improve from 0.74023
Epoch 23/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9199 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 1.1720 - acc: 0.9339 - val_loss: 1.8354 - val_acc: 0.8065

Epoch 00023: loss did not improve from 0.74023
Epoch 24/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2295 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.0447 - acc: 0.9256 - val_loss: 1.4540 - val_acc: 0.7742

Epoch 00024: loss did not improve from 0.74023
Epoch 25/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7563 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.7346 - acc: 0.9752 - val_loss: 1.5597 - val_acc: 0.8065

Epoch 00025: loss improved from 0.74023 to 0.73463, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_9.h5
Epoch 26/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7441 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 1.0370 - acc: 0.9421 - val_loss: 2.2577 - val_acc: 0.7742

Epoch 00026: loss did not improve from 0.73463
Epoch 27/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2201 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.0525 - acc: 0.9008 - val_loss: 1.6074 - val_acc: 0.7097

Epoch 00027: loss did not improve from 0.73463
Epoch 28/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9341 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.8245 - acc: 0.9587 - val_loss: 1.4623 - val_acc: 0.7742

Epoch 00028: loss did not improve from 0.73463
Epoch 29/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0710 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.8992 - acc: 0.9504 - val_loss: 1.8275 - val_acc: 0.8065

Epoch 00029: loss did not improve from 0.73463
Epoch 30/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0133 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.0384 - acc: 0.9256 - val_loss: 1.3826 - val_acc: 0.8065
DeepAmes+ Weights:  31%|███       | 4/13 [00:06<00:14,  1.64s/it]
Epoch 00030: loss did not improve from 0.73463
Epoch 00030: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.3248 - acc: 0.5938
121/121 [==============================] - 0s 2ms/step - loss: 2.7712 - acc: 0.5620 - val_loss: 2.0119 - val_acc: 0.7419

Epoch 00001: loss improved from inf to 2.77122, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.1611 - acc: 0.7500
121/121 [==============================] - 0s 38us/step - loss: 1.9553 - acc: 0.7686 - val_loss: 1.6530 - val_acc: 0.6774

Epoch 00002: loss improved from 2.77122 to 1.95528, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.3080 - acc: 0.6250
121/121 [==============================] - 0s 35us/step - loss: 1.8526 - acc: 0.7355 - val_loss: 1.5656 - val_acc: 0.6452

Epoch 00003: loss improved from 1.95528 to 1.85261, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4576 - acc: 0.6875
121/121 [==============================] - 0s 35us/step - loss: 1.4395 - acc: 0.7769 - val_loss: 1.5485 - val_acc: 0.6774

Epoch 00004: loss improved from 1.85261 to 1.43949, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6887 - acc: 0.7812
121/121 [==============================] - 0s 34us/step - loss: 1.4058 - acc: 0.8099 - val_loss: 1.4147 - val_acc: 0.6452

Epoch 00005: loss improved from 1.43949 to 1.40579, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3284 - acc: 0.7812
121/121 [==============================] - 0s 34us/step - loss: 1.4892 - acc: 0.7769 - val_loss: 1.4555 - val_acc: 0.6774

Epoch 00006: loss did not improve from 1.40579
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4992 - acc: 0.7188
121/121 [==============================] - 0s 33us/step - loss: 1.1793 - acc: 0.8430 - val_loss: 1.3241 - val_acc: 0.6774

Epoch 00007: loss improved from 1.40579 to 1.17926, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5151 - acc: 0.8438
121/121 [==============================] - 0s 34us/step - loss: 1.2609 - acc: 0.8595 - val_loss: 1.4218 - val_acc: 0.7097

Epoch 00008: loss did not improve from 1.17926
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1238 - acc: 0.7812
121/121 [==============================] - 0s 33us/step - loss: 1.0215 - acc: 0.8760 - val_loss: 1.3556 - val_acc: 0.6774

Epoch 00009: loss improved from 1.17926 to 1.02150, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0072 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 1.2211 - acc: 0.8926 - val_loss: 1.3879 - val_acc: 0.7097

Epoch 00010: loss did not improve from 1.02150
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1192 - acc: 0.8438
121/121 [==============================] - 0s 33us/step - loss: 1.0342 - acc: 0.8843 - val_loss: 1.3770 - val_acc: 0.7097

Epoch 00011: loss did not improve from 1.02150
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0819 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.0137 - acc: 0.8926 - val_loss: 1.2845 - val_acc: 0.7419

Epoch 00012: loss improved from 1.02150 to 1.01371, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0062 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.9015 - acc: 0.9256 - val_loss: 1.3634 - val_acc: 0.7419

Epoch 00013: loss improved from 1.01371 to 0.90147, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8527 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.8273 - acc: 0.9504 - val_loss: 1.3432 - val_acc: 0.6774

Epoch 00014: loss improved from 0.90147 to 0.82733, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_10.h5
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1148 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.1769 - acc: 0.9174 - val_loss: 1.7575 - val_acc: 0.7742

Epoch 00015: loss did not improve from 0.82733
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4966 - acc: 0.8438
121/121 [==============================] - 0s 33us/step - loss: 1.1419 - acc: 0.9174 - val_loss: 1.2785 - val_acc: 0.6774

Epoch 00016: loss did not improve from 0.82733
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0236 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 0.8315 - acc: 0.9504 - val_loss: 1.4338 - val_acc: 0.6129

Epoch 00017: loss did not improve from 0.82733
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9376 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.2656 - acc: 0.8926 - val_loss: 1.4569 - val_acc: 0.7742

Epoch 00018: loss did not improve from 0.82733
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2703 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.0798 - acc: 0.9421 - val_loss: 1.1963 - val_acc: 0.6452
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:08<00:13,  1.64s/it]
Epoch 00019: loss did not improve from 0.82733
Epoch 00019: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.6023 - acc: 0.5938
121/121 [==============================] - 0s 2ms/step - loss: 2.6266 - acc: 0.6116 - val_loss: 2.1795 - val_acc: 0.7097

Epoch 00001: loss improved from inf to 2.62663, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.4528 - acc: 0.6875
121/121 [==============================] - 0s 37us/step - loss: 2.0333 - acc: 0.7438 - val_loss: 1.7403 - val_acc: 0.6774

Epoch 00002: loss improved from 2.62663 to 2.03329, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.8568 - acc: 0.7500
121/121 [==============================] - 0s 34us/step - loss: 1.6699 - acc: 0.7686 - val_loss: 1.6642 - val_acc: 0.7097

Epoch 00003: loss improved from 2.03329 to 1.66988, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6428 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.5457 - acc: 0.8099 - val_loss: 1.6246 - val_acc: 0.7097

Epoch 00004: loss improved from 1.66988 to 1.54574, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3098 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.3893 - acc: 0.8430 - val_loss: 1.5515 - val_acc: 0.7097

Epoch 00005: loss improved from 1.54574 to 1.38930, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3013 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.4982 - acc: 0.8347 - val_loss: 1.8872 - val_acc: 0.7419

Epoch 00006: loss did not improve from 1.38930
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6259 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.4853 - acc: 0.8926 - val_loss: 1.5549 - val_acc: 0.6774

Epoch 00007: loss did not improve from 1.38930
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1789 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.4739 - acc: 0.8843 - val_loss: 1.6205 - val_acc: 0.7419

Epoch 00008: loss did not improve from 1.38930
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3921 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.2855 - acc: 0.8926 - val_loss: 1.5315 - val_acc: 0.6452

Epoch 00009: loss improved from 1.38930 to 1.28550, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1814 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.1972 - acc: 0.9008 - val_loss: 1.3562 - val_acc: 0.6452

Epoch 00010: loss improved from 1.28550 to 1.19721, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9759 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.3635 - acc: 0.8926 - val_loss: 1.8293 - val_acc: 0.7419

Epoch 00011: loss did not improve from 1.19721
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3971 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.2883 - acc: 0.9174 - val_loss: 1.5035 - val_acc: 0.6774

Epoch 00012: loss did not improve from 1.19721
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3007 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.1215 - acc: 0.9421 - val_loss: 1.3224 - val_acc: 0.6774

Epoch 00013: loss improved from 1.19721 to 1.12154, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1747 - acc: 0.9688
121/121 [==============================] - 0s 34us/step - loss: 1.0804 - acc: 0.9091 - val_loss: 1.4988 - val_acc: 0.7742

Epoch 00014: loss improved from 1.12154 to 1.08038, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0033 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.1530 - acc: 0.9256 - val_loss: 1.3442 - val_acc: 0.7097

Epoch 00015: loss did not improve from 1.08038
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9873 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 1.0782 - acc: 0.9256 - val_loss: 1.3703 - val_acc: 0.7419

Epoch 00016: loss improved from 1.08038 to 1.07820, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9191 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 0.9467 - acc: 0.9256 - val_loss: 1.4370 - val_acc: 0.6774

Epoch 00017: loss improved from 1.07820 to 0.94672, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8558 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.0342 - acc: 0.9174 - val_loss: 1.5604 - val_acc: 0.7419

Epoch 00018: loss did not improve from 0.94672
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0936 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 1.0511 - acc: 0.9504 - val_loss: 1.4483 - val_acc: 0.7097

Epoch 00019: loss did not improve from 0.94672
Epoch 20/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8537 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.8807 - acc: 0.9421 - val_loss: 1.4499 - val_acc: 0.6774

Epoch 00020: loss improved from 0.94672 to 0.88072, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 21/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8736 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.8878 - acc: 0.9669 - val_loss: 1.4426 - val_acc: 0.6452

Epoch 00021: loss did not improve from 0.88072
Epoch 22/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8405 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.9759 - acc: 0.9256 - val_loss: 1.2985 - val_acc: 0.7419

Epoch 00022: loss did not improve from 0.88072
Epoch 23/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7732 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.8781 - acc: 0.9504 - val_loss: 1.3034 - val_acc: 0.7419

Epoch 00023: loss improved from 0.88072 to 0.87806, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 24/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7805 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 1.0588 - acc: 0.9504 - val_loss: 1.4204 - val_acc: 0.7742

Epoch 00024: loss did not improve from 0.87806
Epoch 25/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7593 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.7730 - acc: 0.9752 - val_loss: 1.4690 - val_acc: 0.7742

Epoch 00025: loss improved from 0.87806 to 0.77303, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 26/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8857 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.8807 - acc: 0.9504 - val_loss: 1.2364 - val_acc: 0.7419

Epoch 00026: loss did not improve from 0.77303
Epoch 27/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6679 - acc: 1.0000
121/121 [==============================] - 0s 31us/step - loss: 0.7242 - acc: 0.9752 - val_loss: 1.2406 - val_acc: 0.7419

Epoch 00027: loss improved from 0.77303 to 0.72422, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 28/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7667 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.7248 - acc: 0.9587 - val_loss: 1.1936 - val_acc: 0.7419

Epoch 00028: loss did not improve from 0.72422
Epoch 29/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6880 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.7416 - acc: 0.9669 - val_loss: 1.2277 - val_acc: 0.7419

Epoch 00029: loss did not improve from 0.72422
Epoch 30/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8107 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.7189 - acc: 0.9587 - val_loss: 1.2552 - val_acc: 0.7419

Epoch 00030: loss improved from 0.72422 to 0.71891, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 31/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6276 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.6142 - acc: 0.9917 - val_loss: 1.2523 - val_acc: 0.7742

Epoch 00031: loss improved from 0.71891 to 0.61420, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_11.h5
Epoch 32/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6126 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.6872 - acc: 0.9669 - val_loss: 1.3034 - val_acc: 0.8065

Epoch 00032: loss did not improve from 0.61420
Epoch 33/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6065 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.7476 - acc: 0.9917 - val_loss: 1.5429 - val_acc: 0.7742

Epoch 00033: loss did not improve from 0.61420
Epoch 34/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1495 - acc: 0.9062
121/121 [==============================] - 0s 31us/step - loss: 1.0080 - acc: 0.9174 - val_loss: 1.5963 - val_acc: 0.7097

Epoch 00034: loss did not improve from 0.61420
Epoch 35/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6652 - acc: 1.0000
121/121 [==============================] - 0s 31us/step - loss: 0.7325 - acc: 0.9752 - val_loss: 1.5330 - val_acc: 0.7419

Epoch 00035: loss did not improve from 0.61420
Epoch 36/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.5889 - acc: 1.0000
121/121 [==============================] - 0s 31us/step - loss: 0.6414 - acc: 0.9835 - val_loss: 1.5991 - val_acc: 0.7097
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:09<00:11,  1.68s/it]
Epoch 00036: loss did not improve from 0.61420
Epoch 00036: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 3.9696 - acc: 0.5312
121/121 [==============================] - 0s 2ms/step - loss: 2.7895 - acc: 0.6364 - val_loss: 2.0040 - val_acc: 0.7419

Epoch 00001: loss improved from inf to 2.78948, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.8702 - acc: 0.6875
121/121 [==============================] - 0s 37us/step - loss: 1.8932 - acc: 0.7521 - val_loss: 1.6306 - val_acc: 0.7742

Epoch 00002: loss improved from 2.78948 to 1.89320, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6114 - acc: 0.7500
121/121 [==============================] - 0s 34us/step - loss: 2.4613 - acc: 0.7273 - val_loss: 1.9755 - val_acc: 0.6452

Epoch 00003: loss did not improve from 1.89320
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.1486 - acc: 0.7188
121/121 [==============================] - 0s 33us/step - loss: 1.9499 - acc: 0.7603 - val_loss: 1.7185 - val_acc: 0.7419

Epoch 00004: loss did not improve from 1.89320
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5738 - acc: 0.7188
121/121 [==============================] - 0s 32us/step - loss: 1.5914 - acc: 0.7934 - val_loss: 1.6181 - val_acc: 0.7419

Epoch 00005: loss improved from 1.89320 to 1.59144, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5799 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.4007 - acc: 0.8430 - val_loss: 1.4331 - val_acc: 0.7419

Epoch 00006: loss improved from 1.59144 to 1.40066, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2628 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.2380 - acc: 0.8347 - val_loss: 1.5162 - val_acc: 0.5806

Epoch 00007: loss improved from 1.40066 to 1.23799, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2204 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.3100 - acc: 0.8512 - val_loss: 1.4361 - val_acc: 0.6452

Epoch 00008: loss did not improve from 1.23799
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2460 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.3032 - acc: 0.8678 - val_loss: 1.5048 - val_acc: 0.6129

Epoch 00009: loss did not improve from 1.23799
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4336 - acc: 0.8125
121/121 [==============================] - 0s 34us/step - loss: 1.2786 - acc: 0.8347 - val_loss: 1.4118 - val_acc: 0.7097

Epoch 00010: loss did not improve from 1.23799
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0492 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.1411 - acc: 0.8595 - val_loss: 1.4313 - val_acc: 0.6774

Epoch 00011: loss improved from 1.23799 to 1.14107, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0632 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.0695 - acc: 0.9008 - val_loss: 1.3813 - val_acc: 0.6774

Epoch 00012: loss improved from 1.14107 to 1.06946, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8849 - acc: 0.9688
121/121 [==============================] - 0s 34us/step - loss: 1.0039 - acc: 0.9421 - val_loss: 1.3250 - val_acc: 0.7097

Epoch 00013: loss improved from 1.06946 to 1.00387, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_12.h5
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0061 - acc: 0.8750
121/121 [==============================] - 0s 34us/step - loss: 1.1974 - acc: 0.8926 - val_loss: 1.2795 - val_acc: 0.6452

Epoch 00014: loss did not improve from 1.00387
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0007 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.0932 - acc: 0.9256 - val_loss: 1.7583 - val_acc: 0.7097

Epoch 00015: loss did not improve from 1.00387
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1190 - acc: 0.8438
121/121 [==============================] - 0s 33us/step - loss: 1.0391 - acc: 0.9174 - val_loss: 1.3091 - val_acc: 0.7419

Epoch 00016: loss did not improve from 1.00387
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3173 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.1219 - acc: 0.8926 - val_loss: 1.2988 - val_acc: 0.7419

Epoch 00017: loss did not improve from 1.00387
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8622 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.1949 - acc: 0.9256 - val_loss: 1.6192 - val_acc: 0.8065
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:11<00:09,  1.62s/it]
Epoch 00018: loss did not improve from 1.00387
Epoch 00018: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 3.1185 - acc: 0.5000
121/121 [==============================] - 0s 2ms/step - loss: 2.9287 - acc: 0.6281 - val_loss: 2.5009 - val_acc: 0.7097

Epoch 00001: loss improved from inf to 2.92868, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.5206 - acc: 0.6875
121/121 [==============================] - 0s 39us/step - loss: 2.2230 - acc: 0.7355 - val_loss: 1.9462 - val_acc: 0.6774

Epoch 00002: loss improved from 2.92868 to 2.22297, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.9327 - acc: 0.7500
121/121 [==============================] - 0s 35us/step - loss: 1.8376 - acc: 0.7934 - val_loss: 1.7662 - val_acc: 0.6774

Epoch 00003: loss improved from 2.22297 to 1.83764, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.7671 - acc: 0.7188
121/121 [==============================] - 0s 34us/step - loss: 1.7535 - acc: 0.7521 - val_loss: 1.8226 - val_acc: 0.6774

Epoch 00004: loss improved from 1.83764 to 1.75355, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6271 - acc: 0.8125
121/121 [==============================] - 0s 34us/step - loss: 1.7888 - acc: 0.8017 - val_loss: 1.8043 - val_acc: 0.6774

Epoch 00005: loss did not improve from 1.75355
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5736 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.4858 - acc: 0.8347 - val_loss: 1.6949 - val_acc: 0.6452

Epoch 00006: loss improved from 1.75355 to 1.48582, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4731 - acc: 0.8438
121/121 [==============================] - 0s 34us/step - loss: 1.4352 - acc: 0.8512 - val_loss: 1.5486 - val_acc: 0.6452

Epoch 00007: loss improved from 1.48582 to 1.43521, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2425 - acc: 0.8438
121/121 [==============================] - 0s 34us/step - loss: 1.5339 - acc: 0.8264 - val_loss: 1.8929 - val_acc: 0.6774

Epoch 00008: loss did not improve from 1.43521
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4970 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.3229 - acc: 0.8512 - val_loss: 1.5782 - val_acc: 0.6774

Epoch 00009: loss improved from 1.43521 to 1.32292, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3736 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.2712 - acc: 0.8926 - val_loss: 1.5175 - val_acc: 0.7097

Epoch 00010: loss improved from 1.32292 to 1.27115, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2775 - acc: 0.9688
121/121 [==============================] - 0s 34us/step - loss: 1.2446 - acc: 0.9091 - val_loss: 1.7089 - val_acc: 0.6774

Epoch 00011: loss improved from 1.27115 to 1.24457, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1713 - acc: 0.8438
121/121 [==============================] - 0s 34us/step - loss: 1.2573 - acc: 0.9091 - val_loss: 1.9565 - val_acc: 0.6774

Epoch 00012: loss did not improve from 1.24457
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2729 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.6005 - acc: 0.9008 - val_loss: 1.7984 - val_acc: 0.6774

Epoch 00013: loss did not improve from 1.24457
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3291 - acc: 0.7812
121/121 [==============================] - 0s 32us/step - loss: 1.2505 - acc: 0.8595 - val_loss: 1.4452 - val_acc: 0.7097

Epoch 00014: loss did not improve from 1.24457
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3615 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.2441 - acc: 0.9008 - val_loss: 1.4284 - val_acc: 0.7097

Epoch 00015: loss improved from 1.24457 to 1.24414, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9607 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 1.0932 - acc: 0.9091 - val_loss: 1.7188 - val_acc: 0.7097

Epoch 00016: loss improved from 1.24414 to 1.09318, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_13.h5
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3166 - acc: 0.8438
121/121 [==============================] - 0s 34us/step - loss: 1.2308 - acc: 0.8843 - val_loss: 1.6818 - val_acc: 0.6774

Epoch 00017: loss did not improve from 1.09318
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2913 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.3094 - acc: 0.9008 - val_loss: 1.9810 - val_acc: 0.7097

Epoch 00018: loss did not improve from 1.09318
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3111 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.1863 - acc: 0.9174 - val_loss: 1.4775 - val_acc: 0.6774

Epoch 00019: loss did not improve from 1.09318
Epoch 20/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9336 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.4184 - acc: 0.9174 - val_loss: 1.5675 - val_acc: 0.6452

Epoch 00020: loss did not improve from 1.09318
Epoch 21/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3674 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.3163 - acc: 0.9091 - val_loss: 1.5655 - val_acc: 0.5161
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:13<00:08,  1.64s/it]
Epoch 00021: loss did not improve from 1.09318
Epoch 00021: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 3.3926 - acc: 0.5312
121/121 [==============================] - 0s 2ms/step - loss: 3.7042 - acc: 0.6198 - val_loss: 2.7546 - val_acc: 0.6774

Epoch 00001: loss improved from inf to 3.70417, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.5163 - acc: 0.6562
121/121 [==============================] - 0s 38us/step - loss: 2.2732 - acc: 0.7273 - val_loss: 1.9877 - val_acc: 0.6774

Epoch 00002: loss improved from 3.70417 to 2.27317, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.8382 - acc: 0.6875
121/121 [==============================] - 0s 34us/step - loss: 1.8762 - acc: 0.7521 - val_loss: 1.7184 - val_acc: 0.6452

Epoch 00003: loss improved from 2.27317 to 1.87622, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6674 - acc: 0.6562
121/121 [==============================] - 0s 33us/step - loss: 1.7203 - acc: 0.7190 - val_loss: 1.7079 - val_acc: 0.6452

Epoch 00004: loss improved from 1.87622 to 1.72032, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5184 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.8195 - acc: 0.7521 - val_loss: 1.8741 - val_acc: 0.6452

Epoch 00005: loss did not improve from 1.72032
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.7057 - acc: 0.7188
121/121 [==============================] - 0s 32us/step - loss: 1.6124 - acc: 0.7603 - val_loss: 1.7190 - val_acc: 0.6452

Epoch 00006: loss improved from 1.72032 to 1.61237, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4807 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.5202 - acc: 0.7603 - val_loss: 1.6112 - val_acc: 0.6129

Epoch 00007: loss improved from 1.61237 to 1.52023, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3540 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.3922 - acc: 0.8182 - val_loss: 1.6633 - val_acc: 0.6452

Epoch 00008: loss improved from 1.52023 to 1.39224, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3508 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.5500 - acc: 0.8264 - val_loss: 1.7074 - val_acc: 0.6774

Epoch 00009: loss did not improve from 1.39224
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3757 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.4581 - acc: 0.8099 - val_loss: 1.7392 - val_acc: 0.6452

Epoch 00010: loss did not improve from 1.39224
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4040 - acc: 0.7500
121/121 [==============================] - 0s 32us/step - loss: 1.3554 - acc: 0.8347 - val_loss: 1.5879 - val_acc: 0.6452

Epoch 00011: loss improved from 1.39224 to 1.35538, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2184 - acc: 0.7500
121/121 [==============================] - 0s 41us/step - loss: 1.4334 - acc: 0.8264 - val_loss: 1.6000 - val_acc: 0.7097

Epoch 00012: loss did not improve from 1.35538
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2751 - acc: 0.8438
121/121 [==============================] - 0s 34us/step - loss: 1.1942 - acc: 0.8926 - val_loss: 1.5809 - val_acc: 0.6774

Epoch 00013: loss improved from 1.35538 to 1.19422, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0048 - acc: 0.9062
121/121 [==============================] - 0s 34us/step - loss: 1.0435 - acc: 0.8843 - val_loss: 1.6074 - val_acc: 0.6129

Epoch 00014: loss improved from 1.19422 to 1.04352, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1073 - acc: 0.9688
121/121 [==============================] - 0s 34us/step - loss: 1.1111 - acc: 0.8760 - val_loss: 1.4516 - val_acc: 0.6452

Epoch 00015: loss did not improve from 1.04352
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8305 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 1.0594 - acc: 0.9091 - val_loss: 1.4414 - val_acc: 0.6452

Epoch 00016: loss did not improve from 1.04352
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0312 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.1143 - acc: 0.8926 - val_loss: 1.4749 - val_acc: 0.6129

Epoch 00017: loss did not improve from 1.04352
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9153 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 0.9544 - acc: 0.9091 - val_loss: 1.3892 - val_acc: 0.6452

Epoch 00018: loss improved from 1.04352 to 0.95444, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7939 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.8891 - acc: 0.9587 - val_loss: 1.3239 - val_acc: 0.7097

Epoch 00019: loss improved from 0.95444 to 0.88907, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 20/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8631 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.1225 - acc: 0.9008 - val_loss: 1.8529 - val_acc: 0.6774

Epoch 00020: loss did not improve from 0.88907
Epoch 21/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2778 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.2282 - acc: 0.8760 - val_loss: 1.6089 - val_acc: 0.6774

Epoch 00021: loss did not improve from 0.88907
Epoch 22/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9566 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.0410 - acc: 0.9008 - val_loss: 1.6872 - val_acc: 0.7097

Epoch 00022: loss did not improve from 0.88907
Epoch 23/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0464 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 0.9606 - acc: 0.9174 - val_loss: 1.4604 - val_acc: 0.6452

Epoch 00023: loss did not improve from 0.88907
Epoch 24/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8004 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 0.7746 - acc: 0.9504 - val_loss: 1.3965 - val_acc: 0.6129

Epoch 00024: loss improved from 0.88907 to 0.77462, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 25/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8396 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.7742 - acc: 0.9587 - val_loss: 1.4768 - val_acc: 0.6129

Epoch 00025: loss improved from 0.77462 to 0.77420, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 26/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8281 - acc: 1.0000
121/121 [==============================] - 0s 33us/step - loss: 0.8832 - acc: 0.9504 - val_loss: 1.4925 - val_acc: 0.6129

Epoch 00026: loss did not improve from 0.77420
Epoch 27/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7789 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.7623 - acc: 0.9752 - val_loss: 1.5326 - val_acc: 0.6129

Epoch 00027: loss improved from 0.77420 to 0.76228, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 28/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7303 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.8439 - acc: 0.9339 - val_loss: 1.3623 - val_acc: 0.6452

Epoch 00028: loss did not improve from 0.76228
Epoch 29/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6875 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 0.7808 - acc: 0.9504 - val_loss: 1.3632 - val_acc: 0.6129

Epoch 00029: loss did not improve from 0.76228
Epoch 30/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7203 - acc: 0.9688
121/121 [==============================] - 0s 31us/step - loss: 0.6884 - acc: 0.9669 - val_loss: 1.4606 - val_acc: 0.6452

Epoch 00030: loss improved from 0.76228 to 0.68839, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_14.h5
Epoch 31/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6091 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.6904 - acc: 0.9835 - val_loss: 1.4343 - val_acc: 0.6452

Epoch 00031: loss did not improve from 0.68839
Epoch 32/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6595 - acc: 0.9375
121/121 [==============================] - 0s 31us/step - loss: 0.7327 - acc: 0.9752 - val_loss: 1.3503 - val_acc: 0.6452

Epoch 00032: loss did not improve from 0.68839
Epoch 33/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8178 - acc: 0.9688
121/121 [==============================] - 0s 31us/step - loss: 0.7727 - acc: 0.9504 - val_loss: 1.3104 - val_acc: 0.6452

Epoch 00033: loss did not improve from 0.68839
Epoch 34/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.6238 - acc: 1.0000
121/121 [==============================] - 0s 31us/step - loss: 0.9402 - acc: 0.9587 - val_loss: 1.5353 - val_acc: 0.6452

Epoch 00034: loss did not improve from 0.68839
Epoch 35/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8017 - acc: 0.8438
121/121 [==============================] - 0s 31us/step - loss: 0.7657 - acc: 0.9421 - val_loss: 1.4289 - val_acc: 0.6452
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:14<00:06,  1.67s/it]
Epoch 00035: loss did not improve from 0.68839
Epoch 00035: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 3.8670 - acc: 0.5938
121/121 [==============================] - 0s 2ms/step - loss: 2.6883 - acc: 0.6777 - val_loss: 1.9940 - val_acc: 0.6774

Epoch 00001: loss improved from inf to 2.68834, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4876 - acc: 0.7188
121/121 [==============================] - 0s 37us/step - loss: 1.8053 - acc: 0.7025 - val_loss: 1.8496 - val_acc: 0.6452

Epoch 00002: loss improved from 2.68834 to 1.80530, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5038 - acc: 0.8750
121/121 [==============================] - 0s 35us/step - loss: 2.4653 - acc: 0.7438 - val_loss: 2.0342 - val_acc: 0.7097

Epoch 00003: loss did not improve from 1.80530
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.9150 - acc: 0.7188
121/121 [==============================] - 0s 33us/step - loss: 1.9618 - acc: 0.7769 - val_loss: 1.7671 - val_acc: 0.6774

Epoch 00004: loss did not improve from 1.80530
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6439 - acc: 0.6562
121/121 [==============================] - 0s 33us/step - loss: 1.7989 - acc: 0.7273 - val_loss: 1.6052 - val_acc: 0.6774

Epoch 00005: loss improved from 1.80530 to 1.79886, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6007 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.8095 - acc: 0.7769 - val_loss: 1.9253 - val_acc: 0.6452

Epoch 00006: loss did not improve from 1.79886
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6076 - acc: 0.7812
121/121 [==============================] - 0s 32us/step - loss: 1.6658 - acc: 0.7851 - val_loss: 1.7486 - val_acc: 0.6452

Epoch 00007: loss improved from 1.79886 to 1.66585, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6455 - acc: 0.6875
121/121 [==============================] - 0s 33us/step - loss: 1.6375 - acc: 0.7769 - val_loss: 1.6109 - val_acc: 0.6452

Epoch 00008: loss improved from 1.66585 to 1.63753, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6199 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.5213 - acc: 0.7934 - val_loss: 1.6201 - val_acc: 0.6452

Epoch 00009: loss improved from 1.63753 to 1.52128, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3374 - acc: 0.7812
121/121 [==============================] - 0s 33us/step - loss: 1.3633 - acc: 0.8017 - val_loss: 1.5498 - val_acc: 0.5806

Epoch 00010: loss improved from 1.52128 to 1.36328, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4542 - acc: 0.8438
121/121 [==============================] - 0s 33us/step - loss: 1.3242 - acc: 0.8264 - val_loss: 1.4617 - val_acc: 0.6774

Epoch 00011: loss improved from 1.36328 to 1.32416, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1274 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.4025 - acc: 0.8678 - val_loss: 1.7508 - val_acc: 0.6774

Epoch 00012: loss did not improve from 1.32416
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5570 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.3883 - acc: 0.8760 - val_loss: 1.5194 - val_acc: 0.6774

Epoch 00013: loss did not improve from 1.32416
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1461 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.0713 - acc: 0.9174 - val_loss: 1.4153 - val_acc: 0.6774

Epoch 00014: loss improved from 1.32416 to 1.07134, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0526 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.0828 - acc: 0.8926 - val_loss: 1.6597 - val_acc: 0.7097

Epoch 00015: loss did not improve from 1.07134
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2387 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 1.3627 - acc: 0.8760 - val_loss: 1.7271 - val_acc: 0.6452

Epoch 00016: loss did not improve from 1.07134
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1431 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.1327 - acc: 0.8760 - val_loss: 1.8046 - val_acc: 0.6452

Epoch 00017: loss did not improve from 1.07134
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0401 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 1.0682 - acc: 0.9256 - val_loss: 1.6525 - val_acc: 0.6452

Epoch 00018: loss improved from 1.07134 to 1.06824, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1063 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.9805 - acc: 0.9091 - val_loss: 1.5418 - val_acc: 0.6452

Epoch 00019: loss improved from 1.06824 to 0.98053, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 20/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8229 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.9414 - acc: 0.9587 - val_loss: 1.4980 - val_acc: 0.6774

Epoch 00020: loss improved from 0.98053 to 0.94142, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 21/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9579 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.9343 - acc: 0.9587 - val_loss: 1.4884 - val_acc: 0.6452

Epoch 00021: loss improved from 0.94142 to 0.93431, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 22/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7901 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 0.7934 - acc: 0.9587 - val_loss: 1.3933 - val_acc: 0.7097

Epoch 00022: loss improved from 0.93431 to 0.79341, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_15.h5
Epoch 23/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9863 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 0.9011 - acc: 0.9091 - val_loss: 1.2173 - val_acc: 0.7419

Epoch 00023: loss did not improve from 0.79341
Epoch 24/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8600 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 0.8782 - acc: 0.9587 - val_loss: 1.4611 - val_acc: 0.6774

Epoch 00024: loss did not improve from 0.79341
Epoch 25/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9936 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 1.0473 - acc: 0.9587 - val_loss: 1.3555 - val_acc: 0.7419

Epoch 00025: loss did not improve from 0.79341
Epoch 26/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.7284 - acc: 0.9375
121/121 [==============================] - 0s 32us/step - loss: 0.8520 - acc: 0.9339 - val_loss: 1.3854 - val_acc: 0.7742

Epoch 00026: loss did not improve from 0.79341
Epoch 27/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9889 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 1.0119 - acc: 0.9256 - val_loss: 1.1495 - val_acc: 0.7742
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:16<00:05,  1.67s/it]
Epoch 00027: loss did not improve from 0.79341
Epoch 00027: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 3.8436 - acc: 0.5312
121/121 [==============================] - 0s 2ms/step - loss: 3.2599 - acc: 0.6694 - val_loss: 2.5715 - val_acc: 0.6774

Epoch 00001: loss improved from inf to 3.25991, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.2647 - acc: 0.6562
121/121 [==============================] - 0s 38us/step - loss: 2.2185 - acc: 0.7190 - val_loss: 1.9233 - val_acc: 0.7419

Epoch 00002: loss improved from 3.25991 to 2.21850, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.7763 - acc: 0.6875
121/121 [==============================] - 0s 34us/step - loss: 1.7899 - acc: 0.7107 - val_loss: 1.7486 - val_acc: 0.7419

Epoch 00003: loss improved from 2.21850 to 1.78989, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.7924 - acc: 0.7188
121/121 [==============================] - 0s 34us/step - loss: 1.6491 - acc: 0.7438 - val_loss: 1.5392 - val_acc: 0.7097

Epoch 00004: loss improved from 1.78989 to 1.64911, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6185 - acc: 0.7188
121/121 [==============================] - 0s 34us/step - loss: 1.6023 - acc: 0.7521 - val_loss: 1.5095 - val_acc: 0.7419

Epoch 00005: loss improved from 1.64911 to 1.60227, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5967 - acc: 0.8750
121/121 [==============================] - 0s 34us/step - loss: 1.6391 - acc: 0.8099 - val_loss: 1.4870 - val_acc: 0.7419

Epoch 00006: loss did not improve from 1.60227
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3748 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.4148 - acc: 0.8182 - val_loss: 1.3987 - val_acc: 0.7742

Epoch 00007: loss improved from 1.60227 to 1.41481, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5863 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.5817 - acc: 0.8017 - val_loss: 1.5970 - val_acc: 0.6452

Epoch 00008: loss did not improve from 1.41481
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2613 - acc: 0.7500
121/121 [==============================] - 0s 32us/step - loss: 1.3341 - acc: 0.8182 - val_loss: 1.7983 - val_acc: 0.6452

Epoch 00009: loss improved from 1.41481 to 1.33405, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5668 - acc: 0.6875
121/121 [==============================] - 0s 34us/step - loss: 1.4170 - acc: 0.8182 - val_loss: 1.5241 - val_acc: 0.6452

Epoch 00010: loss did not improve from 1.33405
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2758 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.7532 - acc: 0.8512 - val_loss: 1.8073 - val_acc: 0.6452

Epoch 00011: loss did not improve from 1.33405
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.7683 - acc: 0.7812
121/121 [==============================] - 0s 32us/step - loss: 1.5613 - acc: 0.8512 - val_loss: 1.5966 - val_acc: 0.6452

Epoch 00012: loss did not improve from 1.33405
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1557 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.1520 - acc: 0.8760 - val_loss: 1.5290 - val_acc: 0.6774

Epoch 00013: loss improved from 1.33405 to 1.15197, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.9632 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.0062 - acc: 0.8926 - val_loss: 1.6086 - val_acc: 0.7097

Epoch 00014: loss improved from 1.15197 to 1.00623, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_16.h5
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1439 - acc: 0.9062
121/121 [==============================] - 0s 33us/step - loss: 1.1023 - acc: 0.9091 - val_loss: 1.5147 - val_acc: 0.6774

Epoch 00015: loss did not improve from 1.00623
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 0.8902 - acc: 0.9688
121/121 [==============================] - 0s 32us/step - loss: 1.4641 - acc: 0.9091 - val_loss: 1.7614 - val_acc: 0.7097

Epoch 00016: loss did not improve from 1.00623
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.2858 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.1497 - acc: 0.9008 - val_loss: 1.6427 - val_acc: 0.6774

Epoch 00017: loss did not improve from 1.00623
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0785 - acc: 0.8750
121/121 [==============================] - 0s 32us/step - loss: 1.6090 - acc: 0.8843 - val_loss: 2.6042 - val_acc: 0.7419

Epoch 00018: loss did not improve from 1.00623
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.0739 - acc: 0.7812
121/121 [==============================] - 0s 32us/step - loss: 1.8255 - acc: 0.8182 - val_loss: 2.0100 - val_acc: 0.7419
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:18<00:03,  1.62s/it]
Epoch 00019: loss did not improve from 1.00623
Epoch 00019: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 4.5572 - acc: 0.5312
121/121 [==============================] - 0s 2ms/step - loss: 4.1971 - acc: 0.6281 - val_loss: 2.7294 - val_acc: 0.6452

Epoch 00001: loss improved from inf to 4.19707, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.6850 - acc: 0.6875
121/121 [==============================] - 0s 38us/step - loss: 2.4792 - acc: 0.7438 - val_loss: 2.0894 - val_acc: 0.6774

Epoch 00002: loss improved from 4.19707 to 2.47924, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.3559 - acc: 0.7500
121/121 [==============================] - 0s 35us/step - loss: 2.0629 - acc: 0.7603 - val_loss: 1.8582 - val_acc: 0.6774

Epoch 00003: loss improved from 2.47924 to 2.06291, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.9610 - acc: 0.7188
121/121 [==============================] - 0s 34us/step - loss: 2.2035 - acc: 0.7273 - val_loss: 1.8262 - val_acc: 0.6774

Epoch 00004: loss did not improve from 2.06291
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.9431 - acc: 0.7500
121/121 [==============================] - 0s 33us/step - loss: 1.7798 - acc: 0.7686 - val_loss: 1.6957 - val_acc: 0.6452

Epoch 00005: loss improved from 2.06291 to 1.77979, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.7163 - acc: 0.7188
121/121 [==============================] - 0s 33us/step - loss: 1.6495 - acc: 0.7273 - val_loss: 1.6756 - val_acc: 0.6774

Epoch 00006: loss improved from 1.77979 to 1.64948, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5170 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.7168 - acc: 0.8017 - val_loss: 1.9613 - val_acc: 0.6774

Epoch 00007: loss did not improve from 1.64948
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.0775 - acc: 0.7188
121/121 [==============================] - 0s 32us/step - loss: 1.7510 - acc: 0.8264 - val_loss: 1.7517 - val_acc: 0.6452

Epoch 00008: loss did not improve from 1.64948
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4653 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.3691 - acc: 0.8760 - val_loss: 1.6806 - val_acc: 0.6452

Epoch 00009: loss improved from 1.64948 to 1.36909, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3317 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.3999 - acc: 0.8678 - val_loss: 1.7286 - val_acc: 0.6452

Epoch 00010: loss did not improve from 1.36909
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6215 - acc: 0.9062
121/121 [==============================] - 0s 32us/step - loss: 1.4635 - acc: 0.8512 - val_loss: 1.6526 - val_acc: 0.6452

Epoch 00011: loss did not improve from 1.36909
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1277 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.7002 - acc: 0.8430 - val_loss: 1.9311 - val_acc: 0.6452

Epoch 00012: loss did not improve from 1.36909
Epoch 13/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.4996 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 1.3758 - acc: 0.8430 - val_loss: 1.5899 - val_acc: 0.6452

Epoch 00013: loss did not improve from 1.36909
Epoch 14/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0853 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.0872 - acc: 0.8926 - val_loss: 1.6133 - val_acc: 0.6774

Epoch 00014: loss improved from 1.36909 to 1.08717, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_17.h5
Epoch 15/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3032 - acc: 0.8750
121/121 [==============================] - 0s 33us/step - loss: 1.2877 - acc: 0.8512 - val_loss: 1.5213 - val_acc: 0.6452

Epoch 00015: loss did not improve from 1.08717
Epoch 16/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.0761 - acc: 0.9375
121/121 [==============================] - 0s 33us/step - loss: 1.1303 - acc: 0.9008 - val_loss: 1.5059 - val_acc: 0.5806

Epoch 00016: loss did not improve from 1.08717
Epoch 17/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.1877 - acc: 1.0000
121/121 [==============================] - 0s 32us/step - loss: 2.1538 - acc: 0.8760 - val_loss: 3.3152 - val_acc: 0.6774

Epoch 00017: loss did not improve from 1.08717
Epoch 18/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.4695 - acc: 0.8125
121/121 [==============================] - 0s 32us/step - loss: 2.2924 - acc: 0.8430 - val_loss: 2.6552 - val_acc: 0.6452

Epoch 00018: loss did not improve from 1.08717
Epoch 19/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.2182 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 2.1567 - acc: 0.8843 - val_loss: 2.1341 - val_acc: 0.6452
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:19<00:01,  1.62s/it]
Epoch 00019: loss did not improve from 1.08717
Epoch 00019: early stopping
Train on 121 samples, validate on 31 samples
Epoch 1/100

 32/121 [======>.......................] - ETA: 0s - loss: 4.5054 - acc: 0.5312
121/121 [==============================] - 0s 2ms/step - loss: 3.1552 - acc: 0.6694 - val_loss: 2.0268 - val_acc: 0.6774

Epoch 00001: loss improved from inf to 3.15522, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.9768 - acc: 0.6250
121/121 [==============================] - 0s 38us/step - loss: 2.1204 - acc: 0.6612 - val_loss: 2.9457 - val_acc: 0.6129

Epoch 00002: loss improved from 3.15522 to 2.12039, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.8532 - acc: 0.6875
121/121 [==============================] - 0s 34us/step - loss: 1.7818 - acc: 0.7025 - val_loss: 2.0014 - val_acc: 0.6774

Epoch 00003: loss improved from 2.12039 to 1.78184, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6314 - acc: 0.6562
121/121 [==============================] - 0s 34us/step - loss: 1.8576 - acc: 0.7273 - val_loss: 2.0260 - val_acc: 0.7419

Epoch 00004: loss did not improve from 1.78184
Epoch 5/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.6313 - acc: 0.7500
121/121 [==============================] - 0s 32us/step - loss: 1.8411 - acc: 0.7769 - val_loss: 1.7704 - val_acc: 0.6452

Epoch 00005: loss did not improve from 1.78184
Epoch 6/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5995 - acc: 0.6875
121/121 [==============================] - 0s 32us/step - loss: 1.5709 - acc: 0.7851 - val_loss: 1.6688 - val_acc: 0.6774

Epoch 00006: loss improved from 1.78184 to 1.57091, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3602 - acc: 0.8125
121/121 [==============================] - 0s 33us/step - loss: 1.4529 - acc: 0.8099 - val_loss: 1.7172 - val_acc: 0.7097

Epoch 00007: loss improved from 1.57091 to 1.45289, saving model to ./results_TA102_with_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3318 - acc: 0.9688
121/121 [==============================] - 0s 33us/step - loss: 1.9998 - acc: 0.8430 - val_loss: 1.9992 - val_acc: 0.8065

Epoch 00008: loss did not improve from 1.45289
Epoch 9/100

 32/121 [======>.......................] - ETA: 0s - loss: 2.0972 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 2.0297 - acc: 0.8430 - val_loss: 1.5502 - val_acc: 0.7097

Epoch 00009: loss did not improve from 1.45289
Epoch 10/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.5648 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.4877 - acc: 0.8843 - val_loss: 1.4605 - val_acc: 0.7419

Epoch 00010: loss did not improve from 1.45289
Epoch 11/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.9206 - acc: 0.8438
121/121 [==============================] - 0s 32us/step - loss: 1.9343 - acc: 0.7934 - val_loss: 1.5893 - val_acc: 0.6774

Epoch 00011: loss did not improve from 1.45289
Epoch 12/100

 32/121 [======>.......................] - ETA: 0s - loss: 1.3698 - acc: 0.7500
121/121 [==============================] - 0s 32us/step - loss: 1.5440 - acc: 0.8264 - val_loss: 1.5173 - val_acc: 0.7097
DeepAmes+ Weights: 100%|██████████| 13/13 [00:21<00:00,  1.60s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:21<00:00,  1.63s/it]

Epoch 00012: loss did not improve from 1.45289
Epoch 00012: early stopping
--- 851.8641459941864 seconds ---

Generating metrics report for TA102_with_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 98 samples.
Processing weight 7...
  Done. 98 samples.
Processing weight 8...
  Done. 98 samples.
Processing weight 9...
  Done. 98 samples.
Processing weight 10...
  Done. 98 samples.
Processing weight 11...
  Done. 98 samples.
Processing weight 12...
  Done. 98 samples.
Processing weight 13...
  Done. 98 samples.
Processing weight 14...
  Done. 98 samples.
Processing weight 15...
  Done. 98 samples.
Processing weight 16...
  Done. 98 samples.
Processing weight 17...
  Done. 98 samples.
Processing weight 18...
  Done. 98 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA102_with_S9/metrics_report_TA102_with_S9.txt

Done!

Completed TA102_with_S9 in 851.86 seconds

================================================================================
[4/16] Processing: TA102_without_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA102_without_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA102_without_S9_Test_mold2.csv
(868, 777)
(694, 777)
(115, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:01<00:29,  1.54s/it]KNN Seeds:  10%|█         | 2/20 [00:03<00:27,  1.56s/it]KNN Seeds:  15%|█▌        | 3/20 [00:04<00:26,  1.56s/it]KNN Seeds:  20%|██        | 4/20 [00:06<00:24,  1.56s/it]KNN Seeds:  25%|██▌       | 5/20 [00:07<00:23,  1.56s/it]KNN Seeds:  30%|███       | 6/20 [00:09<00:21,  1.57s/it]KNN Seeds:  35%|███▌      | 7/20 [00:10<00:20,  1.57s/it]KNN Seeds:  40%|████      | 8/20 [00:12<00:19,  1.59s/it]KNN Seeds:  45%|████▌     | 9/20 [00:14<00:17,  1.60s/it]KNN Seeds:  50%|█████     | 10/20 [00:15<00:16,  1.61s/it]KNN Seeds:  55%|█████▌    | 11/20 [00:17<00:14,  1.62s/it]KNN Seeds:  60%|██████    | 12/20 [00:19<00:13,  1.64s/it]KNN Seeds:  65%|██████▌   | 13/20 [00:20<00:11,  1.65s/it]KNN Seeds:  70%|███████   | 14/20 [00:22<00:09,  1.66s/it]KNN Seeds:  75%|███████▌  | 15/20 [00:24<00:08,  1.67s/it]KNN Seeds:  80%|████████  | 16/20 [00:25<00:06,  1.68s/it]KNN Seeds:  85%|████████▌ | 17/20 [00:27<00:05,  1.69s/it]KNN Seeds:  90%|█████████ | 18/20 [00:29<00:03,  1.71s/it]KNN Seeds:  95%|█████████▌| 19/20 [00:31<00:01,  1.72s/it]KNN Seeds: 100%|██████████| 20/20 [00:32<00:00,  1.72s/it]KNN Seeds: 100%|██████████| 20/20 [00:32<00:00,  1.64s/it]
24
(100, None, 'lbfgs')
(868, 777)
(694, 777)
(115, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:01<00:33,  1.74s/it]LR Seeds:  10%|█         | 2/20 [00:03<00:29,  1.64s/it]LR Seeds:  15%|█▌        | 3/20 [00:04<00:27,  1.62s/it]LR Seeds:  20%|██        | 4/20 [00:06<00:25,  1.62s/it]LR Seeds:  25%|██▌       | 5/20 [00:07<00:23,  1.57s/it]LR Seeds:  30%|███       | 6/20 [00:09<00:21,  1.56s/it]LR Seeds:  35%|███▌      | 7/20 [00:11<00:20,  1.57s/it]LR Seeds:  40%|████      | 8/20 [00:12<00:19,  1.60s/it]LR Seeds:  45%|████▌     | 9/20 [00:14<00:18,  1.65s/it]LR Seeds:  50%|█████     | 10/20 [00:16<00:17,  1.77s/it]LR Seeds:  55%|█████▌    | 11/20 [00:18<00:16,  1.80s/it]LR Seeds:  60%|██████    | 12/20 [00:20<00:15,  1.98s/it]LR Seeds:  65%|██████▌   | 13/20 [00:22<00:13,  1.95s/it]LR Seeds:  70%|███████   | 14/20 [00:24<00:11,  1.93s/it]LR Seeds:  75%|███████▌  | 15/20 [00:26<00:09,  1.92s/it]LR Seeds:  80%|████████  | 16/20 [00:28<00:07,  1.92s/it]LR Seeds:  85%|████████▌ | 17/20 [00:30<00:05,  1.89s/it]LR Seeds:  90%|█████████ | 18/20 [00:32<00:03,  1.91s/it]LR Seeds:  95%|█████████▌| 19/20 [00:34<00:01,  1.90s/it]LR Seeds: 100%|██████████| 20/20 [00:36<00:00,  1.91s/it]LR Seeds: 100%|██████████| 20/20 [00:36<00:00,  1.80s/it]
96
('rbf', 1, 1)
(868, 777)
(694, 777)
(115, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [00:07<02:25,  7.64s/it]SVM Seeds:  10%|█         | 2/20 [00:15<02:17,  7.65s/it]SVM Seeds:  15%|█▌        | 3/20 [00:22<02:10,  7.66s/it]SVM Seeds:  20%|██        | 4/20 [00:30<02:02,  7.67s/it]SVM Seeds:  25%|██▌       | 5/20 [00:38<01:55,  7.68s/it]SVM Seeds:  30%|███       | 6/20 [00:46<01:47,  7.69s/it]SVM Seeds:  35%|███▌      | 7/20 [00:53<01:40,  7.70s/it]SVM Seeds:  40%|████      | 8/20 [01:01<01:32,  7.70s/it]SVM Seeds:  45%|████▌     | 9/20 [01:09<01:24,  7.71s/it]SVM Seeds:  50%|█████     | 10/20 [01:16<01:17,  7.73s/it]SVM Seeds:  55%|█████▌    | 11/20 [01:24<01:09,  7.74s/it]SVM Seeds:  60%|██████    | 12/20 [01:32<01:01,  7.74s/it]SVM Seeds:  65%|██████▌   | 13/20 [01:40<00:54,  7.76s/it]SVM Seeds:  70%|███████   | 14/20 [01:48<00:46,  7.77s/it]SVM Seeds:  75%|███████▌  | 15/20 [01:55<00:38,  7.78s/it]SVM Seeds:  80%|████████  | 16/20 [02:03<00:31,  7.79s/it]SVM Seeds:  85%|████████▌ | 17/20 [02:11<00:23,  7.80s/it]SVM Seeds:  90%|█████████ | 18/20 [02:19<00:15,  7.81s/it]SVM Seeds:  95%|█████████▌| 19/20 [02:27<00:07,  7.82s/it]SVM Seeds: 100%|██████████| 20/20 [02:35<00:00,  7.83s/it]SVM Seeds: 100%|██████████| 20/20 [02:35<00:00,  7.75s/it]
200
(500, None, 70, 1, 'balanced')
(868, 777)
(694, 777)
(115, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:02<00:52,  2.75s/it]RF Seeds:  10%|█         | 2/20 [00:05<00:49,  2.75s/it]RF Seeds:  15%|█▌        | 3/20 [00:08<00:46,  2.75s/it]RF Seeds:  20%|██        | 4/20 [00:11<00:44,  2.76s/it]RF Seeds:  25%|██▌       | 5/20 [00:13<00:41,  2.76s/it]RF Seeds:  30%|███       | 6/20 [00:16<00:38,  2.77s/it]RF Seeds:  35%|███▌      | 7/20 [00:19<00:36,  2.79s/it]RF Seeds:  40%|████      | 8/20 [00:22<00:33,  2.79s/it]RF Seeds:  45%|████▌     | 9/20 [00:25<00:30,  2.80s/it]RF Seeds:  50%|█████     | 10/20 [00:27<00:28,  2.81s/it]RF Seeds:  55%|█████▌    | 11/20 [00:30<00:25,  2.82s/it]RF Seeds:  60%|██████    | 12/20 [00:33<00:22,  2.83s/it]RF Seeds:  65%|██████▌   | 13/20 [00:36<00:19,  2.84s/it]RF Seeds:  70%|███████   | 14/20 [00:39<00:17,  2.85s/it]RF Seeds:  75%|███████▌  | 15/20 [00:42<00:14,  2.86s/it]RF Seeds:  80%|████████  | 16/20 [00:45<00:11,  2.89s/it]RF Seeds:  85%|████████▌ | 17/20 [00:48<00:08,  2.92s/it]RF Seeds:  90%|█████████ | 18/20 [00:51<00:05,  2.93s/it]RF Seeds:  95%|█████████▌| 19/20 [00:54<00:02,  2.94s/it]RF Seeds: 100%|██████████| 20/20 [00:56<00:00,  2.93s/it]RF Seeds: 100%|██████████| 20/20 [00:56<00:00,  2.85s/it]
400
(0.01, 900, 7, 0.8, 6)
(868, 777)
(694, 777)
(115, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:29<09:14, 29.19s/it]XGBoost Seeds:  10%|█         | 2/20 [00:58<08:41, 28.97s/it]XGBoost Seeds:  15%|█▌        | 3/20 [01:27<08:14, 29.06s/it]XGBoost Seeds:  20%|██        | 4/20 [01:56<07:45, 29.06s/it]XGBoost Seeds:  25%|██▌       | 5/20 [02:25<07:15, 29.04s/it]XGBoost Seeds:  30%|███       | 6/20 [02:54<06:47, 29.07s/it]XGBoost Seeds:  35%|███▌      | 7/20 [03:23<06:18, 29.11s/it]XGBoost Seeds:  40%|████      | 8/20 [03:52<05:46, 28.91s/it]XGBoost Seeds:  45%|████▌     | 9/20 [04:21<05:18, 28.93s/it]XGBoost Seeds:  50%|█████     | 10/20 [04:50<04:50, 29.03s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [05:19<04:20, 29.00s/it]XGBoost Seeds:  60%|██████    | 12/20 [05:48<03:52, 29.05s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [06:17<03:22, 28.96s/it]XGBoost Seeds:  70%|███████   | 14/20 [06:45<02:53, 28.88s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [07:14<02:24, 28.87s/it]XGBoost Seeds:  80%|████████  | 16/20 [07:43<01:55, 28.99s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [08:13<01:27, 29.03s/it]XGBoost Seeds:  90%|█████████ | 18/20 [08:41<00:57, 28.99s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [09:10<00:28, 28.91s/it]XGBoost Seeds: 100%|██████████| 20/20 [09:39<00:00, 28.91s/it]XGBoost Seeds: 100%|██████████| 20/20 [09:39<00:00, 28.98s/it]
knn:  87
lr:  97
svm:  77
rf:  98
xgboost:  88
Combining validation predictions is completed
knn:  87
lr:  97
svm:  77
rf:  98
xgboost:  88
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.8271 - acc: 0.6250
139/139 [==============================] - 0s 2ms/step - loss: 1.7692 - acc: 0.6835 - val_loss: 2.6900 - val_acc: 0.4000

Epoch 00001: loss improved from inf to 1.76922, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.8326 - acc: 0.5000
139/139 [==============================] - 0s 42us/step - loss: 1.6415 - acc: 0.6978 - val_loss: 1.4777 - val_acc: 0.6571

Epoch 00002: loss improved from 1.76922 to 1.64145, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3472 - acc: 0.8125
139/139 [==============================] - 0s 39us/step - loss: 1.5363 - acc: 0.7842 - val_loss: 1.4897 - val_acc: 0.6000

Epoch 00003: loss improved from 1.64145 to 1.53631, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3757 - acc: 0.8125
139/139 [==============================] - 0s 39us/step - loss: 1.3658 - acc: 0.8345 - val_loss: 1.3681 - val_acc: 0.7429

Epoch 00004: loss improved from 1.53631 to 1.36581, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3048 - acc: 0.8438
139/139 [==============================] - 0s 38us/step - loss: 1.2564 - acc: 0.8201 - val_loss: 1.5862 - val_acc: 0.7429

Epoch 00005: loss improved from 1.36581 to 1.25640, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2006 - acc: 0.8750
139/139 [==============================] - 0s 38us/step - loss: 1.2327 - acc: 0.8273 - val_loss: 1.4764 - val_acc: 0.6857

Epoch 00006: loss improved from 1.25640 to 1.23268, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3300 - acc: 0.8125
139/139 [==============================] - 0s 38us/step - loss: 1.3170 - acc: 0.8201 - val_loss: 1.3403 - val_acc: 0.7143

Epoch 00007: loss did not improve from 1.23268
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1159 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.1520 - acc: 0.8633 - val_loss: 1.2810 - val_acc: 0.7143

Epoch 00008: loss improved from 1.23268 to 1.15202, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1346 - acc: 0.8438
139/139 [==============================] - 0s 38us/step - loss: 1.1483 - acc: 0.8417 - val_loss: 1.2811 - val_acc: 0.7714

Epoch 00009: loss improved from 1.15202 to 1.14828, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0220 - acc: 0.8750
139/139 [==============================] - 0s 38us/step - loss: 1.1019 - acc: 0.8561 - val_loss: 1.2030 - val_acc: 0.7429

Epoch 00010: loss improved from 1.14828 to 1.10193, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9990 - acc: 0.8750
139/139 [==============================] - 0s 38us/step - loss: 1.0033 - acc: 0.8561 - val_loss: 1.1933 - val_acc: 0.8000

Epoch 00011: loss improved from 1.10193 to 1.00333, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9783 - acc: 0.9688
139/139 [==============================] - 0s 38us/step - loss: 0.9702 - acc: 0.9209 - val_loss: 1.0898 - val_acc: 0.8286

Epoch 00012: loss improved from 1.00333 to 0.97021, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8901 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.9194 - acc: 0.9281 - val_loss: 1.1850 - val_acc: 0.7714

Epoch 00013: loss improved from 0.97021 to 0.91939, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9726 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.8806 - acc: 0.9353 - val_loss: 1.0955 - val_acc: 0.8000

Epoch 00014: loss improved from 0.91939 to 0.88058, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8835 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.8148 - acc: 0.9353 - val_loss: 1.0633 - val_acc: 0.7714

Epoch 00015: loss improved from 0.88058 to 0.81477, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9602 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.9091 - acc: 0.9281 - val_loss: 1.0194 - val_acc: 0.8286

Epoch 00016: loss did not improve from 0.81477
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8488 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.7975 - acc: 0.9353 - val_loss: 0.9957 - val_acc: 0.7714

Epoch 00017: loss improved from 0.81477 to 0.79751, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9043 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.8114 - acc: 0.9281 - val_loss: 0.9444 - val_acc: 0.8286

Epoch 00018: loss did not improve from 0.79751
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.7763 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.6631 - acc: 0.9784 - val_loss: 0.9227 - val_acc: 0.8000

Epoch 00019: loss improved from 0.79751 to 0.66309, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.7482 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.6576 - acc: 0.9712 - val_loss: 0.9337 - val_acc: 0.8286

Epoch 00020: loss improved from 0.66309 to 0.65765, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0126 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.7930 - acc: 0.9568 - val_loss: 0.8888 - val_acc: 0.8286

Epoch 00021: loss did not improve from 0.65765
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8210 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 0.7622 - acc: 0.9353 - val_loss: 0.9866 - val_acc: 0.8286

Epoch 00022: loss did not improve from 0.65765
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6626 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.6426 - acc: 0.9784 - val_loss: 0.9024 - val_acc: 0.8000

Epoch 00023: loss improved from 0.65765 to 0.64258, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6996 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.6595 - acc: 0.9568 - val_loss: 1.4986 - val_acc: 0.8286

Epoch 00024: loss did not improve from 0.64258
Epoch 25/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8892 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.7901 - acc: 0.9568 - val_loss: 1.2772 - val_acc: 0.8000

Epoch 00025: loss did not improve from 0.64258
Epoch 26/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8997 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 0.7371 - acc: 0.9281 - val_loss: 1.1687 - val_acc: 0.8000

Epoch 00026: loss did not improve from 0.64258
Epoch 27/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6554 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.6523 - acc: 0.9640 - val_loss: 1.2548 - val_acc: 0.7714

Epoch 00027: loss did not improve from 0.64258
Epoch 28/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6352 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.6360 - acc: 0.9568 - val_loss: 0.9883 - val_acc: 0.8857

Epoch 00028: loss improved from 0.64258 to 0.63595, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 29/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.7235 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.6926 - acc: 0.9281 - val_loss: 0.8933 - val_acc: 0.8286

Epoch 00029: loss did not improve from 0.63595
Epoch 30/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8007 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.5911 - acc: 0.9856 - val_loss: 0.8458 - val_acc: 0.8857

Epoch 00030: loss improved from 0.63595 to 0.59105, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 31/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6814 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.5870 - acc: 0.9568 - val_loss: 0.9210 - val_acc: 0.8000

Epoch 00031: loss improved from 0.59105 to 0.58698, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 32/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8690 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.5899 - acc: 0.9640 - val_loss: 0.8952 - val_acc: 0.8286

Epoch 00032: loss did not improve from 0.58698
Epoch 33/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.5855 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.5947 - acc: 0.9568 - val_loss: 1.5987 - val_acc: 0.8000

Epoch 00033: loss did not improve from 0.58698
Epoch 34/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3056 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.8064 - acc: 0.9496 - val_loss: 1.6335 - val_acc: 0.8000

Epoch 00034: loss did not improve from 0.58698
Epoch 35/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8600 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.7007 - acc: 0.9424 - val_loss: 1.4336 - val_acc: 0.7714

Epoch 00035: loss did not improve from 0.58698
Epoch 36/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8800 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.5777 - acc: 0.9640 - val_loss: 1.3588 - val_acc: 0.7714

Epoch 00036: loss improved from 0.58698 to 0.57765, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 37/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6195 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.5387 - acc: 0.9712 - val_loss: 1.1859 - val_acc: 0.8000

Epoch 00037: loss improved from 0.57765 to 0.53875, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 38/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.5286 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.5593 - acc: 0.9640 - val_loss: 1.2533 - val_acc: 0.8000

Epoch 00038: loss did not improve from 0.53875
Epoch 39/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6348 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.4744 - acc: 0.9928 - val_loss: 1.1691 - val_acc: 0.7714

Epoch 00039: loss improved from 0.53875 to 0.47442, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_6.h5
Epoch 40/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.5397 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.5206 - acc: 0.9784 - val_loss: 1.2882 - val_acc: 0.7714

Epoch 00040: loss did not improve from 0.47442
Epoch 41/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.7742 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.4942 - acc: 0.9928 - val_loss: 1.1549 - val_acc: 0.8000

Epoch 00041: loss did not improve from 0.47442
Epoch 42/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6998 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.4943 - acc: 0.9856 - val_loss: 1.1111 - val_acc: 0.8000

Epoch 00042: loss did not improve from 0.47442
Epoch 43/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6725 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.5308 - acc: 0.9856 - val_loss: 1.2285 - val_acc: 0.7714

Epoch 00043: loss did not improve from 0.47442
Epoch 44/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.4534 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.6725 - acc: 0.9496 - val_loss: 3.0347 - val_acc: 0.3714
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:21,  1.82s/it]
Epoch 00044: loss did not improve from 0.47442
Epoch 00044: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.8714 - acc: 0.6562
139/139 [==============================] - 0s 2ms/step - loss: 2.0856 - acc: 0.6978 - val_loss: 2.9648 - val_acc: 0.4000

Epoch 00001: loss improved from inf to 2.08556, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.7642 - acc: 0.5312
139/139 [==============================] - 0s 41us/step - loss: 1.8647 - acc: 0.6763 - val_loss: 2.0874 - val_acc: 0.4286

Epoch 00002: loss improved from 2.08556 to 1.86475, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6127 - acc: 0.5938
139/139 [==============================] - 0s 40us/step - loss: 1.7221 - acc: 0.6763 - val_loss: 1.8958 - val_acc: 0.5429

Epoch 00003: loss improved from 1.86475 to 1.72213, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3689 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.5564 - acc: 0.7410 - val_loss: 1.5089 - val_acc: 0.6857

Epoch 00004: loss improved from 1.72213 to 1.55639, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2954 - acc: 0.8438
139/139 [==============================] - 0s 38us/step - loss: 1.3752 - acc: 0.7986 - val_loss: 1.4669 - val_acc: 0.7714

Epoch 00005: loss improved from 1.55639 to 1.37525, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2371 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.4788 - acc: 0.7914 - val_loss: 1.4875 - val_acc: 0.6286

Epoch 00006: loss did not improve from 1.37525
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1907 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.2732 - acc: 0.7914 - val_loss: 1.3438 - val_acc: 0.8000

Epoch 00007: loss improved from 1.37525 to 1.27324, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3168 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.3229 - acc: 0.8417 - val_loss: 1.6879 - val_acc: 0.7429

Epoch 00008: loss did not improve from 1.27324
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1009 - acc: 0.8750
139/139 [==============================] - 0s 38us/step - loss: 1.2300 - acc: 0.8345 - val_loss: 1.4456 - val_acc: 0.7429

Epoch 00009: loss improved from 1.27324 to 1.22998, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2611 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.2436 - acc: 0.8561 - val_loss: 1.3064 - val_acc: 0.7429

Epoch 00010: loss did not improve from 1.22998
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1541 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.2368 - acc: 0.8345 - val_loss: 1.2759 - val_acc: 0.7429

Epoch 00011: loss did not improve from 1.22998
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0547 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 0.9847 - acc: 0.8921 - val_loss: 1.1961 - val_acc: 0.7714

Epoch 00012: loss improved from 1.22998 to 0.98470, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0544 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 0.9998 - acc: 0.8705 - val_loss: 1.1067 - val_acc: 0.8000

Epoch 00013: loss did not improve from 0.98470
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1830 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.0438 - acc: 0.8633 - val_loss: 1.2906 - val_acc: 0.7429

Epoch 00014: loss did not improve from 0.98470
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0883 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.0733 - acc: 0.8777 - val_loss: 1.2303 - val_acc: 0.7429

Epoch 00015: loss did not improve from 0.98470
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0174 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.0645 - acc: 0.8777 - val_loss: 1.0097 - val_acc: 0.8286

Epoch 00016: loss did not improve from 0.98470
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8213 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.8224 - acc: 0.9353 - val_loss: 0.9736 - val_acc: 0.8286

Epoch 00017: loss improved from 0.98470 to 0.82242, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9987 - acc: 0.9688
139/139 [==============================] - 0s 37us/step - loss: 0.9155 - acc: 0.9353 - val_loss: 1.0236 - val_acc: 0.8000

Epoch 00018: loss did not improve from 0.82242
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8918 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.8495 - acc: 0.9137 - val_loss: 1.0342 - val_acc: 0.8286

Epoch 00019: loss did not improve from 0.82242
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9128 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.7726 - acc: 0.9640 - val_loss: 0.9843 - val_acc: 0.8286

Epoch 00020: loss improved from 0.82242 to 0.77256, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9022 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.7485 - acc: 0.9640 - val_loss: 1.0279 - val_acc: 0.8000

Epoch 00021: loss improved from 0.77256 to 0.74850, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_7.h5
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9853 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.8053 - acc: 0.9281 - val_loss: 0.9532 - val_acc: 0.8571

Epoch 00022: loss did not improve from 0.74850
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8440 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.7754 - acc: 0.9353 - val_loss: 0.9320 - val_acc: 0.8000

Epoch 00023: loss did not improve from 0.74850
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8007 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.7886 - acc: 0.9353 - val_loss: 1.3149 - val_acc: 0.7714

Epoch 00024: loss did not improve from 0.74850
Epoch 25/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8051 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.8816 - acc: 0.9137 - val_loss: 1.1344 - val_acc: 0.7429

Epoch 00025: loss did not improve from 0.74850
Epoch 26/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.7973 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.9068 - acc: 0.9209 - val_loss: 1.4190 - val_acc: 0.7429
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:03<00:19,  1.76s/it]
Epoch 00026: loss did not improve from 0.74850
Epoch 00026: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.2863 - acc: 0.5938
139/139 [==============================] - 0s 2ms/step - loss: 2.1329 - acc: 0.6331 - val_loss: 4.0180 - val_acc: 0.4286

Epoch 00001: loss improved from inf to 2.13290, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.2438 - acc: 0.5625
139/139 [==============================] - 0s 40us/step - loss: 2.0227 - acc: 0.6619 - val_loss: 2.0691 - val_acc: 0.4857

Epoch 00002: loss improved from 2.13290 to 2.02275, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6470 - acc: 0.6875
139/139 [==============================] - 0s 38us/step - loss: 1.6544 - acc: 0.7050 - val_loss: 1.6026 - val_acc: 0.7143

Epoch 00003: loss improved from 2.02275 to 1.65445, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3315 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.4463 - acc: 0.7266 - val_loss: 1.6296 - val_acc: 0.6571

Epoch 00004: loss improved from 1.65445 to 1.44631, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4380 - acc: 0.7500
139/139 [==============================] - 0s 36us/step - loss: 1.4082 - acc: 0.7770 - val_loss: 1.4712 - val_acc: 0.7429

Epoch 00005: loss improved from 1.44631 to 1.40819, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3599 - acc: 0.7500
139/139 [==============================] - 0s 36us/step - loss: 1.3704 - acc: 0.7914 - val_loss: 1.4482 - val_acc: 0.7429

Epoch 00006: loss improved from 1.40819 to 1.37044, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1766 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.1835 - acc: 0.8345 - val_loss: 1.3159 - val_acc: 0.7429

Epoch 00007: loss improved from 1.37044 to 1.18348, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1501 - acc: 0.9062
139/139 [==============================] - 0s 37us/step - loss: 1.1437 - acc: 0.8489 - val_loss: 1.2823 - val_acc: 0.7429

Epoch 00008: loss improved from 1.18348 to 1.14371, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2258 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.0942 - acc: 0.8633 - val_loss: 1.3732 - val_acc: 0.7429

Epoch 00009: loss improved from 1.14371 to 1.09424, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0522 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.0613 - acc: 0.8849 - val_loss: 1.4338 - val_acc: 0.7429

Epoch 00010: loss improved from 1.09424 to 1.06132, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1573 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.1075 - acc: 0.8705 - val_loss: 1.2643 - val_acc: 0.7429

Epoch 00011: loss did not improve from 1.06132
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9614 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.9257 - acc: 0.8993 - val_loss: 1.2446 - val_acc: 0.7714

Epoch 00012: loss improved from 1.06132 to 0.92574, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0511 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 1.0271 - acc: 0.9137 - val_loss: 1.5890 - val_acc: 0.7429

Epoch 00013: loss did not improve from 0.92574
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0738 - acc: 0.8438
139/139 [==============================] - 0s 35us/step - loss: 0.9635 - acc: 0.8993 - val_loss: 1.2285 - val_acc: 0.7714

Epoch 00014: loss did not improve from 0.92574
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0774 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.8885 - acc: 0.9424 - val_loss: 1.2876 - val_acc: 0.7429

Epoch 00015: loss improved from 0.92574 to 0.88849, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.7660 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.8858 - acc: 0.9137 - val_loss: 1.0726 - val_acc: 0.8000

Epoch 00016: loss improved from 0.88849 to 0.88579, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9350 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.8821 - acc: 0.9137 - val_loss: 1.4489 - val_acc: 0.7429

Epoch 00017: loss improved from 0.88579 to 0.88207, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8944 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.8254 - acc: 0.9568 - val_loss: 1.1559 - val_acc: 0.7429

Epoch 00018: loss improved from 0.88207 to 0.82537, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8556 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.7357 - acc: 0.9640 - val_loss: 1.0217 - val_acc: 0.8000

Epoch 00019: loss improved from 0.82537 to 0.73574, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_8.h5
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9563 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.8443 - acc: 0.9568 - val_loss: 1.3355 - val_acc: 0.7714

Epoch 00020: loss did not improve from 0.73574
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2294 - acc: 0.8438
139/139 [==============================] - 0s 35us/step - loss: 1.1073 - acc: 0.8993 - val_loss: 2.1724 - val_acc: 0.7429

Epoch 00021: loss did not improve from 0.73574
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9893 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 1.0107 - acc: 0.8921 - val_loss: 1.8439 - val_acc: 0.7143

Epoch 00022: loss did not improve from 0.73574
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0044 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.8050 - acc: 0.9424 - val_loss: 1.8801 - val_acc: 0.7429

Epoch 00023: loss did not improve from 0.73574
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1144 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.9628 - acc: 0.8993 - val_loss: 1.6637 - val_acc: 0.7143
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:05<00:17,  1.76s/it]
Epoch 00024: loss did not improve from 0.73574
Epoch 00024: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.9215 - acc: 0.6875
139/139 [==============================] - 0s 2ms/step - loss: 2.2491 - acc: 0.6978 - val_loss: 4.6021 - val_acc: 0.3143

Epoch 00001: loss improved from inf to 2.24914, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.9939 - acc: 0.4375
139/139 [==============================] - 0s 40us/step - loss: 1.9977 - acc: 0.6043 - val_loss: 2.1751 - val_acc: 0.4571

Epoch 00002: loss improved from 2.24914 to 1.99771, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.2616 - acc: 0.4688
139/139 [==============================] - 0s 38us/step - loss: 1.9226 - acc: 0.6115 - val_loss: 1.7198 - val_acc: 0.6000

Epoch 00003: loss improved from 1.99771 to 1.92261, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5701 - acc: 0.6875
139/139 [==============================] - 0s 37us/step - loss: 1.6403 - acc: 0.7338 - val_loss: 1.6466 - val_acc: 0.5714

Epoch 00004: loss improved from 1.92261 to 1.64027, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5360 - acc: 0.7188
139/139 [==============================] - 0s 37us/step - loss: 1.5496 - acc: 0.7338 - val_loss: 1.6441 - val_acc: 0.6571

Epoch 00005: loss improved from 1.64027 to 1.54955, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5813 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.4278 - acc: 0.7626 - val_loss: 1.5861 - val_acc: 0.7429

Epoch 00006: loss improved from 1.54955 to 1.42778, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5914 - acc: 0.7188
139/139 [==============================] - 0s 36us/step - loss: 1.3820 - acc: 0.7914 - val_loss: 1.4663 - val_acc: 0.7429

Epoch 00007: loss improved from 1.42778 to 1.38200, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2216 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.2080 - acc: 0.8345 - val_loss: 1.7310 - val_acc: 0.7429

Epoch 00008: loss improved from 1.38200 to 1.20800, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3396 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.1709 - acc: 0.8345 - val_loss: 1.5037 - val_acc: 0.7143

Epoch 00009: loss improved from 1.20800 to 1.17087, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1644 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.0422 - acc: 0.9065 - val_loss: 1.4879 - val_acc: 0.7143

Epoch 00010: loss improved from 1.17087 to 1.04215, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8652 - acc: 0.9375
139/139 [==============================] - 0s 37us/step - loss: 1.1102 - acc: 0.8417 - val_loss: 1.4234 - val_acc: 0.7429

Epoch 00011: loss did not improve from 1.04215
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0973 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.0162 - acc: 0.8849 - val_loss: 1.2657 - val_acc: 0.7429

Epoch 00012: loss improved from 1.04215 to 1.01620, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1875 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.0925 - acc: 0.8561 - val_loss: 1.3652 - val_acc: 0.7143

Epoch 00013: loss did not improve from 1.01620
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8983 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.8862 - acc: 0.9424 - val_loss: 1.1522 - val_acc: 0.7143

Epoch 00014: loss improved from 1.01620 to 0.88618, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9737 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 0.9924 - acc: 0.8993 - val_loss: 1.2958 - val_acc: 0.6571

Epoch 00015: loss did not improve from 0.88618
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.7634 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.8386 - acc: 0.9353 - val_loss: 1.2105 - val_acc: 0.7143

Epoch 00016: loss improved from 0.88618 to 0.83861, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9376 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 0.9423 - acc: 0.8777 - val_loss: 1.1021 - val_acc: 0.7143

Epoch 00017: loss did not improve from 0.83861
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8354 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 0.8746 - acc: 0.9137 - val_loss: 1.1530 - val_acc: 0.7429

Epoch 00018: loss did not improve from 0.83861
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8543 - acc: 0.8438
139/139 [==============================] - 0s 35us/step - loss: 0.7630 - acc: 0.9137 - val_loss: 1.1679 - val_acc: 0.7429

Epoch 00019: loss improved from 0.83861 to 0.76304, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8699 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.9576 - acc: 0.9137 - val_loss: 1.4809 - val_acc: 0.7429

Epoch 00020: loss did not improve from 0.76304
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0143 - acc: 0.8750
139/139 [==============================] - 0s 35us/step - loss: 0.9377 - acc: 0.8993 - val_loss: 1.0501 - val_acc: 0.7429

Epoch 00021: loss did not improve from 0.76304
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.7348 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.7762 - acc: 0.9281 - val_loss: 1.2688 - val_acc: 0.6857

Epoch 00022: loss did not improve from 0.76304
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1208 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.8297 - acc: 0.9209 - val_loss: 2.0366 - val_acc: 0.7429

Epoch 00023: loss did not improve from 0.76304
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8237 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.7273 - acc: 0.9424 - val_loss: 1.5980 - val_acc: 0.7429

Epoch 00024: loss improved from 0.76304 to 0.72733, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 25/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6710 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.6486 - acc: 0.9712 - val_loss: 1.2847 - val_acc: 0.7143

Epoch 00025: loss improved from 0.72733 to 0.64859, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_9.h5
Epoch 26/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6821 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.7860 - acc: 0.9496 - val_loss: 1.4718 - val_acc: 0.7714

Epoch 00026: loss did not improve from 0.64859
Epoch 27/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8334 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 0.6943 - acc: 0.9496 - val_loss: 1.3912 - val_acc: 0.7714

Epoch 00027: loss did not improve from 0.64859
Epoch 28/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8210 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.7538 - acc: 0.9568 - val_loss: 1.6285 - val_acc: 0.7714

Epoch 00028: loss did not improve from 0.64859
Epoch 29/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8056 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 1.0766 - acc: 0.9137 - val_loss: 3.2861 - val_acc: 0.4286

Epoch 00029: loss did not improve from 0.64859
Epoch 30/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9728 - acc: 0.8438
139/139 [==============================] - 0s 35us/step - loss: 1.1543 - acc: 0.8777 - val_loss: 2.2805 - val_acc: 0.6571
DeepAmes+ Weights:  31%|███       | 4/13 [00:06<00:15,  1.72s/it]
Epoch 00030: loss did not improve from 0.64859
Epoch 00030: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.4964 - acc: 0.5938
139/139 [==============================] - 0s 2ms/step - loss: 2.3291 - acc: 0.6187 - val_loss: 6.8250 - val_acc: 0.2857

Epoch 00001: loss improved from inf to 2.32905, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.2304 - acc: 0.5000
139/139 [==============================] - 0s 41us/step - loss: 2.0966 - acc: 0.6547 - val_loss: 2.7115 - val_acc: 0.3714

Epoch 00002: loss improved from 2.32905 to 2.09660, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.2825 - acc: 0.5312
139/139 [==============================] - 0s 38us/step - loss: 2.0159 - acc: 0.6475 - val_loss: 1.9880 - val_acc: 0.6857

Epoch 00003: loss improved from 2.09660 to 2.01592, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.8940 - acc: 0.6875
139/139 [==============================] - 0s 38us/step - loss: 1.8469 - acc: 0.6906 - val_loss: 2.1282 - val_acc: 0.4571

Epoch 00004: loss improved from 2.01592 to 1.84693, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6459 - acc: 0.7188
139/139 [==============================] - 0s 38us/step - loss: 1.7117 - acc: 0.6978 - val_loss: 1.5528 - val_acc: 0.6857

Epoch 00005: loss improved from 1.84693 to 1.71172, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5337 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.4736 - acc: 0.7554 - val_loss: 1.7278 - val_acc: 0.7429

Epoch 00006: loss improved from 1.71172 to 1.47356, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5237 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.4994 - acc: 0.7986 - val_loss: 1.5454 - val_acc: 0.7429

Epoch 00007: loss did not improve from 1.47356
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4787 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.2646 - acc: 0.8201 - val_loss: 1.3904 - val_acc: 0.7429

Epoch 00008: loss improved from 1.47356 to 1.26461, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5321 - acc: 0.8438
139/139 [==============================] - 0s 37us/step - loss: 1.3511 - acc: 0.8201 - val_loss: 1.3710 - val_acc: 0.7143

Epoch 00009: loss did not improve from 1.26461
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3901 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.3031 - acc: 0.8129 - val_loss: 1.8075 - val_acc: 0.7143

Epoch 00010: loss did not improve from 1.26461
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3767 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.3208 - acc: 0.8058 - val_loss: 1.6625 - val_acc: 0.7429

Epoch 00011: loss did not improve from 1.26461
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3456 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.2374 - acc: 0.8777 - val_loss: 1.5582 - val_acc: 0.7429

Epoch 00012: loss improved from 1.26461 to 1.23742, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4043 - acc: 0.9062
139/139 [==============================] - 0s 37us/step - loss: 1.2025 - acc: 0.8633 - val_loss: 1.3531 - val_acc: 0.7143

Epoch 00013: loss improved from 1.23742 to 1.20251, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1694 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.0370 - acc: 0.8993 - val_loss: 1.3870 - val_acc: 0.7143

Epoch 00014: loss improved from 1.20251 to 1.03700, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1137 - acc: 0.9688
139/139 [==============================] - 0s 37us/step - loss: 0.9309 - acc: 0.9496 - val_loss: 1.3584 - val_acc: 0.7714

Epoch 00015: loss improved from 1.03700 to 0.93093, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_10.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0738 - acc: 0.9375
139/139 [==============================] - 0s 37us/step - loss: 0.9818 - acc: 0.9281 - val_loss: 1.3265 - val_acc: 0.7429

Epoch 00016: loss did not improve from 0.93093
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0371 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.9640 - acc: 0.9353 - val_loss: 1.2551 - val_acc: 0.7429

Epoch 00017: loss did not improve from 0.93093
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9988 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.9396 - acc: 0.9281 - val_loss: 1.3174 - val_acc: 0.7714

Epoch 00018: loss did not improve from 0.93093
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0843 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.9391 - acc: 0.9424 - val_loss: 1.2956 - val_acc: 0.8000

Epoch 00019: loss did not improve from 0.93093
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0704 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 0.9647 - acc: 0.9209 - val_loss: 1.5137 - val_acc: 0.8000
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:08<00:13,  1.71s/it]
Epoch 00020: loss did not improve from 0.93093
Epoch 00020: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.5632 - acc: 0.5625
139/139 [==============================] - 0s 2ms/step - loss: 2.5274 - acc: 0.6115 - val_loss: 4.0345 - val_acc: 0.3143

Epoch 00001: loss improved from inf to 2.52737, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.4701 - acc: 0.4688
139/139 [==============================] - 0s 40us/step - loss: 2.4544 - acc: 0.5683 - val_loss: 2.2261 - val_acc: 0.4000

Epoch 00002: loss improved from 2.52737 to 2.45436, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.7512 - acc: 0.4688
139/139 [==============================] - 0s 38us/step - loss: 1.8921 - acc: 0.6115 - val_loss: 1.9895 - val_acc: 0.6286

Epoch 00003: loss improved from 2.45436 to 1.89209, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.8281 - acc: 0.7188
139/139 [==============================] - 0s 37us/step - loss: 1.6713 - acc: 0.7410 - val_loss: 1.7872 - val_acc: 0.6857

Epoch 00004: loss improved from 1.89209 to 1.67132, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4960 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.6434 - acc: 0.7194 - val_loss: 2.0579 - val_acc: 0.7143

Epoch 00005: loss improved from 1.67132 to 1.64340, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5402 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.5669 - acc: 0.7626 - val_loss: 1.7505 - val_acc: 0.6857

Epoch 00006: loss improved from 1.64340 to 1.56691, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3244 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.3772 - acc: 0.8058 - val_loss: 1.6523 - val_acc: 0.7143

Epoch 00007: loss improved from 1.56691 to 1.37723, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3089 - acc: 0.8438
139/139 [==============================] - 0s 37us/step - loss: 1.4280 - acc: 0.7914 - val_loss: 1.7171 - val_acc: 0.6571

Epoch 00008: loss did not improve from 1.37723
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4551 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.3291 - acc: 0.7770 - val_loss: 1.6780 - val_acc: 0.7143

Epoch 00009: loss improved from 1.37723 to 1.32908, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4276 - acc: 0.8438
139/139 [==============================] - 0s 37us/step - loss: 1.3958 - acc: 0.8273 - val_loss: 1.6296 - val_acc: 0.7429

Epoch 00010: loss did not improve from 1.32908
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3048 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.1833 - acc: 0.8489 - val_loss: 1.6147 - val_acc: 0.7429

Epoch 00011: loss improved from 1.32908 to 1.18325, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3409 - acc: 0.9062
139/139 [==============================] - 0s 37us/step - loss: 1.2555 - acc: 0.8345 - val_loss: 1.2692 - val_acc: 0.7143

Epoch 00012: loss did not improve from 1.18325
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1169 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.2042 - acc: 0.8489 - val_loss: 1.4888 - val_acc: 0.7143

Epoch 00013: loss did not improve from 1.18325
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2195 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.2887 - acc: 0.7770 - val_loss: 1.6484 - val_acc: 0.6571

Epoch 00014: loss did not improve from 1.18325
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0687 - acc: 0.8438
139/139 [==============================] - 0s 38us/step - loss: 1.1276 - acc: 0.8201 - val_loss: 1.2267 - val_acc: 0.7429

Epoch 00015: loss improved from 1.18325 to 1.12763, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9378 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.0313 - acc: 0.8777 - val_loss: 1.3521 - val_acc: 0.7429

Epoch 00016: loss improved from 1.12763 to 1.03128, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2903 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 0.9818 - acc: 0.9137 - val_loss: 1.2323 - val_acc: 0.7714

Epoch 00017: loss improved from 1.03128 to 0.98176, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0994 - acc: 0.9062
139/139 [==============================] - 0s 37us/step - loss: 0.9956 - acc: 0.8849 - val_loss: 1.3111 - val_acc: 0.7143

Epoch 00018: loss did not improve from 0.98176
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0015 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.8598 - acc: 0.9496 - val_loss: 1.1795 - val_acc: 0.7714

Epoch 00019: loss improved from 0.98176 to 0.85980, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9006 - acc: 0.9375
139/139 [==============================] - 0s 37us/step - loss: 0.8219 - acc: 0.9496 - val_loss: 1.4168 - val_acc: 0.7714

Epoch 00020: loss improved from 0.85980 to 0.82193, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1509 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 0.9623 - acc: 0.8849 - val_loss: 1.2822 - val_acc: 0.7429

Epoch 00021: loss did not improve from 0.82193
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0077 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 0.8493 - acc: 0.9209 - val_loss: 1.0767 - val_acc: 0.8000

Epoch 00022: loss did not improve from 0.82193
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9455 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.7891 - acc: 0.9568 - val_loss: 0.9929 - val_acc: 0.8000

Epoch 00023: loss improved from 0.82193 to 0.78905, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0553 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.8318 - acc: 0.9137 - val_loss: 0.9981 - val_acc: 0.7714

Epoch 00024: loss did not improve from 0.78905
Epoch 25/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9547 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 0.6939 - acc: 0.9784 - val_loss: 1.0084 - val_acc: 0.8000

Epoch 00025: loss improved from 0.78905 to 0.69390, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_11.h5
Epoch 26/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8498 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.6991 - acc: 0.9712 - val_loss: 1.4078 - val_acc: 0.7429

Epoch 00026: loss did not improve from 0.69390
Epoch 27/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0051 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.8202 - acc: 0.9281 - val_loss: 1.0391 - val_acc: 0.7714

Epoch 00027: loss did not improve from 0.69390
Epoch 28/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.6958 - acc: 0.9688
139/139 [==============================] - 0s 37us/step - loss: 1.1960 - acc: 0.8921 - val_loss: 2.0667 - val_acc: 0.6857

Epoch 00028: loss did not improve from 0.69390
Epoch 29/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4410 - acc: 0.8125
139/139 [==============================] - 0s 35us/step - loss: 1.2127 - acc: 0.8129 - val_loss: 1.5011 - val_acc: 0.7429

Epoch 00029: loss did not improve from 0.69390
Epoch 30/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0779 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 0.9751 - acc: 0.8489 - val_loss: 2.4137 - val_acc: 0.7143
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:10<00:12,  1.73s/it]
Epoch 00030: loss did not improve from 0.69390
Epoch 00030: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.2085 - acc: 0.5625
139/139 [==============================] - 0s 2ms/step - loss: 2.9980 - acc: 0.6475 - val_loss: 3.5808 - val_acc: 0.3429

Epoch 00001: loss improved from inf to 2.99800, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.3523 - acc: 0.5000
139/139 [==============================] - 0s 41us/step - loss: 2.0538 - acc: 0.6403 - val_loss: 2.9641 - val_acc: 0.3143

Epoch 00002: loss improved from 2.99800 to 2.05382, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.8533 - acc: 0.6250
139/139 [==============================] - 0s 38us/step - loss: 1.8792 - acc: 0.6475 - val_loss: 2.0553 - val_acc: 0.5143

Epoch 00003: loss improved from 2.05382 to 1.87916, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5030 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.7540 - acc: 0.6978 - val_loss: 2.2779 - val_acc: 0.4000

Epoch 00004: loss improved from 1.87916 to 1.75403, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.9385 - acc: 0.5312
139/139 [==============================] - 0s 37us/step - loss: 1.7538 - acc: 0.6619 - val_loss: 1.4720 - val_acc: 0.6857

Epoch 00005: loss improved from 1.75403 to 1.75384, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6686 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.5314 - acc: 0.7410 - val_loss: 1.6020 - val_acc: 0.7143

Epoch 00006: loss improved from 1.75384 to 1.53135, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3697 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.5031 - acc: 0.7554 - val_loss: 1.4002 - val_acc: 0.6857

Epoch 00007: loss improved from 1.53135 to 1.50312, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3396 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.2697 - acc: 0.7914 - val_loss: 1.3632 - val_acc: 0.7429

Epoch 00008: loss improved from 1.50312 to 1.26974, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3376 - acc: 0.9062
139/139 [==============================] - 0s 37us/step - loss: 1.4193 - acc: 0.8489 - val_loss: 1.6290 - val_acc: 0.7143

Epoch 00009: loss did not improve from 1.26974
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4541 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.5668 - acc: 0.7842 - val_loss: 1.4692 - val_acc: 0.7143

Epoch 00010: loss did not improve from 1.26974
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3427 - acc: 0.7812
139/139 [==============================] - 0s 35us/step - loss: 1.2785 - acc: 0.8058 - val_loss: 1.5395 - val_acc: 0.7429

Epoch 00011: loss did not improve from 1.26974
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1404 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.1950 - acc: 0.8489 - val_loss: 1.3933 - val_acc: 0.7429

Epoch 00012: loss improved from 1.26974 to 1.19499, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0272 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.1772 - acc: 0.8777 - val_loss: 1.2695 - val_acc: 0.7714

Epoch 00013: loss improved from 1.19499 to 1.17720, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1570 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.1141 - acc: 0.8561 - val_loss: 1.4672 - val_acc: 0.7429

Epoch 00014: loss improved from 1.17720 to 1.11413, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1790 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.0762 - acc: 0.8921 - val_loss: 1.2399 - val_acc: 0.7429

Epoch 00015: loss improved from 1.11413 to 1.07621, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0384 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.0033 - acc: 0.9065 - val_loss: 1.2856 - val_acc: 0.7429

Epoch 00016: loss improved from 1.07621 to 1.00330, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9518 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.9393 - acc: 0.9209 - val_loss: 1.0974 - val_acc: 0.7714

Epoch 00017: loss improved from 1.00330 to 0.93934, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_12.h5
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0300 - acc: 0.9688
139/139 [==============================] - 0s 37us/step - loss: 1.0292 - acc: 0.9353 - val_loss: 1.9242 - val_acc: 0.7429

Epoch 00018: loss did not improve from 0.93934
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1554 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.0970 - acc: 0.9137 - val_loss: 2.4471 - val_acc: 0.7429

Epoch 00019: loss did not improve from 0.93934
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1428 - acc: 0.8750
139/139 [==============================] - 0s 35us/step - loss: 1.2589 - acc: 0.8777 - val_loss: 2.0253 - val_acc: 0.8000

Epoch 00020: loss did not improve from 0.93934
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6849 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 1.3011 - acc: 0.8777 - val_loss: 1.8972 - val_acc: 0.7143

Epoch 00021: loss did not improve from 0.93934
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3646 - acc: 0.8125
139/139 [==============================] - 0s 35us/step - loss: 1.2578 - acc: 0.8561 - val_loss: 1.6613 - val_acc: 0.7429
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:12<00:10,  1.69s/it]
Epoch 00022: loss did not improve from 0.93934
Epoch 00022: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.3647 - acc: 0.6250
139/139 [==============================] - 0s 2ms/step - loss: 2.5284 - acc: 0.6475 - val_loss: 8.1120 - val_acc: 0.3714

Epoch 00001: loss improved from inf to 2.52836, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.6920 - acc: 0.5000
139/139 [==============================] - 0s 41us/step - loss: 3.1090 - acc: 0.6475 - val_loss: 3.6241 - val_acc: 0.4000

Epoch 00002: loss did not improve from 2.52836
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.5835 - acc: 0.4375
139/139 [==============================] - 0s 37us/step - loss: 2.3910 - acc: 0.5468 - val_loss: 2.3294 - val_acc: 0.4571

Epoch 00003: loss improved from 2.52836 to 2.39104, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.9483 - acc: 0.5938
139/139 [==============================] - 0s 37us/step - loss: 1.9134 - acc: 0.6403 - val_loss: 1.8585 - val_acc: 0.5714

Epoch 00004: loss improved from 2.39104 to 1.91344, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6496 - acc: 0.5938
139/139 [==============================] - 0s 37us/step - loss: 1.7818 - acc: 0.6619 - val_loss: 1.8884 - val_acc: 0.7143

Epoch 00005: loss improved from 1.91344 to 1.78181, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4936 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.5286 - acc: 0.7698 - val_loss: 1.6709 - val_acc: 0.7143

Epoch 00006: loss improved from 1.78181 to 1.52856, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5835 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.5205 - acc: 0.7770 - val_loss: 1.8348 - val_acc: 0.7143

Epoch 00007: loss improved from 1.52856 to 1.52053, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5954 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.4900 - acc: 0.7554 - val_loss: 1.8002 - val_acc: 0.7143

Epoch 00008: loss improved from 1.52053 to 1.48997, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2481 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.3948 - acc: 0.7914 - val_loss: 1.7835 - val_acc: 0.6571

Epoch 00009: loss improved from 1.48997 to 1.39479, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4470 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.4879 - acc: 0.7770 - val_loss: 1.6097 - val_acc: 0.7143

Epoch 00010: loss did not improve from 1.39479
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4204 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.2368 - acc: 0.8273 - val_loss: 1.7261 - val_acc: 0.7429

Epoch 00011: loss improved from 1.39479 to 1.23682, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2006 - acc: 0.8438
139/139 [==============================] - 0s 37us/step - loss: 1.2478 - acc: 0.8489 - val_loss: 1.6070 - val_acc: 0.7429

Epoch 00012: loss did not improve from 1.23682
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3270 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.3553 - acc: 0.8345 - val_loss: 1.4976 - val_acc: 0.7429

Epoch 00013: loss did not improve from 1.23682
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3126 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.1655 - acc: 0.8849 - val_loss: 1.2886 - val_acc: 0.7429

Epoch 00014: loss improved from 1.23682 to 1.16546, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3185 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.1448 - acc: 0.8705 - val_loss: 1.3579 - val_acc: 0.7429

Epoch 00015: loss improved from 1.16546 to 1.14478, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0962 - acc: 0.8438
139/139 [==============================] - 0s 37us/step - loss: 1.3044 - acc: 0.8489 - val_loss: 1.7999 - val_acc: 0.7429

Epoch 00016: loss did not improve from 1.14478
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2341 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.2560 - acc: 0.8345 - val_loss: 1.7179 - val_acc: 0.7429

Epoch 00017: loss did not improve from 1.14478
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2936 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.2783 - acc: 0.8273 - val_loss: 1.4236 - val_acc: 0.7714

Epoch 00018: loss did not improve from 1.14478
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1611 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.1352 - acc: 0.8633 - val_loss: 1.3623 - val_acc: 0.7429

Epoch 00019: loss improved from 1.14478 to 1.13525, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2841 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.2223 - acc: 0.8345 - val_loss: 1.4726 - val_acc: 0.7429

Epoch 00020: loss did not improve from 1.13525
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2627 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.2752 - acc: 0.8417 - val_loss: 1.3403 - val_acc: 0.7429

Epoch 00021: loss did not improve from 1.13525
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2764 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 0.9684 - acc: 0.8921 - val_loss: 1.3888 - val_acc: 0.7143

Epoch 00022: loss improved from 1.13525 to 0.96842, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9215 - acc: 0.9375
139/139 [==============================] - 0s 37us/step - loss: 1.0425 - acc: 0.9137 - val_loss: 1.3952 - val_acc: 0.7429

Epoch 00023: loss did not improve from 0.96842
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0272 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 1.0241 - acc: 0.8777 - val_loss: 1.3430 - val_acc: 0.7143

Epoch 00024: loss did not improve from 0.96842
Epoch 25/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0631 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 1.1162 - acc: 0.8993 - val_loss: 1.4820 - val_acc: 0.7429

Epoch 00025: loss did not improve from 0.96842
Epoch 26/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1628 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.1476 - acc: 0.8273 - val_loss: 1.4188 - val_acc: 0.7143

Epoch 00026: loss did not improve from 0.96842
Epoch 27/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0502 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 0.9194 - acc: 0.9065 - val_loss: 1.4803 - val_acc: 0.7429

Epoch 00027: loss improved from 0.96842 to 0.91936, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 28/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1302 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.9341 - acc: 0.9209 - val_loss: 1.3860 - val_acc: 0.7143

Epoch 00028: loss did not improve from 0.91936
Epoch 29/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9110 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 0.9270 - acc: 0.8993 - val_loss: 1.2572 - val_acc: 0.7714

Epoch 00029: loss did not improve from 0.91936
Epoch 30/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8808 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.8548 - acc: 0.9353 - val_loss: 1.2961 - val_acc: 0.7429

Epoch 00030: loss improved from 0.91936 to 0.85484, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 31/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8281 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.7142 - acc: 0.9496 - val_loss: 1.2491 - val_acc: 0.7429

Epoch 00031: loss improved from 0.85484 to 0.71422, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 32/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8340 - acc: 0.9375
139/139 [==============================] - 0s 37us/step - loss: 0.6874 - acc: 0.9496 - val_loss: 1.1948 - val_acc: 0.8000

Epoch 00032: loss improved from 0.71422 to 0.68739, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_13.h5
Epoch 33/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9097 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.7373 - acc: 0.9640 - val_loss: 1.1852 - val_acc: 0.8286

Epoch 00033: loss did not improve from 0.68739
Epoch 34/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3810 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 0.9112 - acc: 0.9137 - val_loss: 1.2271 - val_acc: 0.8000

Epoch 00034: loss did not improve from 0.68739
Epoch 35/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8744 - acc: 0.9688
139/139 [==============================] - 0s 36us/step - loss: 0.7345 - acc: 0.9568 - val_loss: 1.3761 - val_acc: 0.7714

Epoch 00035: loss did not improve from 0.68739
Epoch 36/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.8711 - acc: 0.9688
139/139 [==============================] - 0s 35us/step - loss: 0.7814 - acc: 0.9281 - val_loss: 1.1192 - val_acc: 0.8000

Epoch 00036: loss did not improve from 0.68739
Epoch 37/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9931 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 0.6986 - acc: 0.9353 - val_loss: 1.1527 - val_acc: 0.8000
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:13<00:08,  1.74s/it]
Epoch 00037: loss did not improve from 0.68739
Epoch 00037: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.3806 - acc: 0.5625
139/139 [==============================] - 0s 2ms/step - loss: 2.8062 - acc: 0.6475 - val_loss: 4.7840 - val_acc: 0.3429

Epoch 00001: loss improved from inf to 2.80623, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.8008 - acc: 0.4375
139/139 [==============================] - 0s 42us/step - loss: 2.6659 - acc: 0.5540 - val_loss: 3.4616 - val_acc: 0.4286

Epoch 00002: loss improved from 2.80623 to 2.66594, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.6434 - acc: 0.5000
139/139 [==============================] - 0s 38us/step - loss: 2.2479 - acc: 0.5755 - val_loss: 2.1088 - val_acc: 0.7143

Epoch 00003: loss improved from 2.66594 to 2.24794, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.7276 - acc: 0.6875
139/139 [==============================] - 0s 38us/step - loss: 1.8589 - acc: 0.6475 - val_loss: 1.8233 - val_acc: 0.7143

Epoch 00004: loss improved from 2.24794 to 1.85891, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6718 - acc: 0.7188
139/139 [==============================] - 0s 37us/step - loss: 1.7474 - acc: 0.6978 - val_loss: 2.1005 - val_acc: 0.4571

Epoch 00005: loss improved from 1.85891 to 1.74736, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.7683 - acc: 0.6875
139/139 [==============================] - 0s 37us/step - loss: 1.7184 - acc: 0.7122 - val_loss: 1.7387 - val_acc: 0.7143

Epoch 00006: loss improved from 1.74736 to 1.71839, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6141 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.5052 - acc: 0.7626 - val_loss: 1.7601 - val_acc: 0.7429

Epoch 00007: loss improved from 1.71839 to 1.50522, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5412 - acc: 0.7500
139/139 [==============================] - 0s 38us/step - loss: 1.4725 - acc: 0.7338 - val_loss: 1.6535 - val_acc: 0.7429

Epoch 00008: loss improved from 1.50522 to 1.47251, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6148 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.4506 - acc: 0.7770 - val_loss: 1.6466 - val_acc: 0.6857

Epoch 00009: loss improved from 1.47251 to 1.45060, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2191 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.4350 - acc: 0.7626 - val_loss: 2.0063 - val_acc: 0.6857

Epoch 00010: loss improved from 1.45060 to 1.43499, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4539 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.4493 - acc: 0.7842 - val_loss: 1.8300 - val_acc: 0.7429

Epoch 00011: loss did not improve from 1.43499
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5079 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.2814 - acc: 0.8129 - val_loss: 1.5341 - val_acc: 0.7429

Epoch 00012: loss improved from 1.43499 to 1.28136, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3563 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.2808 - acc: 0.8201 - val_loss: 1.7272 - val_acc: 0.7429

Epoch 00013: loss improved from 1.28136 to 1.28077, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3313 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.3001 - acc: 0.8345 - val_loss: 1.5182 - val_acc: 0.7429

Epoch 00014: loss did not improve from 1.28077
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1541 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.1919 - acc: 0.8561 - val_loss: 1.4775 - val_acc: 0.7143

Epoch 00015: loss improved from 1.28077 to 1.19187, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0074 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.3875 - acc: 0.8058 - val_loss: 2.3520 - val_acc: 0.7143

Epoch 00016: loss did not improve from 1.19187
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6325 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.2828 - acc: 0.8345 - val_loss: 2.1105 - val_acc: 0.7143

Epoch 00017: loss did not improve from 1.19187
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1523 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.0955 - acc: 0.8849 - val_loss: 2.2631 - val_acc: 0.7429

Epoch 00018: loss improved from 1.19187 to 1.09552, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1420 - acc: 0.9375
139/139 [==============================] - 0s 37us/step - loss: 1.2521 - acc: 0.8777 - val_loss: 2.0336 - val_acc: 0.7143

Epoch 00019: loss did not improve from 1.09552
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1210 - acc: 0.9375
139/139 [==============================] - 0s 36us/step - loss: 1.3385 - acc: 0.9065 - val_loss: 2.1368 - val_acc: 0.7429

Epoch 00020: loss did not improve from 1.09552
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1271 - acc: 0.8438
139/139 [==============================] - 0s 35us/step - loss: 1.2823 - acc: 0.8129 - val_loss: 1.1706 - val_acc: 0.8286

Epoch 00021: loss did not improve from 1.09552
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0795 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.0473 - acc: 0.8849 - val_loss: 1.6712 - val_acc: 0.7429

Epoch 00022: loss improved from 1.09552 to 1.04733, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1459 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.2204 - acc: 0.8417 - val_loss: 1.4615 - val_acc: 0.7429

Epoch 00023: loss did not improve from 1.04733
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3290 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.0324 - acc: 0.8777 - val_loss: 1.1956 - val_acc: 0.7429

Epoch 00024: loss improved from 1.04733 to 1.03244, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_14.h5
Epoch 25/100

 32/139 [=====>........................] - ETA: 0s - loss: 0.9599 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.6893 - acc: 0.8633 - val_loss: 2.1058 - val_acc: 0.7714

Epoch 00025: loss did not improve from 1.03244
Epoch 26/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3184 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.5652 - acc: 0.8273 - val_loss: 1.7858 - val_acc: 0.7714

Epoch 00026: loss did not improve from 1.03244
Epoch 27/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4327 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.3198 - acc: 0.8345 - val_loss: 1.6806 - val_acc: 0.7714

Epoch 00027: loss did not improve from 1.03244
Epoch 28/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1741 - acc: 0.8125
139/139 [==============================] - 0s 35us/step - loss: 1.0639 - acc: 0.8489 - val_loss: 1.5331 - val_acc: 0.7714

Epoch 00028: loss did not improve from 1.03244
Epoch 29/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3213 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.1591 - acc: 0.8633 - val_loss: 1.8405 - val_acc: 0.7714
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:15<00:07,  1.75s/it]
Epoch 00029: loss did not improve from 1.03244
Epoch 00029: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.5490 - acc: 0.5312
139/139 [==============================] - 0s 2ms/step - loss: 2.5721 - acc: 0.6475 - val_loss: 5.9563 - val_acc: 0.3429

Epoch 00001: loss improved from inf to 2.57213, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.5374 - acc: 0.3750
139/139 [==============================] - 0s 40us/step - loss: 2.7366 - acc: 0.6187 - val_loss: 5.7680 - val_acc: 0.3714

Epoch 00002: loss did not improve from 2.57213
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.4616 - acc: 0.4062
139/139 [==============================] - 0s 37us/step - loss: 3.2808 - acc: 0.4388 - val_loss: 2.6270 - val_acc: 0.3714

Epoch 00003: loss did not improve from 2.57213
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.2296 - acc: 0.5625
139/139 [==============================] - 0s 36us/step - loss: 1.9345 - acc: 0.6187 - val_loss: 2.1682 - val_acc: 0.5429

Epoch 00004: loss improved from 2.57213 to 1.93445, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.4793 - acc: 0.6875
139/139 [==============================] - 0s 37us/step - loss: 1.9818 - acc: 0.6547 - val_loss: 1.8875 - val_acc: 0.6000

Epoch 00005: loss did not improve from 1.93445
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6405 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.6975 - acc: 0.6978 - val_loss: 1.7847 - val_acc: 0.7143

Epoch 00006: loss improved from 1.93445 to 1.69747, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4526 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.6230 - acc: 0.7266 - val_loss: 2.5532 - val_acc: 0.4000

Epoch 00007: loss improved from 1.69747 to 1.62304, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.2973 - acc: 0.4688
139/139 [==============================] - 0s 37us/step - loss: 2.3200 - acc: 0.6475 - val_loss: 2.1275 - val_acc: 0.5429

Epoch 00008: loss did not improve from 1.62304
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6992 - acc: 0.6562
139/139 [==============================] - 0s 36us/step - loss: 1.6427 - acc: 0.6978 - val_loss: 2.0276 - val_acc: 0.7143

Epoch 00009: loss did not improve from 1.62304
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.8625 - acc: 0.7188
139/139 [==============================] - 0s 36us/step - loss: 1.4994 - acc: 0.7554 - val_loss: 1.8540 - val_acc: 0.7429

Epoch 00010: loss improved from 1.62304 to 1.49943, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5874 - acc: 0.7500
139/139 [==============================] - 0s 36us/step - loss: 1.5435 - acc: 0.7482 - val_loss: 1.8945 - val_acc: 0.7429

Epoch 00011: loss did not improve from 1.49943
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4766 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.2721 - acc: 0.8345 - val_loss: 1.7052 - val_acc: 0.7429

Epoch 00012: loss improved from 1.49943 to 1.27209, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4057 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.2760 - acc: 0.8129 - val_loss: 1.8327 - val_acc: 0.7429

Epoch 00013: loss did not improve from 1.27209
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2636 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.1811 - acc: 0.8777 - val_loss: 1.6864 - val_acc: 0.7429

Epoch 00014: loss improved from 1.27209 to 1.18110, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.7341 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.4356 - acc: 0.8058 - val_loss: 1.8505 - val_acc: 0.6000

Epoch 00015: loss did not improve from 1.18110
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3329 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.5325 - acc: 0.7842 - val_loss: 1.7893 - val_acc: 0.7429

Epoch 00016: loss did not improve from 1.18110
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6413 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.3659 - acc: 0.7914 - val_loss: 1.3402 - val_acc: 0.7429

Epoch 00017: loss did not improve from 1.18110
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2669 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.1399 - acc: 0.8561 - val_loss: 1.6505 - val_acc: 0.7429

Epoch 00018: loss improved from 1.18110 to 1.13985, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3704 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.2331 - acc: 0.8273 - val_loss: 1.3316 - val_acc: 0.7429

Epoch 00019: loss did not improve from 1.13985
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.1576 - acc: 0.7500
139/139 [==============================] - 0s 35us/step - loss: 1.6258 - acc: 0.8129 - val_loss: 2.0871 - val_acc: 0.7429

Epoch 00020: loss did not improve from 1.13985
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2306 - acc: 0.9062
139/139 [==============================] - 0s 35us/step - loss: 1.2104 - acc: 0.8561 - val_loss: 1.6048 - val_acc: 0.7429

Epoch 00021: loss did not improve from 1.13985
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1827 - acc: 0.9375
139/139 [==============================] - 0s 35us/step - loss: 1.0470 - acc: 0.8849 - val_loss: 1.7626 - val_acc: 0.7429

Epoch 00022: loss improved from 1.13985 to 1.04701, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_15.h5
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1766 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.3257 - acc: 0.8633 - val_loss: 2.5481 - val_acc: 0.7429

Epoch 00023: loss did not improve from 1.04701
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4256 - acc: 0.8125
139/139 [==============================] - 0s 35us/step - loss: 2.0971 - acc: 0.8129 - val_loss: 2.9194 - val_acc: 0.5429

Epoch 00024: loss did not improve from 1.04701
Epoch 25/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4636 - acc: 0.7812
139/139 [==============================] - 0s 35us/step - loss: 1.4541 - acc: 0.7626 - val_loss: 2.2993 - val_acc: 0.7429

Epoch 00025: loss did not improve from 1.04701
Epoch 26/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.2340 - acc: 0.7812
139/139 [==============================] - 0s 35us/step - loss: 1.5484 - acc: 0.7842 - val_loss: 2.4963 - val_acc: 0.7429

Epoch 00026: loss did not improve from 1.04701
Epoch 27/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2400 - acc: 0.8125
139/139 [==============================] - 0s 35us/step - loss: 1.3143 - acc: 0.8489 - val_loss: 2.2159 - val_acc: 0.7429
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:17<00:05,  1.74s/it]
Epoch 00027: loss did not improve from 1.04701
Epoch 00027: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.9937 - acc: 0.5938
139/139 [==============================] - 0s 2ms/step - loss: 3.1333 - acc: 0.6475 - val_loss: 7.2434 - val_acc: 0.3714

Epoch 00001: loss improved from inf to 3.13333, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.9453 - acc: 0.5312
139/139 [==============================] - 0s 42us/step - loss: 2.7568 - acc: 0.6403 - val_loss: 3.1078 - val_acc: 0.4286

Epoch 00002: loss improved from 3.13333 to 2.75679, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.2897 - acc: 0.5000
139/139 [==============================] - 0s 38us/step - loss: 2.3883 - acc: 0.5683 - val_loss: 2.1163 - val_acc: 0.6857

Epoch 00003: loss improved from 2.75679 to 2.38833, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.0908 - acc: 0.6250
139/139 [==============================] - 0s 37us/step - loss: 2.0019 - acc: 0.6835 - val_loss: 1.9625 - val_acc: 0.6857

Epoch 00004: loss improved from 2.38833 to 2.00189, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4147 - acc: 0.7188
139/139 [==============================] - 0s 37us/step - loss: 1.7641 - acc: 0.6978 - val_loss: 1.9703 - val_acc: 0.7143

Epoch 00005: loss improved from 2.00189 to 1.76408, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5781 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.7387 - acc: 0.7266 - val_loss: 1.8018 - val_acc: 0.7143

Epoch 00006: loss improved from 1.76408 to 1.73866, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6968 - acc: 0.7500
139/139 [==============================] - 0s 37us/step - loss: 1.6997 - acc: 0.6835 - val_loss: 1.7678 - val_acc: 0.6286

Epoch 00007: loss improved from 1.73866 to 1.69973, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5835 - acc: 0.6875
139/139 [==============================] - 0s 37us/step - loss: 1.5945 - acc: 0.7626 - val_loss: 1.9531 - val_acc: 0.6286

Epoch 00008: loss improved from 1.69973 to 1.59452, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4942 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.5192 - acc: 0.7482 - val_loss: 2.0281 - val_acc: 0.4571

Epoch 00009: loss improved from 1.59452 to 1.51924, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.8254 - acc: 0.7188
139/139 [==============================] - 0s 37us/step - loss: 1.6935 - acc: 0.7050 - val_loss: 1.8381 - val_acc: 0.6857

Epoch 00010: loss did not improve from 1.51924
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.0539 - acc: 0.7500
139/139 [==============================] - 0s 36us/step - loss: 1.7513 - acc: 0.7482 - val_loss: 1.7428 - val_acc: 0.7143

Epoch 00011: loss did not improve from 1.51924
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4920 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.3592 - acc: 0.8058 - val_loss: 1.5329 - val_acc: 0.7143

Epoch 00012: loss improved from 1.51924 to 1.35920, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4337 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.3803 - acc: 0.7986 - val_loss: 1.4231 - val_acc: 0.6857

Epoch 00013: loss did not improve from 1.35920
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3770 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.4251 - acc: 0.7914 - val_loss: 1.7100 - val_acc: 0.7143

Epoch 00014: loss did not improve from 1.35920
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3252 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.2644 - acc: 0.8345 - val_loss: 1.4107 - val_acc: 0.7143

Epoch 00015: loss improved from 1.35920 to 1.26444, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3807 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.1230 - acc: 0.8273 - val_loss: 1.3755 - val_acc: 0.7143

Epoch 00016: loss improved from 1.26444 to 1.12303, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0492 - acc: 0.8125
139/139 [==============================] - 0s 38us/step - loss: 1.3186 - acc: 0.8058 - val_loss: 1.7546 - val_acc: 0.7429

Epoch 00017: loss did not improve from 1.12303
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3937 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.1989 - acc: 0.8129 - val_loss: 1.6663 - val_acc: 0.7143

Epoch 00018: loss did not improve from 1.12303
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3127 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.0771 - acc: 0.8561 - val_loss: 1.6753 - val_acc: 0.7143

Epoch 00019: loss improved from 1.12303 to 1.07706, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1026 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.0727 - acc: 0.8633 - val_loss: 1.3616 - val_acc: 0.7429

Epoch 00020: loss improved from 1.07706 to 1.07267, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_16.h5
Epoch 21/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5204 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.4000 - acc: 0.8345 - val_loss: 1.4494 - val_acc: 0.7143

Epoch 00021: loss did not improve from 1.07267
Epoch 22/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1547 - acc: 0.9062
139/139 [==============================] - 0s 36us/step - loss: 1.1646 - acc: 0.8561 - val_loss: 1.3106 - val_acc: 0.8000

Epoch 00022: loss did not improve from 1.07267
Epoch 23/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2327 - acc: 0.7812
139/139 [==============================] - 0s 35us/step - loss: 1.1244 - acc: 0.8489 - val_loss: 1.3127 - val_acc: 0.7429

Epoch 00023: loss did not improve from 1.07267
Epoch 24/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.0517 - acc: 0.8125
139/139 [==============================] - 0s 35us/step - loss: 1.4794 - acc: 0.8417 - val_loss: 2.5099 - val_acc: 0.7143

Epoch 00024: loss did not improve from 1.07267
Epoch 25/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4998 - acc: 0.8125
139/139 [==============================] - 0s 35us/step - loss: 1.1567 - acc: 0.8273 - val_loss: 2.1380 - val_acc: 0.7143
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:19<00:03,  1.71s/it]
Epoch 00025: loss did not improve from 1.07267
Epoch 00025: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.4387 - acc: 0.5938
139/139 [==============================] - 0s 2ms/step - loss: 2.5565 - acc: 0.6475 - val_loss: 9.3206 - val_acc: 0.3143

Epoch 00001: loss improved from inf to 2.55649, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 3.9889 - acc: 0.4688
139/139 [==============================] - 0s 41us/step - loss: 3.1129 - acc: 0.6547 - val_loss: 3.0224 - val_acc: 0.4857

Epoch 00002: loss did not improve from 2.55649
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.3481 - acc: 0.5000
139/139 [==============================] - 0s 37us/step - loss: 2.9066 - acc: 0.5755 - val_loss: 2.2900 - val_acc: 0.5714

Epoch 00003: loss did not improve from 2.55649
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.9158 - acc: 0.6250
139/139 [==============================] - 0s 37us/step - loss: 1.9472 - acc: 0.6835 - val_loss: 1.9518 - val_acc: 0.6286

Epoch 00004: loss improved from 2.55649 to 1.94718, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.7871 - acc: 0.6875
139/139 [==============================] - 0s 37us/step - loss: 1.9940 - acc: 0.6835 - val_loss: 2.2753 - val_acc: 0.6857

Epoch 00005: loss did not improve from 1.94718
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6335 - acc: 0.7188
139/139 [==============================] - 0s 36us/step - loss: 1.6906 - acc: 0.7122 - val_loss: 2.1324 - val_acc: 0.7429

Epoch 00006: loss improved from 1.94718 to 1.69056, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4551 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.5606 - acc: 0.7698 - val_loss: 1.8585 - val_acc: 0.7429

Epoch 00007: loss improved from 1.69056 to 1.56062, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6042 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.5270 - acc: 0.7698 - val_loss: 1.7047 - val_acc: 0.6571

Epoch 00008: loss improved from 1.56062 to 1.52702, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6800 - acc: 0.6875
139/139 [==============================] - 0s 37us/step - loss: 1.5157 - acc: 0.7554 - val_loss: 1.9586 - val_acc: 0.7429

Epoch 00009: loss improved from 1.52702 to 1.51575, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5047 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.4459 - acc: 0.8129 - val_loss: 1.5460 - val_acc: 0.7429

Epoch 00010: loss improved from 1.51575 to 1.44588, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3374 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.3437 - acc: 0.8417 - val_loss: 3.8890 - val_acc: 0.2857

Epoch 00011: loss improved from 1.44588 to 1.34375, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.7166 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.6112 - acc: 0.7554 - val_loss: 2.3464 - val_acc: 0.6286

Epoch 00012: loss did not improve from 1.34375
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5192 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.5963 - acc: 0.7914 - val_loss: 2.1926 - val_acc: 0.5714

Epoch 00013: loss did not improve from 1.34375
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4574 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.3721 - acc: 0.8345 - val_loss: 2.0157 - val_acc: 0.6000

Epoch 00014: loss did not improve from 1.34375
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3812 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.1903 - acc: 0.8489 - val_loss: 1.8217 - val_acc: 0.6286

Epoch 00015: loss improved from 1.34375 to 1.19032, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_17.h5
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1915 - acc: 0.8750
139/139 [==============================] - 0s 37us/step - loss: 1.2173 - acc: 0.8705 - val_loss: 1.7058 - val_acc: 0.6571

Epoch 00016: loss did not improve from 1.19032
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1474 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.2623 - acc: 0.8633 - val_loss: 2.3447 - val_acc: 0.6000

Epoch 00017: loss did not improve from 1.19032
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.1273 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.3603 - acc: 0.8201 - val_loss: 2.0156 - val_acc: 0.6571

Epoch 00018: loss did not improve from 1.19032
Epoch 19/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3228 - acc: 0.8750
139/139 [==============================] - 0s 36us/step - loss: 1.4782 - acc: 0.8489 - val_loss: 1.8598 - val_acc: 0.7714

Epoch 00019: loss did not improve from 1.19032
Epoch 20/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.2116 - acc: 0.8438
139/139 [==============================] - 0s 36us/step - loss: 1.8580 - acc: 0.8058 - val_loss: 1.5298 - val_acc: 0.7714
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:20<00:01,  1.71s/it]
Epoch 00020: loss did not improve from 1.19032
Epoch 00020: early stopping
Train on 139 samples, validate on 35 samples
Epoch 1/100

 32/139 [=====>........................] - ETA: 0s - loss: 4.0286 - acc: 0.5938
139/139 [==============================] - 0s 2ms/step - loss: 3.3607 - acc: 0.6331 - val_loss: 4.8761 - val_acc: 0.4000

Epoch 00001: loss improved from inf to 3.36069, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/139 [=====>........................] - ETA: 0s - loss: 4.8471 - acc: 0.4375
139/139 [==============================] - 0s 41us/step - loss: 3.2402 - acc: 0.5899 - val_loss: 2.6250 - val_acc: 0.5429

Epoch 00002: loss improved from 3.36069 to 3.24018, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.9534 - acc: 0.7500
139/139 [==============================] - 0s 38us/step - loss: 2.1243 - acc: 0.6978 - val_loss: 2.6177 - val_acc: 0.4000

Epoch 00003: loss improved from 3.24018 to 2.12434, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.1303 - acc: 0.5312
139/139 [==============================] - 0s 38us/step - loss: 2.1418 - acc: 0.6115 - val_loss: 2.4658 - val_acc: 0.3429

Epoch 00004: loss did not improve from 2.12434
Epoch 5/100

 32/139 [=====>........................] - ETA: 0s - loss: 2.0797 - acc: 0.5625
139/139 [==============================] - 0s 37us/step - loss: 1.9648 - acc: 0.6835 - val_loss: 2.3357 - val_acc: 0.6286

Epoch 00005: loss improved from 2.12434 to 1.96478, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.7764 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.9153 - acc: 0.7482 - val_loss: 2.3108 - val_acc: 0.6571

Epoch 00006: loss improved from 1.96478 to 1.91532, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6022 - acc: 0.7812
139/139 [==============================] - 0s 37us/step - loss: 1.8609 - acc: 0.7338 - val_loss: 2.2389 - val_acc: 0.5429

Epoch 00007: loss improved from 1.91532 to 1.86087, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6779 - acc: 0.6875
139/139 [==============================] - 0s 37us/step - loss: 1.6603 - acc: 0.6835 - val_loss: 2.0264 - val_acc: 0.6857

Epoch 00008: loss improved from 1.86087 to 1.66031, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6288 - acc: 0.7188
139/139 [==============================] - 0s 39us/step - loss: 1.6835 - acc: 0.7842 - val_loss: 2.1369 - val_acc: 0.6000

Epoch 00009: loss did not improve from 1.66031
Epoch 10/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.9462 - acc: 0.6562
139/139 [==============================] - 0s 36us/step - loss: 1.7266 - acc: 0.7266 - val_loss: 1.7391 - val_acc: 0.6857

Epoch 00010: loss did not improve from 1.66031
Epoch 11/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4932 - acc: 0.7812
139/139 [==============================] - 0s 36us/step - loss: 1.4197 - acc: 0.7914 - val_loss: 1.9068 - val_acc: 0.7429

Epoch 00011: loss improved from 1.66031 to 1.41972, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4101 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.4733 - acc: 0.8058 - val_loss: 1.7813 - val_acc: 0.7429

Epoch 00012: loss did not improve from 1.41972
Epoch 13/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.4680 - acc: 0.8125
139/139 [==============================] - 0s 36us/step - loss: 1.3966 - acc: 0.8201 - val_loss: 1.5789 - val_acc: 0.7429

Epoch 00013: loss improved from 1.41972 to 1.39658, saving model to ./results_TA102_without_S9/DeepAmes_models/weight_18.h5
Epoch 14/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6468 - acc: 0.8125
139/139 [==============================] - 0s 37us/step - loss: 1.9934 - acc: 0.7698 - val_loss: 3.3569 - val_acc: 0.4286

Epoch 00014: loss did not improve from 1.39658
Epoch 15/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.6904 - acc: 0.6250
139/139 [==============================] - 0s 36us/step - loss: 1.9575 - acc: 0.6978 - val_loss: 1.8553 - val_acc: 0.7429

Epoch 00015: loss did not improve from 1.39658
Epoch 16/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5003 - acc: 0.7500
139/139 [==============================] - 0s 36us/step - loss: 2.0206 - acc: 0.7410 - val_loss: 2.1863 - val_acc: 0.7429

Epoch 00016: loss did not improve from 1.39658
Epoch 17/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.5106 - acc: 0.7500
139/139 [==============================] - 0s 36us/step - loss: 1.5654 - acc: 0.7698 - val_loss: 1.8954 - val_acc: 0.7429

Epoch 00017: loss did not improve from 1.39658
Epoch 18/100

 32/139 [=====>........................] - ETA: 0s - loss: 1.3771 - acc: 0.8125
139/139 [==============================] - 0s 38us/step - loss: 1.4686 - acc: 0.7986 - val_loss: 2.2302 - val_acc: 0.7429
DeepAmes+ Weights: 100%|██████████| 13/13 [00:22<00:00,  1.70s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:22<00:00,  1.72s/it]

Epoch 00018: loss did not improve from 1.39658
Epoch 00018: early stopping
--- 934.3008642196655 seconds ---

Generating metrics report for TA102_without_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 115 samples.
Processing weight 7...
  Done. 115 samples.
Processing weight 8...
  Done. 115 samples.
Processing weight 9...
  Done. 115 samples.
Processing weight 10...
  Done. 115 samples.
Processing weight 11...
  Done. 115 samples.
Processing weight 12...
  Done. 115 samples.
Processing weight 13...
  Done. 115 samples.
Processing weight 14...
  Done. 115 samples.
Processing weight 15...
  Done. 115 samples.
Processing weight 16...
  Done. 115 samples.
Processing weight 17...
  Done. 115 samples.
Processing weight 18...
  Done. 115 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA102_without_S9/metrics_report_TA102_without_S9.txt

Done!

Completed TA102_without_S9 in 934.30 seconds

================================================================================
[5/16] Processing: TA104_with_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA104_with_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA104_with_S9_Test_mold2.csv
(268, 777)
(214, 777)
(19, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:00<00:04,  4.08it/s]KNN Seeds:  10%|█         | 2/20 [00:00<00:04,  3.97it/s]KNN Seeds:  15%|█▌        | 3/20 [00:00<00:04,  3.86it/s]KNN Seeds:  20%|██        | 4/20 [00:01<00:04,  3.75it/s]KNN Seeds:  25%|██▌       | 5/20 [00:01<00:04,  3.64it/s]KNN Seeds:  30%|███       | 6/20 [00:01<00:03,  3.52it/s]KNN Seeds:  35%|███▌      | 7/20 [00:01<00:03,  3.42it/s]KNN Seeds:  40%|████      | 8/20 [00:02<00:03,  3.32it/s]KNN Seeds:  45%|████▌     | 9/20 [00:02<00:03,  3.22it/s]KNN Seeds:  50%|█████     | 10/20 [00:02<00:03,  3.12it/s]KNN Seeds:  55%|█████▌    | 11/20 [00:03<00:02,  3.02it/s]KNN Seeds:  60%|██████    | 12/20 [00:03<00:02,  2.93it/s]KNN Seeds:  65%|██████▌   | 13/20 [00:04<00:02,  2.84it/s]KNN Seeds:  70%|███████   | 14/20 [00:04<00:02,  2.76it/s]KNN Seeds:  75%|███████▌  | 15/20 [00:04<00:01,  2.68it/s]KNN Seeds:  80%|████████  | 16/20 [00:05<00:01,  2.61it/s]KNN Seeds:  85%|████████▌ | 17/20 [00:05<00:01,  2.54it/s]KNN Seeds:  90%|█████████ | 18/20 [00:06<00:00,  2.47it/s]KNN Seeds:  95%|█████████▌| 19/20 [00:06<00:00,  2.41it/s]KNN Seeds: 100%|██████████| 20/20 [00:06<00:00,  2.35it/s]KNN Seeds: 100%|██████████| 20/20 [00:06<00:00,  2.87it/s]
24
(100, None, 'lbfgs')
(268, 777)
(214, 777)
(19, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:01<00:24,  1.30s/it]LR Seeds:  10%|█         | 2/20 [00:02<00:24,  1.37s/it]LR Seeds:  15%|█▌        | 3/20 [00:04<00:23,  1.40s/it]LR Seeds:  20%|██        | 4/20 [00:05<00:22,  1.43s/it]LR Seeds:  25%|██▌       | 5/20 [00:07<00:21,  1.44s/it]LR Seeds:  30%|███       | 6/20 [00:08<00:20,  1.44s/it]LR Seeds:  35%|███▌      | 7/20 [00:09<00:18,  1.45s/it]LR Seeds:  40%|████      | 8/20 [00:11<00:17,  1.45s/it]LR Seeds:  45%|████▌     | 9/20 [00:12<00:16,  1.46s/it]LR Seeds:  50%|█████     | 10/20 [00:14<00:14,  1.50s/it]LR Seeds:  55%|█████▌    | 11/20 [00:16<00:13,  1.50s/it]LR Seeds:  60%|██████    | 12/20 [00:17<00:12,  1.51s/it]LR Seeds:  65%|██████▌   | 13/20 [00:19<00:10,  1.52s/it]LR Seeds:  70%|███████   | 14/20 [00:20<00:08,  1.49s/it]LR Seeds:  75%|███████▌  | 15/20 [00:22<00:07,  1.50s/it]LR Seeds:  80%|████████  | 16/20 [00:23<00:06,  1.52s/it]LR Seeds:  85%|████████▌ | 17/20 [00:25<00:04,  1.54s/it]LR Seeds:  90%|█████████ | 18/20 [00:26<00:03,  1.60s/it]LR Seeds:  95%|█████████▌| 19/20 [00:28<00:01,  1.59s/it]LR Seeds: 100%|██████████| 20/20 [00:30<00:00,  1.58s/it]LR Seeds: 100%|██████████| 20/20 [00:30<00:00,  1.50s/it]
96
('rbf', 1, 1)
(268, 777)
(214, 777)
(19, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [00:00<00:16,  1.18it/s]SVM Seeds:  10%|█         | 2/20 [00:01<00:15,  1.17it/s]SVM Seeds:  15%|█▌        | 3/20 [00:02<00:14,  1.16it/s]SVM Seeds:  20%|██        | 4/20 [00:03<00:13,  1.15it/s]SVM Seeds:  25%|██▌       | 5/20 [00:04<00:13,  1.14it/s]SVM Seeds:  30%|███       | 6/20 [00:05<00:12,  1.13it/s]SVM Seeds:  35%|███▌      | 7/20 [00:06<00:11,  1.12it/s]SVM Seeds:  40%|████      | 8/20 [00:07<00:10,  1.11it/s]SVM Seeds:  45%|████▌     | 9/20 [00:08<00:10,  1.09it/s]SVM Seeds:  50%|█████     | 10/20 [00:08<00:09,  1.08it/s]SVM Seeds:  55%|█████▌    | 11/20 [00:09<00:08,  1.07it/s]SVM Seeds:  60%|██████    | 12/20 [00:10<00:07,  1.06it/s]SVM Seeds:  65%|██████▌   | 13/20 [00:11<00:06,  1.05it/s]SVM Seeds:  70%|███████   | 14/20 [00:12<00:05,  1.03it/s]SVM Seeds:  75%|███████▌  | 15/20 [00:13<00:04,  1.02it/s]SVM Seeds:  80%|████████  | 16/20 [00:14<00:03,  1.01it/s]SVM Seeds:  85%|████████▌ | 17/20 [00:15<00:02,  1.00it/s]SVM Seeds:  90%|█████████ | 18/20 [00:16<00:02,  1.01s/it]SVM Seeds:  95%|█████████▌| 19/20 [00:17<00:01,  1.02s/it]SVM Seeds: 100%|██████████| 20/20 [00:19<00:00,  1.03s/it]SVM Seeds: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]
200
(500, None, 70, 1, 'balanced')
(268, 777)
(214, 777)
(19, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:01<00:27,  1.46s/it]RF Seeds:  10%|█         | 2/20 [00:02<00:26,  1.45s/it]RF Seeds:  15%|█▌        | 3/20 [00:04<00:24,  1.45s/it]RF Seeds:  20%|██        | 4/20 [00:05<00:23,  1.46s/it]RF Seeds:  25%|██▌       | 5/20 [00:07<00:21,  1.47s/it]RF Seeds:  30%|███       | 6/20 [00:08<00:20,  1.48s/it]RF Seeds:  35%|███▌      | 7/20 [00:10<00:19,  1.49s/it]RF Seeds:  40%|████      | 8/20 [00:11<00:17,  1.50s/it]RF Seeds:  45%|████▌     | 9/20 [00:13<00:16,  1.50s/it]RF Seeds:  50%|█████     | 10/20 [00:14<00:15,  1.51s/it]RF Seeds:  55%|█████▌    | 11/20 [00:16<00:13,  1.53s/it]RF Seeds:  60%|██████    | 12/20 [00:18<00:12,  1.54s/it]RF Seeds:  65%|██████▌   | 13/20 [00:19<00:10,  1.56s/it]RF Seeds:  70%|███████   | 14/20 [00:21<00:09,  1.56s/it]RF Seeds:  75%|███████▌  | 15/20 [00:22<00:07,  1.57s/it]RF Seeds:  80%|████████  | 16/20 [00:24<00:06,  1.58s/it]RF Seeds:  85%|████████▌ | 17/20 [00:26<00:04,  1.61s/it]RF Seeds:  90%|█████████ | 18/20 [00:27<00:03,  1.61s/it]RF Seeds:  95%|█████████▌| 19/20 [00:29<00:01,  1.62s/it]RF Seeds: 100%|██████████| 20/20 [00:30<00:00,  1.63s/it]RF Seeds: 100%|██████████| 20/20 [00:30<00:00,  1.55s/it]
400
(0.01, 900, 7, 0.8, 6)
(268, 777)
(214, 777)
(19, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:23<07:30, 23.74s/it]XGBoost Seeds:  10%|█         | 2/20 [00:47<07:06, 23.68s/it]XGBoost Seeds:  15%|█▌        | 3/20 [01:10<06:41, 23.60s/it]XGBoost Seeds:  20%|██        | 4/20 [01:34<06:19, 23.70s/it]XGBoost Seeds:  25%|██▌       | 5/20 [01:58<05:56, 23.75s/it]XGBoost Seeds:  30%|███       | 6/20 [02:22<05:31, 23.65s/it]XGBoost Seeds:  35%|███▌      | 7/20 [02:51<05:30, 25.44s/it]XGBoost Seeds:  40%|████      | 8/20 [03:14<04:57, 24.77s/it]XGBoost Seeds:  45%|████▌     | 9/20 [03:37<04:27, 24.31s/it]XGBoost Seeds:  50%|█████     | 10/20 [04:00<03:59, 23.97s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [04:24<03:33, 23.77s/it]XGBoost Seeds:  60%|██████    | 12/20 [04:47<03:08, 23.59s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [05:11<02:45, 23.60s/it]XGBoost Seeds:  70%|███████   | 14/20 [05:34<02:20, 23.47s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [05:57<01:57, 23.41s/it]XGBoost Seeds:  80%|████████  | 16/20 [06:20<01:33, 23.39s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [06:44<01:10, 23.33s/it]XGBoost Seeds:  90%|█████████ | 18/20 [07:07<00:46, 23.28s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [07:30<00:23, 23.23s/it]XGBoost Seeds: 100%|██████████| 20/20 [07:53<00:00, 23.27s/it]XGBoost Seeds: 100%|██████████| 20/20 [07:53<00:00, 23.69s/it]
knn:  100
lr:  83
svm:  59
rf:  98
xgboost:  92
Combining validation predictions is completed
knn:  100
lr:  83
svm:  59
rf:  98
xgboost:  92
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3483 - acc: 0.6875
43/43 [==============================] - 0s 6ms/step - loss: 2.8148 - acc: 0.6279 - val_loss: 0.9454 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 2.81480, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0684 - acc: 0.6250
43/43 [==============================] - 0s 64us/step - loss: 2.0890 - acc: 0.6512 - val_loss: 0.8829 - val_acc: 0.9091

Epoch 00002: loss improved from 2.81480 to 2.08897, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 2.9258 - acc: 0.6250
43/43 [==============================] - 0s 53us/step - loss: 2.4632 - acc: 0.6744 - val_loss: 0.8653 - val_acc: 0.9091

Epoch 00003: loss did not improve from 2.08897
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2280 - acc: 0.6875
43/43 [==============================] - 0s 50us/step - loss: 1.9562 - acc: 0.6977 - val_loss: 1.0130 - val_acc: 0.9091

Epoch 00004: loss improved from 2.08897 to 1.95623, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8586 - acc: 0.6250
43/43 [==============================] - 0s 57us/step - loss: 1.6428 - acc: 0.7209 - val_loss: 1.0041 - val_acc: 0.9091

Epoch 00005: loss improved from 1.95623 to 1.64284, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5777 - acc: 0.6875
43/43 [==============================] - 0s 52us/step - loss: 1.4864 - acc: 0.7674 - val_loss: 0.9327 - val_acc: 0.9091

Epoch 00006: loss improved from 1.64284 to 1.48645, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6202 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 1.4976 - acc: 0.7209 - val_loss: 0.9240 - val_acc: 0.9091

Epoch 00007: loss did not improve from 1.48645
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9630 - acc: 0.6562
43/43 [==============================] - 0s 48us/step - loss: 1.7267 - acc: 0.7209 - val_loss: 0.9117 - val_acc: 0.9091

Epoch 00008: loss did not improve from 1.48645
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6554 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.4561 - acc: 0.7674 - val_loss: 0.9442 - val_acc: 0.8182

Epoch 00009: loss improved from 1.48645 to 1.45605, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6252 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.4937 - acc: 0.7442 - val_loss: 0.8828 - val_acc: 0.8182

Epoch 00010: loss did not improve from 1.45605
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3635 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.2464 - acc: 0.7907 - val_loss: 0.9337 - val_acc: 0.8182

Epoch 00011: loss improved from 1.45605 to 1.24637, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4757 - acc: 0.7812
43/43 [==============================] - 0s 50us/step - loss: 1.3277 - acc: 0.8372 - val_loss: 0.9382 - val_acc: 0.8182

Epoch 00012: loss did not improve from 1.24637
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4046 - acc: 0.7188
43/43 [==============================] - 0s 48us/step - loss: 1.2931 - acc: 0.7442 - val_loss: 0.9461 - val_acc: 0.8182

Epoch 00013: loss did not improve from 1.24637
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2270 - acc: 0.8125
43/43 [==============================] - 0s 48us/step - loss: 1.1398 - acc: 0.8605 - val_loss: 0.8942 - val_acc: 0.8182

Epoch 00014: loss improved from 1.24637 to 1.13980, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2579 - acc: 0.7500
43/43 [==============================] - 0s 54us/step - loss: 1.1392 - acc: 0.7907 - val_loss: 0.9202 - val_acc: 0.9091

Epoch 00015: loss improved from 1.13980 to 1.13921, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1155 - acc: 0.8750
43/43 [==============================] - 0s 56us/step - loss: 1.0146 - acc: 0.9070 - val_loss: 0.8243 - val_acc: 0.9091

Epoch 00016: loss improved from 1.13921 to 1.01459, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1298 - acc: 0.7812
43/43 [==============================] - 0s 51us/step - loss: 1.0589 - acc: 0.8140 - val_loss: 0.8034 - val_acc: 0.9091

Epoch 00017: loss did not improve from 1.01459
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2102 - acc: 0.7812
43/43 [==============================] - 0s 48us/step - loss: 1.1172 - acc: 0.8372 - val_loss: 0.7947 - val_acc: 0.9091

Epoch 00018: loss did not improve from 1.01459
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1664 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.1047 - acc: 0.8140 - val_loss: 0.7823 - val_acc: 1.0000

Epoch 00019: loss did not improve from 1.01459
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0119 - acc: 0.9375
43/43 [==============================] - 0s 48us/step - loss: 0.9291 - acc: 0.9535 - val_loss: 0.8087 - val_acc: 0.9091

Epoch 00020: loss improved from 1.01459 to 0.92913, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0537 - acc: 0.9062
43/43 [==============================] - 0s 51us/step - loss: 0.9599 - acc: 0.9302 - val_loss: 0.7810 - val_acc: 0.9091

Epoch 00021: loss did not improve from 0.92913
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9235 - acc: 0.9375
43/43 [==============================] - 0s 49us/step - loss: 0.9082 - acc: 0.9535 - val_loss: 0.8290 - val_acc: 0.9091

Epoch 00022: loss improved from 0.92913 to 0.90816, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3870 - acc: 0.7812
43/43 [==============================] - 0s 51us/step - loss: 1.2120 - acc: 0.8372 - val_loss: 0.7734 - val_acc: 0.9091

Epoch 00023: loss did not improve from 0.90816
Epoch 24/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8694 - acc: 0.9062
43/43 [==============================] - 0s 50us/step - loss: 0.8629 - acc: 0.9070 - val_loss: 0.7450 - val_acc: 0.9091

Epoch 00024: loss improved from 0.90816 to 0.86288, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 25/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0764 - acc: 0.8750
43/43 [==============================] - 0s 51us/step - loss: 0.9663 - acc: 0.9070 - val_loss: 0.7535 - val_acc: 1.0000

Epoch 00025: loss did not improve from 0.86288
Epoch 26/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1208 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.0054 - acc: 0.8140 - val_loss: 0.7168 - val_acc: 1.0000

Epoch 00026: loss did not improve from 0.86288
Epoch 27/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8341 - acc: 0.9375
43/43 [==============================] - 0s 52us/step - loss: 0.7807 - acc: 0.9535 - val_loss: 0.6886 - val_acc: 1.0000

Epoch 00027: loss improved from 0.86288 to 0.78069, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 28/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8109 - acc: 0.9375
43/43 [==============================] - 0s 53us/step - loss: 0.7628 - acc: 0.9535 - val_loss: 0.7089 - val_acc: 1.0000

Epoch 00028: loss improved from 0.78069 to 0.76280, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 29/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8388 - acc: 0.9062
43/43 [==============================] - 0s 50us/step - loss: 0.7821 - acc: 0.9302 - val_loss: 0.7570 - val_acc: 0.9091

Epoch 00029: loss did not improve from 0.76280
Epoch 30/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7628 - acc: 1.0000
43/43 [==============================] - 0s 50us/step - loss: 0.7318 - acc: 1.0000 - val_loss: 0.6938 - val_acc: 1.0000

Epoch 00030: loss improved from 0.76280 to 0.73180, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 31/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9101 - acc: 0.9062
43/43 [==============================] - 0s 51us/step - loss: 0.8662 - acc: 0.9302 - val_loss: 0.7942 - val_acc: 0.8182

Epoch 00031: loss did not improve from 0.73180
Epoch 32/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8606 - acc: 0.9375
43/43 [==============================] - 0s 49us/step - loss: 0.7955 - acc: 0.9535 - val_loss: 0.7415 - val_acc: 0.9091

Epoch 00032: loss did not improve from 0.73180
Epoch 33/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9011 - acc: 0.9375
43/43 [==============================] - 0s 49us/step - loss: 0.8306 - acc: 0.9535 - val_loss: 0.7813 - val_acc: 0.9091

Epoch 00033: loss did not improve from 0.73180
Epoch 34/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7977 - acc: 1.0000
43/43 [==============================] - 0s 48us/step - loss: 0.7472 - acc: 1.0000 - val_loss: 0.8460 - val_acc: 0.9091

Epoch 00034: loss did not improve from 0.73180
Epoch 35/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7560 - acc: 0.9688
43/43 [==============================] - 0s 49us/step - loss: 0.7287 - acc: 0.9767 - val_loss: 0.6744 - val_acc: 1.0000

Epoch 00035: loss improved from 0.73180 to 0.72873, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 36/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9794 - acc: 0.9375
43/43 [==============================] - 0s 51us/step - loss: 0.9061 - acc: 0.9535 - val_loss: 0.7329 - val_acc: 0.9091

Epoch 00036: loss did not improve from 0.72873
Epoch 37/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8886 - acc: 0.9062
43/43 [==============================] - 0s 49us/step - loss: 0.8055 - acc: 0.9302 - val_loss: 0.7223 - val_acc: 1.0000

Epoch 00037: loss did not improve from 0.72873
Epoch 38/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7727 - acc: 0.9062
43/43 [==============================] - 0s 49us/step - loss: 0.7316 - acc: 0.9302 - val_loss: 0.7118 - val_acc: 1.0000

Epoch 00038: loss did not improve from 0.72873
Epoch 39/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8094 - acc: 0.9375
43/43 [==============================] - 0s 48us/step - loss: 0.7712 - acc: 0.9535 - val_loss: 0.6875 - val_acc: 1.0000

Epoch 00039: loss did not improve from 0.72873
Epoch 40/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7663 - acc: 0.9375
43/43 [==============================] - 0s 48us/step - loss: 0.7179 - acc: 0.9535 - val_loss: 0.6432 - val_acc: 1.0000

Epoch 00040: loss improved from 0.72873 to 0.71788, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 41/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7528 - acc: 0.9375
43/43 [==============================] - 0s 50us/step - loss: 0.7117 - acc: 0.9535 - val_loss: 0.6686 - val_acc: 1.0000

Epoch 00041: loss improved from 0.71788 to 0.71175, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 42/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7464 - acc: 0.9688
43/43 [==============================] - 0s 51us/step - loss: 0.6939 - acc: 0.9767 - val_loss: 0.6060 - val_acc: 1.0000

Epoch 00042: loss improved from 0.71175 to 0.69394, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_6.h5
Epoch 43/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0364 - acc: 0.8750
43/43 [==============================] - 0s 52us/step - loss: 0.9182 - acc: 0.9070 - val_loss: 0.6010 - val_acc: 1.0000

Epoch 00043: loss did not improve from 0.69394
Epoch 44/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9370 - acc: 0.9375
43/43 [==============================] - 0s 50us/step - loss: 0.8664 - acc: 0.9535 - val_loss: 0.6284 - val_acc: 0.9091

Epoch 00044: loss did not improve from 0.69394
Epoch 45/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0160 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 0.9160 - acc: 0.9070 - val_loss: 0.6124 - val_acc: 1.0000

Epoch 00045: loss did not improve from 0.69394
Epoch 46/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7417 - acc: 0.9375
43/43 [==============================] - 0s 48us/step - loss: 0.6942 - acc: 0.9535 - val_loss: 0.5927 - val_acc: 1.0000

Epoch 00046: loss did not improve from 0.69394
Epoch 47/100

32/43 [=====================>........] - ETA: 0s - loss: 0.7585 - acc: 0.9375
43/43 [==============================] - 0s 49us/step - loss: 0.6996 - acc: 0.9535 - val_loss: 0.6083 - val_acc: 1.0000
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:19,  1.65s/it]
Epoch 00047: loss did not improve from 0.69394
Epoch 00047: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 3.4310 - acc: 0.6562
43/43 [==============================] - 0s 6ms/step - loss: 4.6142 - acc: 0.5814 - val_loss: 1.6485 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 4.61417, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 2.5260 - acc: 0.5938
43/43 [==============================] - 0s 61us/step - loss: 2.3097 - acc: 0.6512 - val_loss: 0.8920 - val_acc: 0.9091

Epoch 00002: loss improved from 4.61417 to 2.30970, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8291 - acc: 0.7500
43/43 [==============================] - 0s 53us/step - loss: 1.8024 - acc: 0.7674 - val_loss: 0.9480 - val_acc: 0.9091

Epoch 00003: loss improved from 2.30970 to 1.80243, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2701 - acc: 0.6562
43/43 [==============================] - 0s 51us/step - loss: 2.1386 - acc: 0.6977 - val_loss: 1.0032 - val_acc: 0.9091

Epoch 00004: loss did not improve from 1.80243
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7791 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 1.6215 - acc: 0.7209 - val_loss: 0.9566 - val_acc: 0.9091

Epoch 00005: loss improved from 1.80243 to 1.62150, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7940 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 1.5841 - acc: 0.7674 - val_loss: 0.9575 - val_acc: 0.9091

Epoch 00006: loss improved from 1.62150 to 1.58408, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7667 - acc: 0.6562
43/43 [==============================] - 0s 50us/step - loss: 1.5790 - acc: 0.6977 - val_loss: 0.9234 - val_acc: 0.9091

Epoch 00007: loss improved from 1.58408 to 1.57897, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6139 - acc: 0.7188
43/43 [==============================] - 0s 50us/step - loss: 1.5092 - acc: 0.7442 - val_loss: 0.8827 - val_acc: 0.9091

Epoch 00008: loss improved from 1.57897 to 1.50917, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4869 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.3710 - acc: 0.7907 - val_loss: 0.8975 - val_acc: 0.9091

Epoch 00009: loss improved from 1.50917 to 1.37098, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4295 - acc: 0.7188
43/43 [==============================] - 0s 51us/step - loss: 1.2649 - acc: 0.7907 - val_loss: 0.8953 - val_acc: 0.9091

Epoch 00010: loss improved from 1.37098 to 1.26485, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5509 - acc: 0.7188
43/43 [==============================] - 0s 50us/step - loss: 1.3711 - acc: 0.7907 - val_loss: 0.8760 - val_acc: 0.9091

Epoch 00011: loss did not improve from 1.26485
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4184 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.2810 - acc: 0.7674 - val_loss: 0.8632 - val_acc: 0.9091

Epoch 00012: loss did not improve from 1.26485
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3533 - acc: 0.7500
43/43 [==============================] - 0s 48us/step - loss: 1.2339 - acc: 0.8140 - val_loss: 0.8341 - val_acc: 0.9091

Epoch 00013: loss improved from 1.26485 to 1.23390, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3368 - acc: 0.8750
43/43 [==============================] - 0s 50us/step - loss: 1.2475 - acc: 0.9070 - val_loss: 0.8511 - val_acc: 0.9091

Epoch 00014: loss did not improve from 1.23390
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3128 - acc: 0.7812
43/43 [==============================] - 0s 50us/step - loss: 1.1896 - acc: 0.8372 - val_loss: 0.8303 - val_acc: 0.9091

Epoch 00015: loss improved from 1.23390 to 1.18961, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2490 - acc: 0.7500
43/43 [==============================] - 0s 50us/step - loss: 1.1716 - acc: 0.8140 - val_loss: 0.8258 - val_acc: 0.9091

Epoch 00016: loss improved from 1.18961 to 1.17157, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4231 - acc: 0.7812
43/43 [==============================] - 0s 50us/step - loss: 1.3047 - acc: 0.7907 - val_loss: 1.0128 - val_acc: 0.7273

Epoch 00017: loss did not improve from 1.17157
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1392 - acc: 0.8438
43/43 [==============================] - 0s 49us/step - loss: 1.0480 - acc: 0.8605 - val_loss: 0.9744 - val_acc: 0.7273

Epoch 00018: loss improved from 1.17157 to 1.04803, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2637 - acc: 0.7812
43/43 [==============================] - 0s 50us/step - loss: 1.1530 - acc: 0.8140 - val_loss: 0.8777 - val_acc: 0.9091

Epoch 00019: loss did not improve from 1.04803
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4580 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 1.3234 - acc: 0.8372 - val_loss: 0.8393 - val_acc: 0.9091

Epoch 00020: loss did not improve from 1.04803
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1403 - acc: 0.8125
43/43 [==============================] - 0s 48us/step - loss: 1.0563 - acc: 0.8605 - val_loss: 0.7933 - val_acc: 0.9091

Epoch 00021: loss did not improve from 1.04803
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2290 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 1.1256 - acc: 0.8837 - val_loss: 0.8698 - val_acc: 1.0000

Epoch 00022: loss did not improve from 1.04803
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9111 - acc: 0.9375
43/43 [==============================] - 0s 48us/step - loss: 0.9179 - acc: 0.9535 - val_loss: 0.8341 - val_acc: 0.9091

Epoch 00023: loss improved from 1.04803 to 0.91790, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 24/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4628 - acc: 0.7812
43/43 [==============================] - 0s 50us/step - loss: 1.2654 - acc: 0.8372 - val_loss: 0.7921 - val_acc: 0.9091

Epoch 00024: loss did not improve from 0.91790
Epoch 25/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1897 - acc: 0.8438
43/43 [==============================] - 0s 49us/step - loss: 1.0741 - acc: 0.8837 - val_loss: 0.7889 - val_acc: 1.0000

Epoch 00025: loss did not improve from 0.91790
Epoch 26/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1177 - acc: 0.8750
43/43 [==============================] - 0s 48us/step - loss: 1.0160 - acc: 0.9070 - val_loss: 0.7720 - val_acc: 1.0000

Epoch 00026: loss did not improve from 0.91790
Epoch 27/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9975 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 0.9332 - acc: 0.9070 - val_loss: 0.7367 - val_acc: 1.0000

Epoch 00027: loss did not improve from 0.91790
Epoch 28/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8568 - acc: 0.9375
43/43 [==============================] - 0s 48us/step - loss: 0.8077 - acc: 0.9535 - val_loss: 0.7370 - val_acc: 1.0000

Epoch 00028: loss improved from 0.91790 to 0.80768, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_7.h5
Epoch 29/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9847 - acc: 0.9375
43/43 [==============================] - 0s 51us/step - loss: 0.9417 - acc: 0.9535 - val_loss: 0.7253 - val_acc: 1.0000

Epoch 00029: loss did not improve from 0.80768
Epoch 30/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9325 - acc: 0.9062
43/43 [==============================] - 0s 49us/step - loss: 0.8944 - acc: 0.9302 - val_loss: 0.7539 - val_acc: 1.0000

Epoch 00030: loss did not improve from 0.80768
Epoch 31/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9862 - acc: 0.9062
43/43 [==============================] - 0s 48us/step - loss: 0.8921 - acc: 0.9302 - val_loss: 0.7515 - val_acc: 1.0000

Epoch 00031: loss did not improve from 0.80768
Epoch 32/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9348 - acc: 0.9375
43/43 [==============================] - 0s 49us/step - loss: 0.8574 - acc: 0.9535 - val_loss: 0.7314 - val_acc: 1.0000

Epoch 00032: loss did not improve from 0.80768
Epoch 33/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1252 - acc: 0.8750
43/43 [==============================] - 0s 48us/step - loss: 1.0750 - acc: 0.8605 - val_loss: 0.7146 - val_acc: 1.0000
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:03<00:18,  1.66s/it]
Epoch 00033: loss did not improve from 0.80768
Epoch 00033: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 2.6539 - acc: 0.6875
43/43 [==============================] - 0s 6ms/step - loss: 3.5361 - acc: 0.6047 - val_loss: 2.1131 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 3.53611, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2097 - acc: 0.6250
43/43 [==============================] - 0s 58us/step - loss: 2.1505 - acc: 0.6744 - val_loss: 0.8697 - val_acc: 0.9091

Epoch 00002: loss improved from 3.53611 to 2.15047, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3643 - acc: 0.5938
43/43 [==============================] - 0s 52us/step - loss: 2.1145 - acc: 0.6279 - val_loss: 0.8940 - val_acc: 0.9091

Epoch 00003: loss improved from 2.15047 to 2.11446, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0979 - acc: 0.6875
43/43 [==============================] - 0s 52us/step - loss: 1.9350 - acc: 0.7209 - val_loss: 1.0537 - val_acc: 0.7273

Epoch 00004: loss improved from 2.11446 to 1.93497, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0412 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 1.8629 - acc: 0.7442 - val_loss: 0.9526 - val_acc: 0.9091

Epoch 00005: loss improved from 1.93497 to 1.86287, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2136 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 1.9409 - acc: 0.7209 - val_loss: 0.9278 - val_acc: 0.9091

Epoch 00006: loss did not improve from 1.86287
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8432 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.6690 - acc: 0.7442 - val_loss: 0.9345 - val_acc: 0.9091

Epoch 00007: loss improved from 1.86287 to 1.66897, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8070 - acc: 0.7188
43/43 [==============================] - 0s 50us/step - loss: 1.5750 - acc: 0.7674 - val_loss: 0.9155 - val_acc: 0.9091

Epoch 00008: loss improved from 1.66897 to 1.57501, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6295 - acc: 0.7188
43/43 [==============================] - 0s 50us/step - loss: 1.5430 - acc: 0.7442 - val_loss: 0.8943 - val_acc: 0.9091

Epoch 00009: loss improved from 1.57501 to 1.54303, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9217 - acc: 0.6562
43/43 [==============================] - 0s 50us/step - loss: 1.7037 - acc: 0.6977 - val_loss: 0.9160 - val_acc: 0.8182

Epoch 00010: loss did not improve from 1.54303
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7568 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.5310 - acc: 0.7907 - val_loss: 0.9290 - val_acc: 0.8182

Epoch 00011: loss improved from 1.54303 to 1.53099, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4924 - acc: 0.7188
43/43 [==============================] - 0s 51us/step - loss: 1.3396 - acc: 0.7907 - val_loss: 0.8709 - val_acc: 0.8182

Epoch 00012: loss improved from 1.53099 to 1.33956, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3110 - acc: 0.7188
43/43 [==============================] - 0s 53us/step - loss: 1.1865 - acc: 0.7907 - val_loss: 0.9006 - val_acc: 0.8182

Epoch 00013: loss improved from 1.33956 to 1.18648, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4325 - acc: 0.7812
43/43 [==============================] - 0s 51us/step - loss: 1.2794 - acc: 0.8372 - val_loss: 0.8562 - val_acc: 0.8182

Epoch 00014: loss did not improve from 1.18648
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5697 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.3891 - acc: 0.7674 - val_loss: 0.8335 - val_acc: 0.9091

Epoch 00015: loss did not improve from 1.18648
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4049 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.2669 - acc: 0.8140 - val_loss: 0.8560 - val_acc: 0.9091

Epoch 00016: loss did not improve from 1.18648
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7912 - acc: 0.7812
43/43 [==============================] - 0s 48us/step - loss: 1.6036 - acc: 0.8140 - val_loss: 0.8166 - val_acc: 0.9091

Epoch 00017: loss did not improve from 1.18648
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2127 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.1070 - acc: 0.8372 - val_loss: 0.8351 - val_acc: 0.9091

Epoch 00018: loss improved from 1.18648 to 1.10701, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2884 - acc: 0.7812
43/43 [==============================] - 0s 51us/step - loss: 1.1696 - acc: 0.8372 - val_loss: 0.7664 - val_acc: 1.0000

Epoch 00019: loss did not improve from 1.10701
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3152 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 1.1883 - acc: 0.8605 - val_loss: 0.7650 - val_acc: 1.0000

Epoch 00020: loss did not improve from 1.10701
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1957 - acc: 0.8438
43/43 [==============================] - 0s 49us/step - loss: 1.0674 - acc: 0.8837 - val_loss: 0.7703 - val_acc: 0.9091

Epoch 00021: loss improved from 1.10701 to 1.06743, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1278 - acc: 0.8438
43/43 [==============================] - 0s 50us/step - loss: 1.0211 - acc: 0.8837 - val_loss: 0.7723 - val_acc: 1.0000

Epoch 00022: loss improved from 1.06743 to 1.02110, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0366 - acc: 0.8750
43/43 [==============================] - 0s 50us/step - loss: 0.9515 - acc: 0.9070 - val_loss: 0.7494 - val_acc: 1.0000

Epoch 00023: loss improved from 1.02110 to 0.95153, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_8.h5
Epoch 24/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0784 - acc: 0.8750
43/43 [==============================] - 0s 51us/step - loss: 1.0787 - acc: 0.9070 - val_loss: 0.8284 - val_acc: 0.9091

Epoch 00024: loss did not improve from 0.95153
Epoch 25/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3149 - acc: 0.8750
43/43 [==============================] - 0s 48us/step - loss: 1.1933 - acc: 0.9070 - val_loss: 0.9028 - val_acc: 0.8182

Epoch 00025: loss did not improve from 0.95153
Epoch 26/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1671 - acc: 0.8438
43/43 [==============================] - 0s 49us/step - loss: 1.0899 - acc: 0.8837 - val_loss: 0.7727 - val_acc: 0.8182

Epoch 00026: loss did not improve from 0.95153
Epoch 27/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2238 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 1.1090 - acc: 0.9070 - val_loss: 0.7638 - val_acc: 0.9091

Epoch 00027: loss did not improve from 0.95153
Epoch 28/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0583 - acc: 0.8750
43/43 [==============================] - 0s 48us/step - loss: 0.9646 - acc: 0.9070 - val_loss: 0.7720 - val_acc: 0.9091
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:04<00:16,  1.66s/it]
Epoch 00028: loss did not improve from 0.95153
Epoch 00028: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 3.4068 - acc: 0.6875
43/43 [==============================] - 0s 6ms/step - loss: 4.5847 - acc: 0.6047 - val_loss: 1.1033 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 4.58466, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 2.7796 - acc: 0.6250
43/43 [==============================] - 0s 60us/step - loss: 2.5587 - acc: 0.6744 - val_loss: 1.0381 - val_acc: 0.8182

Epoch 00002: loss improved from 4.58466 to 2.55868, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 2.5603 - acc: 0.5625
43/43 [==============================] - 0s 55us/step - loss: 2.3426 - acc: 0.6047 - val_loss: 1.1486 - val_acc: 0.9091

Epoch 00003: loss improved from 2.55868 to 2.34259, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.7021 - acc: 0.6875
43/43 [==============================] - 0s 53us/step - loss: 2.4397 - acc: 0.6977 - val_loss: 1.1935 - val_acc: 0.8182

Epoch 00004: loss did not improve from 2.34259
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.4507 - acc: 0.5625
43/43 [==============================] - 0s 50us/step - loss: 2.1753 - acc: 0.6047 - val_loss: 1.1445 - val_acc: 0.8182

Epoch 00005: loss improved from 2.34259 to 2.17528, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1058 - acc: 0.6562
43/43 [==============================] - 0s 53us/step - loss: 1.9118 - acc: 0.7209 - val_loss: 1.0932 - val_acc: 0.8182

Epoch 00006: loss improved from 2.17528 to 1.91182, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8817 - acc: 0.6875
43/43 [==============================] - 0s 52us/step - loss: 1.7146 - acc: 0.7442 - val_loss: 1.0182 - val_acc: 0.8182

Epoch 00007: loss improved from 1.91182 to 1.71464, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1624 - acc: 0.6562
43/43 [==============================] - 0s 52us/step - loss: 1.9849 - acc: 0.7209 - val_loss: 1.0290 - val_acc: 0.8182

Epoch 00008: loss did not improve from 1.71464
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9669 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.7461 - acc: 0.7209 - val_loss: 1.0270 - val_acc: 0.8182

Epoch 00009: loss did not improve from 1.71464
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7238 - acc: 0.6250
43/43 [==============================] - 0s 49us/step - loss: 1.5395 - acc: 0.7209 - val_loss: 0.9636 - val_acc: 0.8182

Epoch 00010: loss improved from 1.71464 to 1.53948, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9525 - acc: 0.7188
43/43 [==============================] - 0s 56us/step - loss: 1.8106 - acc: 0.7674 - val_loss: 1.0383 - val_acc: 0.8182

Epoch 00011: loss did not improve from 1.53948
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9333 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.7501 - acc: 0.7674 - val_loss: 1.0087 - val_acc: 0.8182

Epoch 00012: loss did not improve from 1.53948
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9075 - acc: 0.6875
43/43 [==============================] - 0s 50us/step - loss: 1.6983 - acc: 0.7442 - val_loss: 0.9862 - val_acc: 0.8182

Epoch 00013: loss did not improve from 1.53948
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5836 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 1.4927 - acc: 0.7209 - val_loss: 0.9897 - val_acc: 0.8182

Epoch 00014: loss improved from 1.53948 to 1.49269, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4384 - acc: 0.7188
43/43 [==============================] - 0s 52us/step - loss: 1.3247 - acc: 0.7674 - val_loss: 0.9590 - val_acc: 0.8182

Epoch 00015: loss improved from 1.49269 to 1.32475, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5046 - acc: 0.7500
43/43 [==============================] - 0s 52us/step - loss: 1.3488 - acc: 0.8140 - val_loss: 0.9349 - val_acc: 0.8182

Epoch 00016: loss did not improve from 1.32475
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2030 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.1122 - acc: 0.7907 - val_loss: 0.9112 - val_acc: 0.8182

Epoch 00017: loss improved from 1.32475 to 1.11223, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3518 - acc: 0.8438
43/43 [==============================] - 0s 51us/step - loss: 1.2205 - acc: 0.8837 - val_loss: 0.9057 - val_acc: 0.8182

Epoch 00018: loss did not improve from 1.11223
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0409 - acc: 0.8750
43/43 [==============================] - 0s 50us/step - loss: 0.9889 - acc: 0.9070 - val_loss: 0.8850 - val_acc: 0.8182

Epoch 00019: loss improved from 1.11223 to 0.98886, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_9.h5
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4480 - acc: 0.7812
43/43 [==============================] - 0s 51us/step - loss: 1.3672 - acc: 0.8140 - val_loss: 0.9801 - val_acc: 0.8182

Epoch 00020: loss did not improve from 0.98886
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3053 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.1687 - acc: 0.8372 - val_loss: 1.0212 - val_acc: 0.8182

Epoch 00021: loss did not improve from 0.98886
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1838 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 1.1028 - acc: 0.8605 - val_loss: 0.9088 - val_acc: 0.8182

Epoch 00022: loss did not improve from 0.98886
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1633 - acc: 0.8438
43/43 [==============================] - 0s 49us/step - loss: 1.0892 - acc: 0.8837 - val_loss: 0.9177 - val_acc: 0.9091

Epoch 00023: loss did not improve from 0.98886
Epoch 24/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0938 - acc: 0.8125
43/43 [==============================] - 0s 50us/step - loss: 1.0025 - acc: 0.8605 - val_loss: 0.8914 - val_acc: 0.9091
DeepAmes+ Weights:  31%|███       | 4/13 [00:06<00:14,  1.60s/it]
Epoch 00024: loss did not improve from 0.98886
Epoch 00024: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 3.3392 - acc: 0.6562
43/43 [==============================] - 0s 6ms/step - loss: 5.4157 - acc: 0.5581 - val_loss: 2.2742 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 5.41565, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 3.3825 - acc: 0.6562
43/43 [==============================] - 0s 66us/step - loss: 3.1657 - acc: 0.6512 - val_loss: 1.3023 - val_acc: 0.6364

Epoch 00002: loss improved from 5.41565 to 3.16575, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9587 - acc: 0.6250
43/43 [==============================] - 0s 57us/step - loss: 1.9420 - acc: 0.6279 - val_loss: 0.9106 - val_acc: 0.9091

Epoch 00003: loss improved from 3.16575 to 1.94197, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.5986 - acc: 0.5938
43/43 [==============================] - 0s 55us/step - loss: 2.3482 - acc: 0.6279 - val_loss: 0.9967 - val_acc: 0.9091

Epoch 00004: loss did not improve from 1.94197
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0186 - acc: 0.6562
43/43 [==============================] - 0s 53us/step - loss: 1.8060 - acc: 0.6977 - val_loss: 1.0085 - val_acc: 0.9091

Epoch 00005: loss improved from 1.94197 to 1.80604, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7993 - acc: 0.6875
43/43 [==============================] - 0s 54us/step - loss: 1.6285 - acc: 0.7442 - val_loss: 1.0070 - val_acc: 0.9091

Epoch 00006: loss improved from 1.80604 to 1.62846, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8978 - acc: 0.7188
43/43 [==============================] - 0s 54us/step - loss: 1.7762 - acc: 0.7442 - val_loss: 0.9462 - val_acc: 0.9091

Epoch 00007: loss did not improve from 1.62846
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9591 - acc: 0.6250
43/43 [==============================] - 0s 53us/step - loss: 1.7049 - acc: 0.7209 - val_loss: 0.9539 - val_acc: 1.0000

Epoch 00008: loss did not improve from 1.62846
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7991 - acc: 0.7188
43/43 [==============================] - 0s 51us/step - loss: 1.6109 - acc: 0.7674 - val_loss: 0.9074 - val_acc: 1.0000

Epoch 00009: loss improved from 1.62846 to 1.61090, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7295 - acc: 0.6875
43/43 [==============================] - 0s 54us/step - loss: 1.5682 - acc: 0.7209 - val_loss: 0.9091 - val_acc: 0.9091

Epoch 00010: loss improved from 1.61090 to 1.56816, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3333 - acc: 0.7812
43/43 [==============================] - 0s 55us/step - loss: 1.2233 - acc: 0.8372 - val_loss: 0.8899 - val_acc: 1.0000

Epoch 00011: loss improved from 1.56816 to 1.22332, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_10.h5
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5889 - acc: 0.6875
43/43 [==============================] - 0s 55us/step - loss: 1.4279 - acc: 0.7442 - val_loss: 0.8643 - val_acc: 1.0000

Epoch 00012: loss did not improve from 1.22332
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8353 - acc: 0.6875
43/43 [==============================] - 0s 52us/step - loss: 1.6575 - acc: 0.7442 - val_loss: 1.2521 - val_acc: 0.6364

Epoch 00013: loss did not improve from 1.22332
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6137 - acc: 0.6562
43/43 [==============================] - 0s 52us/step - loss: 1.6793 - acc: 0.6744 - val_loss: 1.5759 - val_acc: 0.9091

Epoch 00014: loss did not improve from 1.22332
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9946 - acc: 0.8125
43/43 [==============================] - 0s 52us/step - loss: 1.9745 - acc: 0.7674 - val_loss: 1.0518 - val_acc: 0.9091

Epoch 00015: loss did not improve from 1.22332
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0404 - acc: 0.7188
43/43 [==============================] - 0s 53us/step - loss: 1.8346 - acc: 0.7209 - val_loss: 1.0073 - val_acc: 0.9091
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:08<00:12,  1.60s/it]
Epoch 00016: loss did not improve from 1.22332
Epoch 00016: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 3.3665 - acc: 0.6562
43/43 [==============================] - 0s 6ms/step - loss: 4.2340 - acc: 0.5814 - val_loss: 0.9409 - val_acc: 0.9091

Epoch 00001: loss improved from inf to 4.23399, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9236 - acc: 0.5625
43/43 [==============================] - 0s 62us/step - loss: 2.4097 - acc: 0.6279 - val_loss: 1.2030 - val_acc: 0.9091

Epoch 00002: loss improved from 4.23399 to 2.40971, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 5.8153 - acc: 0.6250
43/43 [==============================] - 0s 56us/step - loss: 4.6360 - acc: 0.6977 - val_loss: 0.9281 - val_acc: 0.9091

Epoch 00003: loss did not improve from 2.40971
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 3.0869 - acc: 0.6250
43/43 [==============================] - 0s 49us/step - loss: 2.6892 - acc: 0.6744 - val_loss: 0.9518 - val_acc: 0.9091

Epoch 00004: loss did not improve from 2.40971
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0803 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.8877 - acc: 0.7442 - val_loss: 0.9751 - val_acc: 0.9091

Epoch 00005: loss improved from 2.40971 to 1.88774, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 2.9952 - acc: 0.6562
43/43 [==============================] - 0s 50us/step - loss: 2.6243 - acc: 0.6512 - val_loss: 0.9039 - val_acc: 0.9091

Epoch 00006: loss did not improve from 1.88774
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3839 - acc: 0.6875
43/43 [==============================] - 0s 50us/step - loss: 2.1351 - acc: 0.7209 - val_loss: 0.9094 - val_acc: 0.9091

Epoch 00007: loss did not improve from 1.88774
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1055 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.8644 - acc: 0.7442 - val_loss: 0.9843 - val_acc: 0.8182

Epoch 00008: loss improved from 1.88774 to 1.86441, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0083 - acc: 0.5625
43/43 [==============================] - 0s 51us/step - loss: 1.7794 - acc: 0.6279 - val_loss: 0.9372 - val_acc: 0.8182

Epoch 00009: loss improved from 1.86441 to 1.77939, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2333 - acc: 0.6562
43/43 [==============================] - 0s 51us/step - loss: 1.9311 - acc: 0.7209 - val_loss: 0.9525 - val_acc: 0.8182

Epoch 00010: loss did not improve from 1.77939
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7560 - acc: 0.6250
43/43 [==============================] - 0s 49us/step - loss: 1.5400 - acc: 0.6744 - val_loss: 0.9534 - val_acc: 0.8182

Epoch 00011: loss improved from 1.77939 to 1.54002, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7036 - acc: 0.7812
43/43 [==============================] - 0s 50us/step - loss: 1.5012 - acc: 0.7907 - val_loss: 0.9247 - val_acc: 0.8182

Epoch 00012: loss improved from 1.54002 to 1.50116, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6629 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.4728 - acc: 0.7907 - val_loss: 0.9022 - val_acc: 0.9091

Epoch 00013: loss improved from 1.50116 to 1.47280, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6258 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.4690 - acc: 0.7907 - val_loss: 0.8750 - val_acc: 0.9091

Epoch 00014: loss improved from 1.47280 to 1.46900, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5578 - acc: 0.7500
43/43 [==============================] - 0s 50us/step - loss: 1.4737 - acc: 0.7907 - val_loss: 0.8858 - val_acc: 0.8182

Epoch 00015: loss did not improve from 1.46900
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6898 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.5352 - acc: 0.7209 - val_loss: 0.9026 - val_acc: 0.8182

Epoch 00016: loss did not improve from 1.46900
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3814 - acc: 0.7812
43/43 [==============================] - 0s 48us/step - loss: 1.2586 - acc: 0.8372 - val_loss: 0.8903 - val_acc: 0.8182

Epoch 00017: loss improved from 1.46900 to 1.25855, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2432 - acc: 0.7188
43/43 [==============================] - 0s 51us/step - loss: 1.1159 - acc: 0.7907 - val_loss: 0.8622 - val_acc: 0.8182

Epoch 00018: loss improved from 1.25855 to 1.11592, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_11.h5
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3833 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.2368 - acc: 0.8140 - val_loss: 0.8435 - val_acc: 0.8182

Epoch 00019: loss did not improve from 1.11592
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3908 - acc: 0.6875
43/43 [==============================] - 0s 48us/step - loss: 1.2383 - acc: 0.7674 - val_loss: 0.8219 - val_acc: 0.8182

Epoch 00020: loss did not improve from 1.11592
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2504 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.1212 - acc: 0.8372 - val_loss: 0.8165 - val_acc: 0.9091

Epoch 00021: loss did not improve from 1.11592
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3572 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.2472 - acc: 0.8140 - val_loss: 1.3163 - val_acc: 0.6364

Epoch 00022: loss did not improve from 1.11592
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1987 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.1264 - acc: 0.8140 - val_loss: 1.0573 - val_acc: 0.6364
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:09<00:11,  1.60s/it]
Epoch 00023: loss did not improve from 1.11592
Epoch 00023: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 4.1048 - acc: 0.6875
43/43 [==============================] - 0s 6ms/step - loss: 6.1314 - acc: 0.6047 - val_loss: 2.3620 - val_acc: 0.9091

Epoch 00001: loss improved from inf to 6.13145, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 3.6152 - acc: 0.7188
43/43 [==============================] - 0s 61us/step - loss: 3.6783 - acc: 0.6744 - val_loss: 0.9896 - val_acc: 0.8182

Epoch 00002: loss improved from 6.13145 to 3.67830, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3017 - acc: 0.6250
43/43 [==============================] - 0s 53us/step - loss: 2.1082 - acc: 0.6512 - val_loss: 1.0646 - val_acc: 0.8182

Epoch 00003: loss improved from 3.67830 to 2.10815, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3764 - acc: 0.6562
43/43 [==============================] - 0s 52us/step - loss: 2.1702 - acc: 0.6512 - val_loss: 1.0768 - val_acc: 0.8182

Epoch 00004: loss did not improve from 2.10815
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1405 - acc: 0.5312
43/43 [==============================] - 0s 50us/step - loss: 1.9220 - acc: 0.5814 - val_loss: 1.0794 - val_acc: 0.8182

Epoch 00005: loss improved from 2.10815 to 1.92203, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1611 - acc: 0.6250
43/43 [==============================] - 0s 51us/step - loss: 1.9544 - acc: 0.6744 - val_loss: 1.0894 - val_acc: 0.8182

Epoch 00006: loss did not improve from 1.92203
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9511 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.7501 - acc: 0.7442 - val_loss: 1.0507 - val_acc: 0.8182

Epoch 00007: loss improved from 1.92203 to 1.75007, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9458 - acc: 0.6562
43/43 [==============================] - 0s 51us/step - loss: 1.7243 - acc: 0.7442 - val_loss: 1.0456 - val_acc: 0.8182

Epoch 00008: loss improved from 1.75007 to 1.72434, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1735 - acc: 0.6250
43/43 [==============================] - 0s 52us/step - loss: 2.0301 - acc: 0.6744 - val_loss: 1.1235 - val_acc: 0.8182

Epoch 00009: loss did not improve from 1.72434
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9611 - acc: 0.6562
43/43 [==============================] - 0s 52us/step - loss: 1.7764 - acc: 0.6977 - val_loss: 1.0776 - val_acc: 0.8182

Epoch 00010: loss did not improve from 1.72434
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0099 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 1.8462 - acc: 0.6977 - val_loss: 1.0444 - val_acc: 0.9091

Epoch 00011: loss did not improve from 1.72434
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9140 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 1.6614 - acc: 0.7442 - val_loss: 0.9994 - val_acc: 0.8182

Epoch 00012: loss improved from 1.72434 to 1.66143, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6696 - acc: 0.7500
43/43 [==============================] - 0s 52us/step - loss: 1.4981 - acc: 0.7907 - val_loss: 0.9868 - val_acc: 0.8182

Epoch 00013: loss improved from 1.66143 to 1.49809, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4516 - acc: 0.7188
43/43 [==============================] - 0s 51us/step - loss: 1.3289 - acc: 0.7674 - val_loss: 0.9706 - val_acc: 0.8182

Epoch 00014: loss improved from 1.49809 to 1.32887, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_12.h5
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7011 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 1.5446 - acc: 0.7674 - val_loss: 0.9802 - val_acc: 0.8182

Epoch 00015: loss did not improve from 1.32887
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9207 - acc: 0.7188
43/43 [==============================] - 0s 50us/step - loss: 1.6402 - acc: 0.7907 - val_loss: 0.9471 - val_acc: 0.8182

Epoch 00016: loss did not improve from 1.32887
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6237 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.4525 - acc: 0.8372 - val_loss: 0.9226 - val_acc: 0.8182

Epoch 00017: loss did not improve from 1.32887
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7510 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.5375 - acc: 0.8372 - val_loss: 0.9555 - val_acc: 0.8182

Epoch 00018: loss did not improve from 1.32887
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5129 - acc: 0.7188
43/43 [==============================] - 0s 48us/step - loss: 1.3790 - acc: 0.7907 - val_loss: 0.9399 - val_acc: 0.8182
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:11<00:09,  1.56s/it]
Epoch 00019: loss did not improve from 1.32887
Epoch 00019: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 4.5551 - acc: 0.6875
43/43 [==============================] - 0s 6ms/step - loss: 4.9608 - acc: 0.6279 - val_loss: 1.1415 - val_acc: 0.9091

Epoch 00001: loss improved from inf to 4.96084, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 2.7940 - acc: 0.4688
43/43 [==============================] - 0s 59us/step - loss: 2.6073 - acc: 0.5581 - val_loss: 1.5571 - val_acc: 0.8182

Epoch 00002: loss improved from 4.96084 to 2.60727, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 3.3198 - acc: 0.6250
43/43 [==============================] - 0s 54us/step - loss: 3.0260 - acc: 0.6047 - val_loss: 1.1089 - val_acc: 0.9091

Epoch 00003: loss did not improve from 2.60727
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 3.1523 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 2.7590 - acc: 0.6977 - val_loss: 1.0988 - val_acc: 0.8182

Epoch 00004: loss did not improve from 2.60727
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.4827 - acc: 0.6875
43/43 [==============================] - 0s 50us/step - loss: 2.1792 - acc: 0.6977 - val_loss: 1.1088 - val_acc: 0.8182

Epoch 00005: loss improved from 2.60727 to 2.17916, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 2.4525 - acc: 0.5938
43/43 [==============================] - 0s 51us/step - loss: 2.1736 - acc: 0.6279 - val_loss: 1.0557 - val_acc: 0.8182

Epoch 00006: loss improved from 2.17916 to 2.17362, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1396 - acc: 0.5625
43/43 [==============================] - 0s 51us/step - loss: 1.9458 - acc: 0.6279 - val_loss: 1.2077 - val_acc: 0.6364

Epoch 00007: loss improved from 2.17362 to 1.94581, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9859 - acc: 0.5625
43/43 [==============================] - 0s 51us/step - loss: 1.7667 - acc: 0.6512 - val_loss: 1.0446 - val_acc: 0.8182

Epoch 00008: loss improved from 1.94581 to 1.76668, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 2.4213 - acc: 0.7188
43/43 [==============================] - 0s 52us/step - loss: 2.1848 - acc: 0.7442 - val_loss: 1.5029 - val_acc: 0.5455

Epoch 00009: loss did not improve from 1.76668
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0357 - acc: 0.6250
43/43 [==============================] - 0s 48us/step - loss: 1.8465 - acc: 0.6512 - val_loss: 1.2087 - val_acc: 0.7273

Epoch 00010: loss did not improve from 1.76668
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0394 - acc: 0.6250
43/43 [==============================] - 0s 49us/step - loss: 1.7994 - acc: 0.6744 - val_loss: 1.1034 - val_acc: 0.8182

Epoch 00011: loss did not improve from 1.76668
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8643 - acc: 0.7188
43/43 [==============================] - 0s 48us/step - loss: 1.6609 - acc: 0.7442 - val_loss: 1.0322 - val_acc: 0.8182

Epoch 00012: loss improved from 1.76668 to 1.66094, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8178 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.6096 - acc: 0.7907 - val_loss: 0.9918 - val_acc: 0.8182

Epoch 00013: loss improved from 1.66094 to 1.60958, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4909 - acc: 0.7500
43/43 [==============================] - 0s 52us/step - loss: 1.4084 - acc: 0.7907 - val_loss: 0.9750 - val_acc: 0.8182

Epoch 00014: loss improved from 1.60958 to 1.40845, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7310 - acc: 0.7812
43/43 [==============================] - 0s 51us/step - loss: 1.5886 - acc: 0.8140 - val_loss: 0.9299 - val_acc: 0.9091

Epoch 00015: loss did not improve from 1.40845
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5613 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.4015 - acc: 0.7907 - val_loss: 0.9843 - val_acc: 0.8182

Epoch 00016: loss improved from 1.40845 to 1.40147, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4642 - acc: 0.7188
43/43 [==============================] - 0s 54us/step - loss: 1.3494 - acc: 0.7674 - val_loss: 0.9181 - val_acc: 0.9091

Epoch 00017: loss improved from 1.40147 to 1.34940, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5150 - acc: 0.7812
43/43 [==============================] - 0s 51us/step - loss: 1.3588 - acc: 0.8372 - val_loss: 0.8780 - val_acc: 0.9091

Epoch 00018: loss did not improve from 1.34940
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3986 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.2556 - acc: 0.8140 - val_loss: 0.8581 - val_acc: 0.9091

Epoch 00019: loss improved from 1.34940 to 1.25560, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3586 - acc: 0.8125
43/43 [==============================] - 0s 51us/step - loss: 1.2421 - acc: 0.8605 - val_loss: 0.8375 - val_acc: 0.9091

Epoch 00020: loss improved from 1.25560 to 1.24208, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3943 - acc: 0.8125
43/43 [==============================] - 0s 51us/step - loss: 1.2828 - acc: 0.8605 - val_loss: 0.9220 - val_acc: 0.8182

Epoch 00021: loss did not improve from 1.24208
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1012 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 2.0141 - acc: 0.7209 - val_loss: 1.0756 - val_acc: 0.8182

Epoch 00022: loss did not improve from 1.24208
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4829 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 1.4018 - acc: 0.8372 - val_loss: 0.9595 - val_acc: 0.9091

Epoch 00023: loss did not improve from 1.24208
Epoch 24/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3235 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.1794 - acc: 0.8140 - val_loss: 0.9518 - val_acc: 0.8182

Epoch 00024: loss improved from 1.24208 to 1.17941, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 25/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1494 - acc: 0.7812
43/43 [==============================] - 0s 51us/step - loss: 1.0482 - acc: 0.8372 - val_loss: 0.8989 - val_acc: 0.9091

Epoch 00025: loss improved from 1.17941 to 1.04825, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 26/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1796 - acc: 0.8438
43/43 [==============================] - 0s 52us/step - loss: 1.0878 - acc: 0.8837 - val_loss: 0.9178 - val_acc: 0.8182

Epoch 00026: loss did not improve from 1.04825
Epoch 27/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3424 - acc: 0.8438
43/43 [==============================] - 0s 51us/step - loss: 1.2031 - acc: 0.8837 - val_loss: 0.8758 - val_acc: 0.8182

Epoch 00027: loss did not improve from 1.04825
Epoch 28/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0450 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 0.9831 - acc: 0.9070 - val_loss: 0.8630 - val_acc: 0.9091

Epoch 00028: loss improved from 1.04825 to 0.98312, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 29/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9840 - acc: 0.9062
43/43 [==============================] - 0s 51us/step - loss: 0.9450 - acc: 0.9302 - val_loss: 0.8663 - val_acc: 0.9091

Epoch 00029: loss improved from 0.98312 to 0.94500, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 30/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9154 - acc: 0.9688
43/43 [==============================] - 0s 51us/step - loss: 0.8779 - acc: 0.9767 - val_loss: 0.8710 - val_acc: 0.8182

Epoch 00030: loss improved from 0.94500 to 0.87793, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 31/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0758 - acc: 0.8750
43/43 [==============================] - 0s 52us/step - loss: 0.9847 - acc: 0.9070 - val_loss: 0.7960 - val_acc: 0.9091

Epoch 00031: loss did not improve from 0.87793
Epoch 32/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5058 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 1.2921 - acc: 0.8605 - val_loss: 0.8344 - val_acc: 1.0000

Epoch 00032: loss did not improve from 0.87793
Epoch 33/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1731 - acc: 0.9062
43/43 [==============================] - 0s 51us/step - loss: 1.0863 - acc: 0.9070 - val_loss: 0.8552 - val_acc: 0.9091

Epoch 00033: loss did not improve from 0.87793
Epoch 34/100

32/43 [=====================>........] - ETA: 0s - loss: 0.8926 - acc: 0.9375
43/43 [==============================] - 0s 50us/step - loss: 0.8627 - acc: 0.9535 - val_loss: 0.7921 - val_acc: 1.0000

Epoch 00034: loss improved from 0.87793 to 0.86269, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_13.h5
Epoch 35/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4288 - acc: 0.8438
43/43 [==============================] - 0s 51us/step - loss: 1.2414 - acc: 0.8837 - val_loss: 1.0553 - val_acc: 0.9091

Epoch 00035: loss did not improve from 0.86269
Epoch 36/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3462 - acc: 0.8438
43/43 [==============================] - 0s 50us/step - loss: 1.2516 - acc: 0.8837 - val_loss: 1.0091 - val_acc: 0.9091

Epoch 00036: loss did not improve from 0.86269
Epoch 37/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0209 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 0.9406 - acc: 0.8605 - val_loss: 0.9640 - val_acc: 0.9091

Epoch 00037: loss did not improve from 0.86269
Epoch 38/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4774 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 1.2808 - acc: 0.9070 - val_loss: 0.9746 - val_acc: 0.9091

Epoch 00038: loss did not improve from 0.86269
Epoch 39/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9304 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 0.8700 - acc: 0.9070 - val_loss: 0.8972 - val_acc: 0.9091
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:12<00:08,  1.62s/it]
Epoch 00039: loss did not improve from 0.86269
Epoch 00039: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 3.5515 - acc: 0.6875
43/43 [==============================] - 0s 6ms/step - loss: 5.6784 - acc: 0.6047 - val_loss: 6.1776 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 5.67844, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 6.2644 - acc: 0.6250
43/43 [==============================] - 0s 58us/step - loss: 6.0815 - acc: 0.6744 - val_loss: 4.4929 - val_acc: 0.9091

Epoch 00002: loss did not improve from 5.67844
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 6.8009 - acc: 0.6250
43/43 [==============================] - 0s 50us/step - loss: 6.5180 - acc: 0.6279 - val_loss: 4.7778 - val_acc: 0.7273

Epoch 00003: loss did not improve from 5.67844
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 5.7530 - acc: 0.4375
43/43 [==============================] - 0s 49us/step - loss: 5.5458 - acc: 0.5116 - val_loss: 4.6067 - val_acc: 0.8182

Epoch 00004: loss improved from 5.67844 to 5.54579, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 5.4941 - acc: 0.6250
43/43 [==============================] - 0s 51us/step - loss: 5.3056 - acc: 0.6977 - val_loss: 4.5795 - val_acc: 0.8182

Epoch 00005: loss improved from 5.54579 to 5.30557, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 5.3840 - acc: 0.6250
43/43 [==============================] - 0s 51us/step - loss: 5.1928 - acc: 0.6744 - val_loss: 4.4382 - val_acc: 0.8182

Epoch 00006: loss improved from 5.30557 to 5.19285, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 5.5378 - acc: 0.5938
43/43 [==============================] - 0s 50us/step - loss: 5.3365 - acc: 0.6512 - val_loss: 4.3785 - val_acc: 0.8182

Epoch 00007: loss did not improve from 5.19285
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 5.4970 - acc: 0.5000
43/43 [==============================] - 0s 49us/step - loss: 5.3115 - acc: 0.5814 - val_loss: 4.3243 - val_acc: 0.8182

Epoch 00008: loss did not improve from 5.19285
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 5.4227 - acc: 0.6875
43/43 [==============================] - 0s 48us/step - loss: 5.1248 - acc: 0.7674 - val_loss: 4.2933 - val_acc: 0.8182

Epoch 00009: loss improved from 5.19285 to 5.12475, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 5.4688 - acc: 0.5625
43/43 [==============================] - 0s 51us/step - loss: 5.2490 - acc: 0.6279 - val_loss: 4.5180 - val_acc: 0.6364

Epoch 00010: loss did not improve from 5.12475
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 4.9996 - acc: 0.5938
43/43 [==============================] - 0s 49us/step - loss: 4.8525 - acc: 0.6512 - val_loss: 4.3219 - val_acc: 0.8182

Epoch 00011: loss improved from 5.12475 to 4.85247, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 4.6758 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 4.5493 - acc: 0.7442 - val_loss: 4.2412 - val_acc: 0.8182

Epoch 00012: loss improved from 4.85247 to 4.54932, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 4.6991 - acc: 0.7500
43/43 [==============================] - 0s 50us/step - loss: 4.5707 - acc: 0.8140 - val_loss: 4.1778 - val_acc: 0.8182

Epoch 00013: loss did not improve from 4.54932
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 4.8189 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 4.6413 - acc: 0.7674 - val_loss: 4.0993 - val_acc: 0.8182

Epoch 00014: loss did not improve from 4.54932
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 4.7318 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 4.5521 - acc: 0.8140 - val_loss: 4.0833 - val_acc: 0.8182

Epoch 00015: loss did not improve from 4.54932
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 4.4757 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 4.3425 - acc: 0.8140 - val_loss: 4.0154 - val_acc: 0.8182

Epoch 00016: loss improved from 4.54932 to 4.34251, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 4.3613 - acc: 0.8438
43/43 [==============================] - 0s 51us/step - loss: 4.3647 - acc: 0.8605 - val_loss: 3.9515 - val_acc: 0.9091

Epoch 00017: loss did not improve from 4.34251
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 4.6051 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 4.4271 - acc: 0.7209 - val_loss: 3.8956 - val_acc: 0.9091

Epoch 00018: loss did not improve from 4.34251
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 4.4028 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 4.2662 - acc: 0.8605 - val_loss: 3.8882 - val_acc: 0.9091

Epoch 00019: loss improved from 4.34251 to 4.26622, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 4.1546 - acc: 0.9062
43/43 [==============================] - 0s 50us/step - loss: 4.0463 - acc: 0.9302 - val_loss: 3.8169 - val_acc: 1.0000

Epoch 00020: loss improved from 4.26622 to 4.04631, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 4.0625 - acc: 0.9062
43/43 [==============================] - 0s 51us/step - loss: 3.9739 - acc: 0.9302 - val_loss: 3.7679 - val_acc: 1.0000

Epoch 00021: loss improved from 4.04631 to 3.97393, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 4.1287 - acc: 0.8125
43/43 [==============================] - 0s 51us/step - loss: 4.0411 - acc: 0.8372 - val_loss: 3.7348 - val_acc: 1.0000

Epoch 00022: loss did not improve from 3.97393
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 4.1423 - acc: 0.8438
43/43 [==============================] - 0s 48us/step - loss: 4.0147 - acc: 0.8837 - val_loss: 3.6633 - val_acc: 1.0000

Epoch 00023: loss did not improve from 3.97393
Epoch 24/100

32/43 [=====================>........] - ETA: 0s - loss: 4.3937 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 4.2022 - acc: 0.8605 - val_loss: 3.6850 - val_acc: 0.9091

Epoch 00024: loss did not improve from 3.97393
Epoch 25/100

32/43 [=====================>........] - ETA: 0s - loss: 4.1884 - acc: 0.7812
43/43 [==============================] - 0s 48us/step - loss: 4.0314 - acc: 0.8372 - val_loss: 3.6644 - val_acc: 0.9091

Epoch 00025: loss did not improve from 3.97393
Epoch 26/100

32/43 [=====================>........] - ETA: 0s - loss: 4.0134 - acc: 0.8750
43/43 [==============================] - 0s 48us/step - loss: 3.9342 - acc: 0.9070 - val_loss: 3.6433 - val_acc: 0.9091

Epoch 00026: loss improved from 3.97393 to 3.93419, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 27/100

32/43 [=====================>........] - ETA: 0s - loss: 3.9833 - acc: 0.9062
43/43 [==============================] - 0s 51us/step - loss: 3.8707 - acc: 0.9302 - val_loss: 3.6112 - val_acc: 0.9091

Epoch 00027: loss improved from 3.93419 to 3.87068, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 28/100

32/43 [=====================>........] - ETA: 0s - loss: 3.8524 - acc: 0.9688
43/43 [==============================] - 0s 50us/step - loss: 3.7765 - acc: 0.9767 - val_loss: 3.5476 - val_acc: 1.0000

Epoch 00028: loss improved from 3.87068 to 3.77653, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 29/100

32/43 [=====================>........] - ETA: 0s - loss: 3.8611 - acc: 0.8750
43/43 [==============================] - 0s 51us/step - loss: 3.7632 - acc: 0.9070 - val_loss: 3.5259 - val_acc: 1.0000

Epoch 00029: loss improved from 3.77653 to 3.76322, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 30/100

32/43 [=====================>........] - ETA: 0s - loss: 3.6041 - acc: 0.9688
43/43 [==============================] - 0s 51us/step - loss: 3.5978 - acc: 0.9767 - val_loss: 3.4846 - val_acc: 1.0000

Epoch 00030: loss improved from 3.76322 to 3.59779, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 31/100

32/43 [=====================>........] - ETA: 0s - loss: 4.2703 - acc: 0.8750
43/43 [==============================] - 0s 50us/step - loss: 4.0757 - acc: 0.9070 - val_loss: 3.4686 - val_acc: 1.0000

Epoch 00031: loss did not improve from 3.59779
Epoch 32/100

32/43 [=====================>........] - ETA: 0s - loss: 3.6109 - acc: 0.9062
43/43 [==============================] - 0s 49us/step - loss: 3.5511 - acc: 0.9302 - val_loss: 3.4406 - val_acc: 1.0000

Epoch 00032: loss improved from 3.59779 to 3.55114, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 33/100

32/43 [=====================>........] - ETA: 0s - loss: 3.5351 - acc: 0.9688
43/43 [==============================] - 0s 52us/step - loss: 3.4878 - acc: 0.9767 - val_loss: 3.4135 - val_acc: 1.0000

Epoch 00033: loss improved from 3.55114 to 3.48780, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_14.h5
Epoch 34/100

32/43 [=====================>........] - ETA: 0s - loss: 3.9447 - acc: 0.9062
43/43 [==============================] - 0s 50us/step - loss: 4.5939 - acc: 0.9070 - val_loss: 5.0490 - val_acc: 0.8182

Epoch 00034: loss did not improve from 3.48780
Epoch 35/100

32/43 [=====================>........] - ETA: 0s - loss: 7.7861 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 6.8357 - acc: 0.8140 - val_loss: 4.4451 - val_acc: 0.9091

Epoch 00035: loss did not improve from 3.48780
Epoch 36/100

32/43 [=====================>........] - ETA: 0s - loss: 5.3191 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 5.0424 - acc: 0.7674 - val_loss: 4.5825 - val_acc: 0.6364

Epoch 00036: loss did not improve from 3.48780
Epoch 37/100

32/43 [=====================>........] - ETA: 0s - loss: 4.8085 - acc: 0.8438
43/43 [==============================] - 0s 48us/step - loss: 4.6757 - acc: 0.8372 - val_loss: 4.3649 - val_acc: 0.6364

Epoch 00037: loss did not improve from 3.48780
Epoch 38/100

32/43 [=====================>........] - ETA: 0s - loss: 5.3191 - acc: 0.7500
43/43 [==============================] - 0s 48us/step - loss: 4.9987 - acc: 0.7674 - val_loss: 4.3413 - val_acc: 0.6364
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:14<00:06,  1.64s/it]
Epoch 00038: loss did not improve from 3.48780
Epoch 00038: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 4.9442 - acc: 0.6875
43/43 [==============================] - 0s 6ms/step - loss: 6.1673 - acc: 0.6047 - val_loss: 2.6010 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 6.16732, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 5.7677 - acc: 0.6875
43/43 [==============================] - 0s 63us/step - loss: 5.2664 - acc: 0.6512 - val_loss: 1.3554 - val_acc: 0.9091

Epoch 00002: loss improved from 6.16732 to 5.26638, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 3.7637 - acc: 0.5625
43/43 [==============================] - 0s 53us/step - loss: 3.2908 - acc: 0.5814 - val_loss: 1.4097 - val_acc: 0.7273

Epoch 00003: loss improved from 5.26638 to 3.29078, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.8753 - acc: 0.5000
43/43 [==============================] - 0s 52us/step - loss: 2.5755 - acc: 0.5116 - val_loss: 1.3462 - val_acc: 0.8182

Epoch 00004: loss improved from 3.29078 to 2.57549, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.4428 - acc: 0.5938
43/43 [==============================] - 0s 51us/step - loss: 2.1868 - acc: 0.6279 - val_loss: 1.2917 - val_acc: 0.9091

Epoch 00005: loss improved from 2.57549 to 2.18683, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 2.5373 - acc: 0.5625
43/43 [==============================] - 0s 51us/step - loss: 2.2705 - acc: 0.6047 - val_loss: 1.1754 - val_acc: 0.9091

Epoch 00006: loss did not improve from 2.18683
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0728 - acc: 0.5625
43/43 [==============================] - 0s 49us/step - loss: 1.8508 - acc: 0.6279 - val_loss: 1.1256 - val_acc: 0.9091

Epoch 00007: loss improved from 2.18683 to 1.85078, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0362 - acc: 0.5938
43/43 [==============================] - 0s 51us/step - loss: 1.8154 - acc: 0.6512 - val_loss: 1.1028 - val_acc: 0.9091

Epoch 00008: loss improved from 1.85078 to 1.81536, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8256 - acc: 0.7188
43/43 [==============================] - 0s 52us/step - loss: 1.6295 - acc: 0.7907 - val_loss: 1.2519 - val_acc: 0.8182

Epoch 00009: loss improved from 1.81536 to 1.62946, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7092 - acc: 0.6562
43/43 [==============================] - 0s 51us/step - loss: 1.5336 - acc: 0.7442 - val_loss: 1.0780 - val_acc: 0.9091

Epoch 00010: loss improved from 1.62946 to 1.53361, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8243 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 1.6554 - acc: 0.7209 - val_loss: 1.0261 - val_acc: 0.9091

Epoch 00011: loss did not improve from 1.53361
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6316 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 1.4945 - acc: 0.7209 - val_loss: 0.9715 - val_acc: 0.9091

Epoch 00012: loss improved from 1.53361 to 1.49449, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1378 - acc: 0.7500
43/43 [==============================] - 0s 50us/step - loss: 3.1672 - acc: 0.6977 - val_loss: 2.4540 - val_acc: 0.9091

Epoch 00013: loss did not improve from 1.49449
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 7.6283 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 6.0632 - acc: 0.6977 - val_loss: 1.7720 - val_acc: 0.9091

Epoch 00014: loss did not improve from 1.49449
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 3.3988 - acc: 0.6562
43/43 [==============================] - 0s 48us/step - loss: 3.2325 - acc: 0.6744 - val_loss: 1.7506 - val_acc: 0.8182

Epoch 00015: loss did not improve from 1.49449
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 2.7669 - acc: 0.3125
43/43 [==============================] - 0s 49us/step - loss: 2.4856 - acc: 0.4419 - val_loss: 1.6184 - val_acc: 0.9091

Epoch 00016: loss did not improve from 1.49449
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 2.6020 - acc: 0.7188
43/43 [==============================] - 0s 48us/step - loss: 2.3762 - acc: 0.7209 - val_loss: 1.5707 - val_acc: 0.9091
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:16<00:04,  1.63s/it]
Epoch 00017: loss did not improve from 1.49449
Epoch 00017: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 4.7593 - acc: 0.7188
43/43 [==============================] - 0s 6ms/step - loss: 5.3692 - acc: 0.6047 - val_loss: 2.0772 - val_acc: 0.9091

Epoch 00001: loss improved from inf to 5.36920, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 3.7391 - acc: 0.6250
43/43 [==============================] - 0s 62us/step - loss: 3.4659 - acc: 0.6047 - val_loss: 1.2218 - val_acc: 0.8182

Epoch 00002: loss improved from 5.36920 to 3.46588, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 2.5719 - acc: 0.4062
43/43 [==============================] - 0s 54us/step - loss: 2.3472 - acc: 0.4651 - val_loss: 1.0626 - val_acc: 0.8182

Epoch 00003: loss improved from 3.46588 to 2.34720, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.6726 - acc: 0.5312
43/43 [==============================] - 0s 52us/step - loss: 2.4926 - acc: 0.5581 - val_loss: 1.2750 - val_acc: 0.9091

Epoch 00004: loss did not improve from 2.34720
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.7469 - acc: 0.6875
43/43 [==============================] - 0s 50us/step - loss: 2.5522 - acc: 0.6744 - val_loss: 1.2902 - val_acc: 0.8182

Epoch 00005: loss did not improve from 2.34720
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1953 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 2.0664 - acc: 0.6744 - val_loss: 1.1943 - val_acc: 0.8182

Epoch 00006: loss improved from 2.34720 to 2.06644, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2165 - acc: 0.5938
43/43 [==============================] - 0s 51us/step - loss: 1.9552 - acc: 0.6279 - val_loss: 1.1604 - val_acc: 0.8182

Epoch 00007: loss improved from 2.06644 to 1.95516, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1831 - acc: 0.6250
43/43 [==============================] - 0s 51us/step - loss: 1.9603 - acc: 0.6744 - val_loss: 1.1211 - val_acc: 0.8182

Epoch 00008: loss did not improve from 1.95516
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0906 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 1.9901 - acc: 0.6977 - val_loss: 1.1598 - val_acc: 0.8182

Epoch 00009: loss did not improve from 1.95516
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8115 - acc: 0.5625
43/43 [==============================] - 0s 49us/step - loss: 1.6749 - acc: 0.6279 - val_loss: 1.0869 - val_acc: 0.8182

Epoch 00010: loss improved from 1.95516 to 1.67491, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0205 - acc: 0.7188
43/43 [==============================] - 0s 51us/step - loss: 1.8348 - acc: 0.7442 - val_loss: 1.0560 - val_acc: 0.8182

Epoch 00011: loss did not improve from 1.67491
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8013 - acc: 0.7188
43/43 [==============================] - 0s 48us/step - loss: 1.6387 - acc: 0.7442 - val_loss: 1.0713 - val_acc: 0.8182

Epoch 00012: loss improved from 1.67491 to 1.63871, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5591 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.4246 - acc: 0.8140 - val_loss: 1.0519 - val_acc: 0.8182

Epoch 00013: loss improved from 1.63871 to 1.42458, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6797 - acc: 0.7188
43/43 [==============================] - 0s 51us/step - loss: 1.5636 - acc: 0.7442 - val_loss: 1.0590 - val_acc: 0.8182

Epoch 00014: loss did not improve from 1.42458
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5761 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.4143 - acc: 0.7907 - val_loss: 1.0244 - val_acc: 0.8182

Epoch 00015: loss improved from 1.42458 to 1.41433, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3973 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 1.2827 - acc: 0.7674 - val_loss: 1.0243 - val_acc: 0.8182

Epoch 00016: loss improved from 1.41433 to 1.28269, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7841 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.6066 - acc: 0.7907 - val_loss: 1.0472 - val_acc: 0.8182

Epoch 00017: loss did not improve from 1.28269
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1529 - acc: 0.8125
43/43 [==============================] - 0s 48us/step - loss: 1.1044 - acc: 0.8372 - val_loss: 0.9728 - val_acc: 0.8182

Epoch 00018: loss improved from 1.28269 to 1.10442, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_16.h5
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4834 - acc: 0.7812
43/43 [==============================] - 0s 50us/step - loss: 1.3540 - acc: 0.7907 - val_loss: 0.9473 - val_acc: 0.8182

Epoch 00019: loss did not improve from 1.10442
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4250 - acc: 0.7812
43/43 [==============================] - 0s 48us/step - loss: 1.2940 - acc: 0.8372 - val_loss: 1.0230 - val_acc: 0.8182

Epoch 00020: loss did not improve from 1.10442
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1919 - acc: 0.8438
43/43 [==============================] - 0s 49us/step - loss: 1.1493 - acc: 0.8837 - val_loss: 0.9588 - val_acc: 0.8182

Epoch 00021: loss did not improve from 1.10442
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4076 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.2769 - acc: 0.8372 - val_loss: 0.9773 - val_acc: 0.8182

Epoch 00022: loss did not improve from 1.10442
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3102 - acc: 0.8438
43/43 [==============================] - 0s 48us/step - loss: 1.2285 - acc: 0.8837 - val_loss: 0.9424 - val_acc: 0.8182
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:17<00:03,  1.59s/it]
Epoch 00023: loss did not improve from 1.10442
Epoch 00023: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 4.7748 - acc: 0.6562
43/43 [==============================] - 0s 6ms/step - loss: 5.6483 - acc: 0.6047 - val_loss: 1.4935 - val_acc: 0.9091

Epoch 00001: loss improved from inf to 5.64833, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 5.8025 - acc: 0.6250
43/43 [==============================] - 0s 62us/step - loss: 5.3846 - acc: 0.5814 - val_loss: 1.2871 - val_acc: 0.9091

Epoch 00002: loss improved from 5.64833 to 5.38456, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 5.5838 - acc: 0.6562
43/43 [==============================] - 0s 54us/step - loss: 4.6240 - acc: 0.6512 - val_loss: 1.1496 - val_acc: 0.9091

Epoch 00003: loss improved from 5.38456 to 4.62403, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 2.7908 - acc: 0.6250
43/43 [==============================] - 0s 52us/step - loss: 2.5846 - acc: 0.6512 - val_loss: 1.1322 - val_acc: 0.9091

Epoch 00004: loss improved from 4.62403 to 2.58460, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 2.8136 - acc: 0.6562
43/43 [==============================] - 0s 51us/step - loss: 2.4517 - acc: 0.6977 - val_loss: 1.1780 - val_acc: 0.9091

Epoch 00005: loss improved from 2.58460 to 2.45174, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 3.4553 - acc: 0.7188
43/43 [==============================] - 0s 52us/step - loss: 3.1796 - acc: 0.6744 - val_loss: 1.2659 - val_acc: 0.8182

Epoch 00006: loss did not improve from 2.45174
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 2.5342 - acc: 0.6250
43/43 [==============================] - 0s 50us/step - loss: 2.2371 - acc: 0.6744 - val_loss: 1.1787 - val_acc: 0.8182

Epoch 00007: loss improved from 2.45174 to 2.23707, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 2.7339 - acc: 0.5625
43/43 [==============================] - 0s 51us/step - loss: 2.3676 - acc: 0.6279 - val_loss: 1.1249 - val_acc: 0.8182

Epoch 00008: loss did not improve from 2.23707
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2163 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 2.0087 - acc: 0.7209 - val_loss: 1.0904 - val_acc: 0.8182

Epoch 00009: loss improved from 2.23707 to 2.00867, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 2.4145 - acc: 0.6250
43/43 [==============================] - 0s 51us/step - loss: 2.3694 - acc: 0.6744 - val_loss: 1.3862 - val_acc: 0.6364

Epoch 00010: loss did not improve from 2.00867
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3447 - acc: 0.5625
43/43 [==============================] - 0s 50us/step - loss: 2.1269 - acc: 0.6279 - val_loss: 1.1570 - val_acc: 0.8182

Epoch 00011: loss did not improve from 2.00867
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2895 - acc: 0.7188
43/43 [==============================] - 0s 50us/step - loss: 2.0730 - acc: 0.7442 - val_loss: 1.1289 - val_acc: 0.8182

Epoch 00012: loss did not improve from 2.00867
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2774 - acc: 0.6562
43/43 [==============================] - 0s 49us/step - loss: 2.0852 - acc: 0.6744 - val_loss: 1.3349 - val_acc: 0.6364

Epoch 00013: loss did not improve from 2.00867
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8507 - acc: 0.6250
43/43 [==============================] - 0s 49us/step - loss: 1.6843 - acc: 0.6977 - val_loss: 1.1874 - val_acc: 0.8182

Epoch 00014: loss improved from 2.00867 to 1.68425, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9117 - acc: 0.7188
43/43 [==============================] - 0s 51us/step - loss: 1.7549 - acc: 0.7442 - val_loss: 1.2400 - val_acc: 0.8182

Epoch 00015: loss did not improve from 1.68425
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7206 - acc: 0.7188
43/43 [==============================] - 0s 49us/step - loss: 1.6280 - acc: 0.7674 - val_loss: 1.1323 - val_acc: 0.8182

Epoch 00016: loss improved from 1.68425 to 1.62799, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_17.h5
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1143 - acc: 0.7500
43/43 [==============================] - 0s 52us/step - loss: 1.9206 - acc: 0.7442 - val_loss: 1.3647 - val_acc: 0.6364

Epoch 00017: loss did not improve from 1.62799
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0020 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.8177 - acc: 0.7907 - val_loss: 1.3187 - val_acc: 0.6364

Epoch 00018: loss did not improve from 1.62799
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8846 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.6512 - acc: 0.8140 - val_loss: 1.2965 - val_acc: 0.6364

Epoch 00019: loss did not improve from 1.62799
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.7130 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.6440 - acc: 0.7674 - val_loss: 1.1164 - val_acc: 0.8182

Epoch 00020: loss did not improve from 1.62799
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 2.0068 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.9149 - acc: 0.7209 - val_loss: 1.1663 - val_acc: 0.9091
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:19<00:01,  1.60s/it]
Epoch 00021: loss did not improve from 1.62799
Epoch 00021: early stopping
Train on 43 samples, validate on 11 samples
Epoch 1/100

32/43 [=====================>........] - ETA: 0s - loss: 5.8945 - acc: 0.6875
43/43 [==============================] - 0s 6ms/step - loss: 7.0433 - acc: 0.6279 - val_loss: 3.0151 - val_acc: 0.3636

Epoch 00001: loss improved from inf to 7.04332, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

32/43 [=====================>........] - ETA: 0s - loss: 5.0690 - acc: 0.6250
43/43 [==============================] - 0s 60us/step - loss: 4.6650 - acc: 0.5814 - val_loss: 1.7169 - val_acc: 0.4545

Epoch 00002: loss improved from 7.04332 to 4.66498, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

32/43 [=====================>........] - ETA: 0s - loss: 4.5014 - acc: 0.2500
43/43 [==============================] - 0s 54us/step - loss: 3.8318 - acc: 0.3721 - val_loss: 1.9842 - val_acc: 0.6364

Epoch 00003: loss improved from 4.66498 to 3.83179, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

32/43 [=====================>........] - ETA: 0s - loss: 4.1287 - acc: 0.5625
43/43 [==============================] - 0s 52us/step - loss: 3.8043 - acc: 0.5349 - val_loss: 2.2528 - val_acc: 0.2727

Epoch 00004: loss improved from 3.83179 to 3.80429, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

32/43 [=====================>........] - ETA: 0s - loss: 3.6951 - acc: 0.2500
43/43 [==============================] - 0s 52us/step - loss: 3.2312 - acc: 0.3023 - val_loss: 1.8812 - val_acc: 0.2727

Epoch 00005: loss improved from 3.80429 to 3.23116, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

32/43 [=====================>........] - ETA: 0s - loss: 2.9569 - acc: 0.3750
43/43 [==============================] - 0s 51us/step - loss: 2.7000 - acc: 0.3953 - val_loss: 1.7206 - val_acc: 0.6364

Epoch 00006: loss improved from 3.23116 to 2.70004, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

32/43 [=====================>........] - ETA: 0s - loss: 3.3136 - acc: 0.3438
43/43 [==============================] - 0s 51us/step - loss: 2.9213 - acc: 0.3953 - val_loss: 1.7889 - val_acc: 0.2727

Epoch 00007: loss did not improve from 2.70004
Epoch 8/100

32/43 [=====================>........] - ETA: 0s - loss: 2.8950 - acc: 0.2812
43/43 [==============================] - 0s 50us/step - loss: 2.6345 - acc: 0.3256 - val_loss: 1.7030 - val_acc: 0.3636

Epoch 00008: loss improved from 2.70004 to 2.63451, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

32/43 [=====================>........] - ETA: 0s - loss: 2.7654 - acc: 0.3750
43/43 [==============================] - 0s 51us/step - loss: 2.4816 - acc: 0.4186 - val_loss: 1.5894 - val_acc: 0.5455

Epoch 00009: loss improved from 2.63451 to 2.48163, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

32/43 [=====================>........] - ETA: 0s - loss: 2.8272 - acc: 0.3750
43/43 [==============================] - 0s 54us/step - loss: 2.5899 - acc: 0.4651 - val_loss: 1.6097 - val_acc: 0.8182

Epoch 00010: loss did not improve from 2.48163
Epoch 11/100

32/43 [=====================>........] - ETA: 0s - loss: 2.8116 - acc: 0.4688
43/43 [==============================] - 0s 50us/step - loss: 2.6111 - acc: 0.5116 - val_loss: 2.1000 - val_acc: 0.3636

Epoch 00011: loss did not improve from 2.48163
Epoch 12/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3741 - acc: 0.3750
43/43 [==============================] - 0s 49us/step - loss: 2.2898 - acc: 0.5116 - val_loss: 2.1479 - val_acc: 0.3636

Epoch 00012: loss improved from 2.48163 to 2.28977, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 13/100

32/43 [=====================>........] - ETA: 0s - loss: 2.5836 - acc: 0.3438
43/43 [==============================] - 0s 51us/step - loss: 2.3424 - acc: 0.4186 - val_loss: 1.7697 - val_acc: 0.4545

Epoch 00013: loss did not improve from 2.28977
Epoch 14/100

32/43 [=====================>........] - ETA: 0s - loss: 2.6486 - acc: 0.4062
43/43 [==============================] - 0s 50us/step - loss: 2.4493 - acc: 0.4884 - val_loss: 1.5433 - val_acc: 0.9091

Epoch 00014: loss did not improve from 2.28977
Epoch 15/100

32/43 [=====================>........] - ETA: 0s - loss: 3.1243 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 2.7913 - acc: 0.6977 - val_loss: 1.8488 - val_acc: 0.4545

Epoch 00015: loss did not improve from 2.28977
Epoch 16/100

32/43 [=====================>........] - ETA: 0s - loss: 2.6584 - acc: 0.5938
43/43 [==============================] - 0s 54us/step - loss: 2.4277 - acc: 0.6279 - val_loss: 1.8773 - val_acc: 0.4545

Epoch 00016: loss did not improve from 2.28977
Epoch 17/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3923 - acc: 0.4375
43/43 [==============================] - 0s 49us/step - loss: 2.1019 - acc: 0.5349 - val_loss: 1.6362 - val_acc: 0.6364

Epoch 00017: loss improved from 2.28977 to 2.10189, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 18/100

32/43 [=====================>........] - ETA: 0s - loss: 2.1826 - acc: 0.5312
43/43 [==============================] - 0s 51us/step - loss: 1.9906 - acc: 0.6047 - val_loss: 1.5953 - val_acc: 0.6364

Epoch 00018: loss improved from 2.10189 to 1.99060, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 19/100

32/43 [=====================>........] - ETA: 0s - loss: 2.2780 - acc: 0.5938
43/43 [==============================] - 0s 51us/step - loss: 2.0582 - acc: 0.6512 - val_loss: 1.5254 - val_acc: 0.6364

Epoch 00019: loss did not improve from 1.99060
Epoch 20/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8212 - acc: 0.5625
43/43 [==============================] - 0s 49us/step - loss: 1.6435 - acc: 0.6279 - val_loss: 1.3502 - val_acc: 0.8182

Epoch 00020: loss improved from 1.99060 to 1.64354, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 21/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9705 - acc: 0.7188
43/43 [==============================] - 0s 50us/step - loss: 1.8096 - acc: 0.7674 - val_loss: 1.3377 - val_acc: 0.8182

Epoch 00021: loss did not improve from 1.64354
Epoch 22/100

32/43 [=====================>........] - ETA: 0s - loss: 2.3873 - acc: 0.6250
43/43 [==============================] - 0s 50us/step - loss: 2.1143 - acc: 0.6744 - val_loss: 1.4270 - val_acc: 0.6364

Epoch 00022: loss did not improve from 1.64354
Epoch 23/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6146 - acc: 0.5938
43/43 [==============================] - 0s 49us/step - loss: 1.4543 - acc: 0.6977 - val_loss: 1.2320 - val_acc: 0.7273

Epoch 00023: loss improved from 1.64354 to 1.45435, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 24/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9189 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.7892 - acc: 0.7442 - val_loss: 1.3187 - val_acc: 0.6364

Epoch 00024: loss did not improve from 1.45435
Epoch 25/100

32/43 [=====================>........] - ETA: 0s - loss: 1.9605 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.7240 - acc: 0.7209 - val_loss: 1.2817 - val_acc: 0.6364

Epoch 00025: loss did not improve from 1.45435
Epoch 26/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5750 - acc: 0.6875
43/43 [==============================] - 0s 49us/step - loss: 1.4882 - acc: 0.7674 - val_loss: 1.1760 - val_acc: 0.8182

Epoch 00026: loss did not improve from 1.45435
Epoch 27/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5519 - acc: 0.7500
43/43 [==============================] - 0s 49us/step - loss: 1.4367 - acc: 0.7907 - val_loss: 1.1108 - val_acc: 0.9091

Epoch 00027: loss improved from 1.45435 to 1.43673, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 28/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5752 - acc: 0.6875
43/43 [==============================] - 0s 51us/step - loss: 1.4044 - acc: 0.7674 - val_loss: 1.0792 - val_acc: 0.8182

Epoch 00028: loss improved from 1.43673 to 1.40440, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 29/100

32/43 [=====================>........] - ETA: 0s - loss: 1.4148 - acc: 0.7500
43/43 [==============================] - 0s 51us/step - loss: 1.2796 - acc: 0.7907 - val_loss: 0.9894 - val_acc: 0.9091

Epoch 00029: loss improved from 1.40440 to 1.27955, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 30/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2012 - acc: 0.8125
43/43 [==============================] - 0s 51us/step - loss: 1.1394 - acc: 0.8372 - val_loss: 0.9956 - val_acc: 0.9091

Epoch 00030: loss improved from 1.27955 to 1.13941, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 31/100

32/43 [=====================>........] - ETA: 0s - loss: 1.8493 - acc: 0.7500
43/43 [==============================] - 0s 50us/step - loss: 1.6241 - acc: 0.8140 - val_loss: 0.9563 - val_acc: 0.9091

Epoch 00031: loss did not improve from 1.13941
Epoch 32/100

32/43 [=====================>........] - ETA: 0s - loss: 1.5665 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.4009 - acc: 0.8140 - val_loss: 0.9511 - val_acc: 0.9091

Epoch 00032: loss did not improve from 1.13941
Epoch 33/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3432 - acc: 0.8438
43/43 [==============================] - 0s 48us/step - loss: 1.2306 - acc: 0.8837 - val_loss: 0.9317 - val_acc: 0.9091

Epoch 00033: loss did not improve from 1.13941
Epoch 34/100

32/43 [=====================>........] - ETA: 0s - loss: 1.3908 - acc: 0.7812
43/43 [==============================] - 0s 49us/step - loss: 1.2489 - acc: 0.8372 - val_loss: 0.9095 - val_acc: 0.9091

Epoch 00034: loss did not improve from 1.13941
Epoch 35/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0568 - acc: 0.9062
43/43 [==============================] - 0s 48us/step - loss: 0.9935 - acc: 0.9302 - val_loss: 0.9003 - val_acc: 0.9091

Epoch 00035: loss improved from 1.13941 to 0.99352, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 36/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1310 - acc: 0.8438
43/43 [==============================] - 0s 51us/step - loss: 1.0538 - acc: 0.8837 - val_loss: 0.8555 - val_acc: 0.9091

Epoch 00036: loss did not improve from 0.99352
Epoch 37/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1393 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 1.0560 - acc: 0.9070 - val_loss: 0.8488 - val_acc: 1.0000

Epoch 00037: loss did not improve from 0.99352
Epoch 38/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0194 - acc: 0.9062
43/43 [==============================] - 0s 50us/step - loss: 0.9654 - acc: 0.9302 - val_loss: 0.8524 - val_acc: 0.9091

Epoch 00038: loss improved from 0.99352 to 0.96539, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 39/100

32/43 [=====================>........] - ETA: 0s - loss: 1.0986 - acc: 0.9375
43/43 [==============================] - 0s 51us/step - loss: 1.0136 - acc: 0.9535 - val_loss: 0.8389 - val_acc: 0.9091

Epoch 00039: loss did not improve from 0.96539
Epoch 40/100

32/43 [=====================>........] - ETA: 0s - loss: 1.1253 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 1.0660 - acc: 0.8605 - val_loss: 0.8127 - val_acc: 0.9091

Epoch 00040: loss did not improve from 0.96539
Epoch 41/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9401 - acc: 0.9375
43/43 [==============================] - 0s 49us/step - loss: 0.8815 - acc: 0.9535 - val_loss: 0.7907 - val_acc: 1.0000

Epoch 00041: loss improved from 0.96539 to 0.88155, saving model to ./results_TA104_with_S9/DeepAmes_models/weight_18.h5
Epoch 42/100

32/43 [=====================>........] - ETA: 0s - loss: 0.9842 - acc: 0.9062
43/43 [==============================] - 0s 50us/step - loss: 0.9205 - acc: 0.9302 - val_loss: 0.7884 - val_acc: 1.0000

Epoch 00042: loss did not improve from 0.88155
Epoch 43/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2303 - acc: 0.9375
43/43 [==============================] - 0s 48us/step - loss: 1.1354 - acc: 0.9535 - val_loss: 0.8553 - val_acc: 0.9091

Epoch 00043: loss did not improve from 0.88155
Epoch 44/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2506 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 1.1293 - acc: 0.9070 - val_loss: 0.8071 - val_acc: 1.0000

Epoch 00044: loss did not improve from 0.88155
Epoch 45/100

32/43 [=====================>........] - ETA: 0s - loss: 1.6028 - acc: 0.8125
43/43 [==============================] - 0s 49us/step - loss: 1.4308 - acc: 0.8372 - val_loss: 0.8517 - val_acc: 0.9091

Epoch 00045: loss did not improve from 0.88155
Epoch 46/100

32/43 [=====================>........] - ETA: 0s - loss: 1.2680 - acc: 0.8750
43/43 [==============================] - 0s 49us/step - loss: 1.1507 - acc: 0.9070 - val_loss: 0.8218 - val_acc: 0.9091
DeepAmes+ Weights: 100%|██████████| 13/13 [00:21<00:00,  1.64s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:21<00:00,  1.62s/it]

Epoch 00046: loss did not improve from 0.88155
Epoch 00046: early stopping
--- 630.7368063926697 seconds ---

Generating metrics report for TA104_with_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 19 samples.
Processing weight 7...
  Done. 19 samples.
Processing weight 8...
  Done. 19 samples.
Processing weight 9...
  Done. 19 samples.
Processing weight 10...
  Done. 19 samples.
Processing weight 11...
  Done. 19 samples.
Processing weight 12...
  Done. 19 samples.
Processing weight 13...
  Done. 19 samples.
Processing weight 14...
  Done. 19 samples.
Processing weight 15...
  Done. 19 samples.
Processing weight 16...
  Done. 19 samples.
Processing weight 17...
  Done. 19 samples.
Processing weight 18...
  Done. 19 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA104_with_S9/metrics_report_TA104_with_S9.txt

Done!

Completed TA104_with_S9 in 630.74 seconds

================================================================================
[6/16] Processing: TA104_without_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA104_without_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA104_without_S9_Test_mold2.csv
(336, 777)
(268, 777)
(28, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:00<00:05,  3.39it/s]KNN Seeds:  10%|█         | 2/20 [00:00<00:05,  3.32it/s]KNN Seeds:  15%|█▌        | 3/20 [00:00<00:05,  3.24it/s]KNN Seeds:  20%|██        | 4/20 [00:01<00:05,  3.16it/s]KNN Seeds:  25%|██▌       | 5/20 [00:01<00:04,  3.09it/s]KNN Seeds:  30%|███       | 6/20 [00:01<00:04,  3.02it/s]KNN Seeds:  35%|███▌      | 7/20 [00:02<00:04,  2.94it/s]KNN Seeds:  40%|████      | 8/20 [00:02<00:04,  2.85it/s]KNN Seeds:  45%|████▌     | 9/20 [00:03<00:03,  2.77it/s]KNN Seeds:  50%|█████     | 10/20 [00:03<00:03,  2.68it/s]KNN Seeds:  55%|█████▌    | 11/20 [00:03<00:03,  2.61it/s]KNN Seeds:  60%|██████    | 12/20 [00:04<00:03,  2.54it/s]KNN Seeds:  65%|██████▌   | 13/20 [00:04<00:02,  2.48it/s]KNN Seeds:  70%|███████   | 14/20 [00:05<00:02,  2.41it/s]KNN Seeds:  75%|███████▌  | 15/20 [00:05<00:02,  2.36it/s]KNN Seeds:  80%|████████  | 16/20 [00:06<00:01,  2.30it/s]KNN Seeds:  85%|████████▌ | 17/20 [00:06<00:01,  2.25it/s]KNN Seeds:  90%|█████████ | 18/20 [00:06<00:00,  2.19it/s]KNN Seeds:  95%|█████████▌| 19/20 [00:07<00:00,  2.14it/s]KNN Seeds: 100%|██████████| 20/20 [00:07<00:00,  2.09it/s]KNN Seeds: 100%|██████████| 20/20 [00:07<00:00,  2.50it/s]
24
(100, None, 'lbfgs')
(336, 777)
(268, 777)
(28, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:01<00:26,  1.41s/it]LR Seeds:  10%|█         | 2/20 [00:02<00:25,  1.44s/it]LR Seeds:  15%|█▌        | 3/20 [00:04<00:24,  1.46s/it]LR Seeds:  20%|██        | 4/20 [00:05<00:23,  1.49s/it]LR Seeds:  25%|██▌       | 5/20 [00:07<00:22,  1.51s/it]LR Seeds:  30%|███       | 6/20 [00:08<00:21,  1.53s/it]LR Seeds:  35%|███▌      | 7/20 [00:10<00:19,  1.53s/it]LR Seeds:  40%|████      | 8/20 [00:12<00:18,  1.54s/it]LR Seeds:  45%|████▌     | 9/20 [00:13<00:17,  1.56s/it]LR Seeds:  50%|█████     | 10/20 [00:15<00:15,  1.56s/it]LR Seeds:  55%|█████▌    | 11/20 [00:16<00:14,  1.58s/it]LR Seeds:  60%|██████    | 12/20 [00:18<00:12,  1.59s/it]LR Seeds:  65%|██████▌   | 13/20 [00:20<00:11,  1.60s/it]LR Seeds:  70%|███████   | 14/20 [00:21<00:09,  1.62s/it]LR Seeds:  75%|███████▌  | 15/20 [00:23<00:08,  1.64s/it]LR Seeds:  80%|████████  | 16/20 [00:25<00:06,  1.64s/it]LR Seeds:  85%|████████▌ | 17/20 [00:26<00:04,  1.65s/it]LR Seeds:  90%|█████████ | 18/20 [00:28<00:03,  1.65s/it]LR Seeds:  95%|█████████▌| 19/20 [00:30<00:01,  1.64s/it]LR Seeds: 100%|██████████| 20/20 [00:31<00:00,  1.66s/it]LR Seeds: 100%|██████████| 20/20 [00:31<00:00,  1.59s/it]
96
('rbf', 1, 1)
(336, 777)
(268, 777)
(28, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [00:01<00:23,  1.25s/it]SVM Seeds:  10%|█         | 2/20 [00:02<00:22,  1.26s/it]SVM Seeds:  15%|█▌        | 3/20 [00:03<00:21,  1.26s/it]SVM Seeds:  20%|██        | 4/20 [00:05<00:20,  1.27s/it]SVM Seeds:  25%|██▌       | 5/20 [00:06<00:19,  1.28s/it]SVM Seeds:  30%|███       | 6/20 [00:07<00:18,  1.29s/it]SVM Seeds:  35%|███▌      | 7/20 [00:08<00:16,  1.30s/it]SVM Seeds:  40%|████      | 8/20 [00:10<00:15,  1.31s/it]SVM Seeds:  45%|████▌     | 9/20 [00:11<00:14,  1.32s/it]SVM Seeds:  50%|█████     | 10/20 [00:12<00:13,  1.33s/it]SVM Seeds:  55%|█████▌    | 11/20 [00:14<00:12,  1.34s/it]SVM Seeds:  60%|██████    | 12/20 [00:15<00:10,  1.35s/it]SVM Seeds:  65%|██████▌   | 13/20 [00:17<00:09,  1.36s/it]SVM Seeds:  70%|███████   | 14/20 [00:18<00:08,  1.37s/it]SVM Seeds:  75%|███████▌  | 15/20 [00:19<00:06,  1.38s/it]SVM Seeds:  80%|████████  | 16/20 [00:21<00:05,  1.39s/it]SVM Seeds:  85%|████████▌ | 17/20 [00:22<00:04,  1.40s/it]SVM Seeds:  90%|█████████ | 18/20 [00:24<00:02,  1.41s/it]SVM Seeds:  95%|█████████▌| 19/20 [00:25<00:01,  1.42s/it]SVM Seeds: 100%|██████████| 20/20 [00:27<00:00,  1.43s/it]SVM Seeds: 100%|██████████| 20/20 [00:27<00:00,  1.36s/it]
200
(500, None, 70, 1, 'balanced')
(336, 777)
(268, 777)
(28, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:01<00:29,  1.55s/it]RF Seeds:  10%|█         | 2/20 [00:03<00:28,  1.56s/it]RF Seeds:  15%|█▌        | 3/20 [00:04<00:26,  1.56s/it]RF Seeds:  20%|██        | 4/20 [00:06<00:25,  1.57s/it]RF Seeds:  25%|██▌       | 5/20 [00:07<00:23,  1.58s/it]RF Seeds:  30%|███       | 6/20 [00:09<00:22,  1.59s/it]RF Seeds:  35%|███▌      | 7/20 [00:11<00:20,  1.60s/it]RF Seeds:  40%|████      | 8/20 [00:12<00:19,  1.61s/it]RF Seeds:  45%|████▌     | 9/20 [00:14<00:17,  1.62s/it]RF Seeds:  50%|█████     | 10/20 [00:16<00:16,  1.63s/it]RF Seeds:  55%|█████▌    | 11/20 [00:17<00:14,  1.64s/it]RF Seeds:  60%|██████    | 12/20 [00:19<00:13,  1.65s/it]RF Seeds:  65%|██████▌   | 13/20 [00:21<00:11,  1.66s/it]RF Seeds:  70%|███████   | 14/20 [00:22<00:10,  1.67s/it]RF Seeds:  75%|███████▌  | 15/20 [00:24<00:08,  1.68s/it]RF Seeds:  80%|████████  | 16/20 [00:26<00:06,  1.70s/it]RF Seeds:  85%|████████▌ | 17/20 [00:27<00:05,  1.71s/it]RF Seeds:  90%|█████████ | 18/20 [00:29<00:03,  1.74s/it]RF Seeds:  95%|█████████▌| 19/20 [00:31<00:01,  1.75s/it]RF Seeds: 100%|██████████| 20/20 [00:33<00:00,  1.75s/it]RF Seeds: 100%|██████████| 20/20 [00:33<00:00,  1.66s/it]
400
(0.01, 900, 7, 0.8, 6)
(336, 777)
(268, 777)
(28, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:24<07:52, 24.86s/it]XGBoost Seeds:  10%|█         | 2/20 [00:49<07:27, 24.83s/it]XGBoost Seeds:  15%|█▌        | 3/20 [01:14<07:02, 24.86s/it]XGBoost Seeds:  20%|██        | 4/20 [01:39<06:37, 24.85s/it]XGBoost Seeds:  25%|██▌       | 5/20 [02:04<06:12, 24.87s/it]XGBoost Seeds:  30%|███       | 6/20 [02:29<05:48, 24.86s/it]XGBoost Seeds:  35%|███▌      | 7/20 [02:53<05:22, 24.82s/it]XGBoost Seeds:  40%|████      | 8/20 [03:18<04:57, 24.82s/it]XGBoost Seeds:  45%|████▌     | 9/20 [03:43<04:32, 24.78s/it]XGBoost Seeds:  50%|█████     | 10/20 [04:08<04:08, 24.80s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [04:33<03:43, 24.81s/it]XGBoost Seeds:  60%|██████    | 12/20 [04:57<03:18, 24.76s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [05:22<02:53, 24.74s/it]XGBoost Seeds:  70%|███████   | 14/20 [05:47<02:28, 24.75s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [06:11<02:03, 24.77s/it]XGBoost Seeds:  80%|████████  | 16/20 [06:36<01:39, 24.82s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [07:01<01:14, 24.81s/it]XGBoost Seeds:  90%|█████████ | 18/20 [07:26<00:49, 24.83s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [07:51<00:24, 24.84s/it]XGBoost Seeds: 100%|██████████| 20/20 [08:16<00:00, 24.89s/it]XGBoost Seeds: 100%|██████████| 20/20 [08:16<00:00, 24.82s/it]
knn:  89
lr:  96
svm:  79
rf:  100
xgboost:  86
Combining validation predictions is completed
knn:  89
lr:  96
svm:  79
rf:  100
xgboost:  86
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 2.2800 - acc: 0.4688
54/54 [==============================] - 0s 5ms/step - loss: 2.1019 - acc: 0.5926 - val_loss: 4.7489 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 2.10193, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.4121 - acc: 0.8125
54/54 [==============================] - 0s 50us/step - loss: 1.4152 - acc: 0.8148 - val_loss: 3.5701 - val_acc: 0.5714

Epoch 00002: loss improved from 2.10193 to 1.41518, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.3400 - acc: 0.8125
54/54 [==============================] - 0s 46us/step - loss: 1.3174 - acc: 0.8148 - val_loss: 3.1325 - val_acc: 0.5714

Epoch 00003: loss improved from 1.41518 to 1.31744, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.2744 - acc: 0.7812
54/54 [==============================] - 0s 43us/step - loss: 1.2191 - acc: 0.8148 - val_loss: 2.8577 - val_acc: 0.5714

Epoch 00004: loss improved from 1.31744 to 1.21913, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.1123 - acc: 0.8125
54/54 [==============================] - 0s 42us/step - loss: 1.1617 - acc: 0.8519 - val_loss: 2.7184 - val_acc: 0.5714

Epoch 00005: loss improved from 1.21913 to 1.16167, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.1720 - acc: 0.8125
54/54 [==============================] - 0s 43us/step - loss: 1.2141 - acc: 0.8519 - val_loss: 3.1561 - val_acc: 0.5714

Epoch 00006: loss did not improve from 1.16167
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.2458 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 1.1113 - acc: 0.8519 - val_loss: 2.7768 - val_acc: 0.5000

Epoch 00007: loss improved from 1.16167 to 1.11126, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 0.9776 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 0.9853 - acc: 0.8889 - val_loss: 2.6014 - val_acc: 0.5714

Epoch 00008: loss improved from 1.11126 to 0.98532, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.0486 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 1.0437 - acc: 0.8889 - val_loss: 2.4519 - val_acc: 0.5000

Epoch 00009: loss did not improve from 0.98532
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 0.9533 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.9748 - acc: 0.9259 - val_loss: 2.5244 - val_acc: 0.5714

Epoch 00010: loss improved from 0.98532 to 0.97481, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.0258 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 0.9400 - acc: 0.9259 - val_loss: 2.6396 - val_acc: 0.6429

Epoch 00011: loss improved from 0.97481 to 0.94003, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.0581 - acc: 0.9062
54/54 [==============================] - 0s 44us/step - loss: 0.9671 - acc: 0.9259 - val_loss: 2.3910 - val_acc: 0.5000

Epoch 00012: loss did not improve from 0.94003
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.0244 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.9253 - acc: 0.9259 - val_loss: 2.3250 - val_acc: 0.5000

Epoch 00013: loss improved from 0.94003 to 0.92533, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 0.8055 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.7882 - acc: 0.9444 - val_loss: 2.3738 - val_acc: 0.5714

Epoch 00014: loss improved from 0.92533 to 0.78816, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 0.9018 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8434 - acc: 0.9444 - val_loss: 2.4078 - val_acc: 0.5714

Epoch 00015: loss did not improve from 0.78816
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 0.8353 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.8110 - acc: 0.9815 - val_loss: 2.3418 - val_acc: 0.5714

Epoch 00016: loss did not improve from 0.78816
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 0.8099 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.7839 - acc: 0.9815 - val_loss: 2.3131 - val_acc: 0.5714

Epoch 00017: loss improved from 0.78816 to 0.78395, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.8064 - acc: 0.9062
54/54 [==============================] - 0s 42us/step - loss: 0.7739 - acc: 0.9444 - val_loss: 2.3854 - val_acc: 0.5714

Epoch 00018: loss improved from 0.78395 to 0.77393, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.6843 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.7067 - acc: 0.9630 - val_loss: 2.3691 - val_acc: 0.5714

Epoch 00019: loss improved from 0.77393 to 0.70669, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_6.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.7723 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7419 - acc: 0.9815 - val_loss: 2.5525 - val_acc: 0.5714

Epoch 00020: loss did not improve from 0.70669
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 0.9386 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.0107 - acc: 0.9074 - val_loss: 5.0525 - val_acc: 0.5714

Epoch 00021: loss did not improve from 0.70669
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 1.5213 - acc: 0.8438
54/54 [==============================] - 0s 40us/step - loss: 1.2562 - acc: 0.8519 - val_loss: 3.9834 - val_acc: 0.6429

Epoch 00022: loss did not improve from 0.70669
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 1.1676 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.0391 - acc: 0.9074 - val_loss: 3.2685 - val_acc: 0.6429

Epoch 00023: loss did not improve from 0.70669
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 1.1291 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 0.9932 - acc: 0.8889 - val_loss: 3.0860 - val_acc: 0.6429
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:18,  1.53s/it]
Epoch 00024: loss did not improve from 0.70669
Epoch 00024: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 1.7951 - acc: 0.6562
54/54 [==============================] - 0s 5ms/step - loss: 1.7826 - acc: 0.6852 - val_loss: 3.9671 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 1.78263, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.5276 - acc: 0.7188
54/54 [==============================] - 0s 50us/step - loss: 1.4898 - acc: 0.7778 - val_loss: 3.5895 - val_acc: 0.5714

Epoch 00002: loss improved from 1.78263 to 1.48984, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.2635 - acc: 0.8438
54/54 [==============================] - 0s 45us/step - loss: 1.1879 - acc: 0.8519 - val_loss: 2.9391 - val_acc: 0.5714

Epoch 00003: loss improved from 1.48984 to 1.18789, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.1390 - acc: 0.8125
54/54 [==============================] - 0s 42us/step - loss: 1.1908 - acc: 0.8148 - val_loss: 2.3616 - val_acc: 0.5000

Epoch 00004: loss did not improve from 1.18789
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.1099 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.0815 - acc: 0.9074 - val_loss: 2.9414 - val_acc: 0.5714

Epoch 00005: loss improved from 1.18789 to 1.08152, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.2618 - acc: 0.8438
54/54 [==============================] - 0s 42us/step - loss: 1.1364 - acc: 0.8889 - val_loss: 2.6265 - val_acc: 0.5000

Epoch 00006: loss did not improve from 1.08152
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 0.9531 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.9028 - acc: 0.9630 - val_loss: 2.4951 - val_acc: 0.4286

Epoch 00007: loss improved from 1.08152 to 0.90278, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.0197 - acc: 0.9062
54/54 [==============================] - 0s 42us/step - loss: 0.9413 - acc: 0.9444 - val_loss: 2.4713 - val_acc: 0.5000

Epoch 00008: loss did not improve from 0.90278
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.0000 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.9370 - acc: 0.9444 - val_loss: 2.4561 - val_acc: 0.4286

Epoch 00009: loss did not improve from 0.90278
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 0.9381 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.8849 - acc: 0.9444 - val_loss: 2.4413 - val_acc: 0.5000

Epoch 00010: loss improved from 0.90278 to 0.88488, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 0.9814 - acc: 0.8438
54/54 [==============================] - 0s 42us/step - loss: 0.9285 - acc: 0.9074 - val_loss: 2.3632 - val_acc: 0.5000

Epoch 00011: loss did not improve from 0.88488
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 0.8514 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.8292 - acc: 0.9630 - val_loss: 2.1462 - val_acc: 0.5000

Epoch 00012: loss improved from 0.88488 to 0.82916, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 0.8745 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8805 - acc: 0.9259 - val_loss: 2.3746 - val_acc: 0.5714

Epoch 00013: loss did not improve from 0.82916
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 0.8427 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.8121 - acc: 0.9630 - val_loss: 2.4641 - val_acc: 0.5714

Epoch 00014: loss improved from 0.82916 to 0.81209, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 0.8573 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8188 - acc: 0.9259 - val_loss: 2.2513 - val_acc: 0.5000

Epoch 00015: loss did not improve from 0.81209
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 0.8343 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7787 - acc: 0.9444 - val_loss: 2.3247 - val_acc: 0.5000

Epoch 00016: loss improved from 0.81209 to 0.77865, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 0.7376 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.7288 - acc: 0.9630 - val_loss: 2.3706 - val_acc: 0.5000

Epoch 00017: loss improved from 0.77865 to 0.72875, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.7123 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6906 - acc: 1.0000 - val_loss: 2.3493 - val_acc: 0.5000

Epoch 00018: loss improved from 0.72875 to 0.69063, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.7062 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6813 - acc: 1.0000 - val_loss: 2.2476 - val_acc: 0.5000

Epoch 00019: loss improved from 0.69063 to 0.68126, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.6925 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.6972 - acc: 1.0000 - val_loss: 2.4261 - val_acc: 0.5714

Epoch 00020: loss did not improve from 0.68126
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 0.8309 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7714 - acc: 0.9444 - val_loss: 2.3840 - val_acc: 0.5000

Epoch 00021: loss did not improve from 0.68126
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.6670 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6504 - acc: 1.0000 - val_loss: 2.5403 - val_acc: 0.5000

Epoch 00022: loss improved from 0.68126 to 0.65038, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.6710 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.6879 - acc: 0.9815 - val_loss: 2.4018 - val_acc: 0.5000

Epoch 00023: loss did not improve from 0.65038
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.7727 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7812 - acc: 0.9444 - val_loss: 3.9686 - val_acc: 0.5000

Epoch 00024: loss did not improve from 0.65038
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 1.0321 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 0.8859 - acc: 0.9074 - val_loss: 2.8105 - val_acc: 0.5000

Epoch 00025: loss did not improve from 0.65038
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.7428 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6962 - acc: 0.9815 - val_loss: 2.6980 - val_acc: 0.5714

Epoch 00026: loss did not improve from 0.65038
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.6462 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6269 - acc: 1.0000 - val_loss: 2.8600 - val_acc: 0.5714

Epoch 00027: loss improved from 0.65038 to 0.62694, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.7060 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.6937 - acc: 0.9630 - val_loss: 2.6648 - val_acc: 0.5714

Epoch 00028: loss did not improve from 0.62694
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 0.7153 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6885 - acc: 0.9815 - val_loss: 2.4178 - val_acc: 0.5714

Epoch 00029: loss did not improve from 0.62694
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 0.6350 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6396 - acc: 0.9815 - val_loss: 2.6205 - val_acc: 0.5714

Epoch 00030: loss did not improve from 0.62694
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 0.7087 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6556 - acc: 0.9815 - val_loss: 2.7513 - val_acc: 0.5714

Epoch 00031: loss did not improve from 0.62694
Epoch 32/100

32/54 [================>.............] - ETA: 0s - loss: 0.5964 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5892 - acc: 1.0000 - val_loss: 2.8611 - val_acc: 0.5714

Epoch 00032: loss improved from 0.62694 to 0.58920, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 33/100

32/54 [================>.............] - ETA: 0s - loss: 0.6023 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5877 - acc: 1.0000 - val_loss: 2.6862 - val_acc: 0.5714

Epoch 00033: loss improved from 0.58920 to 0.58766, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 34/100

32/54 [================>.............] - ETA: 0s - loss: 0.5630 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5651 - acc: 1.0000 - val_loss: 2.6924 - val_acc: 0.5714

Epoch 00034: loss improved from 0.58766 to 0.56505, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 35/100

32/54 [================>.............] - ETA: 0s - loss: 0.5790 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5655 - acc: 1.0000 - val_loss: 2.7092 - val_acc: 0.5714

Epoch 00035: loss did not improve from 0.56505
Epoch 36/100

32/54 [================>.............] - ETA: 0s - loss: 0.5973 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.5731 - acc: 0.9815 - val_loss: 2.4909 - val_acc: 0.5714

Epoch 00036: loss did not improve from 0.56505
Epoch 37/100

32/54 [================>.............] - ETA: 0s - loss: 0.5803 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5596 - acc: 1.0000 - val_loss: 2.8559 - val_acc: 0.5714

Epoch 00037: loss improved from 0.56505 to 0.55962, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_7.h5
Epoch 38/100

32/54 [================>.............] - ETA: 0s - loss: 0.5933 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.6475 - acc: 0.9815 - val_loss: 5.7048 - val_acc: 0.5714

Epoch 00038: loss did not improve from 0.55962
Epoch 39/100

32/54 [================>.............] - ETA: 0s - loss: 1.0538 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 0.9048 - acc: 0.9074 - val_loss: 4.8726 - val_acc: 0.6429

Epoch 00039: loss did not improve from 0.55962
Epoch 40/100

32/54 [================>.............] - ETA: 0s - loss: 0.7687 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7019 - acc: 0.9630 - val_loss: 4.5700 - val_acc: 0.6429

Epoch 00040: loss did not improve from 0.55962
Epoch 41/100

32/54 [================>.............] - ETA: 0s - loss: 0.7480 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7024 - acc: 0.9630 - val_loss: 4.0969 - val_acc: 0.6429

Epoch 00041: loss did not improve from 0.55962
Epoch 42/100

32/54 [================>.............] - ETA: 0s - loss: 0.8020 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7109 - acc: 0.9630 - val_loss: 3.9444 - val_acc: 0.6429
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:03<00:17,  1.63s/it]
Epoch 00042: loss did not improve from 0.55962
Epoch 00042: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 2.2931 - acc: 0.6250
54/54 [==============================] - 0s 5ms/step - loss: 2.2384 - acc: 0.7037 - val_loss: 4.1827 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 2.23836, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.4729 - acc: 0.7500
54/54 [==============================] - 0s 48us/step - loss: 1.5019 - acc: 0.7593 - val_loss: 3.5111 - val_acc: 0.5714

Epoch 00002: loss improved from 2.23836 to 1.50190, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.3895 - acc: 0.7500
54/54 [==============================] - 0s 43us/step - loss: 1.3521 - acc: 0.7593 - val_loss: 3.0805 - val_acc: 0.5714

Epoch 00003: loss improved from 1.50190 to 1.35209, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.2898 - acc: 0.7812
54/54 [==============================] - 0s 43us/step - loss: 1.3167 - acc: 0.7963 - val_loss: 3.0168 - val_acc: 0.5714

Epoch 00004: loss improved from 1.35209 to 1.31675, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.3471 - acc: 0.8125
54/54 [==============================] - 0s 42us/step - loss: 1.4549 - acc: 0.8148 - val_loss: 2.7270 - val_acc: 0.5714

Epoch 00005: loss did not improve from 1.31675
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.2477 - acc: 0.7188
54/54 [==============================] - 0s 41us/step - loss: 1.2048 - acc: 0.7778 - val_loss: 2.9583 - val_acc: 0.5714

Epoch 00006: loss improved from 1.31675 to 1.20479, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.2630 - acc: 0.8125
54/54 [==============================] - 0s 42us/step - loss: 1.1713 - acc: 0.8333 - val_loss: 2.6451 - val_acc: 0.5714

Epoch 00007: loss improved from 1.20479 to 1.17129, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.1945 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.1016 - acc: 0.8889 - val_loss: 2.5324 - val_acc: 0.5714

Epoch 00008: loss improved from 1.17129 to 1.10162, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 0.9661 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 0.9737 - acc: 0.8889 - val_loss: 2.5440 - val_acc: 0.6429

Epoch 00009: loss improved from 1.10162 to 0.97367, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.0658 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 1.0433 - acc: 0.8889 - val_loss: 2.5316 - val_acc: 0.6429

Epoch 00010: loss did not improve from 0.97367
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.0046 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 0.9678 - acc: 0.9074 - val_loss: 2.4403 - val_acc: 0.6429

Epoch 00011: loss improved from 0.97367 to 0.96782, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 0.9738 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.9530 - acc: 0.9259 - val_loss: 2.3606 - val_acc: 0.5714

Epoch 00012: loss improved from 0.96782 to 0.95296, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 0.9299 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 0.9146 - acc: 0.9259 - val_loss: 3.0216 - val_acc: 0.5714

Epoch 00013: loss improved from 0.95296 to 0.91462, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 0.9644 - acc: 0.9062
54/54 [==============================] - 0s 42us/step - loss: 0.8904 - acc: 0.9444 - val_loss: 2.6401 - val_acc: 0.5714

Epoch 00014: loss improved from 0.91462 to 0.89043, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 0.9979 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.9338 - acc: 0.9444 - val_loss: 2.4926 - val_acc: 0.5714

Epoch 00015: loss did not improve from 0.89043
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 0.9139 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.8490 - acc: 0.9444 - val_loss: 2.4257 - val_acc: 0.5714

Epoch 00016: loss improved from 0.89043 to 0.84905, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 0.8035 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.8071 - acc: 0.9630 - val_loss: 2.2732 - val_acc: 0.5714

Epoch 00017: loss improved from 0.84905 to 0.80709, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.8151 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7798 - acc: 0.9630 - val_loss: 2.4898 - val_acc: 0.5714

Epoch 00018: loss improved from 0.80709 to 0.77979, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.7427 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.7185 - acc: 0.9815 - val_loss: 2.4219 - val_acc: 0.5714

Epoch 00019: loss improved from 0.77979 to 0.71846, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_8.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.7763 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.7553 - acc: 0.9815 - val_loss: 2.4271 - val_acc: 0.5714

Epoch 00020: loss did not improve from 0.71846
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 0.7901 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7462 - acc: 0.9630 - val_loss: 2.6382 - val_acc: 0.5714

Epoch 00021: loss did not improve from 0.71846
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.8311 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 0.7571 - acc: 0.9259 - val_loss: 2.2785 - val_acc: 0.5000

Epoch 00022: loss did not improve from 0.71846
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.7849 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7777 - acc: 0.9630 - val_loss: 2.9790 - val_acc: 0.5714

Epoch 00023: loss did not improve from 0.71846
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.8270 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7952 - acc: 0.9630 - val_loss: 3.1282 - val_acc: 0.5714
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:04<00:16,  1.64s/it]
Epoch 00024: loss did not improve from 0.71846
Epoch 00024: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 2.5788 - acc: 0.5625
54/54 [==============================] - 0s 5ms/step - loss: 2.4653 - acc: 0.6667 - val_loss: 4.3955 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 2.46526, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.4551 - acc: 0.7188
54/54 [==============================] - 0s 48us/step - loss: 1.5525 - acc: 0.7222 - val_loss: 3.7257 - val_acc: 0.5714

Epoch 00002: loss improved from 2.46526 to 1.55248, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.4768 - acc: 0.8125
54/54 [==============================] - 0s 43us/step - loss: 1.4032 - acc: 0.7963 - val_loss: 3.2447 - val_acc: 0.5714

Epoch 00003: loss improved from 1.55248 to 1.40315, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.2945 - acc: 0.8438
54/54 [==============================] - 0s 42us/step - loss: 1.3451 - acc: 0.8519 - val_loss: 3.3117 - val_acc: 0.5714

Epoch 00004: loss improved from 1.40315 to 1.34506, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.2466 - acc: 0.7812
54/54 [==============================] - 0s 41us/step - loss: 1.1813 - acc: 0.8148 - val_loss: 2.8252 - val_acc: 0.5714

Epoch 00005: loss improved from 1.34506 to 1.18128, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.1977 - acc: 0.8125
54/54 [==============================] - 0s 42us/step - loss: 1.1968 - acc: 0.8148 - val_loss: 2.6306 - val_acc: 0.5714

Epoch 00006: loss did not improve from 1.18128
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.1903 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.1919 - acc: 0.8333 - val_loss: 2.6547 - val_acc: 0.5714

Epoch 00007: loss did not improve from 1.18128
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.1143 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.0979 - acc: 0.8889 - val_loss: 2.7890 - val_acc: 0.5714

Epoch 00008: loss improved from 1.18128 to 1.09789, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.0933 - acc: 0.8125
54/54 [==============================] - 0s 41us/step - loss: 1.0644 - acc: 0.8704 - val_loss: 2.6275 - val_acc: 0.5714

Epoch 00009: loss improved from 1.09789 to 1.06438, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.0326 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.0566 - acc: 0.9074 - val_loss: 2.6461 - val_acc: 0.5714

Epoch 00010: loss improved from 1.06438 to 1.05660, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.0607 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 1.0204 - acc: 0.8889 - val_loss: 2.6009 - val_acc: 0.6429

Epoch 00011: loss improved from 1.05660 to 1.02039, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 0.9903 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.9582 - acc: 0.9259 - val_loss: 2.2329 - val_acc: 0.5714

Epoch 00012: loss improved from 1.02039 to 0.95823, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.0997 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 1.0088 - acc: 0.9630 - val_loss: 2.6185 - val_acc: 0.6429

Epoch 00013: loss did not improve from 0.95823
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 0.9413 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.9202 - acc: 0.9444 - val_loss: 2.3808 - val_acc: 0.5714

Epoch 00014: loss improved from 0.95823 to 0.92021, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 0.9179 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.8738 - acc: 0.9630 - val_loss: 2.4735 - val_acc: 0.5714

Epoch 00015: loss improved from 0.92021 to 0.87380, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 0.8576 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.8092 - acc: 0.9815 - val_loss: 2.5502 - val_acc: 0.5714

Epoch 00016: loss improved from 0.87380 to 0.80918, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 0.9239 - acc: 0.9375
54/54 [==============================] - 0s 43us/step - loss: 0.8871 - acc: 0.9444 - val_loss: 2.6359 - val_acc: 0.5714

Epoch 00017: loss did not improve from 0.80918
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.8471 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.8092 - acc: 0.9630 - val_loss: 2.6087 - val_acc: 0.5714

Epoch 00018: loss improved from 0.80918 to 0.80917, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.7962 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7661 - acc: 0.9630 - val_loss: 2.7409 - val_acc: 0.5714

Epoch 00019: loss improved from 0.80917 to 0.76609, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.8403 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 0.8178 - acc: 0.9259 - val_loss: 2.9418 - val_acc: 0.5714

Epoch 00020: loss did not improve from 0.76609
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 1.0638 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 0.9452 - acc: 0.9259 - val_loss: 2.6569 - val_acc: 0.5714

Epoch 00021: loss did not improve from 0.76609
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.7702 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.7535 - acc: 0.9815 - val_loss: 2.6014 - val_acc: 0.5714

Epoch 00022: loss improved from 0.76609 to 0.75347, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.8848 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.8555 - acc: 0.9630 - val_loss: 2.6209 - val_acc: 0.5714

Epoch 00023: loss did not improve from 0.75347
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.7751 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.7405 - acc: 0.9815 - val_loss: 3.0342 - val_acc: 0.5714

Epoch 00024: loss improved from 0.75347 to 0.74054, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 0.8012 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7786 - acc: 0.9444 - val_loss: 3.2365 - val_acc: 0.5714

Epoch 00025: loss did not improve from 0.74054
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.8350 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.8000 - acc: 0.9444 - val_loss: 2.9085 - val_acc: 0.5714

Epoch 00026: loss did not improve from 0.74054
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.8068 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7693 - acc: 0.9444 - val_loss: 2.8610 - val_acc: 0.5714

Epoch 00027: loss did not improve from 0.74054
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.8104 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.7487 - acc: 0.9444 - val_loss: 2.6178 - val_acc: 0.5714

Epoch 00028: loss did not improve from 0.74054
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 0.6980 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6944 - acc: 0.9815 - val_loss: 2.6083 - val_acc: 0.5714

Epoch 00029: loss improved from 0.74054 to 0.69440, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 0.7060 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.6758 - acc: 0.9630 - val_loss: 2.5782 - val_acc: 0.5714

Epoch 00030: loss improved from 0.69440 to 0.67576, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 0.6562 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.6470 - acc: 1.0000 - val_loss: 2.9603 - val_acc: 0.5714

Epoch 00031: loss improved from 0.67576 to 0.64704, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 32/100

32/54 [================>.............] - ETA: 0s - loss: 0.6869 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6693 - acc: 0.9815 - val_loss: 2.6886 - val_acc: 0.5714

Epoch 00032: loss did not improve from 0.64704
Epoch 33/100

32/54 [================>.............] - ETA: 0s - loss: 0.7067 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6660 - acc: 0.9815 - val_loss: 2.5819 - val_acc: 0.5714

Epoch 00033: loss did not improve from 0.64704
Epoch 34/100

32/54 [================>.............] - ETA: 0s - loss: 0.6276 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6229 - acc: 1.0000 - val_loss: 2.7902 - val_acc: 0.5714

Epoch 00034: loss improved from 0.64704 to 0.62289, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 35/100

32/54 [================>.............] - ETA: 0s - loss: 0.6931 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6630 - acc: 0.9815 - val_loss: 2.5057 - val_acc: 0.5714

Epoch 00035: loss did not improve from 0.62289
Epoch 36/100

32/54 [================>.............] - ETA: 0s - loss: 0.6402 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6228 - acc: 1.0000 - val_loss: 3.2151 - val_acc: 0.5714

Epoch 00036: loss improved from 0.62289 to 0.62280, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 37/100

32/54 [================>.............] - ETA: 0s - loss: 0.6851 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6541 - acc: 0.9815 - val_loss: 2.4983 - val_acc: 0.5714

Epoch 00037: loss did not improve from 0.62280
Epoch 38/100

32/54 [================>.............] - ETA: 0s - loss: 0.6154 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6101 - acc: 1.0000 - val_loss: 2.7600 - val_acc: 0.5714

Epoch 00038: loss improved from 0.62280 to 0.61007, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 39/100

32/54 [================>.............] - ETA: 0s - loss: 0.6064 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6076 - acc: 0.9815 - val_loss: 2.6814 - val_acc: 0.5714

Epoch 00039: loss improved from 0.61007 to 0.60760, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 40/100

32/54 [================>.............] - ETA: 0s - loss: 0.6402 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6153 - acc: 0.9815 - val_loss: 2.8238 - val_acc: 0.5714

Epoch 00040: loss did not improve from 0.60760
Epoch 41/100

32/54 [================>.............] - ETA: 0s - loss: 0.6002 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5911 - acc: 1.0000 - val_loss: 2.9245 - val_acc: 0.5714

Epoch 00041: loss improved from 0.60760 to 0.59106, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 42/100

32/54 [================>.............] - ETA: 0s - loss: 0.6192 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6053 - acc: 0.9815 - val_loss: 2.8317 - val_acc: 0.5714

Epoch 00042: loss did not improve from 0.59106
Epoch 43/100

32/54 [================>.............] - ETA: 0s - loss: 0.5659 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5683 - acc: 1.0000 - val_loss: 2.9202 - val_acc: 0.5714

Epoch 00043: loss improved from 0.59106 to 0.56832, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 44/100

32/54 [================>.............] - ETA: 0s - loss: 0.5595 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5651 - acc: 1.0000 - val_loss: 2.8295 - val_acc: 0.5714

Epoch 00044: loss improved from 0.56832 to 0.56514, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 45/100

32/54 [================>.............] - ETA: 0s - loss: 0.5809 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5664 - acc: 1.0000 - val_loss: 3.1017 - val_acc: 0.5714

Epoch 00045: loss did not improve from 0.56514
Epoch 46/100

32/54 [================>.............] - ETA: 0s - loss: 0.5610 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5591 - acc: 1.0000 - val_loss: 2.9302 - val_acc: 0.5714

Epoch 00046: loss improved from 0.56514 to 0.55915, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 47/100

32/54 [================>.............] - ETA: 0s - loss: 0.5448 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5392 - acc: 1.0000 - val_loss: 2.9285 - val_acc: 0.5714

Epoch 00047: loss improved from 0.55915 to 0.53924, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 48/100

32/54 [================>.............] - ETA: 0s - loss: 0.5445 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5370 - acc: 1.0000 - val_loss: 2.9331 - val_acc: 0.5714

Epoch 00048: loss improved from 0.53924 to 0.53702, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 49/100

32/54 [================>.............] - ETA: 0s - loss: 0.5374 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5349 - acc: 1.0000 - val_loss: 2.9578 - val_acc: 0.5714

Epoch 00049: loss improved from 0.53702 to 0.53494, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 50/100

32/54 [================>.............] - ETA: 0s - loss: 0.5501 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5426 - acc: 1.0000 - val_loss: 2.7939 - val_acc: 0.5714

Epoch 00050: loss did not improve from 0.53494
Epoch 51/100

32/54 [================>.............] - ETA: 0s - loss: 0.5289 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5223 - acc: 1.0000 - val_loss: 2.8763 - val_acc: 0.5714

Epoch 00051: loss improved from 0.53494 to 0.52230, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 52/100

32/54 [================>.............] - ETA: 0s - loss: 0.5181 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5144 - acc: 1.0000 - val_loss: 2.9629 - val_acc: 0.5714

Epoch 00052: loss improved from 0.52230 to 0.51440, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 53/100

32/54 [================>.............] - ETA: 0s - loss: 0.5410 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5268 - acc: 1.0000 - val_loss: 2.9328 - val_acc: 0.5714

Epoch 00053: loss did not improve from 0.51440
Epoch 54/100

32/54 [================>.............] - ETA: 0s - loss: 0.5154 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5137 - acc: 1.0000 - val_loss: 2.9625 - val_acc: 0.5714

Epoch 00054: loss improved from 0.51440 to 0.51370, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 55/100

32/54 [================>.............] - ETA: 0s - loss: 0.5072 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5054 - acc: 1.0000 - val_loss: 3.0136 - val_acc: 0.5714

Epoch 00055: loss improved from 0.51370 to 0.50545, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 56/100

32/54 [================>.............] - ETA: 0s - loss: 0.5035 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5074 - acc: 1.0000 - val_loss: 2.8599 - val_acc: 0.5714

Epoch 00056: loss did not improve from 0.50545
Epoch 57/100

32/54 [================>.............] - ETA: 0s - loss: 0.4967 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5006 - acc: 1.0000 - val_loss: 3.0725 - val_acc: 0.5714

Epoch 00057: loss improved from 0.50545 to 0.50062, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 58/100

32/54 [================>.............] - ETA: 0s - loss: 0.4935 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4901 - acc: 1.0000 - val_loss: 3.0931 - val_acc: 0.5714

Epoch 00058: loss improved from 0.50062 to 0.49006, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 59/100

32/54 [================>.............] - ETA: 0s - loss: 0.4901 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4933 - acc: 1.0000 - val_loss: 2.9885 - val_acc: 0.5714

Epoch 00059: loss did not improve from 0.49006
Epoch 60/100

32/54 [================>.............] - ETA: 0s - loss: 0.4847 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4814 - acc: 1.0000 - val_loss: 3.0296 - val_acc: 0.5714

Epoch 00060: loss improved from 0.49006 to 0.48140, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 61/100

32/54 [================>.............] - ETA: 0s - loss: 0.4851 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4801 - acc: 1.0000 - val_loss: 3.0867 - val_acc: 0.5714

Epoch 00061: loss improved from 0.48140 to 0.48013, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 62/100

32/54 [================>.............] - ETA: 0s - loss: 0.4790 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4830 - acc: 1.0000 - val_loss: 3.0109 - val_acc: 0.5714

Epoch 00062: loss did not improve from 0.48013
Epoch 63/100

32/54 [================>.............] - ETA: 0s - loss: 0.4728 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4729 - acc: 1.0000 - val_loss: 2.8762 - val_acc: 0.5714

Epoch 00063: loss improved from 0.48013 to 0.47290, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 64/100

32/54 [================>.............] - ETA: 0s - loss: 0.5199 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.4976 - acc: 0.9815 - val_loss: 2.7377 - val_acc: 0.5714

Epoch 00064: loss did not improve from 0.47290
Epoch 65/100

32/54 [================>.............] - ETA: 0s - loss: 0.4830 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4737 - acc: 1.0000 - val_loss: 2.9472 - val_acc: 0.5714

Epoch 00065: loss did not improve from 0.47290
Epoch 66/100

32/54 [================>.............] - ETA: 0s - loss: 0.4673 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4624 - acc: 1.0000 - val_loss: 3.0693 - val_acc: 0.5714

Epoch 00066: loss improved from 0.47290 to 0.46238, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 67/100

32/54 [================>.............] - ETA: 0s - loss: 0.4752 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4687 - acc: 1.0000 - val_loss: 2.8468 - val_acc: 0.5714

Epoch 00067: loss did not improve from 0.46238
Epoch 68/100

32/54 [================>.............] - ETA: 0s - loss: 0.4692 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4605 - acc: 1.0000 - val_loss: 3.1574 - val_acc: 0.5714

Epoch 00068: loss improved from 0.46238 to 0.46052, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 69/100

32/54 [================>.............] - ETA: 0s - loss: 0.4488 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4520 - acc: 1.0000 - val_loss: 3.0504 - val_acc: 0.5714

Epoch 00069: loss improved from 0.46052 to 0.45203, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 70/100

32/54 [================>.............] - ETA: 0s - loss: 0.4572 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4508 - acc: 1.0000 - val_loss: 3.1025 - val_acc: 0.5714

Epoch 00070: loss improved from 0.45203 to 0.45076, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 71/100

32/54 [================>.............] - ETA: 0s - loss: 0.4412 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4493 - acc: 1.0000 - val_loss: 2.9449 - val_acc: 0.5714

Epoch 00071: loss improved from 0.45076 to 0.44927, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 72/100

32/54 [================>.............] - ETA: 0s - loss: 0.4415 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4415 - acc: 1.0000 - val_loss: 3.0199 - val_acc: 0.5714

Epoch 00072: loss improved from 0.44927 to 0.44151, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 73/100

32/54 [================>.............] - ETA: 0s - loss: 0.4386 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4344 - acc: 1.0000 - val_loss: 3.1401 - val_acc: 0.5714

Epoch 00073: loss improved from 0.44151 to 0.43437, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 74/100

32/54 [================>.............] - ETA: 0s - loss: 0.4405 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4361 - acc: 1.0000 - val_loss: 2.9845 - val_acc: 0.5714

Epoch 00074: loss did not improve from 0.43437
Epoch 75/100

32/54 [================>.............] - ETA: 0s - loss: 0.4338 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4368 - acc: 1.0000 - val_loss: 2.8662 - val_acc: 0.5714

Epoch 00075: loss did not improve from 0.43437
Epoch 76/100

32/54 [================>.............] - ETA: 0s - loss: 0.4342 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4311 - acc: 1.0000 - val_loss: 3.1777 - val_acc: 0.5714

Epoch 00076: loss improved from 0.43437 to 0.43110, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 77/100

32/54 [================>.............] - ETA: 0s - loss: 0.4213 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4187 - acc: 1.0000 - val_loss: 3.2311 - val_acc: 0.5714

Epoch 00077: loss improved from 0.43110 to 0.41868, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 78/100

32/54 [================>.............] - ETA: 0s - loss: 0.4303 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4249 - acc: 1.0000 - val_loss: 2.9928 - val_acc: 0.6429

Epoch 00078: loss did not improve from 0.41868
Epoch 79/100

32/54 [================>.............] - ETA: 0s - loss: 0.4315 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4231 - acc: 1.0000 - val_loss: 2.9737 - val_acc: 0.6429

Epoch 00079: loss did not improve from 0.41868
Epoch 80/100

32/54 [================>.............] - ETA: 0s - loss: 0.4169 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4130 - acc: 1.0000 - val_loss: 3.0141 - val_acc: 0.6429

Epoch 00080: loss improved from 0.41868 to 0.41300, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 81/100

32/54 [================>.............] - ETA: 0s - loss: 0.4273 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4195 - acc: 1.0000 - val_loss: 2.6763 - val_acc: 0.6429

Epoch 00081: loss did not improve from 0.41300
Epoch 82/100

32/54 [================>.............] - ETA: 0s - loss: 0.4169 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4094 - acc: 1.0000 - val_loss: 3.1908 - val_acc: 0.5714

Epoch 00082: loss improved from 0.41300 to 0.40940, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 83/100

32/54 [================>.............] - ETA: 0s - loss: 0.4034 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4055 - acc: 1.0000 - val_loss: 3.1059 - val_acc: 0.6429

Epoch 00083: loss improved from 0.40940 to 0.40548, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 84/100

32/54 [================>.............] - ETA: 0s - loss: 0.4008 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3975 - acc: 1.0000 - val_loss: 3.1541 - val_acc: 0.6429

Epoch 00084: loss improved from 0.40548 to 0.39753, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 85/100

32/54 [================>.............] - ETA: 0s - loss: 0.4040 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3990 - acc: 1.0000 - val_loss: 3.1150 - val_acc: 0.6429

Epoch 00085: loss did not improve from 0.39753
Epoch 86/100

32/54 [================>.............] - ETA: 0s - loss: 0.3934 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.3969 - acc: 1.0000 - val_loss: 3.0346 - val_acc: 0.6429

Epoch 00086: loss improved from 0.39753 to 0.39695, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_9.h5
Epoch 87/100

32/54 [================>.............] - ETA: 0s - loss: 0.4445 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4236 - acc: 1.0000 - val_loss: 3.6049 - val_acc: 0.5714

Epoch 00087: loss did not improve from 0.39695
Epoch 88/100

32/54 [================>.............] - ETA: 0s - loss: 0.5174 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 1.0558 - acc: 0.8889 - val_loss: 7.4238 - val_acc: 0.5714

Epoch 00088: loss did not improve from 0.39695
Epoch 89/100

32/54 [================>.............] - ETA: 0s - loss: 1.6589 - acc: 0.8438
54/54 [==============================] - 0s 39us/step - loss: 1.5232 - acc: 0.8519 - val_loss: 5.3377 - val_acc: 0.5714

Epoch 00089: loss did not improve from 0.39695
Epoch 90/100

32/54 [================>.............] - ETA: 0s - loss: 1.4820 - acc: 0.8125
54/54 [==============================] - 0s 39us/step - loss: 1.2435 - acc: 0.8704 - val_loss: 4.8352 - val_acc: 0.5714

Epoch 00090: loss did not improve from 0.39695
Epoch 91/100

32/54 [================>.............] - ETA: 0s - loss: 1.2246 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.0917 - acc: 0.8519 - val_loss: 4.4213 - val_acc: 0.5714
DeepAmes+ Weights:  31%|███       | 4/13 [00:06<00:16,  1.78s/it]
Epoch 00091: loss did not improve from 0.39695
Epoch 00091: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 2.0760 - acc: 0.5938
54/54 [==============================] - 0s 5ms/step - loss: 2.2173 - acc: 0.6667 - val_loss: 4.0329 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 2.21734, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.4622 - acc: 0.6875
54/54 [==============================] - 0s 49us/step - loss: 1.4343 - acc: 0.7407 - val_loss: 3.0228 - val_acc: 0.5714

Epoch 00002: loss improved from 2.21734 to 1.43425, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.1862 - acc: 0.8438
54/54 [==============================] - 0s 44us/step - loss: 1.2380 - acc: 0.8333 - val_loss: 2.9256 - val_acc: 0.5714

Epoch 00003: loss improved from 1.43425 to 1.23801, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.1970 - acc: 0.7812
54/54 [==============================] - 0s 42us/step - loss: 1.1598 - acc: 0.8148 - val_loss: 2.7241 - val_acc: 0.5714

Epoch 00004: loss improved from 1.23801 to 1.15981, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.1601 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 1.1512 - acc: 0.8333 - val_loss: 2.8239 - val_acc: 0.5714

Epoch 00005: loss improved from 1.15981 to 1.15123, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.1281 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 1.1775 - acc: 0.8519 - val_loss: 2.5387 - val_acc: 0.5000

Epoch 00006: loss did not improve from 1.15123
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.1302 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.0710 - acc: 0.8704 - val_loss: 2.5993 - val_acc: 0.5000

Epoch 00007: loss improved from 1.15123 to 1.07100, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.0665 - acc: 0.9062
54/54 [==============================] - 0s 45us/step - loss: 1.0519 - acc: 0.8889 - val_loss: 2.7194 - val_acc: 0.5000

Epoch 00008: loss improved from 1.07100 to 1.05188, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.0604 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 0.9741 - acc: 0.9074 - val_loss: 2.6291 - val_acc: 0.5000

Epoch 00009: loss improved from 1.05188 to 0.97415, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.2132 - acc: 0.8438
54/54 [==============================] - 0s 42us/step - loss: 1.0703 - acc: 0.9074 - val_loss: 2.8032 - val_acc: 0.5000

Epoch 00010: loss did not improve from 0.97415
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.0359 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.0442 - acc: 0.9074 - val_loss: 3.1007 - val_acc: 0.5714

Epoch 00011: loss did not improve from 0.97415
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.2345 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 1.0840 - acc: 0.8889 - val_loss: 2.6034 - val_acc: 0.5714

Epoch 00012: loss did not improve from 0.97415
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.0182 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 0.9101 - acc: 0.9259 - val_loss: 2.4767 - val_acc: 0.5714

Epoch 00013: loss improved from 0.97415 to 0.91011, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 0.9008 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.8766 - acc: 0.9630 - val_loss: 2.8043 - val_acc: 0.5714

Epoch 00014: loss improved from 0.91011 to 0.87658, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 0.8769 - acc: 0.9062
54/54 [==============================] - 0s 42us/step - loss: 0.8445 - acc: 0.9259 - val_loss: 2.5769 - val_acc: 0.5714

Epoch 00015: loss improved from 0.87658 to 0.84454, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 0.9387 - acc: 0.9688
54/54 [==============================] - 0s 43us/step - loss: 0.9342 - acc: 0.9815 - val_loss: 2.6191 - val_acc: 0.5714

Epoch 00016: loss did not improve from 0.84454
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 0.9507 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 0.8592 - acc: 0.9259 - val_loss: 2.4227 - val_acc: 0.5714

Epoch 00017: loss did not improve from 0.84454
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.8729 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.8065 - acc: 0.9630 - val_loss: 2.4931 - val_acc: 0.5714

Epoch 00018: loss improved from 0.84454 to 0.80646, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.7988 - acc: 0.9375
54/54 [==============================] - 0s 43us/step - loss: 0.8056 - acc: 0.9444 - val_loss: 3.0861 - val_acc: 0.6429

Epoch 00019: loss improved from 0.80646 to 0.80564, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.9257 - acc: 0.9375
54/54 [==============================] - 0s 43us/step - loss: 0.8378 - acc: 0.9444 - val_loss: 2.6338 - val_acc: 0.5714

Epoch 00020: loss did not improve from 0.80564
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 0.8338 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.7863 - acc: 0.9815 - val_loss: 2.5268 - val_acc: 0.5714

Epoch 00021: loss improved from 0.80564 to 0.78630, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.8278 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.8339 - acc: 0.9444 - val_loss: 2.4335 - val_acc: 0.5714

Epoch 00022: loss did not improve from 0.78630
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.8065 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7467 - acc: 0.9630 - val_loss: 2.3874 - val_acc: 0.5714

Epoch 00023: loss improved from 0.78630 to 0.74670, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.8338 - acc: 0.8750
54/54 [==============================] - 0s 43us/step - loss: 0.7617 - acc: 0.9259 - val_loss: 2.4416 - val_acc: 0.5714

Epoch 00024: loss did not improve from 0.74670
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 0.7147 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.6866 - acc: 0.9630 - val_loss: 2.4858 - val_acc: 0.5714

Epoch 00025: loss improved from 0.74670 to 0.68656, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.7622 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.7022 - acc: 0.9630 - val_loss: 2.4539 - val_acc: 0.5714

Epoch 00026: loss did not improve from 0.68656
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.6477 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6411 - acc: 0.9815 - val_loss: 2.5737 - val_acc: 0.5000

Epoch 00027: loss improved from 0.68656 to 0.64106, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.6615 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.6386 - acc: 0.9815 - val_loss: 2.6130 - val_acc: 0.5000

Epoch 00028: loss improved from 0.64106 to 0.63861, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 0.6302 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.6107 - acc: 0.9815 - val_loss: 2.7447 - val_acc: 0.5000

Epoch 00029: loss improved from 0.63861 to 0.61068, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 0.6221 - acc: 0.9688
54/54 [==============================] - 0s 43us/step - loss: 0.6217 - acc: 0.9815 - val_loss: 2.3362 - val_acc: 0.5000

Epoch 00030: loss did not improve from 0.61068
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 0.6681 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6272 - acc: 0.9815 - val_loss: 2.7175 - val_acc: 0.5000

Epoch 00031: loss did not improve from 0.61068
Epoch 32/100

32/54 [================>.............] - ETA: 0s - loss: 0.6105 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6049 - acc: 0.9815 - val_loss: 2.8847 - val_acc: 0.5000

Epoch 00032: loss improved from 0.61068 to 0.60492, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 33/100

32/54 [================>.............] - ETA: 0s - loss: 0.5984 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5876 - acc: 1.0000 - val_loss: 2.6688 - val_acc: 0.5000

Epoch 00033: loss improved from 0.60492 to 0.58759, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 34/100

32/54 [================>.............] - ETA: 0s - loss: 0.5923 - acc: 1.0000
54/54 [==============================] - 0s 43us/step - loss: 0.5849 - acc: 1.0000 - val_loss: 2.7657 - val_acc: 0.5000

Epoch 00034: loss improved from 0.58759 to 0.58491, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 35/100

32/54 [================>.............] - ETA: 0s - loss: 0.5458 - acc: 1.0000
54/54 [==============================] - 0s 43us/step - loss: 0.5408 - acc: 1.0000 - val_loss: 2.7810 - val_acc: 0.5000

Epoch 00035: loss improved from 0.58491 to 0.54079, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 36/100

32/54 [================>.............] - ETA: 0s - loss: 0.6411 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.5979 - acc: 0.9815 - val_loss: 2.6649 - val_acc: 0.5000

Epoch 00036: loss did not improve from 0.54079
Epoch 37/100

32/54 [================>.............] - ETA: 0s - loss: 0.5695 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5610 - acc: 1.0000 - val_loss: 2.7858 - val_acc: 0.5000

Epoch 00037: loss did not improve from 0.54079
Epoch 38/100

32/54 [================>.............] - ETA: 0s - loss: 0.5665 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5527 - acc: 1.0000 - val_loss: 2.6654 - val_acc: 0.5000

Epoch 00038: loss did not improve from 0.54079
Epoch 39/100

32/54 [================>.............] - ETA: 0s - loss: 0.5546 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5489 - acc: 1.0000 - val_loss: 2.7602 - val_acc: 0.5000

Epoch 00039: loss did not improve from 0.54079
Epoch 40/100

32/54 [================>.............] - ETA: 0s - loss: 0.5447 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5374 - acc: 1.0000 - val_loss: 2.9050 - val_acc: 0.5000

Epoch 00040: loss improved from 0.54079 to 0.53739, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 41/100

32/54 [================>.............] - ETA: 0s - loss: 0.5580 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.5438 - acc: 0.9815 - val_loss: 2.8373 - val_acc: 0.5000

Epoch 00041: loss did not improve from 0.53739
Epoch 42/100

32/54 [================>.............] - ETA: 0s - loss: 0.5245 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5355 - acc: 0.9815 - val_loss: 2.8443 - val_acc: 0.5000

Epoch 00042: loss improved from 0.53739 to 0.53545, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 43/100

32/54 [================>.............] - ETA: 0s - loss: 0.5247 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5164 - acc: 1.0000 - val_loss: 2.8361 - val_acc: 0.5000

Epoch 00043: loss improved from 0.53545 to 0.51638, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 44/100

32/54 [================>.............] - ETA: 0s - loss: 0.5123 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5084 - acc: 1.0000 - val_loss: 2.6880 - val_acc: 0.5000

Epoch 00044: loss improved from 0.51638 to 0.50843, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 45/100

32/54 [================>.............] - ETA: 0s - loss: 0.5352 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5269 - acc: 1.0000 - val_loss: 2.9000 - val_acc: 0.5000

Epoch 00045: loss did not improve from 0.50843
Epoch 46/100

32/54 [================>.............] - ETA: 0s - loss: 0.5189 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5091 - acc: 1.0000 - val_loss: 2.8666 - val_acc: 0.5000

Epoch 00046: loss did not improve from 0.50843
Epoch 47/100

32/54 [================>.............] - ETA: 0s - loss: 0.5181 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5085 - acc: 1.0000 - val_loss: 2.7587 - val_acc: 0.5000

Epoch 00047: loss did not improve from 0.50843
Epoch 48/100

32/54 [================>.............] - ETA: 0s - loss: 0.4940 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4898 - acc: 1.0000 - val_loss: 2.8735 - val_acc: 0.5000

Epoch 00048: loss improved from 0.50843 to 0.48981, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 49/100

32/54 [================>.............] - ETA: 0s - loss: 0.5131 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.5021 - acc: 0.9815 - val_loss: 2.7355 - val_acc: 0.5714

Epoch 00049: loss did not improve from 0.48981
Epoch 50/100

32/54 [================>.............] - ETA: 0s - loss: 0.4888 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4841 - acc: 1.0000 - val_loss: 2.8373 - val_acc: 0.5714

Epoch 00050: loss improved from 0.48981 to 0.48412, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 51/100

32/54 [================>.............] - ETA: 0s - loss: 0.5269 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5076 - acc: 1.0000 - val_loss: 3.1014 - val_acc: 0.5714

Epoch 00051: loss did not improve from 0.48412
Epoch 52/100

32/54 [================>.............] - ETA: 0s - loss: 0.5066 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.4984 - acc: 0.9815 - val_loss: 2.8836 - val_acc: 0.5000

Epoch 00052: loss did not improve from 0.48412
Epoch 53/100

32/54 [================>.............] - ETA: 0s - loss: 0.4821 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4777 - acc: 1.0000 - val_loss: 2.8896 - val_acc: 0.5000

Epoch 00053: loss improved from 0.48412 to 0.47771, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 54/100

32/54 [================>.............] - ETA: 0s - loss: 0.4978 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.4857 - acc: 0.9815 - val_loss: 2.6646 - val_acc: 0.5000

Epoch 00054: loss did not improve from 0.47771
Epoch 55/100

32/54 [================>.............] - ETA: 0s - loss: 0.4762 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4691 - acc: 1.0000 - val_loss: 2.8924 - val_acc: 0.5000

Epoch 00055: loss improved from 0.47771 to 0.46907, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 56/100

32/54 [================>.............] - ETA: 0s - loss: 0.4856 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.4739 - acc: 1.0000 - val_loss: 2.8405 - val_acc: 0.5000

Epoch 00056: loss did not improve from 0.46907
Epoch 57/100

32/54 [================>.............] - ETA: 0s - loss: 0.5202 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.4970 - acc: 0.9815 - val_loss: 2.7078 - val_acc: 0.5000

Epoch 00057: loss did not improve from 0.46907
Epoch 58/100

32/54 [================>.............] - ETA: 0s - loss: 0.4873 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4681 - acc: 1.0000 - val_loss: 2.9679 - val_acc: 0.5000

Epoch 00058: loss improved from 0.46907 to 0.46812, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 59/100

32/54 [================>.............] - ETA: 0s - loss: 0.5316 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.5034 - acc: 0.9815 - val_loss: 2.9261 - val_acc: 0.5000

Epoch 00059: loss did not improve from 0.46812
Epoch 60/100

32/54 [================>.............] - ETA: 0s - loss: 0.4446 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4440 - acc: 1.0000 - val_loss: 2.8776 - val_acc: 0.5000

Epoch 00060: loss improved from 0.46812 to 0.44400, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 61/100

32/54 [================>.............] - ETA: 0s - loss: 0.4635 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4525 - acc: 1.0000 - val_loss: 2.7191 - val_acc: 0.5000

Epoch 00061: loss did not improve from 0.44400
Epoch 62/100

32/54 [================>.............] - ETA: 0s - loss: 0.4467 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4404 - acc: 1.0000 - val_loss: 2.7662 - val_acc: 0.5000

Epoch 00062: loss improved from 0.44400 to 0.44041, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 63/100

32/54 [================>.............] - ETA: 0s - loss: 0.4532 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4471 - acc: 1.0000 - val_loss: 2.7582 - val_acc: 0.5000

Epoch 00063: loss did not improve from 0.44041
Epoch 64/100

32/54 [================>.............] - ETA: 0s - loss: 0.4561 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4419 - acc: 1.0000 - val_loss: 2.8533 - val_acc: 0.5000

Epoch 00064: loss did not improve from 0.44041
Epoch 65/100

32/54 [================>.............] - ETA: 0s - loss: 0.4478 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4407 - acc: 1.0000 - val_loss: 2.5709 - val_acc: 0.5714

Epoch 00065: loss did not improve from 0.44041
Epoch 66/100

32/54 [================>.............] - ETA: 0s - loss: 0.4279 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4257 - acc: 1.0000 - val_loss: 2.6278 - val_acc: 0.5714

Epoch 00066: loss improved from 0.44041 to 0.42571, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 67/100

32/54 [================>.............] - ETA: 0s - loss: 0.4384 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4312 - acc: 1.0000 - val_loss: 2.8220 - val_acc: 0.5000

Epoch 00067: loss did not improve from 0.42571
Epoch 68/100

32/54 [================>.............] - ETA: 0s - loss: 0.4285 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4217 - acc: 1.0000 - val_loss: 2.8689 - val_acc: 0.5000

Epoch 00068: loss improved from 0.42571 to 0.42173, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 69/100

32/54 [================>.............] - ETA: 0s - loss: 0.4259 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.4170 - acc: 1.0000 - val_loss: 3.0185 - val_acc: 0.5000

Epoch 00069: loss improved from 0.42173 to 0.41703, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 70/100

32/54 [================>.............] - ETA: 0s - loss: 0.4143 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.4092 - acc: 1.0000 - val_loss: 3.0761 - val_acc: 0.5000

Epoch 00070: loss improved from 0.41703 to 0.40920, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 71/100

32/54 [================>.............] - ETA: 0s - loss: 0.4671 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.4433 - acc: 0.9815 - val_loss: 2.6299 - val_acc: 0.5714

Epoch 00071: loss did not improve from 0.40920
Epoch 72/100

32/54 [================>.............] - ETA: 0s - loss: 0.4211 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4104 - acc: 1.0000 - val_loss: 2.8698 - val_acc: 0.5714

Epoch 00072: loss did not improve from 0.40920
Epoch 73/100

32/54 [================>.............] - ETA: 0s - loss: 0.4100 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4040 - acc: 1.0000 - val_loss: 2.8513 - val_acc: 0.5714

Epoch 00073: loss improved from 0.40920 to 0.40402, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 74/100

32/54 [================>.............] - ETA: 0s - loss: 0.4098 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4022 - acc: 1.0000 - val_loss: 2.9595 - val_acc: 0.5714

Epoch 00074: loss improved from 0.40402 to 0.40222, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 75/100

32/54 [================>.............] - ETA: 0s - loss: 0.4242 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.4344 - acc: 0.9815 - val_loss: 4.1907 - val_acc: 0.5000

Epoch 00075: loss did not improve from 0.40222
Epoch 76/100

32/54 [================>.............] - ETA: 0s - loss: 0.6201 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.5423 - acc: 0.9630 - val_loss: 2.8448 - val_acc: 0.5714

Epoch 00076: loss did not improve from 0.40222
Epoch 77/100

32/54 [================>.............] - ETA: 0s - loss: 0.4418 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4300 - acc: 1.0000 - val_loss: 3.1626 - val_acc: 0.5000

Epoch 00077: loss did not improve from 0.40222
Epoch 78/100

32/54 [================>.............] - ETA: 0s - loss: 0.3869 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3933 - acc: 1.0000 - val_loss: 3.0695 - val_acc: 0.5000

Epoch 00078: loss improved from 0.40222 to 0.39329, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 79/100

32/54 [================>.............] - ETA: 0s - loss: 0.3880 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.3911 - acc: 1.0000 - val_loss: 2.9547 - val_acc: 0.5000

Epoch 00079: loss improved from 0.39329 to 0.39112, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 80/100

32/54 [================>.............] - ETA: 0s - loss: 0.4767 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.4398 - acc: 0.9815 - val_loss: 2.7018 - val_acc: 0.5714

Epoch 00080: loss did not improve from 0.39112
Epoch 81/100

32/54 [================>.............] - ETA: 0s - loss: 0.3962 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3899 - acc: 1.0000 - val_loss: 2.8424 - val_acc: 0.5714

Epoch 00081: loss improved from 0.39112 to 0.38987, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 82/100

32/54 [================>.............] - ETA: 0s - loss: 0.3952 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.3895 - acc: 1.0000 - val_loss: 3.0103 - val_acc: 0.5000

Epoch 00082: loss improved from 0.38987 to 0.38948, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 83/100

32/54 [================>.............] - ETA: 0s - loss: 0.3871 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3831 - acc: 1.0000 - val_loss: 2.7924 - val_acc: 0.5714

Epoch 00083: loss improved from 0.38948 to 0.38308, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 84/100

32/54 [================>.............] - ETA: 0s - loss: 0.3709 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3692 - acc: 1.0000 - val_loss: 2.8698 - val_acc: 0.5000

Epoch 00084: loss improved from 0.38308 to 0.36921, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 85/100

32/54 [================>.............] - ETA: 0s - loss: 0.3721 - acc: 1.0000
54/54 [==============================] - 0s 44us/step - loss: 0.3705 - acc: 1.0000 - val_loss: 2.8637 - val_acc: 0.5000

Epoch 00085: loss did not improve from 0.36921
Epoch 86/100

32/54 [================>.............] - ETA: 0s - loss: 0.3683 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3711 - acc: 1.0000 - val_loss: 2.7584 - val_acc: 0.5714

Epoch 00086: loss did not improve from 0.36921
Epoch 87/100

32/54 [================>.............] - ETA: 0s - loss: 0.3857 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3755 - acc: 1.0000 - val_loss: 2.6828 - val_acc: 0.5714

Epoch 00087: loss did not improve from 0.36921
Epoch 88/100

32/54 [================>.............] - ETA: 0s - loss: 0.3752 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3669 - acc: 1.0000 - val_loss: 2.8616 - val_acc: 0.5000

Epoch 00088: loss improved from 0.36921 to 0.36687, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 89/100

32/54 [================>.............] - ETA: 0s - loss: 0.3581 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3554 - acc: 1.0000 - val_loss: 2.9148 - val_acc: 0.5000

Epoch 00089: loss improved from 0.36687 to 0.35538, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 90/100

32/54 [================>.............] - ETA: 0s - loss: 0.3531 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3515 - acc: 1.0000 - val_loss: 2.9256 - val_acc: 0.5000

Epoch 00090: loss improved from 0.35538 to 0.35150, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 91/100

32/54 [================>.............] - ETA: 0s - loss: 0.3529 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.3521 - acc: 1.0000 - val_loss: 2.8897 - val_acc: 0.5000

Epoch 00091: loss did not improve from 0.35150
Epoch 92/100

32/54 [================>.............] - ETA: 0s - loss: 0.3493 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3466 - acc: 1.0000 - val_loss: 2.8472 - val_acc: 0.5000

Epoch 00092: loss improved from 0.35150 to 0.34662, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 93/100

32/54 [================>.............] - ETA: 0s - loss: 0.3410 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.3604 - acc: 1.0000 - val_loss: 2.8151 - val_acc: 0.5000

Epoch 00093: loss did not improve from 0.34662
Epoch 94/100

32/54 [================>.............] - ETA: 0s - loss: 0.3425 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3449 - acc: 1.0000 - val_loss: 2.6773 - val_acc: 0.5000

Epoch 00094: loss improved from 0.34662 to 0.34491, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 95/100

32/54 [================>.............] - ETA: 0s - loss: 0.3369 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3359 - acc: 1.0000 - val_loss: 2.7177 - val_acc: 0.5000

Epoch 00095: loss improved from 0.34491 to 0.33589, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 96/100

32/54 [================>.............] - ETA: 0s - loss: 0.3438 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3389 - acc: 1.0000 - val_loss: 2.8015 - val_acc: 0.5000

Epoch 00096: loss did not improve from 0.33589
Epoch 97/100

32/54 [================>.............] - ETA: 0s - loss: 0.3770 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3568 - acc: 1.0000 - val_loss: 2.8691 - val_acc: 0.5714

Epoch 00097: loss did not improve from 0.33589
Epoch 98/100

32/54 [================>.............] - ETA: 0s - loss: 0.3407 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.3348 - acc: 1.0000 - val_loss: 3.0431 - val_acc: 0.5000

Epoch 00098: loss improved from 0.33589 to 0.33484, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 99/100

32/54 [================>.............] - ETA: 0s - loss: 0.3250 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.3256 - acc: 1.0000 - val_loss: 2.9963 - val_acc: 0.5000

Epoch 00099: loss improved from 0.33484 to 0.32561, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_10.h5
Epoch 100/100

32/54 [================>.............] - ETA: 0s - loss: 0.3326 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.3312 - acc: 1.0000 - val_loss: 2.9449 - val_acc: 0.5000
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:09<00:15,  1.92s/it]
Epoch 00100: loss did not improve from 0.32561
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 3.3667 - acc: 0.5938
54/54 [==============================] - 0s 5ms/step - loss: 3.2030 - acc: 0.6852 - val_loss: 5.0534 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 3.20299, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.7994 - acc: 0.7188
54/54 [==============================] - 0s 48us/step - loss: 1.9038 - acc: 0.7222 - val_loss: 3.5407 - val_acc: 0.5714

Epoch 00002: loss improved from 3.20299 to 1.90380, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.5195 - acc: 0.7500
54/54 [==============================] - 0s 43us/step - loss: 1.5351 - acc: 0.7407 - val_loss: 3.3730 - val_acc: 0.5714

Epoch 00003: loss improved from 1.90380 to 1.53508, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.4594 - acc: 0.7500
54/54 [==============================] - 0s 42us/step - loss: 1.4418 - acc: 0.8148 - val_loss: 3.2226 - val_acc: 0.5714

Epoch 00004: loss improved from 1.53508 to 1.44176, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.3689 - acc: 0.7500
54/54 [==============================] - 0s 42us/step - loss: 1.3663 - acc: 0.7778 - val_loss: 3.2544 - val_acc: 0.5714

Epoch 00005: loss improved from 1.44176 to 1.36633, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.2922 - acc: 0.7812
54/54 [==============================] - 0s 41us/step - loss: 1.2696 - acc: 0.8333 - val_loss: 2.9024 - val_acc: 0.5000

Epoch 00006: loss improved from 1.36633 to 1.26959, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.2844 - acc: 0.8125
54/54 [==============================] - 0s 42us/step - loss: 1.3012 - acc: 0.8148 - val_loss: 3.4992 - val_acc: 0.5714

Epoch 00007: loss did not improve from 1.26959
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.4923 - acc: 0.8125
54/54 [==============================] - 0s 41us/step - loss: 1.4273 - acc: 0.8519 - val_loss: 3.0736 - val_acc: 0.5714

Epoch 00008: loss did not improve from 1.26959
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.3001 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.2806 - acc: 0.8333 - val_loss: 2.8893 - val_acc: 0.5714

Epoch 00009: loss did not improve from 1.26959
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.2319 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.2210 - acc: 0.8519 - val_loss: 2.6465 - val_acc: 0.5000

Epoch 00010: loss improved from 1.26959 to 1.22097, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.1632 - acc: 0.8438
54/54 [==============================] - 0s 42us/step - loss: 1.1485 - acc: 0.8519 - val_loss: 2.7059 - val_acc: 0.5714

Epoch 00011: loss improved from 1.22097 to 1.14850, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.0633 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.0506 - acc: 0.9074 - val_loss: 2.5211 - val_acc: 0.5714

Epoch 00012: loss improved from 1.14850 to 1.05064, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.0210 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.9900 - acc: 0.9259 - val_loss: 2.5176 - val_acc: 0.6429

Epoch 00013: loss improved from 1.05064 to 0.99001, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 1.0297 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 0.9851 - acc: 0.8889 - val_loss: 2.3668 - val_acc: 0.6429

Epoch 00014: loss improved from 0.99001 to 0.98506, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 0.9906 - acc: 0.9062
54/54 [==============================] - 0s 42us/step - loss: 1.0214 - acc: 0.9259 - val_loss: 2.4143 - val_acc: 0.6429

Epoch 00015: loss did not improve from 0.98506
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 1.0663 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.0676 - acc: 0.8889 - val_loss: 2.8383 - val_acc: 0.5714

Epoch 00016: loss did not improve from 0.98506
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 1.1344 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.0220 - acc: 0.9074 - val_loss: 2.5310 - val_acc: 0.6429

Epoch 00017: loss did not improve from 0.98506
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.9545 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.9202 - acc: 0.9259 - val_loss: 2.4785 - val_acc: 0.5714

Epoch 00018: loss improved from 0.98506 to 0.92017, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.9348 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.9158 - acc: 0.9444 - val_loss: 2.3188 - val_acc: 0.5714

Epoch 00019: loss improved from 0.92017 to 0.91579, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.8906 - acc: 0.9062
54/54 [==============================] - 0s 42us/step - loss: 0.8826 - acc: 0.9444 - val_loss: 2.7986 - val_acc: 0.5714

Epoch 00020: loss improved from 0.91579 to 0.88260, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 0.9060 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.8558 - acc: 0.9630 - val_loss: 2.4048 - val_acc: 0.5714

Epoch 00021: loss improved from 0.88260 to 0.85578, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.8733 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.8172 - acc: 0.9630 - val_loss: 2.2932 - val_acc: 0.5714

Epoch 00022: loss improved from 0.85578 to 0.81717, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.8601 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.8490 - acc: 0.9630 - val_loss: 2.1923 - val_acc: 0.5000

Epoch 00023: loss did not improve from 0.81717
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.8661 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.8110 - acc: 0.9815 - val_loss: 2.6288 - val_acc: 0.6429

Epoch 00024: loss improved from 0.81717 to 0.81102, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 0.9320 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 0.8606 - acc: 0.9259 - val_loss: 2.4410 - val_acc: 0.6429

Epoch 00025: loss did not improve from 0.81102
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.8574 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.8160 - acc: 0.9444 - val_loss: 2.4528 - val_acc: 0.5714

Epoch 00026: loss did not improve from 0.81102
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.7863 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.7514 - acc: 0.9815 - val_loss: 2.3724 - val_acc: 0.5714

Epoch 00027: loss improved from 0.81102 to 0.75144, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.7982 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.7523 - acc: 0.9815 - val_loss: 2.3259 - val_acc: 0.5714

Epoch 00028: loss did not improve from 0.75144
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 0.7512 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7344 - acc: 0.9815 - val_loss: 2.3017 - val_acc: 0.5714

Epoch 00029: loss improved from 0.75144 to 0.73443, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 0.7376 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7133 - acc: 0.9630 - val_loss: 2.3773 - val_acc: 0.5714

Epoch 00030: loss improved from 0.73443 to 0.71335, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 0.6962 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.6825 - acc: 1.0000 - val_loss: 2.3559 - val_acc: 0.5714

Epoch 00031: loss improved from 0.71335 to 0.68253, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 32/100

32/54 [================>.............] - ETA: 0s - loss: 0.6670 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.6538 - acc: 1.0000 - val_loss: 2.4444 - val_acc: 0.5714

Epoch 00032: loss improved from 0.68253 to 0.65380, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 33/100

32/54 [================>.............] - ETA: 0s - loss: 0.7084 - acc: 0.9688
54/54 [==============================] - 0s 42us/step - loss: 0.7049 - acc: 0.9815 - val_loss: 2.5040 - val_acc: 0.5714

Epoch 00033: loss did not improve from 0.65380
Epoch 34/100

32/54 [================>.............] - ETA: 0s - loss: 0.6782 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6590 - acc: 1.0000 - val_loss: 2.5521 - val_acc: 0.5714

Epoch 00034: loss did not improve from 0.65380
Epoch 35/100

32/54 [================>.............] - ETA: 0s - loss: 0.6569 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6564 - acc: 1.0000 - val_loss: 2.4895 - val_acc: 0.5714

Epoch 00035: loss did not improve from 0.65380
Epoch 36/100

32/54 [================>.............] - ETA: 0s - loss: 0.6675 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6482 - acc: 0.9815 - val_loss: 2.3801 - val_acc: 0.5714

Epoch 00036: loss improved from 0.65380 to 0.64821, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 37/100

32/54 [================>.............] - ETA: 0s - loss: 0.6279 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.6236 - acc: 1.0000 - val_loss: 2.4280 - val_acc: 0.5714

Epoch 00037: loss improved from 0.64821 to 0.62365, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 38/100

32/54 [================>.............] - ETA: 0s - loss: 0.6352 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.6503 - acc: 1.0000 - val_loss: 2.2427 - val_acc: 0.5714

Epoch 00038: loss did not improve from 0.62365
Epoch 39/100

32/54 [================>.............] - ETA: 0s - loss: 0.7224 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.6765 - acc: 0.9630 - val_loss: 2.4273 - val_acc: 0.5714

Epoch 00039: loss did not improve from 0.62365
Epoch 40/100

32/54 [================>.............] - ETA: 0s - loss: 0.6264 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6244 - acc: 1.0000 - val_loss: 2.3081 - val_acc: 0.5000

Epoch 00040: loss did not improve from 0.62365
Epoch 41/100

32/54 [================>.............] - ETA: 0s - loss: 0.6462 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6287 - acc: 1.0000 - val_loss: 2.2797 - val_acc: 0.5714

Epoch 00041: loss did not improve from 0.62365
Epoch 42/100

32/54 [================>.............] - ETA: 0s - loss: 0.6094 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6060 - acc: 1.0000 - val_loss: 2.4157 - val_acc: 0.5714

Epoch 00042: loss improved from 0.62365 to 0.60600, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 43/100

32/54 [================>.............] - ETA: 0s - loss: 0.6385 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6319 - acc: 0.9815 - val_loss: 2.2103 - val_acc: 0.5000

Epoch 00043: loss did not improve from 0.60600
Epoch 44/100

32/54 [================>.............] - ETA: 0s - loss: 0.5889 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5836 - acc: 1.0000 - val_loss: 2.3757 - val_acc: 0.5714

Epoch 00044: loss improved from 0.60600 to 0.58360, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 45/100

32/54 [================>.............] - ETA: 0s - loss: 0.5850 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5800 - acc: 1.0000 - val_loss: 2.3001 - val_acc: 0.5714

Epoch 00045: loss improved from 0.58360 to 0.58001, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 46/100

32/54 [================>.............] - ETA: 0s - loss: 0.5788 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5727 - acc: 1.0000 - val_loss: 2.4189 - val_acc: 0.5714

Epoch 00046: loss improved from 0.58001 to 0.57273, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 47/100

32/54 [================>.............] - ETA: 0s - loss: 0.5963 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.5797 - acc: 0.9815 - val_loss: 2.4087 - val_acc: 0.5714

Epoch 00047: loss did not improve from 0.57273
Epoch 48/100

32/54 [================>.............] - ETA: 0s - loss: 0.5558 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5624 - acc: 1.0000 - val_loss: 2.2224 - val_acc: 0.6429

Epoch 00048: loss improved from 0.57273 to 0.56244, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 49/100

32/54 [================>.............] - ETA: 0s - loss: 0.5638 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.5552 - acc: 1.0000 - val_loss: 2.5581 - val_acc: 0.5714

Epoch 00049: loss improved from 0.56244 to 0.55516, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 50/100

32/54 [================>.............] - ETA: 0s - loss: 0.6087 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.5901 - acc: 0.9630 - val_loss: 2.2727 - val_acc: 0.6429

Epoch 00050: loss did not improve from 0.55516
Epoch 51/100

32/54 [================>.............] - ETA: 0s - loss: 0.5681 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5583 - acc: 1.0000 - val_loss: 2.4912 - val_acc: 0.5714

Epoch 00051: loss did not improve from 0.55516
Epoch 52/100

32/54 [================>.............] - ETA: 0s - loss: 0.5544 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5512 - acc: 1.0000 - val_loss: 2.5888 - val_acc: 0.5714

Epoch 00052: loss improved from 0.55516 to 0.55121, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 53/100

32/54 [================>.............] - ETA: 0s - loss: 0.5387 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5394 - acc: 1.0000 - val_loss: 2.6526 - val_acc: 0.5714

Epoch 00053: loss improved from 0.55121 to 0.53939, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 54/100

32/54 [================>.............] - ETA: 0s - loss: 0.5397 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5423 - acc: 1.0000 - val_loss: 2.4710 - val_acc: 0.6429

Epoch 00054: loss did not improve from 0.53939
Epoch 55/100

32/54 [================>.............] - ETA: 0s - loss: 0.5368 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5293 - acc: 1.0000 - val_loss: 2.4653 - val_acc: 0.6429

Epoch 00055: loss improved from 0.53939 to 0.52926, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 56/100

32/54 [================>.............] - ETA: 0s - loss: 0.5585 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.5404 - acc: 0.9815 - val_loss: 2.4447 - val_acc: 0.6429

Epoch 00056: loss did not improve from 0.52926
Epoch 57/100

32/54 [================>.............] - ETA: 0s - loss: 0.5216 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5179 - acc: 1.0000 - val_loss: 2.4770 - val_acc: 0.6429

Epoch 00057: loss improved from 0.52926 to 0.51788, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 58/100

32/54 [================>.............] - ETA: 0s - loss: 0.5193 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5280 - acc: 1.0000 - val_loss: 2.3042 - val_acc: 0.6429

Epoch 00058: loss did not improve from 0.51788
Epoch 59/100

32/54 [================>.............] - ETA: 0s - loss: 0.5326 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5225 - acc: 1.0000 - val_loss: 2.5125 - val_acc: 0.5714

Epoch 00059: loss did not improve from 0.51788
Epoch 60/100

32/54 [================>.............] - ETA: 0s - loss: 0.5717 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.5519 - acc: 0.9815 - val_loss: 2.5316 - val_acc: 0.5714

Epoch 00060: loss did not improve from 0.51788
Epoch 61/100

32/54 [================>.............] - ETA: 0s - loss: 0.5180 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5151 - acc: 1.0000 - val_loss: 2.3252 - val_acc: 0.6429

Epoch 00061: loss improved from 0.51788 to 0.51512, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 62/100

32/54 [================>.............] - ETA: 0s - loss: 0.5059 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4983 - acc: 1.0000 - val_loss: 2.6150 - val_acc: 0.5714

Epoch 00062: loss improved from 0.51512 to 0.49833, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 63/100

32/54 [================>.............] - ETA: 0s - loss: 0.4899 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4965 - acc: 1.0000 - val_loss: 2.4437 - val_acc: 0.6429

Epoch 00063: loss improved from 0.49833 to 0.49652, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 64/100

32/54 [================>.............] - ETA: 0s - loss: 0.5161 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5083 - acc: 1.0000 - val_loss: 2.4257 - val_acc: 0.6429

Epoch 00064: loss did not improve from 0.49652
Epoch 65/100

32/54 [================>.............] - ETA: 0s - loss: 0.5034 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4984 - acc: 1.0000 - val_loss: 2.7403 - val_acc: 0.5714

Epoch 00065: loss did not improve from 0.49652
Epoch 66/100

32/54 [================>.............] - ETA: 0s - loss: 0.4815 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4801 - acc: 1.0000 - val_loss: 2.7883 - val_acc: 0.5714

Epoch 00066: loss improved from 0.49652 to 0.48006, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 67/100

32/54 [================>.............] - ETA: 0s - loss: 0.4938 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4842 - acc: 1.0000 - val_loss: 2.6867 - val_acc: 0.6429

Epoch 00067: loss did not improve from 0.48006
Epoch 68/100

32/54 [================>.............] - ETA: 0s - loss: 0.5004 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4914 - acc: 1.0000 - val_loss: 2.7203 - val_acc: 0.6429

Epoch 00068: loss did not improve from 0.48006
Epoch 69/100

32/54 [================>.............] - ETA: 0s - loss: 0.4703 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4726 - acc: 1.0000 - val_loss: 2.6361 - val_acc: 0.6429

Epoch 00069: loss improved from 0.48006 to 0.47256, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 70/100

32/54 [================>.............] - ETA: 0s - loss: 0.4649 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4635 - acc: 1.0000 - val_loss: 2.7038 - val_acc: 0.6429

Epoch 00070: loss improved from 0.47256 to 0.46345, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 71/100

32/54 [================>.............] - ETA: 0s - loss: 0.4833 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4711 - acc: 1.0000 - val_loss: 2.6966 - val_acc: 0.6429

Epoch 00071: loss did not improve from 0.46345
Epoch 72/100

32/54 [================>.............] - ETA: 0s - loss: 0.4593 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4557 - acc: 1.0000 - val_loss: 2.7617 - val_acc: 0.6429

Epoch 00072: loss improved from 0.46345 to 0.45567, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 73/100

32/54 [================>.............] - ETA: 0s - loss: 0.4641 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4616 - acc: 1.0000 - val_loss: 2.4441 - val_acc: 0.6429

Epoch 00073: loss did not improve from 0.45567
Epoch 74/100

32/54 [================>.............] - ETA: 0s - loss: 0.4539 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4607 - acc: 1.0000 - val_loss: 2.7643 - val_acc: 0.6429

Epoch 00074: loss did not improve from 0.45567
Epoch 75/100

32/54 [================>.............] - ETA: 0s - loss: 0.4472 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4432 - acc: 1.0000 - val_loss: 2.7960 - val_acc: 0.6429

Epoch 00075: loss improved from 0.45567 to 0.44318, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 76/100

32/54 [================>.............] - ETA: 0s - loss: 0.4521 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4497 - acc: 1.0000 - val_loss: 2.7597 - val_acc: 0.6429

Epoch 00076: loss did not improve from 0.44318
Epoch 77/100

32/54 [================>.............] - ETA: 0s - loss: 0.4490 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.4420 - acc: 1.0000 - val_loss: 2.8016 - val_acc: 0.6429

Epoch 00077: loss improved from 0.44318 to 0.44202, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 78/100

32/54 [================>.............] - ETA: 0s - loss: 0.4808 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.4632 - acc: 0.9815 - val_loss: 2.4588 - val_acc: 0.5714

Epoch 00078: loss did not improve from 0.44202
Epoch 79/100

32/54 [================>.............] - ETA: 0s - loss: 0.4351 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4312 - acc: 1.0000 - val_loss: 2.5798 - val_acc: 0.6429

Epoch 00079: loss improved from 0.44202 to 0.43117, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_11.h5
Epoch 80/100

32/54 [================>.............] - ETA: 0s - loss: 0.4360 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4321 - acc: 1.0000 - val_loss: 2.6978 - val_acc: 0.6429

Epoch 00080: loss did not improve from 0.43117
Epoch 81/100

32/54 [================>.............] - ETA: 0s - loss: 0.4423 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5790 - acc: 1.0000 - val_loss: 2.1185 - val_acc: 0.3571

Epoch 00081: loss did not improve from 0.43117
Epoch 82/100

32/54 [================>.............] - ETA: 0s - loss: 1.2137 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 1.7209 - acc: 0.8889 - val_loss: 5.2600 - val_acc: 0.5714

Epoch 00082: loss did not improve from 0.43117
Epoch 83/100

32/54 [================>.............] - ETA: 0s - loss: 1.0624 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 0.9323 - acc: 0.9074 - val_loss: 4.6669 - val_acc: 0.6429

Epoch 00083: loss did not improve from 0.43117
Epoch 84/100

32/54 [================>.............] - ETA: 0s - loss: 0.9184 - acc: 0.7812
54/54 [==============================] - 0s 40us/step - loss: 0.8031 - acc: 0.8519 - val_loss: 4.3601 - val_acc: 0.6429
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:11<00:13,  1.96s/it]
Epoch 00084: loss did not improve from 0.43117
Epoch 00084: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 3.2181 - acc: 0.5625
54/54 [==============================] - 0s 5ms/step - loss: 2.9043 - acc: 0.6481 - val_loss: 4.7338 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 2.90434, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.6518 - acc: 0.6875
54/54 [==============================] - 0s 48us/step - loss: 1.6683 - acc: 0.7407 - val_loss: 3.6077 - val_acc: 0.5714

Epoch 00002: loss improved from 2.90434 to 1.66830, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.4334 - acc: 0.7500
54/54 [==============================] - 0s 43us/step - loss: 1.6982 - acc: 0.7593 - val_loss: 3.8171 - val_acc: 0.5714

Epoch 00003: loss did not improve from 1.66830
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.4682 - acc: 0.7500
54/54 [==============================] - 0s 40us/step - loss: 1.4570 - acc: 0.7778 - val_loss: 3.4739 - val_acc: 0.5714

Epoch 00004: loss improved from 1.66830 to 1.45701, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.4927 - acc: 0.7500
54/54 [==============================] - 0s 41us/step - loss: 1.4762 - acc: 0.7778 - val_loss: 3.2967 - val_acc: 0.5714

Epoch 00005: loss did not improve from 1.45701
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.2833 - acc: 0.8125
54/54 [==============================] - 0s 39us/step - loss: 1.2495 - acc: 0.8148 - val_loss: 3.1623 - val_acc: 0.5714

Epoch 00006: loss improved from 1.45701 to 1.24950, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.3230 - acc: 0.7812
54/54 [==============================] - 0s 41us/step - loss: 1.3366 - acc: 0.8519 - val_loss: 3.1042 - val_acc: 0.5714

Epoch 00007: loss did not improve from 1.24950
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.2108 - acc: 0.7812
54/54 [==============================] - 0s 39us/step - loss: 1.2300 - acc: 0.8148 - val_loss: 2.9951 - val_acc: 0.5714

Epoch 00008: loss improved from 1.24950 to 1.22996, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.2013 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 1.1867 - acc: 0.8889 - val_loss: 2.7593 - val_acc: 0.5714

Epoch 00009: loss improved from 1.22996 to 1.18675, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.0352 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 1.0878 - acc: 0.9444 - val_loss: 2.8400 - val_acc: 0.5714

Epoch 00010: loss improved from 1.18675 to 1.08778, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.0723 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.1168 - acc: 0.8889 - val_loss: 2.8711 - val_acc: 0.5714

Epoch 00011: loss did not improve from 1.08778
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.0925 - acc: 0.8750
54/54 [==============================] - 0s 39us/step - loss: 1.0467 - acc: 0.8704 - val_loss: 2.8407 - val_acc: 0.5714

Epoch 00012: loss improved from 1.08778 to 1.04670, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.0267 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 1.0115 - acc: 0.9444 - val_loss: 2.7745 - val_acc: 0.5714

Epoch 00013: loss improved from 1.04670 to 1.01151, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 1.0545 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 0.9873 - acc: 0.9259 - val_loss: 2.5565 - val_acc: 0.5714

Epoch 00014: loss improved from 1.01151 to 0.98727, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 1.0203 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 1.0461 - acc: 0.9444 - val_loss: 2.4961 - val_acc: 0.5000

Epoch 00015: loss did not improve from 0.98727
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 0.9195 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.9298 - acc: 0.9259 - val_loss: 2.5977 - val_acc: 0.5000

Epoch 00016: loss improved from 0.98727 to 0.92981, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 0.9917 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.9468 - acc: 0.9444 - val_loss: 2.6015 - val_acc: 0.5000

Epoch 00017: loss did not improve from 0.92981
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 1.0066 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 0.9620 - acc: 0.9259 - val_loss: 2.6217 - val_acc: 0.5000

Epoch 00018: loss did not improve from 0.92981
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.9782 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 0.9936 - acc: 0.9259 - val_loss: 2.8147 - val_acc: 0.5000

Epoch 00019: loss did not improve from 0.92981
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.9699 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 0.9259 - acc: 0.9259 - val_loss: 2.3882 - val_acc: 0.5000

Epoch 00020: loss improved from 0.92981 to 0.92594, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 0.8245 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.8216 - acc: 0.9630 - val_loss: 2.5448 - val_acc: 0.5000

Epoch 00021: loss improved from 0.92594 to 0.82162, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.7397 - acc: 1.0000
54/54 [==============================] - 0s 43us/step - loss: 0.7546 - acc: 1.0000 - val_loss: 2.5502 - val_acc: 0.5000

Epoch 00022: loss improved from 0.82162 to 0.75458, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_12.h5
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.7676 - acc: 1.0000
54/54 [==============================] - 0s 43us/step - loss: 0.7613 - acc: 0.9815 - val_loss: 2.7922 - val_acc: 0.5000

Epoch 00023: loss did not improve from 0.75458
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.7707 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7816 - acc: 0.9630 - val_loss: 2.7437 - val_acc: 0.5000

Epoch 00024: loss did not improve from 0.75458
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 0.8388 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.8053 - acc: 0.9630 - val_loss: 2.5686 - val_acc: 0.5000

Epoch 00025: loss did not improve from 0.75458
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.8043 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.7971 - acc: 0.9444 - val_loss: 2.5072 - val_acc: 0.5000

Epoch 00026: loss did not improve from 0.75458
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.7433 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.7634 - acc: 0.9815 - val_loss: 2.5923 - val_acc: 0.5000
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:12<00:11,  1.86s/it]
Epoch 00027: loss did not improve from 0.75458
Epoch 00027: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 3.2817 - acc: 0.5625
54/54 [==============================] - 0s 5ms/step - loss: 3.0197 - acc: 0.6481 - val_loss: 4.4575 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 3.01972, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.5526 - acc: 0.7188
54/54 [==============================] - 0s 50us/step - loss: 1.5215 - acc: 0.7407 - val_loss: 3.5795 - val_acc: 0.5714

Epoch 00002: loss improved from 3.01972 to 1.52151, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.6172 - acc: 0.7188
54/54 [==============================] - 0s 43us/step - loss: 1.6080 - acc: 0.7593 - val_loss: 3.2839 - val_acc: 0.5714

Epoch 00003: loss did not improve from 1.52151
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.5168 - acc: 0.7500
54/54 [==============================] - 0s 41us/step - loss: 1.4437 - acc: 0.7593 - val_loss: 3.1073 - val_acc: 0.5714

Epoch 00004: loss improved from 1.52151 to 1.44368, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.2978 - acc: 0.7812
54/54 [==============================] - 0s 42us/step - loss: 1.3643 - acc: 0.7963 - val_loss: 2.9435 - val_acc: 0.5714

Epoch 00005: loss improved from 1.44368 to 1.36428, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.2630 - acc: 0.7812
54/54 [==============================] - 0s 42us/step - loss: 1.2811 - acc: 0.8148 - val_loss: 2.7334 - val_acc: 0.5714

Epoch 00006: loss improved from 1.36428 to 1.28113, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.3127 - acc: 0.8125
54/54 [==============================] - 0s 42us/step - loss: 1.3111 - acc: 0.8148 - val_loss: 2.7236 - val_acc: 0.5714

Epoch 00007: loss did not improve from 1.28113
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.0861 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 1.1761 - acc: 0.8704 - val_loss: 2.9339 - val_acc: 0.5714

Epoch 00008: loss improved from 1.28113 to 1.17608, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.4288 - acc: 0.8125
54/54 [==============================] - 0s 41us/step - loss: 1.3624 - acc: 0.8148 - val_loss: 2.6686 - val_acc: 0.5714

Epoch 00009: loss did not improve from 1.17608
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.2731 - acc: 0.8438
54/54 [==============================] - 0s 40us/step - loss: 1.1947 - acc: 0.8889 - val_loss: 2.6666 - val_acc: 0.5714

Epoch 00010: loss did not improve from 1.17608
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.2110 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.1200 - acc: 0.9074 - val_loss: 2.5284 - val_acc: 0.5714

Epoch 00011: loss improved from 1.17608 to 1.12004, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.2044 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.1194 - acc: 0.8889 - val_loss: 2.5842 - val_acc: 0.6429

Epoch 00012: loss improved from 1.12004 to 1.11939, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.0670 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 1.0964 - acc: 0.9259 - val_loss: 2.9646 - val_acc: 0.5714

Epoch 00013: loss improved from 1.11939 to 1.09643, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 1.0588 - acc: 0.9062
54/54 [==============================] - 0s 42us/step - loss: 1.1717 - acc: 0.9444 - val_loss: 2.1348 - val_acc: 0.5000

Epoch 00014: loss did not improve from 1.09643
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 1.1141 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.0586 - acc: 0.9259 - val_loss: 3.1134 - val_acc: 0.5714

Epoch 00015: loss improved from 1.09643 to 1.05863, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 1.1834 - acc: 0.8125
54/54 [==============================] - 0s 42us/step - loss: 1.0960 - acc: 0.8519 - val_loss: 2.7370 - val_acc: 0.5714

Epoch 00016: loss did not improve from 1.05863
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 1.0628 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.9748 - acc: 0.9444 - val_loss: 2.5294 - val_acc: 0.5714

Epoch 00017: loss improved from 1.05863 to 0.97482, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.9497 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.9245 - acc: 0.9074 - val_loss: 2.3886 - val_acc: 0.5714

Epoch 00018: loss improved from 0.97482 to 0.92447, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.8997 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8511 - acc: 0.9259 - val_loss: 2.5065 - val_acc: 0.5714

Epoch 00019: loss improved from 0.92447 to 0.85114, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.9020 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.8982 - acc: 0.9630 - val_loss: 3.1491 - val_acc: 0.6429

Epoch 00020: loss did not improve from 0.85114
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 1.2230 - acc: 0.8438
54/54 [==============================] - 0s 40us/step - loss: 1.0479 - acc: 0.9074 - val_loss: 2.2943 - val_acc: 0.5714

Epoch 00021: loss did not improve from 0.85114
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.9715 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8797 - acc: 0.9444 - val_loss: 2.6765 - val_acc: 0.5714

Epoch 00022: loss did not improve from 0.85114
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.9226 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.8603 - acc: 0.9630 - val_loss: 2.4922 - val_acc: 0.5714

Epoch 00023: loss did not improve from 0.85114
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.8627 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7956 - acc: 0.9630 - val_loss: 2.5288 - val_acc: 0.5714

Epoch 00024: loss improved from 0.85114 to 0.79561, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 0.7792 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7537 - acc: 0.9630 - val_loss: 2.5092 - val_acc: 0.5714

Epoch 00025: loss improved from 0.79561 to 0.75368, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.7346 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.7332 - acc: 1.0000 - val_loss: 2.5129 - val_acc: 0.5714

Epoch 00026: loss improved from 0.75368 to 0.73320, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.7016 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.7066 - acc: 1.0000 - val_loss: 2.6238 - val_acc: 0.5714

Epoch 00027: loss improved from 0.73320 to 0.70660, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.7340 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7198 - acc: 0.9630 - val_loss: 2.3017 - val_acc: 0.5714

Epoch 00028: loss did not improve from 0.70660
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 0.7290 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.7108 - acc: 1.0000 - val_loss: 2.4977 - val_acc: 0.5714

Epoch 00029: loss did not improve from 0.70660
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 0.6683 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6962 - acc: 0.9815 - val_loss: 2.4250 - val_acc: 0.6429

Epoch 00030: loss improved from 0.70660 to 0.69618, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 0.7738 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7722 - acc: 0.9630 - val_loss: 2.2377 - val_acc: 0.6429

Epoch 00031: loss did not improve from 0.69618
Epoch 32/100

32/54 [================>.............] - ETA: 0s - loss: 0.7129 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.7097 - acc: 0.9815 - val_loss: 2.3551 - val_acc: 0.5714

Epoch 00032: loss did not improve from 0.69618
Epoch 33/100

32/54 [================>.............] - ETA: 0s - loss: 0.7667 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7225 - acc: 0.9630 - val_loss: 2.9090 - val_acc: 0.6429

Epoch 00033: loss did not improve from 0.69618
Epoch 34/100

32/54 [================>.............] - ETA: 0s - loss: 0.6551 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.6767 - acc: 1.0000 - val_loss: 2.5737 - val_acc: 0.6429

Epoch 00034: loss improved from 0.69618 to 0.67669, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 35/100

32/54 [================>.............] - ETA: 0s - loss: 0.7616 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7337 - acc: 0.9630 - val_loss: 2.4427 - val_acc: 0.6429

Epoch 00035: loss did not improve from 0.67669
Epoch 36/100

32/54 [================>.............] - ETA: 0s - loss: 0.7304 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6929 - acc: 0.9815 - val_loss: 2.6046 - val_acc: 0.6429

Epoch 00036: loss did not improve from 0.67669
Epoch 37/100

32/54 [================>.............] - ETA: 0s - loss: 0.6608 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6515 - acc: 0.9815 - val_loss: 2.5400 - val_acc: 0.6429

Epoch 00037: loss improved from 0.67669 to 0.65146, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 38/100

32/54 [================>.............] - ETA: 0s - loss: 0.6347 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6246 - acc: 1.0000 - val_loss: 2.6141 - val_acc: 0.6429

Epoch 00038: loss improved from 0.65146 to 0.62464, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 39/100

32/54 [================>.............] - ETA: 0s - loss: 0.6373 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6345 - acc: 1.0000 - val_loss: 2.7466 - val_acc: 0.6429

Epoch 00039: loss did not improve from 0.62464
Epoch 40/100

32/54 [================>.............] - ETA: 0s - loss: 0.6332 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6196 - acc: 1.0000 - val_loss: 2.5424 - val_acc: 0.6429

Epoch 00040: loss improved from 0.62464 to 0.61961, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 41/100

32/54 [================>.............] - ETA: 0s - loss: 0.6053 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6022 - acc: 1.0000 - val_loss: 2.5297 - val_acc: 0.6429

Epoch 00041: loss improved from 0.61961 to 0.60219, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 42/100

32/54 [================>.............] - ETA: 0s - loss: 0.6185 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6020 - acc: 0.9815 - val_loss: 2.5120 - val_acc: 0.6429

Epoch 00042: loss improved from 0.60219 to 0.60200, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 43/100

32/54 [================>.............] - ETA: 0s - loss: 0.6078 - acc: 1.0000
54/54 [==============================] - 0s 42us/step - loss: 0.6000 - acc: 1.0000 - val_loss: 2.4509 - val_acc: 0.6429

Epoch 00043: loss improved from 0.60200 to 0.60001, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 44/100

32/54 [================>.............] - ETA: 0s - loss: 0.6080 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6009 - acc: 0.9815 - val_loss: 2.3765 - val_acc: 0.6429

Epoch 00044: loss did not improve from 0.60001
Epoch 45/100

32/54 [================>.............] - ETA: 0s - loss: 0.5983 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5864 - acc: 1.0000 - val_loss: 2.4807 - val_acc: 0.6429

Epoch 00045: loss improved from 0.60001 to 0.58643, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 46/100

32/54 [================>.............] - ETA: 0s - loss: 0.5803 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5769 - acc: 1.0000 - val_loss: 2.5837 - val_acc: 0.6429

Epoch 00046: loss improved from 0.58643 to 0.57688, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 47/100

32/54 [================>.............] - ETA: 0s - loss: 0.5888 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5857 - acc: 1.0000 - val_loss: 2.4322 - val_acc: 0.6429

Epoch 00047: loss did not improve from 0.57688
Epoch 48/100

32/54 [================>.............] - ETA: 0s - loss: 0.5923 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5778 - acc: 1.0000 - val_loss: 2.5760 - val_acc: 0.6429

Epoch 00048: loss did not improve from 0.57688
Epoch 49/100

32/54 [================>.............] - ETA: 0s - loss: 0.6086 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.5864 - acc: 0.9815 - val_loss: 2.3786 - val_acc: 0.6429

Epoch 00049: loss did not improve from 0.57688
Epoch 50/100

32/54 [================>.............] - ETA: 0s - loss: 0.6178 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.5911 - acc: 0.9815 - val_loss: 2.5347 - val_acc: 0.6429

Epoch 00050: loss did not improve from 0.57688
Epoch 51/100

32/54 [================>.............] - ETA: 0s - loss: 0.5512 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5506 - acc: 1.0000 - val_loss: 2.5875 - val_acc: 0.6429

Epoch 00051: loss improved from 0.57688 to 0.55057, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 52/100

32/54 [================>.............] - ETA: 0s - loss: 0.5962 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.5838 - acc: 0.9815 - val_loss: 2.5334 - val_acc: 0.6429

Epoch 00052: loss did not improve from 0.55057
Epoch 53/100

32/54 [================>.............] - ETA: 0s - loss: 0.5480 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5426 - acc: 1.0000 - val_loss: 2.6538 - val_acc: 0.6429

Epoch 00053: loss improved from 0.55057 to 0.54262, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 54/100

32/54 [================>.............] - ETA: 0s - loss: 0.5437 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5416 - acc: 1.0000 - val_loss: 2.3502 - val_acc: 0.5714

Epoch 00054: loss improved from 0.54262 to 0.54163, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 55/100

32/54 [================>.............] - ETA: 0s - loss: 0.5499 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5446 - acc: 1.0000 - val_loss: 2.5298 - val_acc: 0.6429

Epoch 00055: loss did not improve from 0.54163
Epoch 56/100

32/54 [================>.............] - ETA: 0s - loss: 0.5272 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5264 - acc: 1.0000 - val_loss: 2.5104 - val_acc: 0.6429

Epoch 00056: loss improved from 0.54163 to 0.52640, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 57/100

32/54 [================>.............] - ETA: 0s - loss: 0.5706 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5483 - acc: 1.0000 - val_loss: 2.6933 - val_acc: 0.6429

Epoch 00057: loss did not improve from 0.52640
Epoch 58/100

32/54 [================>.............] - ETA: 0s - loss: 0.5149 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5138 - acc: 1.0000 - val_loss: 2.7824 - val_acc: 0.6429

Epoch 00058: loss improved from 0.52640 to 0.51380, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 59/100

32/54 [================>.............] - ETA: 0s - loss: 0.5279 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5325 - acc: 1.0000 - val_loss: 2.5906 - val_acc: 0.6429

Epoch 00059: loss did not improve from 0.51380
Epoch 60/100

32/54 [================>.............] - ETA: 0s - loss: 0.5416 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5315 - acc: 1.0000 - val_loss: 2.7171 - val_acc: 0.6429

Epoch 00060: loss did not improve from 0.51380
Epoch 61/100

32/54 [================>.............] - ETA: 0s - loss: 0.5201 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5224 - acc: 1.0000 - val_loss: 2.6773 - val_acc: 0.6429

Epoch 00061: loss did not improve from 0.51380
Epoch 62/100

32/54 [================>.............] - ETA: 0s - loss: 0.5308 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5202 - acc: 1.0000 - val_loss: 2.6281 - val_acc: 0.6429

Epoch 00062: loss did not improve from 0.51380
Epoch 63/100

32/54 [================>.............] - ETA: 0s - loss: 0.5167 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5111 - acc: 1.0000 - val_loss: 2.6678 - val_acc: 0.6429

Epoch 00063: loss improved from 0.51380 to 0.51112, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 64/100

32/54 [================>.............] - ETA: 0s - loss: 0.4961 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4931 - acc: 1.0000 - val_loss: 2.6449 - val_acc: 0.6429

Epoch 00064: loss improved from 0.51112 to 0.49305, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 65/100

32/54 [================>.............] - ETA: 0s - loss: 0.4879 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.4892 - acc: 1.0000 - val_loss: 2.6385 - val_acc: 0.6429

Epoch 00065: loss improved from 0.49305 to 0.48922, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_13.h5
Epoch 66/100

32/54 [================>.............] - ETA: 0s - loss: 0.4997 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.4909 - acc: 1.0000 - val_loss: 2.8928 - val_acc: 0.6429

Epoch 00066: loss did not improve from 0.48922
Epoch 67/100

32/54 [================>.............] - ETA: 0s - loss: 0.5350 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.5156 - acc: 0.9815 - val_loss: 2.5465 - val_acc: 0.5714

Epoch 00067: loss did not improve from 0.48922
Epoch 68/100

32/54 [================>.............] - ETA: 0s - loss: 0.5502 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5371 - acc: 1.0000 - val_loss: 2.7994 - val_acc: 0.6429

Epoch 00068: loss did not improve from 0.48922
Epoch 69/100

32/54 [================>.............] - ETA: 0s - loss: 0.6204 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.6371 - acc: 0.9630 - val_loss: 5.0029 - val_acc: 0.5714

Epoch 00069: loss did not improve from 0.48922
Epoch 70/100

32/54 [================>.............] - ETA: 0s - loss: 1.1127 - acc: 0.8438
54/54 [==============================] - 0s 39us/step - loss: 0.8838 - acc: 0.8889 - val_loss: 4.0149 - val_acc: 0.6429
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:14<00:09,  1.84s/it]
Epoch 00070: loss did not improve from 0.48922
Epoch 00070: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 3.4880 - acc: 0.6562
54/54 [==============================] - 0s 5ms/step - loss: 3.1230 - acc: 0.7037 - val_loss: 4.7120 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 3.12303, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.5578 - acc: 0.6875
54/54 [==============================] - 0s 48us/step - loss: 1.8352 - acc: 0.6852 - val_loss: 3.9927 - val_acc: 0.5714

Epoch 00002: loss improved from 3.12303 to 1.83519, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.6362 - acc: 0.6875
54/54 [==============================] - 0s 43us/step - loss: 1.6648 - acc: 0.7407 - val_loss: 3.6898 - val_acc: 0.5714

Epoch 00003: loss improved from 1.83519 to 1.66483, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.5230 - acc: 0.7500
54/54 [==============================] - 0s 41us/step - loss: 1.6046 - acc: 0.7407 - val_loss: 3.4452 - val_acc: 0.5714

Epoch 00004: loss improved from 1.66483 to 1.60455, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.5146 - acc: 0.7188
54/54 [==============================] - 0s 42us/step - loss: 1.6035 - acc: 0.7222 - val_loss: 3.4828 - val_acc: 0.5714

Epoch 00005: loss improved from 1.60455 to 1.60347, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.4848 - acc: 0.7812
54/54 [==============================] - 0s 41us/step - loss: 1.4431 - acc: 0.8148 - val_loss: 3.2412 - val_acc: 0.5714

Epoch 00006: loss improved from 1.60347 to 1.44310, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.4395 - acc: 0.8125
54/54 [==============================] - 0s 41us/step - loss: 1.3608 - acc: 0.8148 - val_loss: 3.2218 - val_acc: 0.5714

Epoch 00007: loss improved from 1.44310 to 1.36080, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.3378 - acc: 0.8125
54/54 [==============================] - 0s 41us/step - loss: 1.4339 - acc: 0.8148 - val_loss: 3.4316 - val_acc: 0.5714

Epoch 00008: loss did not improve from 1.36080
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.3838 - acc: 0.8125
54/54 [==============================] - 0s 39us/step - loss: 1.3554 - acc: 0.8333 - val_loss: 3.0446 - val_acc: 0.5714

Epoch 00009: loss improved from 1.36080 to 1.35538, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.3476 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.3382 - acc: 0.8519 - val_loss: 2.8064 - val_acc: 0.5714

Epoch 00010: loss improved from 1.35538 to 1.33823, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.1774 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 1.1427 - acc: 0.9074 - val_loss: 2.8321 - val_acc: 0.5714

Epoch 00011: loss improved from 1.33823 to 1.14274, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.3163 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.2882 - acc: 0.8519 - val_loss: 2.8373 - val_acc: 0.5714

Epoch 00012: loss did not improve from 1.14274
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.2263 - acc: 0.8125
54/54 [==============================] - 0s 39us/step - loss: 1.1786 - acc: 0.8519 - val_loss: 2.6283 - val_acc: 0.5714

Epoch 00013: loss did not improve from 1.14274
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 1.3549 - acc: 0.8438
54/54 [==============================] - 0s 40us/step - loss: 1.2543 - acc: 0.8889 - val_loss: 2.6348 - val_acc: 0.5714

Epoch 00014: loss did not improve from 1.14274
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 1.1049 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 1.0811 - acc: 0.9259 - val_loss: 3.1582 - val_acc: 0.5714

Epoch 00015: loss improved from 1.14274 to 1.08111, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 1.3725 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 1.2820 - acc: 0.8704 - val_loss: 2.8287 - val_acc: 0.5714

Epoch 00016: loss did not improve from 1.08111
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 1.1592 - acc: 0.8750
54/54 [==============================] - 0s 39us/step - loss: 1.0707 - acc: 0.8889 - val_loss: 2.8611 - val_acc: 0.5714

Epoch 00017: loss improved from 1.08111 to 1.07075, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 1.1322 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.1056 - acc: 0.8889 - val_loss: 2.6201 - val_acc: 0.5714

Epoch 00018: loss did not improve from 1.07075
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.9564 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.9442 - acc: 0.9444 - val_loss: 2.6373 - val_acc: 0.5714

Epoch 00019: loss improved from 1.07075 to 0.94415, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.9930 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.9362 - acc: 0.9259 - val_loss: 2.6213 - val_acc: 0.5714

Epoch 00020: loss improved from 0.94415 to 0.93623, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 1.0420 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.9683 - acc: 0.9259 - val_loss: 2.5867 - val_acc: 0.5714

Epoch 00021: loss did not improve from 0.93623
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.8609 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.8638 - acc: 0.9815 - val_loss: 2.4443 - val_acc: 0.5714

Epoch 00022: loss improved from 0.93623 to 0.86379, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.9942 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.9608 - acc: 0.9444 - val_loss: 2.6053 - val_acc: 0.4286

Epoch 00023: loss did not improve from 0.86379
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.8860 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.8831 - acc: 0.9444 - val_loss: 2.3823 - val_acc: 0.5000

Epoch 00024: loss did not improve from 0.86379
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 1.0153 - acc: 0.8750
54/54 [==============================] - 0s 39us/step - loss: 0.9122 - acc: 0.9259 - val_loss: 2.6934 - val_acc: 0.5000

Epoch 00025: loss did not improve from 0.86379
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.8572 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.8008 - acc: 0.9630 - val_loss: 2.8359 - val_acc: 0.5000

Epoch 00026: loss improved from 0.86379 to 0.80082, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_14.h5
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.9444 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8883 - acc: 0.9444 - val_loss: 3.2795 - val_acc: 0.5714

Epoch 00027: loss did not improve from 0.80082
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.8886 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.8532 - acc: 0.9630 - val_loss: 2.7277 - val_acc: 0.5714

Epoch 00028: loss did not improve from 0.80082
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 0.8679 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 0.8154 - acc: 0.9444 - val_loss: 2.6842 - val_acc: 0.5000

Epoch 00029: loss did not improve from 0.80082
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 0.8476 - acc: 0.9375
54/54 [==============================] - 0s 38us/step - loss: 0.8079 - acc: 0.9630 - val_loss: 2.5381 - val_acc: 0.5000

Epoch 00030: loss did not improve from 0.80082
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 0.8415 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.8086 - acc: 0.9815 - val_loss: 2.4172 - val_acc: 0.5714
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:16<00:07,  1.78s/it]
Epoch 00031: loss did not improve from 0.80082
Epoch 00031: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 3.1143 - acc: 0.6250
54/54 [==============================] - 0s 5ms/step - loss: 3.1800 - acc: 0.6852 - val_loss: 3.8269 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 3.18000, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.6811 - acc: 0.7188
54/54 [==============================] - 0s 50us/step - loss: 1.7011 - acc: 0.7407 - val_loss: 3.2705 - val_acc: 0.5714

Epoch 00002: loss improved from 3.18000 to 1.70112, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.5123 - acc: 0.7188
54/54 [==============================] - 0s 43us/step - loss: 1.6046 - acc: 0.7593 - val_loss: 3.4726 - val_acc: 0.5714

Epoch 00003: loss improved from 1.70112 to 1.60457, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.5239 - acc: 0.7812
54/54 [==============================] - 0s 42us/step - loss: 1.4627 - acc: 0.8148 - val_loss: 2.9673 - val_acc: 0.5000

Epoch 00004: loss improved from 1.60457 to 1.46272, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.4597 - acc: 0.8125
54/54 [==============================] - 0s 41us/step - loss: 1.5105 - acc: 0.7778 - val_loss: 3.1899 - val_acc: 0.5714

Epoch 00005: loss did not improve from 1.46272
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.4200 - acc: 0.7812
54/54 [==============================] - 0s 40us/step - loss: 1.4600 - acc: 0.7963 - val_loss: 2.9603 - val_acc: 0.5714

Epoch 00006: loss improved from 1.46272 to 1.46000, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.4009 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.3746 - acc: 0.8519 - val_loss: 3.0547 - val_acc: 0.5714

Epoch 00007: loss improved from 1.46000 to 1.37464, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.2188 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 1.2299 - acc: 0.8519 - val_loss: 3.0113 - val_acc: 0.5000

Epoch 00008: loss improved from 1.37464 to 1.22989, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.4706 - acc: 0.8750
54/54 [==============================] - 0s 42us/step - loss: 1.3117 - acc: 0.8704 - val_loss: 3.0057 - val_acc: 0.4286

Epoch 00009: loss did not improve from 1.22989
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.2752 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.1645 - acc: 0.9074 - val_loss: 3.1288 - val_acc: 0.5000

Epoch 00010: loss improved from 1.22989 to 1.16448, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.2882 - acc: 0.8125
54/54 [==============================] - 0s 41us/step - loss: 1.1724 - acc: 0.8889 - val_loss: 2.6840 - val_acc: 0.5000

Epoch 00011: loss did not improve from 1.16448
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.0678 - acc: 0.8438
54/54 [==============================] - 0s 40us/step - loss: 1.0433 - acc: 0.8704 - val_loss: 2.7077 - val_acc: 0.5000

Epoch 00012: loss improved from 1.16448 to 1.04330, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.0562 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.0834 - acc: 0.9259 - val_loss: 3.1449 - val_acc: 0.5000

Epoch 00013: loss did not improve from 1.04330
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 1.3485 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.2151 - acc: 0.8704 - val_loss: 2.6259 - val_acc: 0.5000

Epoch 00014: loss did not improve from 1.04330
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 1.0933 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.0168 - acc: 0.9074 - val_loss: 2.6487 - val_acc: 0.5000

Epoch 00015: loss improved from 1.04330 to 1.01677, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 1.0681 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 0.9820 - acc: 0.9259 - val_loss: 2.6327 - val_acc: 0.5000

Epoch 00016: loss improved from 1.01677 to 0.98197, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 0.9667 - acc: 0.9062
54/54 [==============================] - 0s 42us/step - loss: 0.9846 - acc: 0.9259 - val_loss: 2.5988 - val_acc: 0.5000

Epoch 00017: loss did not improve from 0.98197
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.9848 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 0.9018 - acc: 0.9259 - val_loss: 2.8742 - val_acc: 0.5000

Epoch 00018: loss improved from 0.98197 to 0.90182, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 1.0135 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 0.9370 - acc: 0.9074 - val_loss: 2.6184 - val_acc: 0.5000

Epoch 00019: loss did not improve from 0.90182
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.9880 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 0.9388 - acc: 0.8889 - val_loss: 2.9622 - val_acc: 0.5714

Epoch 00020: loss did not improve from 0.90182
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 0.9234 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.9089 - acc: 0.9444 - val_loss: 3.1239 - val_acc: 0.5000

Epoch 00021: loss did not improve from 0.90182
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 1.1036 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.9784 - acc: 0.9444 - val_loss: 2.3967 - val_acc: 0.4286

Epoch 00022: loss did not improve from 0.90182
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.9561 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.8796 - acc: 0.9630 - val_loss: 2.4846 - val_acc: 0.5714

Epoch 00023: loss improved from 0.90182 to 0.87965, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.9274 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.9243 - acc: 0.9815 - val_loss: 2.8332 - val_acc: 0.5714

Epoch 00024: loss did not improve from 0.87965
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 1.0293 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 0.9512 - acc: 0.9259 - val_loss: 2.8730 - val_acc: 0.5000

Epoch 00025: loss did not improve from 0.87965
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.8630 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.8436 - acc: 0.9444 - val_loss: 3.0493 - val_acc: 0.5000

Epoch 00026: loss improved from 0.87965 to 0.84360, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.8084 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7766 - acc: 0.9815 - val_loss: 2.8796 - val_acc: 0.5714

Epoch 00027: loss improved from 0.84360 to 0.77657, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.8165 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7925 - acc: 0.9630 - val_loss: 2.6250 - val_acc: 0.5714

Epoch 00028: loss did not improve from 0.77657
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 0.7474 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.7400 - acc: 0.9630 - val_loss: 2.7544 - val_acc: 0.5714

Epoch 00029: loss improved from 0.77657 to 0.74000, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 0.8199 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7825 - acc: 0.9444 - val_loss: 2.8046 - val_acc: 0.5714

Epoch 00030: loss did not improve from 0.74000
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 0.7569 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.7439 - acc: 0.9630 - val_loss: 2.8253 - val_acc: 0.5714

Epoch 00031: loss did not improve from 0.74000
Epoch 32/100

32/54 [================>.............] - ETA: 0s - loss: 0.6842 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.6908 - acc: 0.9815 - val_loss: 2.6303 - val_acc: 0.5714

Epoch 00032: loss improved from 0.74000 to 0.69080, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 33/100

32/54 [================>.............] - ETA: 0s - loss: 0.7336 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7310 - acc: 0.9815 - val_loss: 2.5364 - val_acc: 0.5000

Epoch 00033: loss did not improve from 0.69080
Epoch 34/100

32/54 [================>.............] - ETA: 0s - loss: 0.7277 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.7147 - acc: 1.0000 - val_loss: 2.8505 - val_acc: 0.5714

Epoch 00034: loss did not improve from 0.69080
Epoch 35/100

32/54 [================>.............] - ETA: 0s - loss: 0.6862 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.6677 - acc: 1.0000 - val_loss: 2.9624 - val_acc: 0.5714

Epoch 00035: loss improved from 0.69080 to 0.66774, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 36/100

32/54 [================>.............] - ETA: 0s - loss: 0.7430 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7101 - acc: 0.9630 - val_loss: 2.4956 - val_acc: 0.5714

Epoch 00036: loss did not improve from 0.66774
Epoch 37/100

32/54 [================>.............] - ETA: 0s - loss: 0.7347 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.7015 - acc: 0.9815 - val_loss: 2.7535 - val_acc: 0.5714

Epoch 00037: loss did not improve from 0.66774
Epoch 38/100

32/54 [================>.............] - ETA: 0s - loss: 0.7492 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.7036 - acc: 0.9815 - val_loss: 2.8528 - val_acc: 0.5714

Epoch 00038: loss did not improve from 0.66774
Epoch 39/100

32/54 [================>.............] - ETA: 0s - loss: 0.7018 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.6869 - acc: 0.9630 - val_loss: 2.7109 - val_acc: 0.5714

Epoch 00039: loss did not improve from 0.66774
Epoch 40/100

32/54 [================>.............] - ETA: 0s - loss: 0.6433 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.6312 - acc: 1.0000 - val_loss: 3.1397 - val_acc: 0.5714

Epoch 00040: loss improved from 0.66774 to 0.63115, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 41/100

32/54 [================>.............] - ETA: 0s - loss: 0.6523 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.6324 - acc: 1.0000 - val_loss: 3.0238 - val_acc: 0.5714

Epoch 00041: loss did not improve from 0.63115
Epoch 42/100

32/54 [================>.............] - ETA: 0s - loss: 0.6476 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.6301 - acc: 0.9815 - val_loss: 2.9939 - val_acc: 0.5714

Epoch 00042: loss improved from 0.63115 to 0.63014, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 43/100

32/54 [================>.............] - ETA: 0s - loss: 0.6651 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6367 - acc: 0.9815 - val_loss: 2.9315 - val_acc: 0.5714

Epoch 00043: loss did not improve from 0.63014
Epoch 44/100

32/54 [================>.............] - ETA: 0s - loss: 0.6114 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.6063 - acc: 1.0000 - val_loss: 3.0785 - val_acc: 0.5714

Epoch 00044: loss improved from 0.63014 to 0.60634, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 45/100

32/54 [================>.............] - ETA: 0s - loss: 0.6331 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.6157 - acc: 0.9815 - val_loss: 2.7702 - val_acc: 0.5714

Epoch 00045: loss did not improve from 0.60634
Epoch 46/100

32/54 [================>.............] - ETA: 0s - loss: 0.5887 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5888 - acc: 1.0000 - val_loss: 2.9006 - val_acc: 0.5714

Epoch 00046: loss improved from 0.60634 to 0.58879, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 47/100

32/54 [================>.............] - ETA: 0s - loss: 0.6294 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6335 - acc: 0.9815 - val_loss: 2.5611 - val_acc: 0.5000

Epoch 00047: loss did not improve from 0.58879
Epoch 48/100

32/54 [================>.............] - ETA: 0s - loss: 0.5991 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5885 - acc: 1.0000 - val_loss: 2.8347 - val_acc: 0.5000

Epoch 00048: loss improved from 0.58879 to 0.58852, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 49/100

32/54 [================>.............] - ETA: 0s - loss: 0.6622 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.6227 - acc: 0.9815 - val_loss: 2.8175 - val_acc: 0.5714

Epoch 00049: loss did not improve from 0.58852
Epoch 50/100

32/54 [================>.............] - ETA: 0s - loss: 0.5844 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5818 - acc: 1.0000 - val_loss: 2.7730 - val_acc: 0.5714

Epoch 00050: loss improved from 0.58852 to 0.58183, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 51/100

32/54 [================>.............] - ETA: 0s - loss: 0.6082 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5935 - acc: 1.0000 - val_loss: 2.8279 - val_acc: 0.5714

Epoch 00051: loss did not improve from 0.58183
Epoch 52/100

32/54 [================>.............] - ETA: 0s - loss: 0.6382 - acc: 0.9375
54/54 [==============================] - 0s 38us/step - loss: 0.6119 - acc: 0.9630 - val_loss: 2.8334 - val_acc: 0.5714

Epoch 00052: loss did not improve from 0.58183
Epoch 53/100

32/54 [================>.............] - ETA: 0s - loss: 0.5511 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5490 - acc: 1.0000 - val_loss: 2.7668 - val_acc: 0.5714

Epoch 00053: loss improved from 0.58183 to 0.54897, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 54/100

32/54 [================>.............] - ETA: 0s - loss: 0.5659 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5643 - acc: 1.0000 - val_loss: 2.9783 - val_acc: 0.5714

Epoch 00054: loss did not improve from 0.54897
Epoch 55/100

32/54 [================>.............] - ETA: 0s - loss: 0.5505 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5594 - acc: 1.0000 - val_loss: 2.9192 - val_acc: 0.5714

Epoch 00055: loss did not improve from 0.54897
Epoch 56/100

32/54 [================>.............] - ETA: 0s - loss: 0.5447 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.5418 - acc: 1.0000 - val_loss: 2.9292 - val_acc: 0.5714

Epoch 00056: loss improved from 0.54897 to 0.54178, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 57/100

32/54 [================>.............] - ETA: 0s - loss: 0.5537 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5450 - acc: 1.0000 - val_loss: 2.9954 - val_acc: 0.5714

Epoch 00057: loss did not improve from 0.54178
Epoch 58/100

32/54 [================>.............] - ETA: 0s - loss: 0.5616 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5443 - acc: 1.0000 - val_loss: 2.7234 - val_acc: 0.5714

Epoch 00058: loss did not improve from 0.54178
Epoch 59/100

32/54 [================>.............] - ETA: 0s - loss: 0.5404 - acc: 1.0000
54/54 [==============================] - 0s 38us/step - loss: 0.5316 - acc: 1.0000 - val_loss: 2.7756 - val_acc: 0.5714

Epoch 00059: loss improved from 0.54178 to 0.53160, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 60/100

32/54 [================>.............] - ETA: 0s - loss: 0.5225 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5195 - acc: 1.0000 - val_loss: 2.8192 - val_acc: 0.5714

Epoch 00060: loss improved from 0.53160 to 0.51955, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 61/100

32/54 [================>.............] - ETA: 0s - loss: 0.5496 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5403 - acc: 1.0000 - val_loss: 3.1795 - val_acc: 0.5714

Epoch 00061: loss did not improve from 0.51955
Epoch 62/100

32/54 [================>.............] - ETA: 0s - loss: 0.5145 - acc: 1.0000
54/54 [==============================] - 0s 38us/step - loss: 0.5162 - acc: 1.0000 - val_loss: 3.0323 - val_acc: 0.5714

Epoch 00062: loss improved from 0.51955 to 0.51619, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 63/100

32/54 [================>.............] - ETA: 0s - loss: 0.5101 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.5063 - acc: 1.0000 - val_loss: 3.0624 - val_acc: 0.5714

Epoch 00063: loss improved from 0.51619 to 0.50632, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 64/100

32/54 [================>.............] - ETA: 0s - loss: 0.4995 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.5065 - acc: 1.0000 - val_loss: 3.0941 - val_acc: 0.5714

Epoch 00064: loss did not improve from 0.50632
Epoch 65/100

32/54 [================>.............] - ETA: 0s - loss: 0.5105 - acc: 1.0000
54/54 [==============================] - 0s 38us/step - loss: 0.5019 - acc: 1.0000 - val_loss: 3.0941 - val_acc: 0.5714

Epoch 00065: loss improved from 0.50632 to 0.50190, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_15.h5
Epoch 66/100

32/54 [================>.............] - ETA: 0s - loss: 0.5479 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.5864 - acc: 0.9815 - val_loss: 3.6509 - val_acc: 0.5000

Epoch 00066: loss did not improve from 0.50190
Epoch 67/100

32/54 [================>.............] - ETA: 0s - loss: 0.6862 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.6691 - acc: 0.9630 - val_loss: 3.9251 - val_acc: 0.5714

Epoch 00067: loss did not improve from 0.50190
Epoch 68/100

32/54 [================>.............] - ETA: 0s - loss: 0.7649 - acc: 0.8438
54/54 [==============================] - 0s 39us/step - loss: 0.7322 - acc: 0.9074 - val_loss: 2.3793 - val_acc: 0.5000

Epoch 00068: loss did not improve from 0.50190
Epoch 69/100

32/54 [================>.............] - ETA: 0s - loss: 0.7499 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.7085 - acc: 0.9444 - val_loss: 4.3204 - val_acc: 0.5714

Epoch 00069: loss did not improve from 0.50190
Epoch 70/100

32/54 [================>.............] - ETA: 0s - loss: 0.6562 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 0.6382 - acc: 0.9444 - val_loss: 4.3988 - val_acc: 0.5714
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:18<00:05,  1.81s/it]
Epoch 00070: loss did not improve from 0.50190
Epoch 00070: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 3.6673 - acc: 0.5938
54/54 [==============================] - 0s 5ms/step - loss: 3.4226 - acc: 0.6481 - val_loss: 3.8391 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 3.42260, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.6843 - acc: 0.7188
54/54 [==============================] - 0s 49us/step - loss: 1.8023 - acc: 0.7407 - val_loss: 3.4691 - val_acc: 0.5714

Epoch 00002: loss improved from 3.42260 to 1.80230, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.5395 - acc: 0.7188
54/54 [==============================] - 0s 45us/step - loss: 1.6137 - acc: 0.7593 - val_loss: 3.3096 - val_acc: 0.5714

Epoch 00003: loss improved from 1.80230 to 1.61370, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.4833 - acc: 0.7188
54/54 [==============================] - 0s 43us/step - loss: 1.5254 - acc: 0.7593 - val_loss: 3.3070 - val_acc: 0.5714

Epoch 00004: loss improved from 1.61370 to 1.52537, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.4977 - acc: 0.7500
54/54 [==============================] - 0s 42us/step - loss: 1.4283 - acc: 0.7407 - val_loss: 3.0560 - val_acc: 0.5000

Epoch 00005: loss improved from 1.52537 to 1.42826, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.2092 - acc: 0.7812
54/54 [==============================] - 0s 41us/step - loss: 1.3158 - acc: 0.8519 - val_loss: 2.9833 - val_acc: 0.5000

Epoch 00006: loss improved from 1.42826 to 1.31582, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.3225 - acc: 0.7812
54/54 [==============================] - 0s 41us/step - loss: 1.2458 - acc: 0.8519 - val_loss: 2.8533 - val_acc: 0.5000

Epoch 00007: loss improved from 1.31582 to 1.24576, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.2276 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.2190 - acc: 0.8519 - val_loss: 2.7529 - val_acc: 0.5000

Epoch 00008: loss improved from 1.24576 to 1.21900, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.2338 - acc: 0.8438
54/54 [==============================] - 0s 42us/step - loss: 1.1661 - acc: 0.8704 - val_loss: 2.6616 - val_acc: 0.5000

Epoch 00009: loss improved from 1.21900 to 1.16605, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.2463 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.1820 - acc: 0.8704 - val_loss: 2.6851 - val_acc: 0.5000

Epoch 00010: loss did not improve from 1.16605
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.2004 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.1304 - acc: 0.9074 - val_loss: 2.7438 - val_acc: 0.5714

Epoch 00011: loss improved from 1.16605 to 1.13040, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.0748 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 1.0613 - acc: 0.9444 - val_loss: 2.5422 - val_acc: 0.5714

Epoch 00012: loss improved from 1.13040 to 1.06132, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.1725 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.1245 - acc: 0.9074 - val_loss: 2.5802 - val_acc: 0.5714

Epoch 00013: loss did not improve from 1.06132
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 1.1419 - acc: 0.8750
54/54 [==============================] - 0s 39us/step - loss: 1.0409 - acc: 0.9259 - val_loss: 2.4631 - val_acc: 0.5714

Epoch 00014: loss improved from 1.06132 to 1.04087, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 1.0203 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.9822 - acc: 0.9259 - val_loss: 2.2865 - val_acc: 0.5714

Epoch 00015: loss improved from 1.04087 to 0.98221, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 1.0180 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.9223 - acc: 0.9630 - val_loss: 2.4318 - val_acc: 0.5714

Epoch 00016: loss improved from 0.98221 to 0.92228, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 0.9136 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.8843 - acc: 0.9444 - val_loss: 2.4165 - val_acc: 0.5714

Epoch 00017: loss improved from 0.92228 to 0.88429, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.8937 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.8595 - acc: 0.9630 - val_loss: 2.3572 - val_acc: 0.6429

Epoch 00018: loss improved from 0.88429 to 0.85953, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.8842 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8647 - acc: 0.9444 - val_loss: 2.3510 - val_acc: 0.5714

Epoch 00019: loss did not improve from 0.85953
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.8336 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.7991 - acc: 0.9630 - val_loss: 2.1893 - val_acc: 0.5000

Epoch 00020: loss improved from 0.85953 to 0.79915, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 0.8764 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.8515 - acc: 0.9444 - val_loss: 2.2665 - val_acc: 0.5000

Epoch 00021: loss did not improve from 0.79915
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.7745 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.7719 - acc: 0.9815 - val_loss: 2.2564 - val_acc: 0.5714

Epoch 00022: loss improved from 0.79915 to 0.77193, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.7414 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7400 - acc: 0.9815 - val_loss: 2.6216 - val_acc: 0.5714

Epoch 00023: loss improved from 0.77193 to 0.74002, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_16.h5
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.9187 - acc: 0.9375
54/54 [==============================] - 0s 42us/step - loss: 0.9062 - acc: 0.9630 - val_loss: 2.6815 - val_acc: 0.5000

Epoch 00024: loss did not improve from 0.74002
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 1.2148 - acc: 0.8438
54/54 [==============================] - 0s 40us/step - loss: 1.0363 - acc: 0.9074 - val_loss: 2.3021 - val_acc: 0.4286

Epoch 00025: loss did not improve from 0.74002
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.9429 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.8507 - acc: 0.9444 - val_loss: 2.3263 - val_acc: 0.5000

Epoch 00026: loss did not improve from 0.74002
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.8286 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 0.7801 - acc: 0.9444 - val_loss: 2.1923 - val_acc: 0.4286

Epoch 00027: loss did not improve from 0.74002
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.7831 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.7704 - acc: 0.9630 - val_loss: 2.4268 - val_acc: 0.5000
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:19<00:03,  1.74s/it]
Epoch 00028: loss did not improve from 0.74002
Epoch 00028: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 4.5105 - acc: 0.5312
54/54 [==============================] - 0s 5ms/step - loss: 4.1342 - acc: 0.6296 - val_loss: 4.6846 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 4.13420, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.9553 - acc: 0.7500
54/54 [==============================] - 0s 51us/step - loss: 2.1292 - acc: 0.7593 - val_loss: 3.9546 - val_acc: 0.5714

Epoch 00002: loss improved from 4.13420 to 2.12916, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.8810 - acc: 0.6875
54/54 [==============================] - 0s 44us/step - loss: 1.8947 - acc: 0.7037 - val_loss: 3.6390 - val_acc: 0.5714

Epoch 00003: loss improved from 2.12916 to 1.89471, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.8480 - acc: 0.6875
54/54 [==============================] - 0s 42us/step - loss: 1.9301 - acc: 0.7222 - val_loss: 3.4337 - val_acc: 0.5714

Epoch 00004: loss did not improve from 1.89471
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.6589 - acc: 0.6875
54/54 [==============================] - 0s 39us/step - loss: 1.7531 - acc: 0.7407 - val_loss: 3.4697 - val_acc: 0.5714

Epoch 00005: loss improved from 1.89471 to 1.75310, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.7582 - acc: 0.6875
54/54 [==============================] - 0s 41us/step - loss: 1.7249 - acc: 0.7407 - val_loss: 3.1651 - val_acc: 0.5714

Epoch 00006: loss improved from 1.75310 to 1.72493, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.6121 - acc: 0.7188
54/54 [==============================] - 0s 41us/step - loss: 1.6387 - acc: 0.7593 - val_loss: 3.1672 - val_acc: 0.5714

Epoch 00007: loss improved from 1.72493 to 1.63868, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.5727 - acc: 0.7500
54/54 [==============================] - 0s 41us/step - loss: 1.6836 - acc: 0.7778 - val_loss: 3.2483 - val_acc: 0.5714

Epoch 00008: loss did not improve from 1.63868
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.5526 - acc: 0.7500
54/54 [==============================] - 0s 40us/step - loss: 1.5355 - acc: 0.7963 - val_loss: 3.0467 - val_acc: 0.5714

Epoch 00009: loss improved from 1.63868 to 1.53553, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.4252 - acc: 0.7812
54/54 [==============================] - 0s 41us/step - loss: 1.4168 - acc: 0.8333 - val_loss: 2.8644 - val_acc: 0.5714

Epoch 00010: loss improved from 1.53553 to 1.41681, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.4885 - acc: 0.7500
54/54 [==============================] - 0s 41us/step - loss: 1.4709 - acc: 0.7963 - val_loss: 2.9411 - val_acc: 0.5714

Epoch 00011: loss did not improve from 1.41681
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.4397 - acc: 0.7812
54/54 [==============================] - 0s 39us/step - loss: 1.4425 - acc: 0.8148 - val_loss: 3.0598 - val_acc: 0.5714

Epoch 00012: loss did not improve from 1.41681
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.3725 - acc: 0.8438
54/54 [==============================] - 0s 40us/step - loss: 1.3483 - acc: 0.8519 - val_loss: 2.6746 - val_acc: 0.5714

Epoch 00013: loss improved from 1.41681 to 1.34827, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 1.3700 - acc: 0.8438
54/54 [==============================] - 0s 42us/step - loss: 1.3620 - acc: 0.8704 - val_loss: 2.6029 - val_acc: 0.5714

Epoch 00014: loss did not improve from 1.34827
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 1.2890 - acc: 0.8125
54/54 [==============================] - 0s 39us/step - loss: 1.3002 - acc: 0.8333 - val_loss: 2.4887 - val_acc: 0.5714

Epoch 00015: loss improved from 1.34827 to 1.30022, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 1.2680 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.3504 - acc: 0.8889 - val_loss: 3.1760 - val_acc: 0.5714

Epoch 00016: loss did not improve from 1.30022
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 1.2317 - acc: 0.8438
54/54 [==============================] - 0s 39us/step - loss: 1.2184 - acc: 0.8889 - val_loss: 2.7893 - val_acc: 0.5714

Epoch 00017: loss improved from 1.30022 to 1.21840, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 1.2986 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 1.2257 - acc: 0.8889 - val_loss: 2.7725 - val_acc: 0.5714

Epoch 00018: loss did not improve from 1.21840
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 1.1754 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 1.1347 - acc: 0.9259 - val_loss: 2.8327 - val_acc: 0.5714

Epoch 00019: loss improved from 1.21840 to 1.13472, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 1.1290 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.1163 - acc: 0.9074 - val_loss: 2.8679 - val_acc: 0.5714

Epoch 00020: loss improved from 1.13472 to 1.11626, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 1.2668 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.2244 - acc: 0.9074 - val_loss: 2.3389 - val_acc: 0.5000

Epoch 00021: loss did not improve from 1.11626
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 1.0901 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 1.0666 - acc: 0.9259 - val_loss: 2.6965 - val_acc: 0.5000

Epoch 00022: loss improved from 1.11626 to 1.06656, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 1.0596 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 1.0380 - acc: 0.9444 - val_loss: 2.6188 - val_acc: 0.5000

Epoch 00023: loss improved from 1.06656 to 1.03799, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.9654 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.9458 - acc: 0.9630 - val_loss: 2.7514 - val_acc: 0.5000

Epoch 00024: loss improved from 1.03799 to 0.94576, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 0.9411 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.9482 - acc: 0.9444 - val_loss: 2.8948 - val_acc: 0.5000

Epoch 00025: loss did not improve from 0.94576
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.9184 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.9294 - acc: 0.9444 - val_loss: 2.6212 - val_acc: 0.5000

Epoch 00026: loss improved from 0.94576 to 0.92936, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.8899 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.9113 - acc: 0.9815 - val_loss: 2.9701 - val_acc: 0.5000

Epoch 00027: loss improved from 0.92936 to 0.91131, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_17.h5
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 1.0352 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.1316 - acc: 0.9074 - val_loss: 5.9457 - val_acc: 0.5714

Epoch 00028: loss did not improve from 0.91131
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 1.6049 - acc: 0.8750
54/54 [==============================] - 0s 39us/step - loss: 1.3803 - acc: 0.8889 - val_loss: 4.4185 - val_acc: 0.5714

Epoch 00029: loss did not improve from 0.91131
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 1.2018 - acc: 0.9375
54/54 [==============================] - 0s 38us/step - loss: 1.1105 - acc: 0.9444 - val_loss: 3.8295 - val_acc: 0.6429

Epoch 00030: loss did not improve from 0.91131
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 1.1675 - acc: 0.9062
54/54 [==============================] - 0s 39us/step - loss: 1.0834 - acc: 0.9444 - val_loss: 3.4817 - val_acc: 0.6429

Epoch 00031: loss did not improve from 0.91131
Epoch 32/100

32/54 [================>.............] - ETA: 0s - loss: 1.2321 - acc: 0.8750
54/54 [==============================] - 0s 39us/step - loss: 1.1540 - acc: 0.9074 - val_loss: 3.6145 - val_acc: 0.6429
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:21<00:01,  1.73s/it]
Epoch 00032: loss did not improve from 0.91131
Epoch 00032: early stopping
Train on 54 samples, validate on 14 samples
Epoch 1/100

32/54 [================>.............] - ETA: 0s - loss: 3.7429 - acc: 0.5625
54/54 [==============================] - 0s 5ms/step - loss: 3.4522 - acc: 0.6296 - val_loss: 4.9516 - val_acc: 0.5714

Epoch 00001: loss improved from inf to 3.45225, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

32/54 [================>.............] - ETA: 0s - loss: 1.8549 - acc: 0.6875
54/54 [==============================] - 0s 49us/step - loss: 1.9207 - acc: 0.7037 - val_loss: 4.0805 - val_acc: 0.5714

Epoch 00002: loss improved from 3.45225 to 1.92072, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

32/54 [================>.............] - ETA: 0s - loss: 1.6865 - acc: 0.7188
54/54 [==============================] - 0s 43us/step - loss: 1.7441 - acc: 0.7037 - val_loss: 3.8879 - val_acc: 0.5714

Epoch 00003: loss improved from 1.92072 to 1.74409, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

32/54 [================>.............] - ETA: 0s - loss: 1.6199 - acc: 0.7500
54/54 [==============================] - 0s 42us/step - loss: 1.5480 - acc: 0.7407 - val_loss: 3.5415 - val_acc: 0.5714

Epoch 00004: loss improved from 1.74409 to 1.54799, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

32/54 [================>.............] - ETA: 0s - loss: 1.4969 - acc: 0.7500
54/54 [==============================] - 0s 41us/step - loss: 1.5459 - acc: 0.7778 - val_loss: 3.3687 - val_acc: 0.5000

Epoch 00005: loss improved from 1.54799 to 1.54591, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

32/54 [================>.............] - ETA: 0s - loss: 1.5115 - acc: 0.7812
54/54 [==============================] - 0s 42us/step - loss: 1.4934 - acc: 0.7963 - val_loss: 3.3452 - val_acc: 0.5000

Epoch 00006: loss improved from 1.54591 to 1.49335, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

32/54 [================>.............] - ETA: 0s - loss: 1.2925 - acc: 0.7812
54/54 [==============================] - 0s 41us/step - loss: 1.3513 - acc: 0.7963 - val_loss: 3.3747 - val_acc: 0.5714

Epoch 00007: loss improved from 1.49335 to 1.35134, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

32/54 [================>.............] - ETA: 0s - loss: 1.4567 - acc: 0.7812
54/54 [==============================] - 0s 42us/step - loss: 1.4963 - acc: 0.7778 - val_loss: 3.0246 - val_acc: 0.5714

Epoch 00008: loss did not improve from 1.35134
Epoch 9/100

32/54 [================>.............] - ETA: 0s - loss: 1.3437 - acc: 0.8125
54/54 [==============================] - 0s 40us/step - loss: 1.3292 - acc: 0.8333 - val_loss: 2.9680 - val_acc: 0.5000

Epoch 00009: loss improved from 1.35134 to 1.32921, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

32/54 [================>.............] - ETA: 0s - loss: 1.2625 - acc: 0.8125
54/54 [==============================] - 0s 41us/step - loss: 1.2502 - acc: 0.8519 - val_loss: 3.0541 - val_acc: 0.5000

Epoch 00010: loss improved from 1.32921 to 1.25023, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

32/54 [================>.............] - ETA: 0s - loss: 1.2244 - acc: 0.8438
54/54 [==============================] - 0s 42us/step - loss: 1.1308 - acc: 0.8889 - val_loss: 3.1767 - val_acc: 0.5000

Epoch 00011: loss improved from 1.25023 to 1.13078, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

32/54 [================>.............] - ETA: 0s - loss: 1.1214 - acc: 0.8438
54/54 [==============================] - 0s 41us/step - loss: 1.1516 - acc: 0.8704 - val_loss: 3.0935 - val_acc: 0.5000

Epoch 00012: loss did not improve from 1.13078
Epoch 13/100

32/54 [================>.............] - ETA: 0s - loss: 1.0445 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 1.0452 - acc: 0.9444 - val_loss: 3.2785 - val_acc: 0.5714

Epoch 00013: loss improved from 1.13078 to 1.04518, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 14/100

32/54 [================>.............] - ETA: 0s - loss: 1.1813 - acc: 0.8750
54/54 [==============================] - 0s 41us/step - loss: 1.1498 - acc: 0.9074 - val_loss: 2.9226 - val_acc: 0.5000

Epoch 00014: loss did not improve from 1.04518
Epoch 15/100

32/54 [================>.............] - ETA: 0s - loss: 1.0197 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.0145 - acc: 0.9074 - val_loss: 2.7517 - val_acc: 0.5000

Epoch 00015: loss improved from 1.04518 to 1.01455, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

32/54 [================>.............] - ETA: 0s - loss: 1.0547 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 1.0916 - acc: 0.9259 - val_loss: 3.1863 - val_acc: 0.5714

Epoch 00016: loss did not improve from 1.01455
Epoch 17/100

32/54 [================>.............] - ETA: 0s - loss: 1.0167 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.0190 - acc: 0.8889 - val_loss: 2.6614 - val_acc: 0.4286

Epoch 00017: loss did not improve from 1.01455
Epoch 18/100

32/54 [================>.............] - ETA: 0s - loss: 0.8801 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.8854 - acc: 0.9444 - val_loss: 2.6462 - val_acc: 0.5000

Epoch 00018: loss improved from 1.01455 to 0.88538, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 19/100

32/54 [================>.............] - ETA: 0s - loss: 0.8992 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8768 - acc: 0.9259 - val_loss: 2.5992 - val_acc: 0.5714

Epoch 00019: loss improved from 0.88538 to 0.87678, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 20/100

32/54 [================>.............] - ETA: 0s - loss: 0.9535 - acc: 0.8750
54/54 [==============================] - 0s 43us/step - loss: 0.9957 - acc: 0.9074 - val_loss: 2.6693 - val_acc: 0.6429

Epoch 00020: loss did not improve from 0.87678
Epoch 21/100

32/54 [================>.............] - ETA: 0s - loss: 1.0320 - acc: 0.9062
54/54 [==============================] - 0s 40us/step - loss: 0.9629 - acc: 0.9074 - val_loss: 2.8252 - val_acc: 0.6429

Epoch 00021: loss did not improve from 0.87678
Epoch 22/100

32/54 [================>.............] - ETA: 0s - loss: 0.9634 - acc: 0.9375
54/54 [==============================] - 0s 40us/step - loss: 0.9331 - acc: 0.9444 - val_loss: 2.8459 - val_acc: 0.6429

Epoch 00022: loss did not improve from 0.87678
Epoch 23/100

32/54 [================>.............] - ETA: 0s - loss: 0.8789 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.8332 - acc: 0.9815 - val_loss: 2.3449 - val_acc: 0.4286

Epoch 00023: loss improved from 0.87678 to 0.83316, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 24/100

32/54 [================>.............] - ETA: 0s - loss: 0.9338 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 1.0175 - acc: 0.9630 - val_loss: 3.9437 - val_acc: 0.6429

Epoch 00024: loss did not improve from 0.83316
Epoch 25/100

32/54 [================>.............] - ETA: 0s - loss: 1.1908 - acc: 0.8750
54/54 [==============================] - 0s 40us/step - loss: 1.0745 - acc: 0.8889 - val_loss: 3.1740 - val_acc: 0.6429

Epoch 00025: loss did not improve from 0.83316
Epoch 26/100

32/54 [================>.............] - ETA: 0s - loss: 0.8418 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.8309 - acc: 0.9444 - val_loss: 2.9919 - val_acc: 0.5714

Epoch 00026: loss improved from 0.83316 to 0.83093, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 27/100

32/54 [================>.............] - ETA: 0s - loss: 0.8199 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.8043 - acc: 0.9444 - val_loss: 2.9571 - val_acc: 0.5714

Epoch 00027: loss improved from 0.83093 to 0.80434, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 28/100

32/54 [================>.............] - ETA: 0s - loss: 0.7997 - acc: 0.9062
54/54 [==============================] - 0s 41us/step - loss: 0.7889 - acc: 0.9444 - val_loss: 2.9330 - val_acc: 0.5714

Epoch 00028: loss improved from 0.80434 to 0.78886, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 29/100

32/54 [================>.............] - ETA: 0s - loss: 0.7784 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7873 - acc: 0.9444 - val_loss: 2.6197 - val_acc: 0.5714

Epoch 00029: loss improved from 0.78886 to 0.78731, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 30/100

32/54 [================>.............] - ETA: 0s - loss: 0.7166 - acc: 1.0000
54/54 [==============================] - 0s 41us/step - loss: 0.7159 - acc: 1.0000 - val_loss: 2.8078 - val_acc: 0.5714

Epoch 00030: loss improved from 0.78731 to 0.71588, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 31/100

32/54 [================>.............] - ETA: 0s - loss: 0.7486 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7496 - acc: 0.9444 - val_loss: 2.7029 - val_acc: 0.6429

Epoch 00031: loss did not improve from 0.71588
Epoch 32/100

32/54 [================>.............] - ETA: 0s - loss: 0.7324 - acc: 0.9688
54/54 [==============================] - 0s 40us/step - loss: 0.7250 - acc: 0.9630 - val_loss: 2.7294 - val_acc: 0.5714

Epoch 00032: loss did not improve from 0.71588
Epoch 33/100

32/54 [================>.............] - ETA: 0s - loss: 0.6907 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.6996 - acc: 1.0000 - val_loss: 2.4253 - val_acc: 0.6429

Epoch 00033: loss improved from 0.71588 to 0.69955, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 34/100

32/54 [================>.............] - ETA: 0s - loss: 0.7128 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7269 - acc: 0.9815 - val_loss: 2.4566 - val_acc: 0.6429

Epoch 00034: loss did not improve from 0.69955
Epoch 35/100

32/54 [================>.............] - ETA: 0s - loss: 0.7921 - acc: 0.9688
54/54 [==============================] - 0s 41us/step - loss: 0.7362 - acc: 0.9815 - val_loss: 2.7481 - val_acc: 0.5714

Epoch 00035: loss did not improve from 0.69955
Epoch 36/100

32/54 [================>.............] - ETA: 0s - loss: 0.6947 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.6897 - acc: 0.9815 - val_loss: 2.5731 - val_acc: 0.6429

Epoch 00036: loss improved from 0.69955 to 0.68965, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 37/100

32/54 [================>.............] - ETA: 0s - loss: 0.6997 - acc: 1.0000
54/54 [==============================] - 0s 40us/step - loss: 0.7513 - acc: 0.9815 - val_loss: 2.2614 - val_acc: 0.6429

Epoch 00037: loss did not improve from 0.68965
Epoch 38/100

32/54 [================>.............] - ETA: 0s - loss: 0.7591 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.7143 - acc: 0.9815 - val_loss: 3.0302 - val_acc: 0.5714

Epoch 00038: loss did not improve from 0.68965
Epoch 39/100

32/54 [================>.............] - ETA: 0s - loss: 0.8442 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.7746 - acc: 0.9815 - val_loss: 2.7691 - val_acc: 0.5000

Epoch 00039: loss did not improve from 0.68965
Epoch 40/100

32/54 [================>.............] - ETA: 0s - loss: 0.6363 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.6443 - acc: 1.0000 - val_loss: 2.9239 - val_acc: 0.5714

Epoch 00040: loss improved from 0.68965 to 0.64432, saving model to ./results_TA104_without_S9/DeepAmes_models/weight_18.h5
Epoch 41/100

32/54 [================>.............] - ETA: 0s - loss: 0.7231 - acc: 0.9375
54/54 [==============================] - 0s 41us/step - loss: 0.7434 - acc: 0.9630 - val_loss: 2.6028 - val_acc: 0.5000

Epoch 00041: loss did not improve from 0.64432
Epoch 42/100

32/54 [================>.............] - ETA: 0s - loss: 0.6665 - acc: 1.0000
54/54 [==============================] - 0s 39us/step - loss: 0.7038 - acc: 0.9630 - val_loss: 2.8008 - val_acc: 0.5000

Epoch 00042: loss did not improve from 0.64432
Epoch 43/100

32/54 [================>.............] - ETA: 0s - loss: 0.7338 - acc: 0.9375
54/54 [==============================] - 0s 39us/step - loss: 0.8395 - acc: 0.9259 - val_loss: 4.1305 - val_acc: 0.5714

Epoch 00043: loss did not improve from 0.64432
Epoch 44/100

32/54 [================>.............] - ETA: 0s - loss: 1.1442 - acc: 0.8750
54/54 [==============================] - 0s 39us/step - loss: 1.0186 - acc: 0.8889 - val_loss: 2.5703 - val_acc: 0.6429

Epoch 00044: loss did not improve from 0.64432
Epoch 45/100

32/54 [================>.............] - ETA: 0s - loss: 0.6637 - acc: 0.9688
54/54 [==============================] - 0s 39us/step - loss: 0.6877 - acc: 0.9815 - val_loss: 2.7196 - val_acc: 0.5714
DeepAmes+ Weights: 100%|██████████| 13/13 [00:23<00:00,  1.74s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:23<00:00,  1.78s/it]

Epoch 00045: loss did not improve from 0.64432
Epoch 00045: early stopping
--- 669.6553275585175 seconds ---

Generating metrics report for TA104_without_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 28 samples.
Processing weight 7...
  Done. 28 samples.
Processing weight 8...
  Done. 28 samples.
Processing weight 9...
  Done. 28 samples.
Processing weight 10...
  Done. 28 samples.
Processing weight 11...
  Done. 28 samples.
Processing weight 12...
  Done. 28 samples.
Processing weight 13...
  Done. 28 samples.
Processing weight 14...
  Done. 28 samples.
Processing weight 15...
  Done. 28 samples.
Processing weight 16...
  Done. 28 samples.
Processing weight 17...
  Done. 28 samples.
Processing weight 18...
  Done. 28 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA104_without_S9/metrics_report_TA104_without_S9.txt

Done!

Completed TA104_without_S9 in 669.66 seconds

================================================================================
[7/16] Processing: TA1535_with_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA1535_with_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA1535_with_S9_Test_mold2.csv
(3023, 777)
(2418, 777)
(342, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:15<04:49, 15.24s/it]KNN Seeds:  10%|█         | 2/20 [00:30<04:32, 15.16s/it]KNN Seeds:  15%|█▌        | 3/20 [00:45<04:18, 15.19s/it]KNN Seeds:  20%|██        | 4/20 [01:00<04:02, 15.14s/it]KNN Seeds:  25%|██▌       | 5/20 [01:15<03:47, 15.14s/it]KNN Seeds:  30%|███       | 6/20 [01:30<03:31, 15.08s/it]KNN Seeds:  35%|███▌      | 7/20 [01:45<03:15, 15.07s/it]KNN Seeds:  40%|████      | 8/20 [02:00<03:01, 15.11s/it]KNN Seeds:  45%|████▌     | 9/20 [02:16<02:46, 15.14s/it]KNN Seeds:  50%|█████     | 10/20 [02:31<02:31, 15.13s/it]KNN Seeds:  55%|█████▌    | 11/20 [02:46<02:16, 15.19s/it]KNN Seeds:  60%|██████    | 12/20 [03:01<02:01, 15.25s/it]KNN Seeds:  65%|██████▌   | 13/20 [03:17<01:46, 15.27s/it]KNN Seeds:  70%|███████   | 14/20 [03:32<01:31, 15.30s/it]KNN Seeds:  75%|███████▌  | 15/20 [03:48<01:16, 15.34s/it]KNN Seeds:  80%|████████  | 16/20 [04:03<01:01, 15.32s/it]KNN Seeds:  85%|████████▌ | 17/20 [04:18<00:45, 15.31s/it]KNN Seeds:  90%|█████████ | 18/20 [04:34<00:30, 15.35s/it]KNN Seeds:  95%|█████████▌| 19/20 [04:49<00:15, 15.33s/it]KNN Seeds: 100%|██████████| 20/20 [05:04<00:00, 15.37s/it]KNN Seeds: 100%|██████████| 20/20 [05:04<00:00, 15.24s/it]
24
(100, None, 'lbfgs')
(3023, 777)
(2418, 777)
(342, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:02<00:51,  2.72s/it]LR Seeds:  10%|█         | 2/20 [00:05<00:44,  2.50s/it]LR Seeds:  15%|█▌        | 3/20 [00:07<00:41,  2.42s/it]LR Seeds:  20%|██        | 4/20 [00:09<00:38,  2.41s/it]LR Seeds:  25%|██▌       | 5/20 [00:12<00:35,  2.40s/it]LR Seeds:  30%|███       | 6/20 [00:14<00:33,  2.40s/it]LR Seeds:  35%|███▌      | 7/20 [00:16<00:31,  2.39s/it]LR Seeds:  40%|████      | 8/20 [00:19<00:28,  2.39s/it]LR Seeds:  45%|████▌     | 9/20 [00:21<00:26,  2.39s/it]LR Seeds:  50%|█████     | 10/20 [00:24<00:23,  2.40s/it]LR Seeds:  55%|█████▌    | 11/20 [00:26<00:21,  2.40s/it]LR Seeds:  60%|██████    | 12/20 [00:28<00:19,  2.41s/it]LR Seeds:  65%|██████▌   | 13/20 [00:31<00:16,  2.43s/it]LR Seeds:  70%|███████   | 14/20 [00:33<00:14,  2.43s/it]LR Seeds:  75%|███████▌  | 15/20 [00:36<00:12,  2.45s/it]LR Seeds:  80%|████████  | 16/20 [00:38<00:09,  2.44s/it]LR Seeds:  85%|████████▌ | 17/20 [00:41<00:07,  2.50s/it]LR Seeds:  90%|█████████ | 18/20 [00:44<00:05,  2.55s/it]LR Seeds:  95%|█████████▌| 19/20 [00:46<00:02,  2.54s/it]LR Seeds: 100%|██████████| 20/20 [00:49<00:00,  2.54s/it]LR Seeds: 100%|██████████| 20/20 [00:49<00:00,  2.46s/it]
96
('rbf', 1, 1)
(3023, 777)
(2418, 777)
(342, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [01:28<27:59, 88.42s/it]SVM Seeds:  10%|█         | 2/20 [02:56<26:31, 88.40s/it]SVM Seeds:  15%|█▌        | 3/20 [04:25<25:03, 88.43s/it]SVM Seeds:  20%|██        | 4/20 [05:53<23:34, 88.42s/it]SVM Seeds:  25%|██▌       | 5/20 [07:22<22:06, 88.44s/it]SVM Seeds:  30%|███       | 6/20 [08:50<20:37, 88.41s/it]SVM Seeds:  35%|███▌      | 7/20 [10:18<19:09, 88.41s/it]SVM Seeds:  40%|████      | 8/20 [11:47<17:40, 88.38s/it]SVM Seeds:  45%|████▌     | 9/20 [13:15<16:12, 88.37s/it]SVM Seeds:  50%|█████     | 10/20 [14:43<14:43, 88.37s/it]SVM Seeds:  55%|█████▌    | 11/20 [16:12<13:14, 88.32s/it]SVM Seeds:  60%|██████    | 12/20 [17:40<11:46, 88.32s/it]SVM Seeds:  65%|██████▌   | 13/20 [19:08<10:18, 88.29s/it]SVM Seeds:  70%|███████   | 14/20 [20:36<08:49, 88.23s/it]SVM Seeds:  75%|███████▌  | 15/20 [22:04<07:21, 88.22s/it]SVM Seeds:  80%|████████  | 16/20 [23:33<05:52, 88.20s/it]SVM Seeds:  85%|████████▌ | 17/20 [25:01<04:24, 88.23s/it]SVM Seeds:  90%|█████████ | 18/20 [26:29<02:56, 88.24s/it]SVM Seeds:  95%|█████████▌| 19/20 [27:57<01:28, 88.20s/it]SVM Seeds: 100%|██████████| 20/20 [29:26<00:00, 88.23s/it]SVM Seeds: 100%|██████████| 20/20 [29:26<00:00, 88.30s/it]
200
(500, None, 70, 1, 'balanced')
(3023, 777)
(2418, 777)
(342, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:08<02:47,  8.79s/it]RF Seeds:  10%|█         | 2/20 [00:17<02:38,  8.78s/it]RF Seeds:  15%|█▌        | 3/20 [00:26<02:29,  8.80s/it]RF Seeds:  20%|██        | 4/20 [00:35<02:20,  8.81s/it]RF Seeds:  25%|██▌       | 5/20 [00:44<02:12,  8.82s/it]RF Seeds:  30%|███       | 6/20 [00:52<02:03,  8.82s/it]RF Seeds:  35%|███▌      | 7/20 [01:01<01:54,  8.84s/it]RF Seeds:  40%|████      | 8/20 [01:10<01:46,  8.84s/it]RF Seeds:  45%|████▌     | 9/20 [01:19<01:37,  8.86s/it]RF Seeds:  50%|█████     | 10/20 [01:28<01:28,  8.90s/it]RF Seeds:  55%|█████▌    | 11/20 [01:37<01:20,  8.90s/it]RF Seeds:  60%|██████    | 12/20 [01:46<01:11,  8.89s/it]RF Seeds:  65%|██████▌   | 13/20 [01:55<01:02,  8.90s/it]RF Seeds:  70%|███████   | 14/20 [02:04<00:53,  8.90s/it]RF Seeds:  75%|███████▌  | 15/20 [02:12<00:44,  8.91s/it]RF Seeds:  80%|████████  | 16/20 [02:21<00:35,  8.93s/it]RF Seeds:  85%|████████▌ | 17/20 [02:31<00:26,  8.99s/it]RF Seeds:  90%|█████████ | 18/20 [02:40<00:17,  8.99s/it]RF Seeds:  95%|█████████▌| 19/20 [02:49<00:08,  8.99s/it]RF Seeds: 100%|██████████| 20/20 [02:58<00:00,  8.99s/it]RF Seeds: 100%|██████████| 20/20 [02:58<00:00,  8.90s/it]
400
(0.01, 900, 7, 0.8, 6)
(3023, 777)
(2418, 777)
(342, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:44<14:08, 44.64s/it]XGBoost Seeds:  10%|█         | 2/20 [01:29<13:24, 44.71s/it]XGBoost Seeds:  15%|█▌        | 3/20 [02:14<12:41, 44.78s/it]XGBoost Seeds:  20%|██        | 4/20 [02:59<11:56, 44.79s/it]XGBoost Seeds:  25%|██▌       | 5/20 [03:43<11:12, 44.80s/it]XGBoost Seeds:  30%|███       | 6/20 [04:28<10:27, 44.81s/it]XGBoost Seeds:  35%|███▌      | 7/20 [05:13<09:43, 44.86s/it]XGBoost Seeds:  40%|████      | 8/20 [05:58<08:58, 44.89s/it]XGBoost Seeds:  45%|████▌     | 9/20 [06:43<08:13, 44.86s/it]XGBoost Seeds:  50%|█████     | 10/20 [07:28<07:28, 44.88s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [08:13<06:43, 44.86s/it]XGBoost Seeds:  60%|██████    | 12/20 [08:58<05:59, 44.89s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [09:42<05:14, 44.86s/it]XGBoost Seeds:  70%|███████   | 14/20 [10:27<04:29, 44.85s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [11:12<03:44, 44.89s/it]XGBoost Seeds:  80%|████████  | 16/20 [11:57<02:59, 44.90s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [12:42<02:14, 44.92s/it]XGBoost Seeds:  90%|█████████ | 18/20 [13:27<01:29, 44.88s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [14:12<00:44, 44.88s/it]XGBoost Seeds: 100%|██████████| 20/20 [14:57<00:00, 44.87s/it]XGBoost Seeds: 100%|██████████| 20/20 [14:57<00:00, 44.86s/it]
knn:  96
lr:  98
svm:  85
rf:  96
xgboost:  74
Combining validation predictions is completed
knn:  96
lr:  98
svm:  85
rf:  96
xgboost:  74
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 2.2680 - acc: 0.5000
484/484 [==============================] - 0s 562us/step - loss: 1.5398 - acc: 0.7707 - val_loss: 1.4349 - val_acc: 0.4545

Epoch 00001: loss improved from inf to 1.53979, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 1.9766 - acc: 0.7188
484/484 [==============================] - 0s 34us/step - loss: 1.4576 - acc: 0.8409 - val_loss: 1.0731 - val_acc: 0.8099

Epoch 00002: loss improved from 1.53979 to 1.45757, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3343 - acc: 0.8125
484/484 [==============================] - 0s 32us/step - loss: 1.3259 - acc: 0.8781 - val_loss: 1.0201 - val_acc: 0.8430

Epoch 00003: loss improved from 1.45757 to 1.32595, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.7215 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.2435 - acc: 0.8740 - val_loss: 1.0008 - val_acc: 0.8264

Epoch 00004: loss improved from 1.32595 to 1.24354, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0183 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 1.1287 - acc: 0.8967 - val_loss: 0.9211 - val_acc: 0.8430

Epoch 00005: loss improved from 1.24354 to 1.12871, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1346 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.0969 - acc: 0.8988 - val_loss: 0.9422 - val_acc: 0.8430

Epoch 00006: loss improved from 1.12871 to 1.09692, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0473 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 1.0173 - acc: 0.9070 - val_loss: 0.9257 - val_acc: 0.8099

Epoch 00007: loss improved from 1.09692 to 1.01729, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1556 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.0116 - acc: 0.9008 - val_loss: 0.9092 - val_acc: 0.8099

Epoch 00008: loss improved from 1.01729 to 1.01163, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8310 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 1.0072 - acc: 0.9132 - val_loss: 0.8664 - val_acc: 0.8182

Epoch 00009: loss improved from 1.01163 to 1.00721, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8848 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 0.9397 - acc: 0.9174 - val_loss: 0.8907 - val_acc: 0.8678

Epoch 00010: loss improved from 1.00721 to 0.93967, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8575 - acc: 0.9688
484/484 [==============================] - 0s 31us/step - loss: 0.9167 - acc: 0.9112 - val_loss: 0.8520 - val_acc: 0.8017

Epoch 00011: loss improved from 0.93967 to 0.91673, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7132 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 0.9138 - acc: 0.9194 - val_loss: 0.8823 - val_acc: 0.7603

Epoch 00012: loss improved from 0.91673 to 0.91383, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4124 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 0.9577 - acc: 0.8905 - val_loss: 0.8494 - val_acc: 0.8182

Epoch 00013: loss did not improve from 0.91383
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8643 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 0.9499 - acc: 0.8946 - val_loss: 0.9054 - val_acc: 0.7934

Epoch 00014: loss did not improve from 0.91383
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 0.5772 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 0.8098 - acc: 0.9298 - val_loss: 0.8915 - val_acc: 0.8182

Epoch 00015: loss improved from 0.91383 to 0.80984, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 0.5038 - acc: 1.0000
484/484 [==============================] - 0s 30us/step - loss: 0.8236 - acc: 0.9215 - val_loss: 0.7893 - val_acc: 0.8347

Epoch 00016: loss did not improve from 0.80984
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6613 - acc: 1.0000
484/484 [==============================] - 0s 30us/step - loss: 0.8055 - acc: 0.9215 - val_loss: 0.9801 - val_acc: 0.7769

Epoch 00017: loss improved from 0.80984 to 0.80552, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6791 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 0.7817 - acc: 0.9153 - val_loss: 0.9471 - val_acc: 0.8099

Epoch 00018: loss improved from 0.80552 to 0.78174, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 19/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9964 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 0.8841 - acc: 0.9070 - val_loss: 0.9220 - val_acc: 0.7769

Epoch 00019: loss did not improve from 0.78174
Epoch 20/100

 32/484 [>.............................] - ETA: 0s - loss: 0.5679 - acc: 1.0000
484/484 [==============================] - 0s 30us/step - loss: 0.7273 - acc: 0.9380 - val_loss: 0.8490 - val_acc: 0.7438

Epoch 00020: loss improved from 0.78174 to 0.72733, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_6.h5
Epoch 21/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6196 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 0.7979 - acc: 0.9277 - val_loss: 0.8550 - val_acc: 0.8099

Epoch 00021: loss did not improve from 0.72733
Epoch 22/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7904 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 0.7998 - acc: 0.8967 - val_loss: 0.7960 - val_acc: 0.8182

Epoch 00022: loss did not improve from 0.72733
Epoch 23/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6965 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 0.7994 - acc: 0.9194 - val_loss: 0.8232 - val_acc: 0.8182

Epoch 00023: loss did not improve from 0.72733
Epoch 24/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9089 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 0.7603 - acc: 0.9091 - val_loss: 0.7785 - val_acc: 0.7851

Epoch 00024: loss did not improve from 0.72733
Epoch 25/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6411 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 0.7324 - acc: 0.9318 - val_loss: 0.8413 - val_acc: 0.8099
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:22,  1.92s/it]
Epoch 00025: loss did not improve from 0.72733
Epoch 00025: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 2.1207 - acc: 0.6562
484/484 [==============================] - 0s 577us/step - loss: 1.6617 - acc: 0.7459 - val_loss: 1.2060 - val_acc: 0.7025

Epoch 00001: loss improved from inf to 1.66172, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4813 - acc: 0.8125
484/484 [==============================] - 0s 33us/step - loss: 1.4215 - acc: 0.8264 - val_loss: 1.1267 - val_acc: 0.7769

Epoch 00002: loss improved from 1.66172 to 1.42151, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4516 - acc: 0.8750
484/484 [==============================] - 0s 33us/step - loss: 1.3013 - acc: 0.8678 - val_loss: 1.0547 - val_acc: 0.8099

Epoch 00003: loss improved from 1.42151 to 1.30130, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1708 - acc: 0.8750
484/484 [==============================] - 0s 32us/step - loss: 1.2594 - acc: 0.8595 - val_loss: 1.1452 - val_acc: 0.7851

Epoch 00004: loss improved from 1.30130 to 1.25941, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2507 - acc: 0.8125
484/484 [==============================] - 0s 32us/step - loss: 1.1199 - acc: 0.9050 - val_loss: 1.0263 - val_acc: 0.8347

Epoch 00005: loss improved from 1.25941 to 1.11986, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9883 - acc: 0.9375
484/484 [==============================] - 0s 32us/step - loss: 1.1412 - acc: 0.8864 - val_loss: 0.8743 - val_acc: 0.8760

Epoch 00006: loss did not improve from 1.11986
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1411 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.0652 - acc: 0.9008 - val_loss: 0.8999 - val_acc: 0.8678

Epoch 00007: loss improved from 1.11986 to 1.06521, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0593 - acc: 0.9062
484/484 [==============================] - 0s 32us/step - loss: 1.0572 - acc: 0.9029 - val_loss: 0.9905 - val_acc: 0.7686

Epoch 00008: loss improved from 1.06521 to 1.05721, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0412 - acc: 0.8438
484/484 [==============================] - 0s 32us/step - loss: 1.0548 - acc: 0.8905 - val_loss: 1.0473 - val_acc: 0.7934

Epoch 00009: loss improved from 1.05721 to 1.05477, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9726 - acc: 0.9375
484/484 [==============================] - 0s 32us/step - loss: 1.0600 - acc: 0.9008 - val_loss: 1.0284 - val_acc: 0.8182

Epoch 00010: loss did not improve from 1.05477
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1911 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 0.9869 - acc: 0.8946 - val_loss: 0.8459 - val_acc: 0.8264

Epoch 00011: loss improved from 1.05477 to 0.98689, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7353 - acc: 0.9688
484/484 [==============================] - 0s 32us/step - loss: 1.0232 - acc: 0.8967 - val_loss: 0.9969 - val_acc: 0.7934

Epoch 00012: loss did not improve from 0.98689
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0716 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.0216 - acc: 0.8905 - val_loss: 0.9759 - val_acc: 0.7851

Epoch 00013: loss did not improve from 0.98689
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8447 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 0.9627 - acc: 0.8946 - val_loss: 1.0933 - val_acc: 0.7190

Epoch 00014: loss improved from 0.98689 to 0.96274, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8824 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 0.9384 - acc: 0.8926 - val_loss: 1.0694 - val_acc: 0.7355

Epoch 00015: loss improved from 0.96274 to 0.93839, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3884 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 0.9799 - acc: 0.8905 - val_loss: 0.8706 - val_acc: 0.7603

Epoch 00016: loss did not improve from 0.93839
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7460 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 0.8337 - acc: 0.9236 - val_loss: 0.9284 - val_acc: 0.7686

Epoch 00017: loss improved from 0.93839 to 0.83375, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6150 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 0.8822 - acc: 0.9070 - val_loss: 1.0055 - val_acc: 0.7438

Epoch 00018: loss did not improve from 0.83375
Epoch 19/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2275 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 0.9552 - acc: 0.8864 - val_loss: 1.1332 - val_acc: 0.7190

Epoch 00019: loss did not improve from 0.83375
Epoch 20/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7758 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 0.8483 - acc: 0.9153 - val_loss: 0.9026 - val_acc: 0.8017

Epoch 00020: loss did not improve from 0.83375
Epoch 21/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6360 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 0.8049 - acc: 0.9132 - val_loss: 0.9706 - val_acc: 0.7438

Epoch 00021: loss improved from 0.83375 to 0.80487, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 22/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7537 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 0.7708 - acc: 0.9256 - val_loss: 0.9101 - val_acc: 0.7521

Epoch 00022: loss improved from 0.80487 to 0.77081, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 23/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6248 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 0.7917 - acc: 0.9215 - val_loss: 0.8183 - val_acc: 0.7521

Epoch 00023: loss did not improve from 0.77081
Epoch 24/100

 32/484 [>.............................] - ETA: 0s - loss: 0.4543 - acc: 0.9688
484/484 [==============================] - 0s 30us/step - loss: 0.7178 - acc: 0.9442 - val_loss: 0.7675 - val_acc: 0.8099

Epoch 00024: loss improved from 0.77081 to 0.71775, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 25/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7446 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 0.7657 - acc: 0.9153 - val_loss: 0.7405 - val_acc: 0.7934

Epoch 00025: loss did not improve from 0.71775
Epoch 26/100

 32/484 [>.............................] - ETA: 0s - loss: 0.4711 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 0.7626 - acc: 0.9112 - val_loss: 0.9648 - val_acc: 0.7438

Epoch 00026: loss did not improve from 0.71775
Epoch 27/100

 32/484 [>.............................] - ETA: 0s - loss: 0.5800 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 0.8507 - acc: 0.8988 - val_loss: 0.9311 - val_acc: 0.6446

Epoch 00027: loss did not improve from 0.71775
Epoch 28/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7489 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 0.6874 - acc: 0.9298 - val_loss: 0.8330 - val_acc: 0.7686

Epoch 00028: loss improved from 0.71775 to 0.68737, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_7.h5
Epoch 29/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6252 - acc: 0.9688
484/484 [==============================] - 0s 31us/step - loss: 0.8422 - acc: 0.9215 - val_loss: 0.8728 - val_acc: 0.8099

Epoch 00029: loss did not improve from 0.68737
Epoch 30/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8483 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 0.8648 - acc: 0.9112 - val_loss: 0.6939 - val_acc: 0.8512

Epoch 00030: loss did not improve from 0.68737
Epoch 31/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1058 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 0.7191 - acc: 0.9277 - val_loss: 0.6330 - val_acc: 0.8678

Epoch 00031: loss did not improve from 0.68737
Epoch 32/100

 32/484 [>.............................] - ETA: 0s - loss: 0.5767 - acc: 0.9688
484/484 [==============================] - 0s 30us/step - loss: 0.7528 - acc: 0.9236 - val_loss: 0.6346 - val_acc: 0.8678

Epoch 00032: loss did not improve from 0.68737
Epoch 33/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6675 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 0.8592 - acc: 0.9029 - val_loss: 0.8528 - val_acc: 0.8182
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:04<00:22,  2.07s/it]
Epoch 00033: loss did not improve from 0.68737
Epoch 00033: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 2.8885 - acc: 0.5625
484/484 [==============================] - 0s 559us/step - loss: 1.7488 - acc: 0.7397 - val_loss: 1.1248 - val_acc: 0.8099

Epoch 00001: loss improved from inf to 1.74882, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 1.8421 - acc: 0.7500
484/484 [==============================] - 0s 33us/step - loss: 1.4928 - acc: 0.8306 - val_loss: 1.0949 - val_acc: 0.7769

Epoch 00002: loss improved from 1.74882 to 1.49278, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3413 - acc: 0.8125
484/484 [==============================] - 0s 32us/step - loss: 1.3599 - acc: 0.8678 - val_loss: 1.1023 - val_acc: 0.7025

Epoch 00003: loss improved from 1.49278 to 1.35988, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3809 - acc: 0.7812
484/484 [==============================] - 0s 31us/step - loss: 1.3142 - acc: 0.8616 - val_loss: 1.0497 - val_acc: 0.7438

Epoch 00004: loss improved from 1.35988 to 1.31421, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2377 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.2991 - acc: 0.8678 - val_loss: 1.0977 - val_acc: 0.7355

Epoch 00005: loss improved from 1.31421 to 1.29906, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2964 - acc: 0.7812
484/484 [==============================] - 0s 32us/step - loss: 1.2325 - acc: 0.8760 - val_loss: 1.0388 - val_acc: 0.7438

Epoch 00006: loss improved from 1.29906 to 1.23247, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2015 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.1833 - acc: 0.8988 - val_loss: 0.9993 - val_acc: 0.7438

Epoch 00007: loss improved from 1.23247 to 1.18335, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9335 - acc: 0.9688
484/484 [==============================] - 0s 30us/step - loss: 1.0638 - acc: 0.9153 - val_loss: 1.0272 - val_acc: 0.7190

Epoch 00008: loss improved from 1.18335 to 1.06380, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8405 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 1.0167 - acc: 0.9132 - val_loss: 1.0095 - val_acc: 0.7107

Epoch 00009: loss improved from 1.06380 to 1.01667, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7715 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 0.9319 - acc: 0.9194 - val_loss: 0.8950 - val_acc: 0.8017

Epoch 00010: loss improved from 1.01667 to 0.93191, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7751 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 0.9668 - acc: 0.9215 - val_loss: 0.9983 - val_acc: 0.7355

Epoch 00011: loss did not improve from 0.93191
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0767 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 0.9966 - acc: 0.9153 - val_loss: 0.9444 - val_acc: 0.7107

Epoch 00012: loss did not improve from 0.93191
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0227 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 1.1191 - acc: 0.8905 - val_loss: 0.9336 - val_acc: 0.7438

Epoch 00013: loss did not improve from 0.93191
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7296 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 1.0425 - acc: 0.9029 - val_loss: 1.1645 - val_acc: 0.7851

Epoch 00014: loss did not improve from 0.93191
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4001 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.1300 - acc: 0.8946 - val_loss: 0.9359 - val_acc: 0.8264
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:05<00:19,  1.96s/it]
Epoch 00015: loss did not improve from 0.93191
Epoch 00015: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 1.9092 - acc: 0.5312
484/484 [==============================] - 0s 562us/step - loss: 1.8342 - acc: 0.7314 - val_loss: 1.2876 - val_acc: 0.7107

Epoch 00001: loss improved from inf to 1.83420, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4524 - acc: 0.7812
484/484 [==============================] - 0s 33us/step - loss: 1.5013 - acc: 0.8430 - val_loss: 1.1852 - val_acc: 0.7273

Epoch 00002: loss improved from 1.83420 to 1.50129, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6964 - acc: 0.8125
484/484 [==============================] - 0s 32us/step - loss: 1.5293 - acc: 0.8368 - val_loss: 1.2555 - val_acc: 0.6777

Epoch 00003: loss did not improve from 1.50129
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4720 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.4342 - acc: 0.8554 - val_loss: 1.0819 - val_acc: 0.7851

Epoch 00004: loss improved from 1.50129 to 1.43415, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6144 - acc: 0.8125
484/484 [==============================] - 0s 32us/step - loss: 1.4168 - acc: 0.8698 - val_loss: 1.0967 - val_acc: 0.7851

Epoch 00005: loss improved from 1.43415 to 1.41684, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2511 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 1.3169 - acc: 0.8698 - val_loss: 1.1741 - val_acc: 0.7273

Epoch 00006: loss improved from 1.41684 to 1.31691, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1014 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.3322 - acc: 0.8471 - val_loss: 1.0902 - val_acc: 0.7851

Epoch 00007: loss did not improve from 1.31691
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2623 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.1700 - acc: 0.8864 - val_loss: 0.9597 - val_acc: 0.8017

Epoch 00008: loss improved from 1.31691 to 1.17004, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8677 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 1.1612 - acc: 0.8843 - val_loss: 0.9553 - val_acc: 0.7934

Epoch 00009: loss improved from 1.17004 to 1.16116, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9281 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 1.0252 - acc: 0.9070 - val_loss: 0.9872 - val_acc: 0.7521

Epoch 00010: loss improved from 1.16116 to 1.02524, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0663 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.1394 - acc: 0.8926 - val_loss: 1.3384 - val_acc: 0.6281

Epoch 00011: loss did not improve from 1.02524
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9089 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.0817 - acc: 0.8884 - val_loss: 1.1830 - val_acc: 0.7273

Epoch 00012: loss did not improve from 1.02524
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2217 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 1.0861 - acc: 0.8905 - val_loss: 1.0215 - val_acc: 0.7438

Epoch 00013: loss did not improve from 1.02524
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9312 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 0.9650 - acc: 0.9070 - val_loss: 0.9871 - val_acc: 0.7934

Epoch 00014: loss improved from 1.02524 to 0.96502, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1182 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 0.9505 - acc: 0.9091 - val_loss: 0.8973 - val_acc: 0.7686

Epoch 00015: loss improved from 0.96502 to 0.95050, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7659 - acc: 0.9688
484/484 [==============================] - 0s 31us/step - loss: 0.8203 - acc: 0.9421 - val_loss: 1.0009 - val_acc: 0.8017

Epoch 00016: loss improved from 0.95050 to 0.82034, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_9.h5
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6527 - acc: 0.9688
484/484 [==============================] - 0s 31us/step - loss: 0.8899 - acc: 0.9070 - val_loss: 0.9141 - val_acc: 0.7521

Epoch 00017: loss did not improve from 0.82034
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6489 - acc: 0.9688
484/484 [==============================] - 0s 30us/step - loss: 0.9649 - acc: 0.8884 - val_loss: 0.8512 - val_acc: 0.8017

Epoch 00018: loss did not improve from 0.82034
Epoch 19/100

 32/484 [>.............................] - ETA: 0s - loss: 0.5848 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 0.9827 - acc: 0.8905 - val_loss: 0.9289 - val_acc: 0.8182

Epoch 00019: loss did not improve from 0.82034
Epoch 20/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8062 - acc: 0.9688
484/484 [==============================] - 0s 30us/step - loss: 0.9751 - acc: 0.9091 - val_loss: 0.9441 - val_acc: 0.7686

Epoch 00020: loss did not improve from 0.82034
Epoch 21/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0398 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 1.0349 - acc: 0.8905 - val_loss: 0.9976 - val_acc: 0.7273
DeepAmes+ Weights:  31%|███       | 4/13 [00:07<00:17,  1.90s/it]
Epoch 00021: loss did not improve from 0.82034
Epoch 00021: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 2.5409 - acc: 0.6562
484/484 [==============================] - 0s 568us/step - loss: 1.8603 - acc: 0.7045 - val_loss: 1.3375 - val_acc: 0.5785

Epoch 00001: loss improved from inf to 1.86033, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 2.3023 - acc: 0.7188
484/484 [==============================] - 0s 33us/step - loss: 1.6535 - acc: 0.8223 - val_loss: 1.3182 - val_acc: 0.6694

Epoch 00002: loss improved from 1.86033 to 1.65349, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5357 - acc: 0.9062
484/484 [==============================] - 0s 32us/step - loss: 1.5117 - acc: 0.8450 - val_loss: 1.1370 - val_acc: 0.7851

Epoch 00003: loss improved from 1.65349 to 1.51174, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5834 - acc: 0.8125
484/484 [==============================] - 0s 32us/step - loss: 1.4218 - acc: 0.8595 - val_loss: 1.1047 - val_acc: 0.7769

Epoch 00004: loss improved from 1.51174 to 1.42176, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3257 - acc: 0.8750
484/484 [==============================] - 0s 32us/step - loss: 1.3485 - acc: 0.8926 - val_loss: 1.0441 - val_acc: 0.7107

Epoch 00005: loss improved from 1.42176 to 1.34847, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2533 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.3382 - acc: 0.8678 - val_loss: 1.0842 - val_acc: 0.7521

Epoch 00006: loss improved from 1.34847 to 1.33818, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6838 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.3047 - acc: 0.8636 - val_loss: 0.9153 - val_acc: 0.8099

Epoch 00007: loss improved from 1.33818 to 1.30472, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2717 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.2988 - acc: 0.8595 - val_loss: 1.1167 - val_acc: 0.7521

Epoch 00008: loss improved from 1.30472 to 1.29881, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4286 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.2199 - acc: 0.8884 - val_loss: 1.0644 - val_acc: 0.8099

Epoch 00009: loss improved from 1.29881 to 1.21986, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1758 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.1836 - acc: 0.8740 - val_loss: 1.0443 - val_acc: 0.8099

Epoch 00010: loss improved from 1.21986 to 1.18358, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 1.8916 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.2242 - acc: 0.8740 - val_loss: 0.9728 - val_acc: 0.8182

Epoch 00011: loss did not improve from 1.18358
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1226 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 1.0685 - acc: 0.9112 - val_loss: 0.8667 - val_acc: 0.8264

Epoch 00012: loss improved from 1.18358 to 1.06855, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1581 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 1.0980 - acc: 0.8946 - val_loss: 0.8926 - val_acc: 0.7521

Epoch 00013: loss did not improve from 1.06855
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8693 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 1.1261 - acc: 0.8843 - val_loss: 0.8452 - val_acc: 0.8017

Epoch 00014: loss did not improve from 1.06855
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7781 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 1.0971 - acc: 0.8967 - val_loss: 0.8448 - val_acc: 0.7934

Epoch 00015: loss did not improve from 1.06855
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8007 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 0.8698 - acc: 0.9174 - val_loss: 0.8061 - val_acc: 0.8264

Epoch 00016: loss improved from 1.06855 to 0.86984, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_10.h5
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0759 - acc: 0.9375
484/484 [==============================] - 0s 31us/step - loss: 1.0237 - acc: 0.8843 - val_loss: 0.8143 - val_acc: 0.8099

Epoch 00017: loss did not improve from 0.86984
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8206 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.0407 - acc: 0.9091 - val_loss: 0.8229 - val_acc: 0.8017

Epoch 00018: loss did not improve from 0.86984
Epoch 19/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5102 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.1540 - acc: 0.8864 - val_loss: 0.8732 - val_acc: 0.7273

Epoch 00019: loss did not improve from 0.86984
Epoch 20/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0081 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.0175 - acc: 0.8802 - val_loss: 0.9094 - val_acc: 0.7438

Epoch 00020: loss did not improve from 0.86984
Epoch 21/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0100 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 0.9856 - acc: 0.9050 - val_loss: 0.9173 - val_acc: 0.7603
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:09<00:15,  1.92s/it]
Epoch 00021: loss did not improve from 0.86984
Epoch 00021: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 3.3606 - acc: 0.4688
484/484 [==============================] - 0s 557us/step - loss: 1.9684 - acc: 0.7190 - val_loss: 1.3379 - val_acc: 0.6529

Epoch 00001: loss improved from inf to 1.96839, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5407 - acc: 0.8750
484/484 [==============================] - 0s 33us/step - loss: 1.6956 - acc: 0.8058 - val_loss: 1.2071 - val_acc: 0.6694

Epoch 00002: loss improved from 1.96839 to 1.69556, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 2.0132 - acc: 0.7188
484/484 [==============================] - 0s 31us/step - loss: 1.7494 - acc: 0.7603 - val_loss: 1.1859 - val_acc: 0.7355

Epoch 00003: loss did not improve from 1.69556
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4336 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.4780 - acc: 0.8223 - val_loss: 1.0715 - val_acc: 0.7934

Epoch 00004: loss improved from 1.69556 to 1.47805, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2637 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.3724 - acc: 0.8264 - val_loss: 1.0322 - val_acc: 0.8017

Epoch 00005: loss improved from 1.47805 to 1.37240, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2960 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.3100 - acc: 0.8657 - val_loss: 0.9906 - val_acc: 0.8099

Epoch 00006: loss improved from 1.37240 to 1.31002, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1381 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.3327 - acc: 0.8760 - val_loss: 1.0195 - val_acc: 0.6777

Epoch 00007: loss did not improve from 1.31002
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9073 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 1.2222 - acc: 0.8636 - val_loss: 0.9883 - val_acc: 0.7521

Epoch 00008: loss improved from 1.31002 to 1.22217, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0543 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 1.2330 - acc: 0.8657 - val_loss: 1.0346 - val_acc: 0.7603

Epoch 00009: loss did not improve from 1.22217
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6784 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.3168 - acc: 0.8492 - val_loss: 0.9301 - val_acc: 0.7107

Epoch 00010: loss did not improve from 1.22217
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9566 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 1.1841 - acc: 0.8802 - val_loss: 0.8663 - val_acc: 0.8430

Epoch 00011: loss improved from 1.22217 to 1.18409, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3082 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.2154 - acc: 0.8843 - val_loss: 1.0517 - val_acc: 0.7438

Epoch 00012: loss did not improve from 1.18409
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6638 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.2585 - acc: 0.8492 - val_loss: 1.0592 - val_acc: 0.6860

Epoch 00013: loss did not improve from 1.18409
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3442 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.1673 - acc: 0.8326 - val_loss: 1.0701 - val_acc: 0.6694

Epoch 00014: loss improved from 1.18409 to 1.16730, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8124 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 1.0713 - acc: 0.8698 - val_loss: 0.9839 - val_acc: 0.7190

Epoch 00015: loss improved from 1.16730 to 1.07135, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7547 - acc: 0.9375
484/484 [==============================] - 0s 30us/step - loss: 1.1613 - acc: 0.8636 - val_loss: 1.0833 - val_acc: 0.7025

Epoch 00016: loss did not improve from 1.07135
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8657 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.0513 - acc: 0.8905 - val_loss: 1.0972 - val_acc: 0.7025

Epoch 00017: loss improved from 1.07135 to 1.05132, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9112 - acc: 0.7812
484/484 [==============================] - 0s 30us/step - loss: 1.0369 - acc: 0.8864 - val_loss: 1.0000 - val_acc: 0.7769

Epoch 00018: loss improved from 1.05132 to 1.03689, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 19/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5132 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.2673 - acc: 0.8450 - val_loss: 1.0694 - val_acc: 0.7107

Epoch 00019: loss did not improve from 1.03689
Epoch 20/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0103 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.0560 - acc: 0.8781 - val_loss: 1.0068 - val_acc: 0.6860

Epoch 00020: loss did not improve from 1.03689
Epoch 21/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8103 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 0.9373 - acc: 0.9091 - val_loss: 1.1596 - val_acc: 0.7438

Epoch 00021: loss improved from 1.03689 to 0.93725, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_11.h5
Epoch 22/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8640 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.0245 - acc: 0.8822 - val_loss: 1.0228 - val_acc: 0.7521

Epoch 00022: loss did not improve from 0.93725
Epoch 23/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6835 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.0120 - acc: 0.9070 - val_loss: 1.1076 - val_acc: 0.5289

Epoch 00023: loss did not improve from 0.93725
Epoch 24/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0627 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 1.0720 - acc: 0.8864 - val_loss: 0.9262 - val_acc: 0.7686

Epoch 00024: loss did not improve from 0.93725
Epoch 25/100

 32/484 [>.............................] - ETA: 0s - loss: 0.5924 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 0.9489 - acc: 0.8926 - val_loss: 0.9680 - val_acc: 0.7686

Epoch 00025: loss did not improve from 0.93725
Epoch 26/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1805 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 1.0376 - acc: 0.8843 - val_loss: 0.9401 - val_acc: 0.7521
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:11<00:13,  1.95s/it]
Epoch 00026: loss did not improve from 0.93725
Epoch 00026: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 3.6886 - acc: 0.5625
484/484 [==============================] - 0s 564us/step - loss: 2.1500 - acc: 0.7004 - val_loss: 1.4007 - val_acc: 0.6033

Epoch 00001: loss improved from inf to 2.15001, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5289 - acc: 0.8125
484/484 [==============================] - 0s 34us/step - loss: 1.7459 - acc: 0.7934 - val_loss: 1.2404 - val_acc: 0.6364

Epoch 00002: loss improved from 2.15001 to 1.74590, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6566 - acc: 0.7188
484/484 [==============================] - 0s 33us/step - loss: 1.6107 - acc: 0.7872 - val_loss: 1.1545 - val_acc: 0.6777

Epoch 00003: loss improved from 1.74590 to 1.61067, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4203 - acc: 0.7500
484/484 [==============================] - 0s 31us/step - loss: 1.5716 - acc: 0.7810 - val_loss: 1.1500 - val_acc: 0.7025

Epoch 00004: loss improved from 1.61067 to 1.57164, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1756 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 1.5187 - acc: 0.8347 - val_loss: 1.2162 - val_acc: 0.6777

Epoch 00005: loss improved from 1.57164 to 1.51869, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4764 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.5206 - acc: 0.8202 - val_loss: 1.1327 - val_acc: 0.7438

Epoch 00006: loss did not improve from 1.51869
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5409 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.3924 - acc: 0.8450 - val_loss: 1.1137 - val_acc: 0.6777

Epoch 00007: loss improved from 1.51869 to 1.39241, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3799 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.3748 - acc: 0.8223 - val_loss: 0.9894 - val_acc: 0.7273

Epoch 00008: loss improved from 1.39241 to 1.37482, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0409 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.3467 - acc: 0.8533 - val_loss: 0.9854 - val_acc: 0.7025

Epoch 00009: loss improved from 1.37482 to 1.34673, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6026 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.2971 - acc: 0.8533 - val_loss: 1.2432 - val_acc: 0.6612

Epoch 00010: loss improved from 1.34673 to 1.29708, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0950 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 1.2756 - acc: 0.8636 - val_loss: 1.1115 - val_acc: 0.7190

Epoch 00011: loss improved from 1.29708 to 1.27563, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8751 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.1736 - acc: 0.8719 - val_loss: 1.0735 - val_acc: 0.6942

Epoch 00012: loss improved from 1.27563 to 1.17359, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2736 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.1852 - acc: 0.8781 - val_loss: 1.0981 - val_acc: 0.6694

Epoch 00013: loss did not improve from 1.17359
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8243 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.0981 - acc: 0.8616 - val_loss: 0.9955 - val_acc: 0.6777

Epoch 00014: loss improved from 1.17359 to 1.09809, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3328 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.3590 - acc: 0.8430 - val_loss: 0.9891 - val_acc: 0.7273

Epoch 00015: loss did not improve from 1.09809
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9149 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.1558 - acc: 0.8533 - val_loss: 0.9821 - val_acc: 0.7603

Epoch 00016: loss did not improve from 1.09809
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9981 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.2129 - acc: 0.8616 - val_loss: 0.9286 - val_acc: 0.7355

Epoch 00017: loss did not improve from 1.09809
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8769 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.0815 - acc: 0.8802 - val_loss: 1.0232 - val_acc: 0.7603

Epoch 00018: loss improved from 1.09809 to 1.08150, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 19/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6792 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.0307 - acc: 0.8864 - val_loss: 1.0718 - val_acc: 0.7025

Epoch 00019: loss improved from 1.08150 to 1.03068, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 20/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3757 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.1118 - acc: 0.8884 - val_loss: 0.9801 - val_acc: 0.7521

Epoch 00020: loss did not improve from 1.03068
Epoch 21/100

 32/484 [>.............................] - ETA: 0s - loss: 2.2436 - acc: 0.7188
484/484 [==============================] - 0s 30us/step - loss: 1.2686 - acc: 0.8533 - val_loss: 1.2980 - val_acc: 0.6777

Epoch 00021: loss did not improve from 1.03068
Epoch 22/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1777 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.1118 - acc: 0.8595 - val_loss: 1.0978 - val_acc: 0.7355

Epoch 00022: loss did not improve from 1.03068
Epoch 23/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8592 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 0.9483 - acc: 0.8967 - val_loss: 1.0454 - val_acc: 0.7769

Epoch 00023: loss improved from 1.03068 to 0.94829, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 24/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7315 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 0.8796 - acc: 0.8967 - val_loss: 1.0001 - val_acc: 0.6446

Epoch 00024: loss improved from 0.94829 to 0.87960, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_12.h5
Epoch 25/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6153 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 0.9667 - acc: 0.9050 - val_loss: 1.0445 - val_acc: 0.7521

Epoch 00025: loss did not improve from 0.87960
Epoch 26/100

 32/484 [>.............................] - ETA: 0s - loss: 0.6442 - acc: 0.9688
484/484 [==============================] - 0s 31us/step - loss: 0.9175 - acc: 0.9112 - val_loss: 0.8380 - val_acc: 0.8017

Epoch 00026: loss did not improve from 0.87960
Epoch 27/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3874 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.1687 - acc: 0.8822 - val_loss: 1.0705 - val_acc: 0.6446

Epoch 00027: loss did not improve from 0.87960
Epoch 28/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8850 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 0.8835 - acc: 0.9070 - val_loss: 1.0810 - val_acc: 0.6860

Epoch 00028: loss did not improve from 0.87960
Epoch 29/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9160 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 0.9844 - acc: 0.8781 - val_loss: 0.8687 - val_acc: 0.7686
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:13<00:11,  1.96s/it]
Epoch 00029: loss did not improve from 0.87960
Epoch 00029: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 3.6320 - acc: 0.5625
484/484 [==============================] - 0s 560us/step - loss: 2.1835 - acc: 0.7107 - val_loss: 1.4580 - val_acc: 0.6446

Epoch 00001: loss improved from inf to 2.18354, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6520 - acc: 0.7188
484/484 [==============================] - 0s 33us/step - loss: 1.7310 - acc: 0.7707 - val_loss: 1.3134 - val_acc: 0.6446

Epoch 00002: loss improved from 2.18354 to 1.73095, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.7803 - acc: 0.7188
484/484 [==============================] - 0s 32us/step - loss: 1.7166 - acc: 0.7603 - val_loss: 1.2416 - val_acc: 0.6612

Epoch 00003: loss improved from 1.73095 to 1.71657, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 2.0862 - acc: 0.7500
484/484 [==============================] - 0s 31us/step - loss: 1.6849 - acc: 0.8058 - val_loss: 1.2688 - val_acc: 0.6612

Epoch 00004: loss improved from 1.71657 to 1.68487, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 2.0828 - acc: 0.7812
484/484 [==============================] - 0s 32us/step - loss: 1.6292 - acc: 0.8140 - val_loss: 1.1037 - val_acc: 0.7438

Epoch 00005: loss improved from 1.68487 to 1.62920, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5272 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.4383 - acc: 0.8161 - val_loss: 1.3340 - val_acc: 0.5785

Epoch 00006: loss improved from 1.62920 to 1.43828, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5876 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.5133 - acc: 0.8182 - val_loss: 1.1750 - val_acc: 0.6860

Epoch 00007: loss did not improve from 1.43828
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1140 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.3041 - acc: 0.8760 - val_loss: 1.1780 - val_acc: 0.6033

Epoch 00008: loss improved from 1.43828 to 1.30406, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0930 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.3469 - acc: 0.8264 - val_loss: 1.0624 - val_acc: 0.7355

Epoch 00009: loss did not improve from 1.30406
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5154 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.4115 - acc: 0.8574 - val_loss: 1.0648 - val_acc: 0.7107

Epoch 00010: loss did not improve from 1.30406
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9498 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.2415 - acc: 0.8512 - val_loss: 1.0984 - val_acc: 0.6777

Epoch 00011: loss improved from 1.30406 to 1.24150, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9615 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.1260 - acc: 0.8802 - val_loss: 1.1172 - val_acc: 0.5620

Epoch 00012: loss improved from 1.24150 to 1.12597, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2171 - acc: 0.9062
484/484 [==============================] - 0s 31us/step - loss: 1.3175 - acc: 0.8554 - val_loss: 1.0863 - val_acc: 0.6777

Epoch 00013: loss did not improve from 1.12597
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8499 - acc: 0.8438
484/484 [==============================] - 0s 32us/step - loss: 1.1396 - acc: 0.8430 - val_loss: 1.1416 - val_acc: 0.7273

Epoch 00014: loss did not improve from 1.12597
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9999 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.2399 - acc: 0.8698 - val_loss: 1.1647 - val_acc: 0.6942

Epoch 00015: loss did not improve from 1.12597
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9180 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.1559 - acc: 0.8760 - val_loss: 0.9461 - val_acc: 0.7190

Epoch 00016: loss did not improve from 1.12597
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0750 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.2511 - acc: 0.8574 - val_loss: 1.0918 - val_acc: 0.6364
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:15<00:09,  1.93s/it]
Epoch 00017: loss did not improve from 1.12597
Epoch 00017: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 4s - loss: 2.4468 - acc: 0.5938
484/484 [==============================] - 0s 769us/step - loss: 2.2566 - acc: 0.7211 - val_loss: 1.2986 - val_acc: 0.6612

Epoch 00001: loss improved from inf to 2.25662, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 1.7787 - acc: 0.6562
484/484 [==============================] - 0s 32us/step - loss: 1.8073 - acc: 0.7562 - val_loss: 1.3362 - val_acc: 0.6116

Epoch 00002: loss improved from 2.25662 to 1.80730, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 2.0346 - acc: 0.6875
484/484 [==============================] - 0s 32us/step - loss: 1.8473 - acc: 0.7521 - val_loss: 1.4113 - val_acc: 0.5868

Epoch 00003: loss did not improve from 1.80730
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.8010 - acc: 0.6562
484/484 [==============================] - 0s 31us/step - loss: 1.6520 - acc: 0.7975 - val_loss: 1.3624 - val_acc: 0.6529

Epoch 00004: loss improved from 1.80730 to 1.65196, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.7229 - acc: 0.7500
484/484 [==============================] - 0s 32us/step - loss: 1.6004 - acc: 0.7810 - val_loss: 1.3088 - val_acc: 0.6364

Epoch 00005: loss improved from 1.65196 to 1.60043, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 2.1656 - acc: 0.7500
484/484 [==============================] - 0s 31us/step - loss: 1.5848 - acc: 0.7872 - val_loss: 1.2763 - val_acc: 0.5620

Epoch 00006: loss improved from 1.60043 to 1.58482, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3957 - acc: 0.7812
484/484 [==============================] - 0s 31us/step - loss: 1.5120 - acc: 0.8120 - val_loss: 1.3897 - val_acc: 0.5620

Epoch 00007: loss improved from 1.58482 to 1.51203, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.8657 - acc: 0.6562
484/484 [==============================] - 0s 31us/step - loss: 1.5903 - acc: 0.7913 - val_loss: 1.1916 - val_acc: 0.6446

Epoch 00008: loss did not improve from 1.51203
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3496 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.4135 - acc: 0.8161 - val_loss: 1.1065 - val_acc: 0.6860

Epoch 00009: loss improved from 1.51203 to 1.41353, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0234 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.3090 - acc: 0.8223 - val_loss: 1.2255 - val_acc: 0.5702

Epoch 00010: loss improved from 1.41353 to 1.30898, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9935 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.3258 - acc: 0.8306 - val_loss: 1.4238 - val_acc: 0.3636

Epoch 00011: loss did not improve from 1.30898
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 2.1278 - acc: 0.7812
484/484 [==============================] - 0s 30us/step - loss: 1.5066 - acc: 0.8120 - val_loss: 1.2681 - val_acc: 0.4876

Epoch 00012: loss did not improve from 1.30898
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1505 - acc: 0.7812
484/484 [==============================] - 0s 31us/step - loss: 1.2672 - acc: 0.8430 - val_loss: 1.1312 - val_acc: 0.5868

Epoch 00013: loss improved from 1.30898 to 1.26716, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7947 - acc: 0.8438
484/484 [==============================] - 0s 31us/step - loss: 1.2689 - acc: 0.8368 - val_loss: 1.1696 - val_acc: 0.5537

Epoch 00014: loss did not improve from 1.26716
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2658 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.4003 - acc: 0.8120 - val_loss: 1.6472 - val_acc: 0.5372

Epoch 00015: loss did not improve from 1.26716
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8668 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.3274 - acc: 0.8285 - val_loss: 1.3508 - val_acc: 0.6281

Epoch 00016: loss did not improve from 1.26716
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9260 - acc: 0.7812
484/484 [==============================] - 0s 30us/step - loss: 1.2897 - acc: 0.8430 - val_loss: 1.4936 - val_acc: 0.2231

Epoch 00017: loss did not improve from 1.26716
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 2.0334 - acc: 0.7500
484/484 [==============================] - 0s 30us/step - loss: 1.3564 - acc: 0.8554 - val_loss: 1.0506 - val_acc: 0.6612
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:17<00:07,  1.91s/it]
Epoch 00018: loss did not improve from 1.26716
Epoch 00018: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 3.5937 - acc: 0.5938
484/484 [==============================] - 0s 562us/step - loss: 2.4428 - acc: 0.7211 - val_loss: 1.4825 - val_acc: 0.6529

Epoch 00001: loss improved from inf to 2.44276, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 2.0147 - acc: 0.7188
484/484 [==============================] - 0s 33us/step - loss: 1.8855 - acc: 0.7335 - val_loss: 1.3026 - val_acc: 0.6364

Epoch 00002: loss improved from 2.44276 to 1.88546, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.7845 - acc: 0.6875
484/484 [==============================] - 0s 32us/step - loss: 1.7654 - acc: 0.7955 - val_loss: 1.2357 - val_acc: 0.6777

Epoch 00003: loss improved from 1.88546 to 1.76536, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.7783 - acc: 0.7500
484/484 [==============================] - 0s 31us/step - loss: 1.6395 - acc: 0.7851 - val_loss: 1.1535 - val_acc: 0.7190

Epoch 00004: loss improved from 1.76536 to 1.63948, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 2.2901 - acc: 0.7188
484/484 [==============================] - 0s 31us/step - loss: 1.7034 - acc: 0.7872 - val_loss: 1.3319 - val_acc: 0.6446

Epoch 00005: loss did not improve from 1.63948
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5048 - acc: 0.7188
484/484 [==============================] - 0s 31us/step - loss: 1.5990 - acc: 0.8099 - val_loss: 1.2885 - val_acc: 0.6529

Epoch 00006: loss improved from 1.63948 to 1.59896, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3707 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.5315 - acc: 0.8347 - val_loss: 1.4550 - val_acc: 0.6116

Epoch 00007: loss improved from 1.59896 to 1.53149, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.8402 - acc: 0.7812
484/484 [==============================] - 0s 31us/step - loss: 1.4681 - acc: 0.8244 - val_loss: 1.2211 - val_acc: 0.6281

Epoch 00008: loss improved from 1.53149 to 1.46814, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2203 - acc: 0.7500
484/484 [==============================] - 0s 31us/step - loss: 1.3819 - acc: 0.8326 - val_loss: 1.3072 - val_acc: 0.5868

Epoch 00009: loss improved from 1.46814 to 1.38194, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2901 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.4735 - acc: 0.8554 - val_loss: 1.1481 - val_acc: 0.7273

Epoch 00010: loss did not improve from 1.38194
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2343 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.4873 - acc: 0.8533 - val_loss: 1.1505 - val_acc: 0.7025

Epoch 00011: loss did not improve from 1.38194
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1288 - acc: 0.9062
484/484 [==============================] - 0s 30us/step - loss: 1.2827 - acc: 0.8533 - val_loss: 1.1195 - val_acc: 0.6942

Epoch 00012: loss improved from 1.38194 to 1.28271, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0406 - acc: 0.7812
484/484 [==============================] - 0s 31us/step - loss: 1.3119 - acc: 0.8533 - val_loss: 1.2934 - val_acc: 0.5207

Epoch 00013: loss did not improve from 1.28271
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0975 - acc: 0.7188
484/484 [==============================] - 0s 30us/step - loss: 1.2216 - acc: 0.8616 - val_loss: 1.1141 - val_acc: 0.7438

Epoch 00014: loss improved from 1.28271 to 1.22159, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_15.h5
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1707 - acc: 0.8750
484/484 [==============================] - 0s 31us/step - loss: 1.3331 - acc: 0.8017 - val_loss: 1.1560 - val_acc: 0.6777

Epoch 00015: loss did not improve from 1.22159
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6283 - acc: 0.7500
484/484 [==============================] - 0s 30us/step - loss: 1.3880 - acc: 0.8471 - val_loss: 1.0923 - val_acc: 0.7521

Epoch 00016: loss did not improve from 1.22159
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 0.7956 - acc: 0.8125
484/484 [==============================] - 0s 31us/step - loss: 1.2400 - acc: 0.8430 - val_loss: 1.2575 - val_acc: 0.7190

Epoch 00017: loss did not improve from 1.22159
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1660 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.2603 - acc: 0.8533 - val_loss: 1.5850 - val_acc: 0.3884

Epoch 00018: loss did not improve from 1.22159
Epoch 19/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4323 - acc: 0.7500
484/484 [==============================] - 0s 30us/step - loss: 1.4165 - acc: 0.8326 - val_loss: 1.0323 - val_acc: 0.6942
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:19<00:05,  1.90s/it]
Epoch 00019: loss did not improve from 1.22159
Epoch 00019: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 2.7674 - acc: 0.5000
484/484 [==============================] - 0s 565us/step - loss: 2.6475 - acc: 0.6921 - val_loss: 1.7208 - val_acc: 0.6116

Epoch 00001: loss improved from inf to 2.64746, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 3.2783 - acc: 0.5938
484/484 [==============================] - 0s 36us/step - loss: 2.1085 - acc: 0.7190 - val_loss: 1.4330 - val_acc: 0.6364

Epoch 00002: loss improved from 2.64746 to 2.10852, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 2.0807 - acc: 0.6562
484/484 [==============================] - 0s 34us/step - loss: 1.7363 - acc: 0.7603 - val_loss: 1.2426 - val_acc: 0.6694

Epoch 00003: loss improved from 2.10852 to 1.73628, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.9679 - acc: 0.6875
484/484 [==============================] - 0s 34us/step - loss: 1.8252 - acc: 0.7417 - val_loss: 1.3533 - val_acc: 0.6446

Epoch 00004: loss did not improve from 1.73628
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 2.1594 - acc: 0.6250
484/484 [==============================] - 0s 34us/step - loss: 1.7264 - acc: 0.7355 - val_loss: 1.2649 - val_acc: 0.6281

Epoch 00005: loss improved from 1.73628 to 1.72645, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 2.2506 - acc: 0.7500
484/484 [==============================] - 0s 33us/step - loss: 1.6871 - acc: 0.7541 - val_loss: 1.2520 - val_acc: 0.6529

Epoch 00006: loss improved from 1.72645 to 1.68713, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6506 - acc: 0.7188
484/484 [==============================] - 0s 33us/step - loss: 1.5501 - acc: 0.8182 - val_loss: 1.1682 - val_acc: 0.5868

Epoch 00007: loss improved from 1.68713 to 1.55013, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1376 - acc: 0.7812
484/484 [==============================] - 0s 32us/step - loss: 1.4743 - acc: 0.8058 - val_loss: 1.2778 - val_acc: 0.5950

Epoch 00008: loss improved from 1.55013 to 1.47429, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.8393 - acc: 0.7812
484/484 [==============================] - 0s 32us/step - loss: 1.6475 - acc: 0.7831 - val_loss: 1.1720 - val_acc: 0.5785

Epoch 00009: loss did not improve from 1.47429
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2141 - acc: 0.8750
484/484 [==============================] - 0s 32us/step - loss: 1.4912 - acc: 0.8368 - val_loss: 1.1571 - val_acc: 0.6860

Epoch 00010: loss did not improve from 1.47429
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0384 - acc: 0.7812
484/484 [==============================] - 0s 32us/step - loss: 1.4315 - acc: 0.8244 - val_loss: 1.1311 - val_acc: 0.7438

Epoch 00011: loss improved from 1.47429 to 1.43154, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3689 - acc: 0.7500
484/484 [==============================] - 0s 33us/step - loss: 1.4448 - acc: 0.8264 - val_loss: 1.0289 - val_acc: 0.7438

Epoch 00012: loss did not improve from 1.43154
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2801 - acc: 0.8438
484/484 [==============================] - 0s 33us/step - loss: 1.2231 - acc: 0.8595 - val_loss: 1.1186 - val_acc: 0.5620

Epoch 00013: loss improved from 1.43154 to 1.22309, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_16.h5
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 1.9389 - acc: 0.8438
484/484 [==============================] - 0s 33us/step - loss: 1.3687 - acc: 0.8533 - val_loss: 1.0917 - val_acc: 0.7107

Epoch 00014: loss did not improve from 1.22309
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9719 - acc: 0.8125
484/484 [==============================] - 0s 32us/step - loss: 1.3639 - acc: 0.8388 - val_loss: 1.0957 - val_acc: 0.6860

Epoch 00015: loss did not improve from 1.22309
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 2.3481 - acc: 0.7500
484/484 [==============================] - 0s 32us/step - loss: 1.5752 - acc: 0.8326 - val_loss: 1.1693 - val_acc: 0.7025

Epoch 00016: loss did not improve from 1.22309
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4707 - acc: 0.7500
484/484 [==============================] - 0s 32us/step - loss: 1.5226 - acc: 0.8161 - val_loss: 1.3180 - val_acc: 0.6198

Epoch 00017: loss did not improve from 1.22309
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3321 - acc: 0.8125
484/484 [==============================] - 0s 32us/step - loss: 1.3123 - acc: 0.8079 - val_loss: 1.7620 - val_acc: 0.2397
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:21<00:03,  1.87s/it]
Epoch 00018: loss did not improve from 1.22309
Epoch 00018: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 3.8793 - acc: 0.5625
484/484 [==============================] - 0s 575us/step - loss: 2.5496 - acc: 0.6736 - val_loss: 1.6205 - val_acc: 0.5372

Epoch 00001: loss improved from inf to 2.54958, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 2.6680 - acc: 0.5312
484/484 [==============================] - 0s 33us/step - loss: 2.0555 - acc: 0.6446 - val_loss: 1.3941 - val_acc: 0.5702

Epoch 00002: loss improved from 2.54958 to 2.05555, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5742 - acc: 0.6562
484/484 [==============================] - 0s 31us/step - loss: 1.7678 - acc: 0.7128 - val_loss: 1.2502 - val_acc: 0.6446

Epoch 00003: loss improved from 2.05555 to 1.76777, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6299 - acc: 0.5938
484/484 [==============================] - 0s 31us/step - loss: 1.8323 - acc: 0.7851 - val_loss: 1.3624 - val_acc: 0.6198

Epoch 00004: loss did not improve from 1.76777
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 2.2118 - acc: 0.7500
484/484 [==============================] - 0s 31us/step - loss: 1.9108 - acc: 0.7169 - val_loss: 1.4537 - val_acc: 0.5702

Epoch 00005: loss did not improve from 1.76777
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5603 - acc: 0.7188
484/484 [==============================] - 0s 31us/step - loss: 1.6029 - acc: 0.7459 - val_loss: 1.5592 - val_acc: 0.3388

Epoch 00006: loss improved from 1.76777 to 1.60294, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4368 - acc: 0.6562
484/484 [==============================] - 0s 31us/step - loss: 1.6938 - acc: 0.7521 - val_loss: 1.3684 - val_acc: 0.6364

Epoch 00007: loss did not improve from 1.60294
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4150 - acc: 0.7500
484/484 [==============================] - 0s 30us/step - loss: 1.6560 - acc: 0.7603 - val_loss: 1.3392 - val_acc: 0.7355

Epoch 00008: loss did not improve from 1.60294
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 2.2118 - acc: 0.6875
484/484 [==============================] - 0s 30us/step - loss: 1.6430 - acc: 0.8079 - val_loss: 1.2993 - val_acc: 0.7107

Epoch 00009: loss did not improve from 1.60294
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3910 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.4634 - acc: 0.8120 - val_loss: 1.2031 - val_acc: 0.6364

Epoch 00010: loss improved from 1.60294 to 1.46343, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_17.h5
Epoch 11/100

 32/484 [>.............................] - ETA: 0s - loss: 1.7306 - acc: 0.7500
484/484 [==============================] - 0s 30us/step - loss: 1.5823 - acc: 0.7893 - val_loss: 1.3808 - val_acc: 0.5124

Epoch 00011: loss did not improve from 1.46343
Epoch 12/100

 32/484 [>.............................] - ETA: 0s - loss: 1.5550 - acc: 0.6875
484/484 [==============================] - 0s 30us/step - loss: 1.5487 - acc: 0.7913 - val_loss: 1.0935 - val_acc: 0.6694

Epoch 00012: loss did not improve from 1.46343
Epoch 13/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1403 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.5520 - acc: 0.7831 - val_loss: 1.2936 - val_acc: 0.5372

Epoch 00013: loss did not improve from 1.46343
Epoch 14/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0719 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.3103 - acc: 0.8306 - val_loss: 1.0878 - val_acc: 0.6777

Epoch 00014: loss improved from 1.46343 to 1.31027, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_17.h5
Epoch 15/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0970 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.4219 - acc: 0.8388 - val_loss: 1.1237 - val_acc: 0.6942

Epoch 00015: loss did not improve from 1.31027
Epoch 16/100

 32/484 [>.............................] - ETA: 0s - loss: 1.3771 - acc: 0.7812
484/484 [==============================] - 0s 30us/step - loss: 1.3359 - acc: 0.8306 - val_loss: 0.9223 - val_acc: 0.7769

Epoch 00016: loss did not improve from 1.31027
Epoch 17/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1027 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.2875 - acc: 0.8244 - val_loss: 1.2007 - val_acc: 0.5785

Epoch 00017: loss improved from 1.31027 to 1.28752, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_17.h5
Epoch 18/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1402 - acc: 0.6562
484/484 [==============================] - 0s 30us/step - loss: 1.3557 - acc: 0.8471 - val_loss: 1.0305 - val_acc: 0.7273

Epoch 00018: loss did not improve from 1.28752
Epoch 19/100

 32/484 [>.............................] - ETA: 0s - loss: 0.8832 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.2149 - acc: 0.8492 - val_loss: 1.0650 - val_acc: 0.7355

Epoch 00019: loss improved from 1.28752 to 1.21493, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_17.h5
Epoch 20/100

 32/484 [>.............................] - ETA: 0s - loss: 1.0672 - acc: 0.8438
484/484 [==============================] - 0s 30us/step - loss: 1.3090 - acc: 0.8554 - val_loss: 1.2476 - val_acc: 0.6033

Epoch 00020: loss did not improve from 1.21493
Epoch 21/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4429 - acc: 0.8750
484/484 [==============================] - 0s 30us/step - loss: 1.4022 - acc: 0.8120 - val_loss: 1.3467 - val_acc: 0.5868

Epoch 00021: loss did not improve from 1.21493
Epoch 22/100

 32/484 [>.............................] - ETA: 0s - loss: 0.9973 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.3938 - acc: 0.8368 - val_loss: 1.3116 - val_acc: 0.5207

Epoch 00022: loss did not improve from 1.21493
Epoch 23/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1445 - acc: 0.7812
484/484 [==============================] - 0s 30us/step - loss: 1.3124 - acc: 0.8430 - val_loss: 1.0729 - val_acc: 0.6529

Epoch 00023: loss did not improve from 1.21493
Epoch 24/100

 32/484 [>.............................] - ETA: 0s - loss: 1.1681 - acc: 0.8125
484/484 [==============================] - 0s 30us/step - loss: 1.3397 - acc: 0.8368 - val_loss: 1.2779 - val_acc: 0.6860
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:23<00:01,  1.90s/it]
Epoch 00024: loss did not improve from 1.21493
Epoch 00024: early stopping
Train on 484 samples, validate on 121 samples
Epoch 1/100

 32/484 [>.............................] - ETA: 3s - loss: 4.1140 - acc: 0.6250
484/484 [==============================] - 0s 560us/step - loss: 2.5727 - acc: 0.7231 - val_loss: 1.6181 - val_acc: 0.4711

Epoch 00001: loss improved from inf to 2.57275, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/484 [>.............................] - ETA: 0s - loss: 2.0290 - acc: 0.5625
484/484 [==============================] - 0s 32us/step - loss: 2.1999 - acc: 0.6901 - val_loss: 1.4616 - val_acc: 0.5620

Epoch 00002: loss improved from 2.57275 to 2.19991, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/484 [>.............................] - ETA: 0s - loss: 2.2962 - acc: 0.6250
484/484 [==============================] - 0s 32us/step - loss: 1.9737 - acc: 0.6983 - val_loss: 1.4374 - val_acc: 0.6033

Epoch 00003: loss improved from 2.19991 to 1.97365, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/484 [>.............................] - ETA: 0s - loss: 1.9910 - acc: 0.7812
484/484 [==============================] - 0s 31us/step - loss: 1.9498 - acc: 0.7479 - val_loss: 1.3399 - val_acc: 0.6281

Epoch 00004: loss improved from 1.97365 to 1.94984, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/484 [>.............................] - ETA: 0s - loss: 1.6317 - acc: 0.6875
484/484 [==============================] - 0s 32us/step - loss: 1.6561 - acc: 0.7541 - val_loss: 1.4067 - val_acc: 0.5207

Epoch 00005: loss improved from 1.94984 to 1.65610, saving model to ./results_TA1535_with_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/484 [>.............................] - ETA: 0s - loss: 3.0097 - acc: 0.6250
484/484 [==============================] - 0s 31us/step - loss: 1.9865 - acc: 0.7583 - val_loss: 1.5900 - val_acc: 0.4545

Epoch 00006: loss did not improve from 1.65610
Epoch 7/100

 32/484 [>.............................] - ETA: 0s - loss: 1.2960 - acc: 0.6562
484/484 [==============================] - 0s 30us/step - loss: 1.7966 - acc: 0.7645 - val_loss: 1.5867 - val_acc: 0.4380

Epoch 00007: loss did not improve from 1.65610
Epoch 8/100

 32/484 [>.............................] - ETA: 0s - loss: 1.4411 - acc: 0.6562
484/484 [==============================] - 0s 30us/step - loss: 1.7221 - acc: 0.7562 - val_loss: 1.3794 - val_acc: 0.4793

Epoch 00008: loss did not improve from 1.65610
Epoch 9/100

 32/484 [>.............................] - ETA: 0s - loss: 1.7912 - acc: 0.7500
484/484 [==============================] - 0s 30us/step - loss: 1.6795 - acc: 0.7707 - val_loss: 1.3801 - val_acc: 0.4876

Epoch 00009: loss did not improve from 1.65610
Epoch 10/100

 32/484 [>.............................] - ETA: 0s - loss: 2.5227 - acc: 0.6875
484/484 [==============================] - 0s 30us/step - loss: 1.7529 - acc: 0.7603 - val_loss: 1.5022 - val_acc: 0.4380
DeepAmes+ Weights: 100%|██████████| 13/13 [00:24<00:00,  1.84s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:24<00:00,  1.90s/it]

Epoch 00010: loss did not improve from 1.65610
Epoch 00010: early stopping
--- 3270.744893312454 seconds ---

Generating metrics report for TA1535_with_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 342 samples.
Processing weight 7...
  Done. 342 samples.
Processing weight 8...
  Done. 342 samples.
Processing weight 9...
  Done. 342 samples.
Processing weight 10...
  Done. 342 samples.
Processing weight 11...
  Done. 342 samples.
Processing weight 12...
  Done. 342 samples.
Processing weight 13...
  Done. 342 samples.
Processing weight 14...
  Done. 342 samples.
Processing weight 15...
  Done. 342 samples.
Processing weight 16...
  Done. 342 samples.
Processing weight 17...
  Done. 342 samples.
Processing weight 18...
  Done. 342 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA1535_with_S9/metrics_report_TA1535_with_S9.txt

Done!

Completed TA1535_with_S9 in 3270.74 seconds

================================================================================
[8/16] Processing: TA1535_without_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA1535_without_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA1535_without_S9_Test_mold2.csv
(3229, 777)
(2583, 777)
(361, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:16<05:22, 16.97s/it]KNN Seeds:  10%|█         | 2/20 [00:34<05:09, 17.18s/it]KNN Seeds:  15%|█▌        | 3/20 [00:51<04:50, 17.09s/it]KNN Seeds:  20%|██        | 4/20 [01:07<04:29, 16.87s/it]KNN Seeds:  25%|██▌       | 5/20 [01:24<04:14, 16.97s/it]KNN Seeds:  30%|███       | 6/20 [01:41<03:57, 16.98s/it]KNN Seeds:  35%|███▌      | 7/20 [01:59<03:41, 17.05s/it]KNN Seeds:  40%|████      | 8/20 [02:16<03:24, 17.07s/it]KNN Seeds:  45%|████▌     | 9/20 [02:33<03:08, 17.14s/it]KNN Seeds:  50%|█████     | 10/20 [02:50<02:51, 17.13s/it]KNN Seeds:  55%|█████▌    | 11/20 [03:07<02:33, 17.09s/it]KNN Seeds:  60%|██████    | 12/20 [03:25<02:17, 17.18s/it]KNN Seeds:  65%|██████▌   | 13/20 [03:42<02:00, 17.25s/it]KNN Seeds:  70%|███████   | 14/20 [03:59<01:43, 17.20s/it]KNN Seeds:  75%|███████▌  | 15/20 [04:16<01:25, 17.15s/it]KNN Seeds:  80%|████████  | 16/20 [04:33<01:08, 17.22s/it]KNN Seeds:  85%|████████▌ | 17/20 [04:51<00:51, 17.22s/it]KNN Seeds:  90%|█████████ | 18/20 [05:08<00:34, 17.29s/it]KNN Seeds:  95%|█████████▌| 19/20 [05:25<00:17, 17.23s/it]KNN Seeds: 100%|██████████| 20/20 [05:43<00:00, 17.29s/it]KNN Seeds: 100%|██████████| 20/20 [05:43<00:00, 17.16s/it]
24
(100, None, 'lbfgs')
(3229, 777)
(2583, 777)
(361, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:02<00:44,  2.32s/it]LR Seeds:  10%|█         | 2/20 [00:04<00:42,  2.35s/it]LR Seeds:  15%|█▌        | 3/20 [00:07<00:40,  2.37s/it]LR Seeds:  20%|██        | 4/20 [00:09<00:38,  2.38s/it]LR Seeds:  25%|██▌       | 5/20 [00:11<00:35,  2.40s/it]LR Seeds:  30%|███       | 6/20 [00:14<00:33,  2.41s/it]LR Seeds:  35%|███▌      | 7/20 [00:16<00:31,  2.42s/it]LR Seeds:  40%|████      | 8/20 [00:19<00:29,  2.43s/it]LR Seeds:  45%|████▌     | 9/20 [00:21<00:26,  2.45s/it]LR Seeds:  50%|█████     | 10/20 [00:24<00:24,  2.45s/it]LR Seeds:  55%|█████▌    | 11/20 [00:26<00:22,  2.45s/it]LR Seeds:  60%|██████    | 12/20 [00:29<00:19,  2.46s/it]LR Seeds:  65%|██████▌   | 13/20 [00:31<00:17,  2.47s/it]LR Seeds:  70%|███████   | 14/20 [00:34<00:14,  2.47s/it]LR Seeds:  75%|███████▌  | 15/20 [00:36<00:12,  2.47s/it]LR Seeds:  80%|████████  | 16/20 [00:39<00:09,  2.49s/it]LR Seeds:  85%|████████▌ | 17/20 [00:41<00:07,  2.51s/it]LR Seeds:  90%|█████████ | 18/20 [00:44<00:05,  2.57s/it]LR Seeds:  95%|█████████▌| 19/20 [00:46<00:02,  2.58s/it]LR Seeds: 100%|██████████| 20/20 [00:49<00:00,  2.58s/it]LR Seeds: 100%|██████████| 20/20 [00:49<00:00,  2.48s/it]
96
('rbf', 1, 1)
(3229, 777)
(2583, 777)
(361, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [01:40<31:41, 100.06s/it]SVM Seeds:  10%|█         | 2/20 [03:19<29:58, 99.92s/it] SVM Seeds:  15%|█▌        | 3/20 [04:59<28:19, 99.96s/it]SVM Seeds:  20%|██        | 4/20 [06:39<26:40, 100.00s/it]SVM Seeds:  25%|██▌       | 5/20 [08:19<24:59, 99.97s/it] SVM Seeds:  30%|███       | 6/20 [09:59<23:20, 100.02s/it]SVM Seeds:  35%|███▌      | 7/20 [11:40<21:40, 100.04s/it]SVM Seeds:  40%|████      | 8/20 [13:20<20:01, 100.12s/it]SVM Seeds:  45%|████▌     | 9/20 [15:00<18:21, 100.11s/it]SVM Seeds:  50%|█████     | 10/20 [16:40<16:40, 100.04s/it]SVM Seeds:  55%|█████▌    | 11/20 [18:20<15:00, 100.07s/it]SVM Seeds:  60%|██████    | 12/20 [20:00<13:20, 100.11s/it]SVM Seeds:  65%|██████▌   | 13/20 [21:40<11:40, 100.12s/it]SVM Seeds:  70%|███████   | 14/20 [23:21<10:00, 100.17s/it]SVM Seeds:  75%|███████▌  | 15/20 [25:01<08:21, 100.24s/it]SVM Seeds:  80%|████████  | 16/20 [26:41<06:40, 100.18s/it]SVM Seeds:  85%|████████▌ | 17/20 [28:21<05:00, 100.19s/it]SVM Seeds:  90%|█████████ | 18/20 [30:01<03:20, 100.15s/it]SVM Seeds:  95%|█████████▌| 19/20 [31:41<01:40, 100.15s/it]SVM Seeds: 100%|██████████| 20/20 [33:22<00:00, 100.19s/it]SVM Seeds: 100%|██████████| 20/20 [33:22<00:00, 100.11s/it]
200
(500, None, 70, 1, 'balanced')
(3229, 777)
(2583, 777)
(361, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:08<02:50,  8.97s/it]RF Seeds:  10%|█         | 2/20 [00:17<02:40,  8.94s/it]RF Seeds:  15%|█▌        | 3/20 [00:26<02:31,  8.94s/it]RF Seeds:  20%|██        | 4/20 [00:35<02:23,  8.95s/it]RF Seeds:  25%|██▌       | 5/20 [00:44<02:14,  8.96s/it]RF Seeds:  30%|███       | 6/20 [00:53<02:05,  8.97s/it]RF Seeds:  35%|███▌      | 7/20 [01:02<01:56,  8.98s/it]RF Seeds:  40%|████      | 8/20 [01:11<01:47,  8.99s/it]RF Seeds:  45%|████▌     | 9/20 [01:20<01:38,  8.99s/it]RF Seeds:  50%|█████     | 10/20 [01:29<01:30,  9.00s/it]RF Seeds:  55%|█████▌    | 11/20 [01:38<01:21,  9.01s/it]RF Seeds:  60%|██████    | 12/20 [01:47<01:12,  9.02s/it]RF Seeds:  65%|██████▌   | 13/20 [01:56<01:03,  9.03s/it]RF Seeds:  70%|███████   | 14/20 [02:05<00:54,  9.04s/it]RF Seeds:  75%|███████▌  | 15/20 [02:15<00:45,  9.06s/it]RF Seeds:  80%|████████  | 16/20 [02:24<00:36,  9.07s/it]RF Seeds:  85%|████████▌ | 17/20 [02:33<00:27,  9.12s/it]RF Seeds:  90%|█████████ | 18/20 [02:42<00:18,  9.11s/it]RF Seeds:  95%|█████████▌| 19/20 [02:51<00:09,  9.14s/it]RF Seeds: 100%|██████████| 20/20 [03:00<00:00,  9.14s/it]RF Seeds: 100%|██████████| 20/20 [03:00<00:00,  9.04s/it]
400
(0.01, 900, 7, 0.8, 6)
(3229, 777)
(2583, 777)
(361, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:44<14:13, 44.92s/it]XGBoost Seeds:  10%|█         | 2/20 [01:29<13:28, 44.90s/it]XGBoost Seeds:  15%|█▌        | 3/20 [02:14<12:43, 44.93s/it]XGBoost Seeds:  20%|██        | 4/20 [02:59<11:59, 44.96s/it]XGBoost Seeds:  25%|██▌       | 5/20 [03:44<11:14, 44.96s/it]XGBoost Seeds:  30%|███       | 6/20 [04:29<10:29, 44.95s/it]XGBoost Seeds:  35%|███▌      | 7/20 [05:14<09:44, 44.98s/it]XGBoost Seeds:  40%|████      | 8/20 [05:59<08:59, 44.97s/it]XGBoost Seeds:  45%|████▌     | 9/20 [06:44<08:14, 44.99s/it]XGBoost Seeds:  50%|█████     | 10/20 [07:29<07:30, 45.03s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [08:14<06:45, 45.08s/it]XGBoost Seeds:  60%|██████    | 12/20 [09:00<06:01, 45.13s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [09:45<05:16, 45.17s/it]XGBoost Seeds:  70%|███████   | 14/20 [10:30<04:31, 45.17s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [11:16<03:46, 45.23s/it]XGBoost Seeds:  80%|████████  | 16/20 [12:01<03:00, 45.16s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [12:46<02:15, 45.13s/it]XGBoost Seeds:  90%|█████████ | 18/20 [13:31<01:30, 45.13s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [14:16<00:45, 45.16s/it]XGBoost Seeds: 100%|██████████| 20/20 [15:01<00:00, 45.19s/it]XGBoost Seeds: 100%|██████████| 20/20 [15:01<00:00, 45.09s/it]
knn:  98
lr:  98
svm:  76
rf:  99
xgboost:  76
Combining validation predictions is completed
knn:  98
lr:  98
svm:  76
rf:  99
xgboost:  76
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 2.4397 - acc: 0.5625
516/516 [==============================] - 0s 542us/step - loss: 1.5980 - acc: 0.8178 - val_loss: 1.1271 - val_acc: 0.8846

Epoch 00001: loss improved from inf to 1.59798, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0631 - acc: 0.9062
516/516 [==============================] - 0s 33us/step - loss: 1.2574 - acc: 0.8818 - val_loss: 1.0140 - val_acc: 0.8923

Epoch 00002: loss improved from 1.59798 to 1.25738, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9927 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.2755 - acc: 0.8740 - val_loss: 0.9703 - val_acc: 0.9077

Epoch 00003: loss did not improve from 1.25738
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8422 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.1830 - acc: 0.8895 - val_loss: 0.8175 - val_acc: 0.9308

Epoch 00004: loss improved from 1.25738 to 1.18301, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7724 - acc: 0.9688
516/516 [==============================] - 0s 32us/step - loss: 1.0797 - acc: 0.9167 - val_loss: 0.7695 - val_acc: 0.9077

Epoch 00005: loss improved from 1.18301 to 1.07969, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8183 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.1008 - acc: 0.9050 - val_loss: 0.7643 - val_acc: 0.9154

Epoch 00006: loss did not improve from 1.07969
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8202 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.0374 - acc: 0.8992 - val_loss: 0.7367 - val_acc: 0.9000

Epoch 00007: loss improved from 1.07969 to 1.03740, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6944 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9403 - acc: 0.9128 - val_loss: 0.6963 - val_acc: 0.9231

Epoch 00008: loss improved from 1.03740 to 0.94031, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7065 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9661 - acc: 0.9089 - val_loss: 0.6799 - val_acc: 0.9231

Epoch 00009: loss did not improve from 0.94031
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7303 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.0176 - acc: 0.9109 - val_loss: 0.7149 - val_acc: 0.8846

Epoch 00010: loss did not improve from 0.94031
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6576 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 0.8745 - acc: 0.9070 - val_loss: 0.6990 - val_acc: 0.8923

Epoch 00011: loss improved from 0.94031 to 0.87454, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5959 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9011 - acc: 0.9128 - val_loss: 0.7259 - val_acc: 0.8769

Epoch 00012: loss did not improve from 0.87454
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6550 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 0.8979 - acc: 0.9109 - val_loss: 0.6326 - val_acc: 0.8923

Epoch 00013: loss did not improve from 0.87454
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4972 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7950 - acc: 0.9205 - val_loss: 0.5918 - val_acc: 0.9000

Epoch 00014: loss improved from 0.87454 to 0.79502, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6537 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7951 - acc: 0.9205 - val_loss: 0.5696 - val_acc: 0.9000

Epoch 00015: loss did not improve from 0.79502
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4639 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.8118 - acc: 0.9147 - val_loss: 0.4929 - val_acc: 0.9231

Epoch 00016: loss did not improve from 0.79502
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5564 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7345 - acc: 0.9089 - val_loss: 0.4737 - val_acc: 0.9308

Epoch 00017: loss improved from 0.79502 to 0.73446, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4928 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 0.7926 - acc: 0.9167 - val_loss: 0.5499 - val_acc: 0.9154

Epoch 00018: loss did not improve from 0.73446
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4489 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.6554 - acc: 0.9302 - val_loss: 0.5006 - val_acc: 0.9154

Epoch 00019: loss improved from 0.73446 to 0.65538, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_6.h5
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5084 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.8632 - acc: 0.8934 - val_loss: 0.5393 - val_acc: 0.8923

Epoch 00020: loss did not improve from 0.65538
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4500 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7956 - acc: 0.9147 - val_loss: 0.5138 - val_acc: 0.9000

Epoch 00021: loss did not improve from 0.65538
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5150 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.7045 - acc: 0.9264 - val_loss: 0.4900 - val_acc: 0.8846

Epoch 00022: loss did not improve from 0.65538
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 0.3382 - acc: 1.0000
516/516 [==============================] - 0s 31us/step - loss: 0.7904 - acc: 0.9167 - val_loss: 0.4664 - val_acc: 0.8923

Epoch 00023: loss did not improve from 0.65538
Epoch 24/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4776 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.8061 - acc: 0.9012 - val_loss: 0.5014 - val_acc: 0.8846
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:22,  1.91s/it]
Epoch 00024: loss did not improve from 0.65538
Epoch 00024: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 2.0493 - acc: 0.5938
516/516 [==============================] - 0s 541us/step - loss: 1.7135 - acc: 0.7888 - val_loss: 1.1086 - val_acc: 0.8692

Epoch 00001: loss improved from inf to 1.71345, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0795 - acc: 0.9062
516/516 [==============================] - 0s 33us/step - loss: 1.4002 - acc: 0.8624 - val_loss: 1.0334 - val_acc: 0.9000

Epoch 00002: loss improved from 1.71345 to 1.40024, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9660 - acc: 0.9375
516/516 [==============================] - 0s 32us/step - loss: 1.2437 - acc: 0.8857 - val_loss: 0.9281 - val_acc: 0.9000

Epoch 00003: loss improved from 1.40024 to 1.24370, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9965 - acc: 0.9688
516/516 [==============================] - 0s 32us/step - loss: 1.2500 - acc: 0.8895 - val_loss: 0.9004 - val_acc: 0.8923

Epoch 00004: loss did not improve from 1.24370
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8427 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.1943 - acc: 0.8953 - val_loss: 0.8826 - val_acc: 0.9000

Epoch 00005: loss improved from 1.24370 to 1.19427, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1511 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.2416 - acc: 0.8857 - val_loss: 0.8843 - val_acc: 0.8538

Epoch 00006: loss did not improve from 1.19427
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8386 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.0615 - acc: 0.8934 - val_loss: 0.8494 - val_acc: 0.8923

Epoch 00007: loss improved from 1.19427 to 1.06147, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8899 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.0928 - acc: 0.8953 - val_loss: 0.8098 - val_acc: 0.8846

Epoch 00008: loss did not improve from 1.06147
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7365 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.9956 - acc: 0.8934 - val_loss: 0.6868 - val_acc: 0.9231

Epoch 00009: loss improved from 1.06147 to 0.99564, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7134 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9869 - acc: 0.9089 - val_loss: 0.6592 - val_acc: 0.9231

Epoch 00010: loss improved from 0.99564 to 0.98693, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6980 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.9041 - acc: 0.9089 - val_loss: 0.6700 - val_acc: 0.8846

Epoch 00011: loss improved from 0.98693 to 0.90414, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7113 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.1044 - acc: 0.8818 - val_loss: 0.9197 - val_acc: 0.8538

Epoch 00012: loss did not improve from 0.90414
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6446 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9575 - acc: 0.8953 - val_loss: 0.7414 - val_acc: 0.8538

Epoch 00013: loss did not improve from 0.90414
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5746 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.8877 - acc: 0.9012 - val_loss: 0.7015 - val_acc: 0.8692

Epoch 00014: loss improved from 0.90414 to 0.88773, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6020 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9009 - acc: 0.9012 - val_loss: 0.6546 - val_acc: 0.8846

Epoch 00015: loss did not improve from 0.88773
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5809 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.8477 - acc: 0.9070 - val_loss: 0.5941 - val_acc: 0.9154

Epoch 00016: loss improved from 0.88773 to 0.84766, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5259 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.8359 - acc: 0.9050 - val_loss: 0.6103 - val_acc: 0.8923

Epoch 00017: loss improved from 0.84766 to 0.83593, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5363 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.7902 - acc: 0.9089 - val_loss: 0.5272 - val_acc: 0.9077

Epoch 00018: loss improved from 0.83593 to 0.79018, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7031 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.8312 - acc: 0.9031 - val_loss: 0.5801 - val_acc: 0.8846

Epoch 00019: loss did not improve from 0.79018
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5112 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7756 - acc: 0.9050 - val_loss: 0.6047 - val_acc: 0.8846

Epoch 00020: loss improved from 0.79018 to 0.77564, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4875 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7540 - acc: 0.9225 - val_loss: 0.5730 - val_acc: 0.9077

Epoch 00021: loss improved from 0.77564 to 0.75399, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4301 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.8270 - acc: 0.9031 - val_loss: 0.5857 - val_acc: 0.9154

Epoch 00022: loss did not improve from 0.75399
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6414 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.7723 - acc: 0.9050 - val_loss: 0.6224 - val_acc: 0.8923

Epoch 00023: loss did not improve from 0.75399
Epoch 24/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4333 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.7187 - acc: 0.9205 - val_loss: 0.5307 - val_acc: 0.8923

Epoch 00024: loss improved from 0.75399 to 0.71867, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 25/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5709 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7942 - acc: 0.9109 - val_loss: 0.5185 - val_acc: 0.8769

Epoch 00025: loss did not improve from 0.71867
Epoch 26/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5085 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.6629 - acc: 0.9302 - val_loss: 0.5192 - val_acc: 0.9154

Epoch 00026: loss improved from 0.71867 to 0.66295, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_7.h5
Epoch 27/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4369 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.7148 - acc: 0.9264 - val_loss: 0.4680 - val_acc: 0.9077

Epoch 00027: loss did not improve from 0.66295
Epoch 28/100

 32/516 [>.............................] - ETA: 0s - loss: 0.3624 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.7645 - acc: 0.9167 - val_loss: 0.5169 - val_acc: 0.9000

Epoch 00028: loss did not improve from 0.66295
Epoch 29/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5298 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7267 - acc: 0.9109 - val_loss: 0.4196 - val_acc: 0.9385

Epoch 00029: loss did not improve from 0.66295
Epoch 30/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4785 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.8020 - acc: 0.9012 - val_loss: 0.4530 - val_acc: 0.9154

Epoch 00030: loss did not improve from 0.66295
Epoch 31/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5302 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.7093 - acc: 0.9089 - val_loss: 0.6728 - val_acc: 0.8538
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:04<00:22,  2.06s/it]
Epoch 00031: loss did not improve from 0.66295
Epoch 00031: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 1.6360 - acc: 0.6562
516/516 [==============================] - 0s 526us/step - loss: 1.5554 - acc: 0.8120 - val_loss: 1.1732 - val_acc: 0.8769

Epoch 00001: loss improved from inf to 1.55542, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0220 - acc: 0.9375
516/516 [==============================] - 0s 33us/step - loss: 1.3470 - acc: 0.8624 - val_loss: 0.9051 - val_acc: 0.9308

Epoch 00002: loss improved from 1.55542 to 1.34697, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9481 - acc: 0.9375
516/516 [==============================] - 0s 32us/step - loss: 1.3617 - acc: 0.8624 - val_loss: 0.8848 - val_acc: 0.9077

Epoch 00003: loss did not improve from 1.34697
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8225 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.1470 - acc: 0.8857 - val_loss: 0.8414 - val_acc: 0.9154

Epoch 00004: loss improved from 1.34697 to 1.14698, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8532 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.1662 - acc: 0.8915 - val_loss: 0.8010 - val_acc: 0.9308

Epoch 00005: loss did not improve from 1.14698
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7782 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.0760 - acc: 0.9031 - val_loss: 0.8132 - val_acc: 0.9308

Epoch 00006: loss improved from 1.14698 to 1.07605, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8762 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.1461 - acc: 0.8876 - val_loss: 0.8044 - val_acc: 0.8846

Epoch 00007: loss did not improve from 1.07605
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7286 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9987 - acc: 0.9012 - val_loss: 0.8234 - val_acc: 0.9000

Epoch 00008: loss improved from 1.07605 to 0.99875, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7421 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.9676 - acc: 0.9167 - val_loss: 0.7197 - val_acc: 0.8615

Epoch 00009: loss improved from 0.99875 to 0.96759, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7177 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.0299 - acc: 0.9012 - val_loss: 0.6949 - val_acc: 0.8769

Epoch 00010: loss did not improve from 0.96759
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6457 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 0.9927 - acc: 0.8934 - val_loss: 0.7027 - val_acc: 0.8615

Epoch 00011: loss did not improve from 0.96759
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7642 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 0.9280 - acc: 0.8973 - val_loss: 0.6874 - val_acc: 0.9077

Epoch 00012: loss improved from 0.96759 to 0.92798, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6045 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.0115 - acc: 0.8876 - val_loss: 0.6180 - val_acc: 0.8846

Epoch 00013: loss did not improve from 0.92798
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5866 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.9481 - acc: 0.8973 - val_loss: 0.6424 - val_acc: 0.9231

Epoch 00014: loss did not improve from 0.92798
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5178 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.8777 - acc: 0.9050 - val_loss: 0.5576 - val_acc: 0.9308

Epoch 00015: loss improved from 0.92798 to 0.87768, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5616 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.8309 - acc: 0.9167 - val_loss: 0.5218 - val_acc: 0.9231

Epoch 00016: loss improved from 0.87768 to 0.83087, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5887 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9914 - acc: 0.9012 - val_loss: 0.6030 - val_acc: 0.8846

Epoch 00017: loss did not improve from 0.83087
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5890 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.9025 - acc: 0.8973 - val_loss: 0.5473 - val_acc: 0.8615

Epoch 00018: loss did not improve from 0.83087
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6687 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.8839 - acc: 0.9147 - val_loss: 0.5629 - val_acc: 0.9000

Epoch 00019: loss did not improve from 0.83087
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6001 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.8082 - acc: 0.8992 - val_loss: 0.5643 - val_acc: 0.9077

Epoch 00020: loss improved from 0.83087 to 0.80818, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6020 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.7284 - acc: 0.9264 - val_loss: 0.4662 - val_acc: 0.9231

Epoch 00021: loss improved from 0.80818 to 0.72841, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.3918 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.7368 - acc: 0.9225 - val_loss: 0.4909 - val_acc: 0.9231

Epoch 00022: loss did not improve from 0.72841
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5351 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.8668 - acc: 0.8973 - val_loss: 0.5175 - val_acc: 0.9154

Epoch 00023: loss did not improve from 0.72841
Epoch 24/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4201 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.9059 - acc: 0.9128 - val_loss: 0.6526 - val_acc: 0.8846

Epoch 00024: loss did not improve from 0.72841
Epoch 25/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5185 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.6540 - acc: 0.9302 - val_loss: 0.6273 - val_acc: 0.9000

Epoch 00025: loss improved from 0.72841 to 0.65403, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_8.h5
Epoch 26/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4930 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 0.7088 - acc: 0.9322 - val_loss: 0.4305 - val_acc: 0.9231

Epoch 00026: loss did not improve from 0.65403
Epoch 27/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4113 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.7357 - acc: 0.9283 - val_loss: 0.4397 - val_acc: 0.9385

Epoch 00027: loss did not improve from 0.65403
Epoch 28/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4597 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.6627 - acc: 0.9399 - val_loss: 0.4388 - val_acc: 0.9462

Epoch 00028: loss did not improve from 0.65403
Epoch 29/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5709 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.9018 - acc: 0.9089 - val_loss: 0.5966 - val_acc: 0.8846

Epoch 00029: loss did not improve from 0.65403
Epoch 30/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4798 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.6994 - acc: 0.9360 - val_loss: 0.4382 - val_acc: 0.9462
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:06<00:20,  2.08s/it]
Epoch 00030: loss did not improve from 0.65403
Epoch 00030: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 2.4529 - acc: 0.6250
516/516 [==============================] - 0s 530us/step - loss: 1.7630 - acc: 0.8120 - val_loss: 1.2128 - val_acc: 0.8538

Epoch 00001: loss improved from inf to 1.76300, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2144 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.5692 - acc: 0.8624 - val_loss: 1.2190 - val_acc: 0.8846

Epoch 00002: loss improved from 1.76300 to 1.56924, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1623 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.4792 - acc: 0.8663 - val_loss: 1.0726 - val_acc: 0.8769

Epoch 00003: loss improved from 1.56924 to 1.47919, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0369 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.3473 - acc: 0.8760 - val_loss: 0.9580 - val_acc: 0.9077

Epoch 00004: loss improved from 1.47919 to 1.34728, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9283 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.3436 - acc: 0.8857 - val_loss: 0.9319 - val_acc: 0.9000

Epoch 00005: loss improved from 1.34728 to 1.34356, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9565 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.3017 - acc: 0.8779 - val_loss: 1.0414 - val_acc: 0.8692

Epoch 00006: loss improved from 1.34356 to 1.30174, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9857 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.1738 - acc: 0.8934 - val_loss: 0.8771 - val_acc: 0.9231

Epoch 00007: loss improved from 1.30174 to 1.17382, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8374 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.1761 - acc: 0.8992 - val_loss: 0.8804 - val_acc: 0.8692

Epoch 00008: loss did not improve from 1.17382
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1681 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.2443 - acc: 0.8779 - val_loss: 0.8605 - val_acc: 0.9000

Epoch 00009: loss did not improve from 1.17382
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8143 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.2688 - acc: 0.8857 - val_loss: 0.8397 - val_acc: 0.8692

Epoch 00010: loss did not improve from 1.17382
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8023 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.1029 - acc: 0.8895 - val_loss: 0.7604 - val_acc: 0.9154

Epoch 00011: loss improved from 1.17382 to 1.10293, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7372 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.0151 - acc: 0.8934 - val_loss: 0.7213 - val_acc: 0.9000

Epoch 00012: loss improved from 1.10293 to 1.01506, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6375 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.9609 - acc: 0.9089 - val_loss: 0.7068 - val_acc: 0.9154

Epoch 00013: loss improved from 1.01506 to 0.96086, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6118 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.9450 - acc: 0.9031 - val_loss: 0.6723 - val_acc: 0.9000

Epoch 00014: loss improved from 0.96086 to 0.94503, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6972 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.1145 - acc: 0.8895 - val_loss: 0.7276 - val_acc: 0.9000

Epoch 00015: loss did not improve from 0.94503
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8961 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.2588 - acc: 0.8837 - val_loss: 0.8549 - val_acc: 0.8846

Epoch 00016: loss did not improve from 0.94503
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5857 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.9817 - acc: 0.8992 - val_loss: 1.0753 - val_acc: 0.8462

Epoch 00017: loss did not improve from 0.94503
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6478 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.9757 - acc: 0.9031 - val_loss: 0.6683 - val_acc: 0.8923

Epoch 00018: loss did not improve from 0.94503
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6838 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.8855 - acc: 0.9109 - val_loss: 0.5944 - val_acc: 0.9154

Epoch 00019: loss improved from 0.94503 to 0.88546, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.4915 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.7446 - acc: 0.9419 - val_loss: 0.5965 - val_acc: 0.9154

Epoch 00020: loss improved from 0.88546 to 0.74460, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_9.h5
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5051 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.8106 - acc: 0.9205 - val_loss: 0.5326 - val_acc: 0.9308

Epoch 00021: loss did not improve from 0.74460
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6637 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.8257 - acc: 0.9089 - val_loss: 0.7016 - val_acc: 0.8846

Epoch 00022: loss did not improve from 0.74460
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 1.6501 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.9382 - acc: 0.9109 - val_loss: 0.4974 - val_acc: 0.9308

Epoch 00023: loss did not improve from 0.74460
Epoch 24/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5962 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.8597 - acc: 0.9070 - val_loss: 0.4791 - val_acc: 0.9615

Epoch 00024: loss did not improve from 0.74460
Epoch 25/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5520 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.8185 - acc: 0.9147 - val_loss: 0.5235 - val_acc: 0.9231
DeepAmes+ Weights:  31%|███       | 4/13 [00:08<00:18,  2.02s/it]
Epoch 00025: loss did not improve from 0.74460
Epoch 00025: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 1.6107 - acc: 0.6562
516/516 [==============================] - 0s 537us/step - loss: 1.6769 - acc: 0.8081 - val_loss: 1.0461 - val_acc: 0.8692

Epoch 00001: loss improved from inf to 1.67689, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3790 - acc: 0.8750
516/516 [==============================] - 0s 33us/step - loss: 1.4525 - acc: 0.8450 - val_loss: 0.9655 - val_acc: 0.8769

Epoch 00002: loss improved from 1.67689 to 1.45246, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9683 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.3948 - acc: 0.8547 - val_loss: 0.8805 - val_acc: 0.8846

Epoch 00003: loss improved from 1.45246 to 1.39477, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9678 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.2742 - acc: 0.8740 - val_loss: 0.9217 - val_acc: 0.8615

Epoch 00004: loss improved from 1.39477 to 1.27420, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7874 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.2470 - acc: 0.8760 - val_loss: 0.8771 - val_acc: 0.8615

Epoch 00005: loss improved from 1.27420 to 1.24700, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8776 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.1767 - acc: 0.8779 - val_loss: 0.8189 - val_acc: 0.8692

Epoch 00006: loss improved from 1.24700 to 1.17671, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7500 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.1226 - acc: 0.8915 - val_loss: 0.8721 - val_acc: 0.8615

Epoch 00007: loss improved from 1.17671 to 1.12257, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8919 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.1455 - acc: 0.8915 - val_loss: 0.7244 - val_acc: 0.8615

Epoch 00008: loss did not improve from 1.12257
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8625 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.1449 - acc: 0.8818 - val_loss: 0.6937 - val_acc: 0.8923

Epoch 00009: loss did not improve from 1.12257
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7486 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.0873 - acc: 0.8876 - val_loss: 0.6891 - val_acc: 0.8769

Epoch 00010: loss improved from 1.12257 to 1.08727, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6267 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.0161 - acc: 0.9070 - val_loss: 0.6776 - val_acc: 0.8769

Epoch 00011: loss improved from 1.08727 to 1.01613, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6946 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9430 - acc: 0.8973 - val_loss: 0.6186 - val_acc: 0.9077

Epoch 00012: loss improved from 1.01613 to 0.94296, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9817 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 0.9384 - acc: 0.9050 - val_loss: 0.7000 - val_acc: 0.8769

Epoch 00013: loss improved from 0.94296 to 0.93838, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6236 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.0465 - acc: 0.8934 - val_loss: 0.6252 - val_acc: 0.8692

Epoch 00014: loss did not improve from 0.93838
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5900 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.0148 - acc: 0.8973 - val_loss: 0.6478 - val_acc: 0.8769

Epoch 00015: loss did not improve from 0.93838
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5614 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 0.9710 - acc: 0.8953 - val_loss: 0.6484 - val_acc: 0.8923

Epoch 00016: loss did not improve from 0.93838
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5644 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9742 - acc: 0.8953 - val_loss: 0.5799 - val_acc: 0.8692

Epoch 00017: loss did not improve from 0.93838
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8495 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9550 - acc: 0.9012 - val_loss: 0.5220 - val_acc: 0.9231
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:10<00:15,  1.99s/it]
Epoch 00018: loss did not improve from 0.93838
Epoch 00018: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 2.1436 - acc: 0.6250
516/516 [==============================] - 0s 524us/step - loss: 1.9612 - acc: 0.7597 - val_loss: 1.4629 - val_acc: 0.8154

Epoch 00001: loss improved from inf to 1.96123, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.4063 - acc: 0.8438
516/516 [==============================] - 0s 32us/step - loss: 1.7647 - acc: 0.8120 - val_loss: 1.2819 - val_acc: 0.8615

Epoch 00002: loss improved from 1.96123 to 1.76471, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1094 - acc: 0.9375
516/516 [==============================] - 0s 32us/step - loss: 1.5242 - acc: 0.8605 - val_loss: 1.1827 - val_acc: 0.8538

Epoch 00003: loss improved from 1.76471 to 1.52423, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2085 - acc: 0.8750
516/516 [==============================] - 0s 31us/step - loss: 1.5017 - acc: 0.8566 - val_loss: 1.2074 - val_acc: 0.8769

Epoch 00004: loss improved from 1.52423 to 1.50167, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0491 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.4056 - acc: 0.8605 - val_loss: 1.0332 - val_acc: 0.8923

Epoch 00005: loss improved from 1.50167 to 1.40557, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0818 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4167 - acc: 0.8876 - val_loss: 1.0142 - val_acc: 0.8538

Epoch 00006: loss did not improve from 1.40557
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9335 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.3819 - acc: 0.8682 - val_loss: 0.9209 - val_acc: 0.8923

Epoch 00007: loss improved from 1.40557 to 1.38187, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8539 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.3983 - acc: 0.8682 - val_loss: 0.9045 - val_acc: 0.8615

Epoch 00008: loss did not improve from 1.38187
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8434 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.2742 - acc: 0.8721 - val_loss: 0.9276 - val_acc: 0.8538

Epoch 00009: loss improved from 1.38187 to 1.27415, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9185 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.2316 - acc: 0.8779 - val_loss: 0.8057 - val_acc: 0.9000

Epoch 00010: loss improved from 1.27415 to 1.23156, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9971 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.1633 - acc: 0.8798 - val_loss: 0.7418 - val_acc: 0.8769

Epoch 00011: loss improved from 1.23156 to 1.16333, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7334 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.3330 - acc: 0.8643 - val_loss: 0.8027 - val_acc: 0.8769

Epoch 00012: loss did not improve from 1.16333
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7439 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3007 - acc: 0.8663 - val_loss: 0.8532 - val_acc: 0.8538

Epoch 00013: loss did not improve from 1.16333
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7665 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.0836 - acc: 0.8779 - val_loss: 0.7296 - val_acc: 0.9000

Epoch 00014: loss improved from 1.16333 to 1.08361, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7273 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.0848 - acc: 0.8992 - val_loss: 0.8247 - val_acc: 0.8615

Epoch 00015: loss did not improve from 1.08361
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7009 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.0316 - acc: 0.8915 - val_loss: 0.8037 - val_acc: 0.9077

Epoch 00016: loss improved from 1.08361 to 1.03157, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_11.h5
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7474 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.1106 - acc: 0.8934 - val_loss: 0.8977 - val_acc: 0.7308

Epoch 00017: loss did not improve from 1.03157
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6996 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.1387 - acc: 0.8624 - val_loss: 0.6250 - val_acc: 0.9154

Epoch 00018: loss did not improve from 1.03157
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9259 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.2211 - acc: 0.8702 - val_loss: 0.7079 - val_acc: 0.8692

Epoch 00019: loss did not improve from 1.03157
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6789 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.1041 - acc: 0.8760 - val_loss: 0.6889 - val_acc: 0.8692

Epoch 00020: loss did not improve from 1.03157
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6536 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.2656 - acc: 0.8566 - val_loss: 0.8204 - val_acc: 0.8692
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:11<00:13,  1.97s/it]
Epoch 00021: loss did not improve from 1.03157
Epoch 00021: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 2.0651 - acc: 0.6875
516/516 [==============================] - 0s 528us/step - loss: 1.9747 - acc: 0.7829 - val_loss: 1.4273 - val_acc: 0.8000

Epoch 00001: loss improved from inf to 1.97472, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3384 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.6309 - acc: 0.8372 - val_loss: 1.3835 - val_acc: 0.8462

Epoch 00002: loss improved from 1.97472 to 1.63092, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2171 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.5686 - acc: 0.8391 - val_loss: 1.2719 - val_acc: 0.8538

Epoch 00003: loss improved from 1.63092 to 1.56860, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1243 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.6304 - acc: 0.8508 - val_loss: 1.1412 - val_acc: 0.8769

Epoch 00004: loss did not improve from 1.56860
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1926 - acc: 0.8750
516/516 [==============================] - 0s 31us/step - loss: 1.5037 - acc: 0.8450 - val_loss: 1.0302 - val_acc: 0.8846

Epoch 00005: loss improved from 1.56860 to 1.50367, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0697 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.4354 - acc: 0.8585 - val_loss: 1.0234 - val_acc: 0.8615

Epoch 00006: loss improved from 1.50367 to 1.43542, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0625 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.3491 - acc: 0.8740 - val_loss: 0.9141 - val_acc: 0.8846

Epoch 00007: loss improved from 1.43542 to 1.34913, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9582 - acc: 0.9062
516/516 [==============================] - 0s 33us/step - loss: 1.3314 - acc: 0.8779 - val_loss: 0.9372 - val_acc: 0.8615

Epoch 00008: loss improved from 1.34913 to 1.33137, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9483 - acc: 0.9062
516/516 [==============================] - 0s 33us/step - loss: 1.3028 - acc: 0.8624 - val_loss: 0.8223 - val_acc: 0.8846

Epoch 00009: loss improved from 1.33137 to 1.30277, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0145 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.3079 - acc: 0.8624 - val_loss: 0.8411 - val_acc: 0.8692

Epoch 00010: loss did not improve from 1.30277
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7600 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.2241 - acc: 0.8760 - val_loss: 0.8079 - val_acc: 0.8692

Epoch 00011: loss improved from 1.30277 to 1.22412, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7315 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.2600 - acc: 0.8798 - val_loss: 0.8662 - val_acc: 0.8615

Epoch 00012: loss did not improve from 1.22412
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7468 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.2224 - acc: 0.8643 - val_loss: 0.8145 - val_acc: 0.8615

Epoch 00013: loss improved from 1.22412 to 1.22239, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8585 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.1740 - acc: 0.8740 - val_loss: 0.8400 - val_acc: 0.8538

Epoch 00014: loss improved from 1.22239 to 1.17405, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8137 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.2453 - acc: 0.8624 - val_loss: 0.9345 - val_acc: 0.8462

Epoch 00015: loss did not improve from 1.17405
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6838 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.1097 - acc: 0.8779 - val_loss: 0.8650 - val_acc: 0.8846

Epoch 00016: loss improved from 1.17405 to 1.10969, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6664 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.2211 - acc: 0.8760 - val_loss: 0.7650 - val_acc: 0.8846

Epoch 00017: loss did not improve from 1.10969
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7108 - acc: 0.9688
516/516 [==============================] - 0s 31us/step - loss: 1.1431 - acc: 0.8798 - val_loss: 0.8244 - val_acc: 0.8692

Epoch 00018: loss did not improve from 1.10969
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7391 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.0610 - acc: 0.8779 - val_loss: 0.8241 - val_acc: 0.8692

Epoch 00019: loss improved from 1.10969 to 1.06103, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5981 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 0.9377 - acc: 0.8818 - val_loss: 0.7284 - val_acc: 0.8692

Epoch 00020: loss improved from 1.06103 to 0.93767, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_12.h5
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0627 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.0935 - acc: 0.8915 - val_loss: 0.8678 - val_acc: 0.8615

Epoch 00021: loss did not improve from 0.93767
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7935 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 0.9677 - acc: 0.9147 - val_loss: 0.7074 - val_acc: 0.8846

Epoch 00022: loss did not improve from 0.93767
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7266 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.0748 - acc: 0.8682 - val_loss: 0.5380 - val_acc: 0.8923

Epoch 00023: loss did not improve from 0.93767
Epoch 24/100

 32/516 [>.............................] - ETA: 0s - loss: 1.4557 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.1476 - acc: 0.8663 - val_loss: 0.6524 - val_acc: 0.9000

Epoch 00024: loss did not improve from 0.93767
Epoch 25/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6367 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.0182 - acc: 0.8760 - val_loss: 0.5685 - val_acc: 0.8846
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:13<00:11,  1.97s/it]
Epoch 00025: loss did not improve from 0.93767
Epoch 00025: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 2.3905 - acc: 0.5938
516/516 [==============================] - 0s 535us/step - loss: 2.0736 - acc: 0.7946 - val_loss: 1.5302 - val_acc: 0.8231

Epoch 00001: loss improved from inf to 2.07362, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3284 - acc: 0.9375
516/516 [==============================] - 0s 33us/step - loss: 1.9137 - acc: 0.8236 - val_loss: 1.3505 - val_acc: 0.8615

Epoch 00002: loss improved from 2.07362 to 1.91372, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2576 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.7555 - acc: 0.8353 - val_loss: 1.3051 - val_acc: 0.8538

Epoch 00003: loss improved from 1.91372 to 1.75547, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1617 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.6994 - acc: 0.8508 - val_loss: 1.2916 - val_acc: 0.8462

Epoch 00004: loss improved from 1.75547 to 1.69940, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1885 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.6850 - acc: 0.8605 - val_loss: 1.1884 - val_acc: 0.8615

Epoch 00005: loss improved from 1.69940 to 1.68498, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0808 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4783 - acc: 0.8663 - val_loss: 1.0832 - val_acc: 0.9077

Epoch 00006: loss improved from 1.68498 to 1.47834, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1448 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4638 - acc: 0.8857 - val_loss: 1.1186 - val_acc: 0.8077

Epoch 00007: loss improved from 1.47834 to 1.46378, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2350 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.3751 - acc: 0.8760 - val_loss: 0.9683 - val_acc: 0.8923

Epoch 00008: loss improved from 1.46378 to 1.37508, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9330 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.3787 - acc: 0.8760 - val_loss: 0.9074 - val_acc: 0.8692

Epoch 00009: loss did not improve from 1.37508
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9247 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.2504 - acc: 0.8895 - val_loss: 0.8897 - val_acc: 0.8846

Epoch 00010: loss improved from 1.37508 to 1.25036, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_13.h5
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8746 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4023 - acc: 0.8663 - val_loss: 0.8809 - val_acc: 0.8692

Epoch 00011: loss did not improve from 1.25036
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8618 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.3862 - acc: 0.8585 - val_loss: 0.8985 - val_acc: 0.8615

Epoch 00012: loss did not improve from 1.25036
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8232 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.2602 - acc: 0.8798 - val_loss: 0.8563 - val_acc: 0.8615

Epoch 00013: loss did not improve from 1.25036
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7739 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.3348 - acc: 0.8702 - val_loss: 0.8957 - val_acc: 0.8692

Epoch 00014: loss did not improve from 1.25036
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7588 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.2895 - acc: 0.8605 - val_loss: 0.8706 - val_acc: 0.8615
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:15<00:09,  1.93s/it]
Epoch 00015: loss did not improve from 1.25036
Epoch 00015: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 1.9376 - acc: 0.6250
516/516 [==============================] - 0s 524us/step - loss: 2.0034 - acc: 0.7907 - val_loss: 1.5440 - val_acc: 0.7923

Epoch 00001: loss improved from inf to 2.00345, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2187 - acc: 0.8750
516/516 [==============================] - 0s 32us/step - loss: 1.9939 - acc: 0.8043 - val_loss: 1.3289 - val_acc: 0.8462

Epoch 00002: loss improved from 2.00345 to 1.99394, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2704 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.6388 - acc: 0.8391 - val_loss: 1.2156 - val_acc: 0.8538

Epoch 00003: loss improved from 1.99394 to 1.63883, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1959 - acc: 0.9062
516/516 [==============================] - 0s 33us/step - loss: 1.5360 - acc: 0.8391 - val_loss: 1.0758 - val_acc: 0.8692

Epoch 00004: loss improved from 1.63883 to 1.53599, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9952 - acc: 0.9375
516/516 [==============================] - 0s 32us/step - loss: 1.5240 - acc: 0.8450 - val_loss: 1.0349 - val_acc: 0.8615

Epoch 00005: loss improved from 1.53599 to 1.52401, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9312 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.3903 - acc: 0.8430 - val_loss: 0.9741 - val_acc: 0.8538

Epoch 00006: loss improved from 1.52401 to 1.39028, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0018 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.5586 - acc: 0.8411 - val_loss: 1.0825 - val_acc: 0.8385

Epoch 00007: loss did not improve from 1.39028
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9949 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3857 - acc: 0.8450 - val_loss: 0.9726 - val_acc: 0.8615

Epoch 00008: loss improved from 1.39028 to 1.38570, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8450 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.3258 - acc: 0.8682 - val_loss: 0.9063 - val_acc: 0.8692

Epoch 00009: loss improved from 1.38570 to 1.32585, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9089 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.3384 - acc: 0.8547 - val_loss: 0.8264 - val_acc: 0.8615

Epoch 00010: loss did not improve from 1.32585
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8225 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.3761 - acc: 0.8566 - val_loss: 0.8700 - val_acc: 0.8615

Epoch 00011: loss did not improve from 1.32585
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8367 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.4096 - acc: 0.8663 - val_loss: 1.0117 - val_acc: 0.8462

Epoch 00012: loss did not improve from 1.32585
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8872 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3114 - acc: 0.8585 - val_loss: 0.9686 - val_acc: 0.8385

Epoch 00013: loss improved from 1.32585 to 1.31135, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7156 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.2442 - acc: 0.8469 - val_loss: 0.8083 - val_acc: 0.8308

Epoch 00014: loss improved from 1.31135 to 1.24418, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8223 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.2829 - acc: 0.8527 - val_loss: 0.8755 - val_acc: 0.8385

Epoch 00015: loss did not improve from 1.24418
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7573 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.4126 - acc: 0.8605 - val_loss: 1.0566 - val_acc: 0.8308

Epoch 00016: loss did not improve from 1.24418
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9200 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.1994 - acc: 0.8818 - val_loss: 1.2749 - val_acc: 0.4385

Epoch 00017: loss improved from 1.24418 to 1.19938, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7113 - acc: 0.7812
516/516 [==============================] - 0s 30us/step - loss: 1.4102 - acc: 0.8391 - val_loss: 1.0494 - val_acc: 0.8231

Epoch 00018: loss did not improve from 1.19938
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7247 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.2551 - acc: 0.8663 - val_loss: 0.9093 - val_acc: 0.8385

Epoch 00019: loss did not improve from 1.19938
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7278 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.2933 - acc: 0.8798 - val_loss: 1.1202 - val_acc: 0.6692

Epoch 00020: loss did not improve from 1.19938
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0158 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.0534 - acc: 0.8450 - val_loss: 0.7533 - val_acc: 0.8385

Epoch 00021: loss improved from 1.19938 to 1.05343, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_14.h5
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6786 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.0605 - acc: 0.8760 - val_loss: 0.9521 - val_acc: 0.8308

Epoch 00022: loss did not improve from 1.05343
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 0.5448 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.2016 - acc: 0.8624 - val_loss: 0.9778 - val_acc: 0.8308

Epoch 00023: loss did not improve from 1.05343
Epoch 24/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7404 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.8301 - acc: 0.8043 - val_loss: 1.1559 - val_acc: 0.8385

Epoch 00024: loss did not improve from 1.05343
Epoch 25/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8200 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.2169 - acc: 0.8624 - val_loss: 0.7309 - val_acc: 0.8769

Epoch 00025: loss did not improve from 1.05343
Epoch 26/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6393 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.2404 - acc: 0.8605 - val_loss: 0.6621 - val_acc: 0.8923
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:17<00:07,  1.96s/it]
Epoch 00026: loss did not improve from 1.05343
Epoch 00026: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 1.8892 - acc: 0.6250
516/516 [==============================] - 0s 526us/step - loss: 2.0217 - acc: 0.7771 - val_loss: 1.4514 - val_acc: 0.8615

Epoch 00001: loss improved from inf to 2.02169, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2852 - acc: 0.8750
516/516 [==============================] - 0s 32us/step - loss: 1.8216 - acc: 0.8217 - val_loss: 1.3483 - val_acc: 0.8462

Epoch 00002: loss improved from 2.02169 to 1.82158, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2348 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.7177 - acc: 0.8256 - val_loss: 1.1799 - val_acc: 0.8462

Epoch 00003: loss improved from 1.82158 to 1.71765, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3744 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.6980 - acc: 0.8198 - val_loss: 1.1742 - val_acc: 0.8462

Epoch 00004: loss improved from 1.71765 to 1.69800, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0630 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.6232 - acc: 0.8488 - val_loss: 1.0906 - val_acc: 0.8538

Epoch 00005: loss improved from 1.69800 to 1.62318, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0802 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.5501 - acc: 0.8411 - val_loss: 1.0063 - val_acc: 0.8692

Epoch 00006: loss improved from 1.62318 to 1.55006, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9797 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4874 - acc: 0.8353 - val_loss: 0.9889 - val_acc: 0.8462

Epoch 00007: loss improved from 1.55006 to 1.48737, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9781 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4392 - acc: 0.8663 - val_loss: 1.0835 - val_acc: 0.8692

Epoch 00008: loss improved from 1.48737 to 1.43918, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9635 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.4909 - acc: 0.8469 - val_loss: 0.9879 - val_acc: 0.8692

Epoch 00009: loss did not improve from 1.43918
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0500 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.2942 - acc: 0.8643 - val_loss: 0.9276 - val_acc: 0.8923

Epoch 00010: loss improved from 1.43918 to 1.29415, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9577 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.3017 - acc: 0.8643 - val_loss: 0.8291 - val_acc: 0.8846

Epoch 00011: loss did not improve from 1.29415
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8463 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.1989 - acc: 0.8702 - val_loss: 0.9268 - val_acc: 0.8538

Epoch 00012: loss improved from 1.29415 to 1.19894, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8738 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3118 - acc: 0.8663 - val_loss: 0.9598 - val_acc: 0.8462

Epoch 00013: loss did not improve from 1.19894
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8749 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.1691 - acc: 0.8740 - val_loss: 0.9109 - val_acc: 0.8692

Epoch 00014: loss improved from 1.19894 to 1.16915, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7542 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.1629 - acc: 0.8818 - val_loss: 1.0808 - val_acc: 0.8462

Epoch 00015: loss improved from 1.16915 to 1.16288, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8052 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.3537 - acc: 0.8818 - val_loss: 1.0642 - val_acc: 0.8462

Epoch 00016: loss did not improve from 1.16288
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7456 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.2974 - acc: 0.8682 - val_loss: 0.9683 - val_acc: 0.8077

Epoch 00017: loss did not improve from 1.16288
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7330 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.1512 - acc: 0.8624 - val_loss: 0.8795 - val_acc: 0.8385

Epoch 00018: loss improved from 1.16288 to 1.15119, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_15.h5
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6712 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.5973 - acc: 0.8566 - val_loss: 1.2787 - val_acc: 0.8385

Epoch 00019: loss did not improve from 1.15119
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8718 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3855 - acc: 0.8702 - val_loss: 0.8366 - val_acc: 0.8769

Epoch 00020: loss did not improve from 1.15119
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1372 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.4409 - acc: 0.8353 - val_loss: 0.8919 - val_acc: 0.8000

Epoch 00021: loss did not improve from 1.15119
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7823 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3205 - acc: 0.8488 - val_loss: 0.8940 - val_acc: 0.8077

Epoch 00022: loss did not improve from 1.15119
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7543 - acc: 0.8438
516/516 [==============================] - 0s 30us/step - loss: 1.5272 - acc: 0.8488 - val_loss: 0.8102 - val_acc: 0.8846
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:19<00:05,  1.97s/it]
Epoch 00023: loss did not improve from 1.15119
Epoch 00023: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 3.1825 - acc: 0.6250
516/516 [==============================] - 0s 527us/step - loss: 2.1598 - acc: 0.7926 - val_loss: 1.4613 - val_acc: 0.8231

Epoch 00001: loss improved from inf to 2.15981, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3387 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.8449 - acc: 0.8256 - val_loss: 1.3891 - val_acc: 0.8231

Epoch 00002: loss improved from 2.15981 to 1.84488, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1601 - acc: 0.9375
516/516 [==============================] - 0s 32us/step - loss: 1.6500 - acc: 0.8430 - val_loss: 1.1703 - val_acc: 0.8462

Epoch 00003: loss improved from 1.84488 to 1.64996, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1570 - acc: 0.8750
516/516 [==============================] - 0s 31us/step - loss: 1.5876 - acc: 0.8333 - val_loss: 1.1412 - val_acc: 0.8385

Epoch 00004: loss improved from 1.64996 to 1.58756, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0402 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4796 - acc: 0.8508 - val_loss: 1.0884 - val_acc: 0.8538

Epoch 00005: loss improved from 1.58756 to 1.47958, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0088 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4700 - acc: 0.8450 - val_loss: 0.9806 - val_acc: 0.8538

Epoch 00006: loss improved from 1.47958 to 1.47003, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0300 - acc: 0.8750
516/516 [==============================] - 0s 31us/step - loss: 1.5566 - acc: 0.8527 - val_loss: 1.1020 - val_acc: 0.8385

Epoch 00007: loss did not improve from 1.47003
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0284 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3691 - acc: 0.8740 - val_loss: 0.9250 - val_acc: 0.8462

Epoch 00008: loss improved from 1.47003 to 1.36909, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8957 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3759 - acc: 0.8682 - val_loss: 1.0317 - val_acc: 0.8308

Epoch 00009: loss did not improve from 1.36909
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8551 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.3155 - acc: 0.8740 - val_loss: 0.9897 - val_acc: 0.8615

Epoch 00010: loss improved from 1.36909 to 1.31547, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8950 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.3750 - acc: 0.8605 - val_loss: 1.0872 - val_acc: 0.6923

Epoch 00011: loss did not improve from 1.31547
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8002 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.2409 - acc: 0.8411 - val_loss: 0.8195 - val_acc: 0.8615

Epoch 00012: loss improved from 1.31547 to 1.24089, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7683 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.3361 - acc: 0.8643 - val_loss: 0.7680 - val_acc: 0.8538

Epoch 00013: loss did not improve from 1.24089
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7673 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.1929 - acc: 0.8740 - val_loss: 0.8618 - val_acc: 0.8692

Epoch 00014: loss improved from 1.24089 to 1.19294, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7242 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.4085 - acc: 0.8605 - val_loss: 0.7619 - val_acc: 0.9000

Epoch 00015: loss did not improve from 1.19294
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9297 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.3719 - acc: 0.8527 - val_loss: 1.0436 - val_acc: 0.8385

Epoch 00016: loss did not improve from 1.19294
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8568 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.3075 - acc: 0.8566 - val_loss: 0.9439 - val_acc: 0.8692

Epoch 00017: loss did not improve from 1.19294
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.7789 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.3093 - acc: 0.8527 - val_loss: 0.7248 - val_acc: 0.8692

Epoch 00018: loss did not improve from 1.19294
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8302 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.1746 - acc: 0.8643 - val_loss: 0.8104 - val_acc: 0.8692

Epoch 00019: loss improved from 1.19294 to 1.17463, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_16.h5
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 0.6230 - acc: 0.9688
516/516 [==============================] - 0s 30us/step - loss: 1.6753 - acc: 0.8314 - val_loss: 1.2636 - val_acc: 0.8000

Epoch 00020: loss did not improve from 1.17463
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1442 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.7354 - acc: 0.8120 - val_loss: 1.0935 - val_acc: 0.8308

Epoch 00021: loss did not improve from 1.17463
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8868 - acc: 0.8438
516/516 [==============================] - 0s 30us/step - loss: 1.4339 - acc: 0.8178 - val_loss: 0.9158 - val_acc: 0.8385

Epoch 00022: loss did not improve from 1.17463
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0375 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.6571 - acc: 0.7888 - val_loss: 0.9177 - val_acc: 0.8462

Epoch 00023: loss did not improve from 1.17463
Epoch 24/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1055 - acc: 0.7500
516/516 [==============================] - 0s 30us/step - loss: 1.2845 - acc: 0.8004 - val_loss: 0.7129 - val_acc: 0.8615
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:21<00:03,  1.94s/it]
Epoch 00024: loss did not improve from 1.17463
Epoch 00024: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 3.3620 - acc: 0.6562
516/516 [==============================] - 0s 542us/step - loss: 2.6210 - acc: 0.7442 - val_loss: 1.7659 - val_acc: 0.8308

Epoch 00001: loss improved from inf to 2.62100, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.8796 - acc: 0.8750
516/516 [==============================] - 0s 33us/step - loss: 2.3240 - acc: 0.8101 - val_loss: 1.7107 - val_acc: 0.8385

Epoch 00002: loss improved from 2.62100 to 2.32395, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.6639 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 2.1949 - acc: 0.8275 - val_loss: 1.6580 - val_acc: 0.8385

Epoch 00003: loss improved from 2.32395 to 2.19486, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.6165 - acc: 0.8750
516/516 [==============================] - 0s 32us/step - loss: 2.0826 - acc: 0.8159 - val_loss: 1.5701 - val_acc: 0.8154

Epoch 00004: loss improved from 2.19486 to 2.08262, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 1.4822 - acc: 0.8750
516/516 [==============================] - 0s 32us/step - loss: 1.9522 - acc: 0.8140 - val_loss: 1.4638 - val_acc: 0.8385

Epoch 00005: loss improved from 2.08262 to 1.95217, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 1.4398 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.9047 - acc: 0.8430 - val_loss: 1.4897 - val_acc: 0.7769

Epoch 00006: loss improved from 1.95217 to 1.90474, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3055 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.7993 - acc: 0.8508 - val_loss: 1.3992 - val_acc: 0.8462

Epoch 00007: loss improved from 1.90474 to 1.79929, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2702 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.8080 - acc: 0.8527 - val_loss: 1.2782 - val_acc: 0.8385

Epoch 00008: loss did not improve from 1.79929
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1258 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.6393 - acc: 0.8547 - val_loss: 1.2868 - val_acc: 0.8462

Epoch 00009: loss improved from 1.79929 to 1.63926, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0450 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.6600 - acc: 0.8527 - val_loss: 1.3430 - val_acc: 0.8462

Epoch 00010: loss did not improve from 1.63926
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0847 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.6172 - acc: 0.8566 - val_loss: 1.2384 - val_acc: 0.7077

Epoch 00011: loss improved from 1.63926 to 1.61724, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 2.1853 - acc: 0.6875
516/516 [==============================] - 0s 31us/step - loss: 1.7461 - acc: 0.8295 - val_loss: 1.1558 - val_acc: 0.8154

Epoch 00012: loss did not improve from 1.61724
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1126 - acc: 0.8750
516/516 [==============================] - 0s 31us/step - loss: 1.6966 - acc: 0.8256 - val_loss: 1.1902 - val_acc: 0.8077

Epoch 00013: loss did not improve from 1.61724
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0530 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.7219 - acc: 0.8314 - val_loss: 1.0918 - val_acc: 0.8308

Epoch 00014: loss did not improve from 1.61724
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9871 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.4698 - acc: 0.8702 - val_loss: 0.9187 - val_acc: 0.8846

Epoch 00015: loss improved from 1.61724 to 1.46984, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9350 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.4526 - acc: 0.8411 - val_loss: 1.1056 - val_acc: 0.8538

Epoch 00016: loss improved from 1.46984 to 1.45256, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_17.h5
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9290 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.5501 - acc: 0.8702 - val_loss: 1.1068 - val_acc: 0.8615

Epoch 00017: loss did not improve from 1.45256
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8820 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.5713 - acc: 0.8353 - val_loss: 0.9784 - val_acc: 0.8538

Epoch 00018: loss did not improve from 1.45256
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1706 - acc: 0.9375
516/516 [==============================] - 0s 31us/step - loss: 1.5536 - acc: 0.8585 - val_loss: 1.1171 - val_acc: 0.8231

Epoch 00019: loss did not improve from 1.45256
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2783 - acc: 0.8438
516/516 [==============================] - 0s 31us/step - loss: 1.5318 - acc: 0.8275 - val_loss: 0.9441 - val_acc: 0.8308

Epoch 00020: loss did not improve from 1.45256
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8353 - acc: 0.8750
516/516 [==============================] - 0s 31us/step - loss: 1.4780 - acc: 0.8411 - val_loss: 1.0064 - val_acc: 0.8462
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:23<00:01,  1.96s/it]
Epoch 00021: loss did not improve from 1.45256
Epoch 00021: early stopping
Train on 516 samples, validate on 130 samples
Epoch 1/100

 32/516 [>.............................] - ETA: 3s - loss: 3.1351 - acc: 0.5938
516/516 [==============================] - 0s 525us/step - loss: 2.6746 - acc: 0.7578 - val_loss: 1.8350 - val_acc: 0.8231

Epoch 00001: loss improved from inf to 2.67460, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/516 [>.............................] - ETA: 0s - loss: 1.7422 - acc: 0.8438
516/516 [==============================] - 0s 33us/step - loss: 2.3164 - acc: 0.7868 - val_loss: 1.8071 - val_acc: 0.7692

Epoch 00002: loss improved from 2.67460 to 2.31635, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/516 [>.............................] - ETA: 0s - loss: 1.5760 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 2.0800 - acc: 0.8081 - val_loss: 1.5606 - val_acc: 0.8308

Epoch 00003: loss improved from 2.31635 to 2.08000, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/516 [>.............................] - ETA: 0s - loss: 1.5417 - acc: 0.9062
516/516 [==============================] - 0s 32us/step - loss: 1.9681 - acc: 0.8217 - val_loss: 1.5051 - val_acc: 0.8385

Epoch 00004: loss improved from 2.08000 to 1.96806, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3592 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.9896 - acc: 0.8159 - val_loss: 1.4717 - val_acc: 0.8308

Epoch 00005: loss did not improve from 1.96806
Epoch 6/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2832 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.8839 - acc: 0.8391 - val_loss: 1.4412 - val_acc: 0.8154

Epoch 00006: loss improved from 1.96806 to 1.88389, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3214 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.8221 - acc: 0.8353 - val_loss: 1.4481 - val_acc: 0.6846

Epoch 00007: loss improved from 1.88389 to 1.82212, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/516 [>.............................] - ETA: 0s - loss: 1.3489 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.7236 - acc: 0.8488 - val_loss: 1.1657 - val_acc: 0.8462

Epoch 00008: loss improved from 1.82212 to 1.72360, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/516 [>.............................] - ETA: 0s - loss: 1.2095 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.6849 - acc: 0.8508 - val_loss: 1.1568 - val_acc: 0.8462

Epoch 00009: loss improved from 1.72360 to 1.68493, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1933 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.6023 - acc: 0.8585 - val_loss: 1.1238 - val_acc: 0.8538

Epoch 00010: loss improved from 1.68493 to 1.60229, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0946 - acc: 0.9062
516/516 [==============================] - 0s 31us/step - loss: 1.6061 - acc: 0.8605 - val_loss: 1.1793 - val_acc: 0.8615

Epoch 00011: loss did not improve from 1.60229
Epoch 12/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1651 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.6489 - acc: 0.8275 - val_loss: 1.1757 - val_acc: 0.8692

Epoch 00012: loss did not improve from 1.60229
Epoch 13/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9964 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.5516 - acc: 0.8566 - val_loss: 0.9670 - val_acc: 0.8615

Epoch 00013: loss improved from 1.60229 to 1.55161, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 14/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0475 - acc: 0.7812
516/516 [==============================] - 0s 30us/step - loss: 1.6885 - acc: 0.8372 - val_loss: 1.0044 - val_acc: 0.9000

Epoch 00014: loss did not improve from 1.55161
Epoch 15/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0145 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.4588 - acc: 0.8624 - val_loss: 1.0278 - val_acc: 0.8692

Epoch 00015: loss improved from 1.55161 to 1.45881, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0412 - acc: 0.8438
516/516 [==============================] - 0s 30us/step - loss: 1.5563 - acc: 0.8566 - val_loss: 0.9778 - val_acc: 0.8538

Epoch 00016: loss did not improve from 1.45881
Epoch 17/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9634 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.6185 - acc: 0.8391 - val_loss: 1.0311 - val_acc: 0.7846

Epoch 00017: loss did not improve from 1.45881
Epoch 18/100

 32/516 [>.............................] - ETA: 0s - loss: 1.1447 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.4320 - acc: 0.8585 - val_loss: 0.8714 - val_acc: 0.9154

Epoch 00018: loss improved from 1.45881 to 1.43203, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 19/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0274 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.3499 - acc: 0.8779 - val_loss: 1.1124 - val_acc: 0.4462

Epoch 00019: loss improved from 1.43203 to 1.34986, saving model to ./results_TA1535_without_S9/DeepAmes_models/weight_18.h5
Epoch 20/100

 32/516 [>.............................] - ETA: 0s - loss: 2.2983 - acc: 0.6875
516/516 [==============================] - 0s 30us/step - loss: 1.9269 - acc: 0.8004 - val_loss: 1.5285 - val_acc: 0.5692

Epoch 00020: loss did not improve from 1.34986
Epoch 21/100

 32/516 [>.............................] - ETA: 0s - loss: 1.0660 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.6652 - acc: 0.8140 - val_loss: 0.9012 - val_acc: 0.8692

Epoch 00021: loss did not improve from 1.34986
Epoch 22/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9416 - acc: 0.9375
516/516 [==============================] - 0s 30us/step - loss: 1.6152 - acc: 0.8527 - val_loss: 1.2234 - val_acc: 0.8692

Epoch 00022: loss did not improve from 1.34986
Epoch 23/100

 32/516 [>.............................] - ETA: 0s - loss: 0.9631 - acc: 0.8750
516/516 [==============================] - 0s 30us/step - loss: 1.4891 - acc: 0.8527 - val_loss: 1.1113 - val_acc: 0.8615

Epoch 00023: loss did not improve from 1.34986
Epoch 24/100

 32/516 [>.............................] - ETA: 0s - loss: 0.8003 - acc: 0.9062
516/516 [==============================] - 0s 30us/step - loss: 1.4235 - acc: 0.8450 - val_loss: 1.0781 - val_acc: 0.8462
DeepAmes+ Weights: 100%|██████████| 13/13 [00:25<00:00,  1.97s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:25<00:00,  1.98s/it]

Epoch 00024: loss did not improve from 1.34986
Epoch 00024: early stopping
--- 3553.8739907741547 seconds ---

Generating metrics report for TA1535_without_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 361 samples.
Processing weight 7...
  Done. 361 samples.
Processing weight 8...
  Done. 361 samples.
Processing weight 9...
  Done. 361 samples.
Processing weight 10...
  Done. 361 samples.
Processing weight 11...
  Done. 361 samples.
Processing weight 12...
  Done. 361 samples.
Processing weight 13...
  Done. 361 samples.
Processing weight 14...
  Done. 361 samples.
Processing weight 15...
  Done. 361 samples.
Processing weight 16...
  Done. 361 samples.
Processing weight 17...
  Done. 361 samples.
Processing weight 18...
  Done. 361 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA1535_without_S9/metrics_report_TA1535_without_S9.txt

Done!

Completed TA1535_without_S9 in 3553.87 seconds

================================================================================
[9/16] Processing: TA1537_with_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA1537_with_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA1537_with_S9_Test_mold2.csv
(2798, 777)
(2238, 777)
(330, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:11<03:39, 11.55s/it]KNN Seeds:  10%|█         | 2/20 [00:23<03:29, 11.64s/it]KNN Seeds:  15%|█▌        | 3/20 [00:34<03:17, 11.62s/it]KNN Seeds:  20%|██        | 4/20 [00:46<03:05, 11.57s/it]KNN Seeds:  25%|██▌       | 5/20 [00:57<02:52, 11.53s/it]KNN Seeds:  30%|███       | 6/20 [01:09<02:41, 11.53s/it]KNN Seeds:  35%|███▌      | 7/20 [01:21<02:30, 11.60s/it]KNN Seeds:  40%|████      | 8/20 [01:32<02:19, 11.61s/it]KNN Seeds:  45%|████▌     | 9/20 [01:44<02:07, 11.56s/it]KNN Seeds:  50%|█████     | 10/20 [01:55<01:55, 11.57s/it]KNN Seeds:  55%|█████▌    | 11/20 [02:07<01:43, 11.55s/it]KNN Seeds:  60%|██████    | 12/20 [02:19<01:33, 11.63s/it]KNN Seeds:  65%|██████▌   | 13/20 [02:30<01:21, 11.62s/it]KNN Seeds:  70%|███████   | 14/20 [02:42<01:09, 11.61s/it]KNN Seeds:  75%|███████▌  | 15/20 [02:53<00:58, 11.65s/it]KNN Seeds:  80%|████████  | 16/20 [03:05<00:46, 11.64s/it]KNN Seeds:  85%|████████▌ | 17/20 [03:17<00:34, 11.66s/it]KNN Seeds:  90%|█████████ | 18/20 [03:29<00:23, 11.71s/it]KNN Seeds:  95%|█████████▌| 19/20 [03:40<00:11, 11.69s/it]KNN Seeds: 100%|██████████| 20/20 [03:52<00:00, 11.71s/it]KNN Seeds: 100%|██████████| 20/20 [03:52<00:00, 11.63s/it]
24
(100, None, 'lbfgs')
(2798, 777)
(2238, 777)
(330, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:02<00:41,  2.17s/it]LR Seeds:  10%|█         | 2/20 [00:04<00:39,  2.20s/it]LR Seeds:  15%|█▌        | 3/20 [00:06<00:37,  2.22s/it]LR Seeds:  20%|██        | 4/20 [00:08<00:35,  2.22s/it]LR Seeds:  25%|██▌       | 5/20 [00:11<00:33,  2.22s/it]LR Seeds:  30%|███       | 6/20 [00:13<00:31,  2.23s/it]LR Seeds:  35%|███▌      | 7/20 [00:15<00:29,  2.25s/it]LR Seeds:  40%|████      | 8/20 [00:17<00:27,  2.27s/it]LR Seeds:  45%|████▌     | 9/20 [00:20<00:25,  2.29s/it]LR Seeds:  50%|█████     | 10/20 [00:22<00:22,  2.29s/it]LR Seeds:  55%|█████▌    | 11/20 [00:24<00:20,  2.31s/it]LR Seeds:  60%|██████    | 12/20 [00:27<00:18,  2.32s/it]LR Seeds:  65%|██████▌   | 13/20 [00:29<00:16,  2.33s/it]LR Seeds:  70%|███████   | 14/20 [00:31<00:14,  2.34s/it]LR Seeds:  75%|███████▌  | 15/20 [00:34<00:11,  2.35s/it]LR Seeds:  80%|████████  | 16/20 [00:36<00:09,  2.36s/it]LR Seeds:  85%|████████▌ | 17/20 [00:39<00:07,  2.37s/it]LR Seeds:  90%|█████████ | 18/20 [00:41<00:04,  2.38s/it]LR Seeds:  95%|█████████▌| 19/20 [00:43<00:02,  2.39s/it]LR Seeds: 100%|██████████| 20/20 [00:46<00:00,  2.43s/it]LR Seeds: 100%|██████████| 20/20 [00:46<00:00,  2.32s/it]
96
('rbf', 1, 1)
(2798, 777)
(2238, 777)
(330, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [01:14<23:44, 74.96s/it]SVM Seeds:  10%|█         | 2/20 [02:30<22:30, 75.04s/it]SVM Seeds:  15%|█▌        | 3/20 [03:44<21:14, 74.97s/it]SVM Seeds:  20%|██        | 4/20 [04:59<20:00, 75.00s/it]SVM Seeds:  25%|██▌       | 5/20 [06:15<18:45, 75.04s/it]SVM Seeds:  30%|███       | 6/20 [07:29<17:29, 74.99s/it]SVM Seeds:  35%|███▌      | 7/20 [08:45<16:15, 75.03s/it]SVM Seeds:  40%|████      | 8/20 [10:00<15:00, 75.01s/it]SVM Seeds:  45%|████▌     | 9/20 [11:14<13:44, 74.98s/it]SVM Seeds:  50%|█████     | 10/20 [12:30<12:30, 75.01s/it]SVM Seeds:  55%|█████▌    | 11/20 [13:45<11:14, 75.00s/it]SVM Seeds:  60%|██████    | 12/20 [15:00<10:00, 75.05s/it]SVM Seeds:  65%|██████▌   | 13/20 [16:15<08:45, 75.05s/it]SVM Seeds:  70%|███████   | 14/20 [17:30<07:30, 75.07s/it]SVM Seeds:  75%|███████▌  | 15/20 [18:45<06:15, 75.12s/it]SVM Seeds:  80%|████████  | 16/20 [20:00<05:00, 75.09s/it]SVM Seeds:  85%|████████▌ | 17/20 [21:15<03:45, 75.11s/it]SVM Seeds:  90%|█████████ | 18/20 [22:31<02:30, 75.15s/it]SVM Seeds:  95%|█████████▌| 19/20 [23:46<01:15, 75.17s/it]SVM Seeds: 100%|██████████| 20/20 [25:01<00:00, 75.13s/it]SVM Seeds: 100%|██████████| 20/20 [25:01<00:00, 75.06s/it]
200
(500, None, 70, 1, 'balanced')
(2798, 777)
(2238, 777)
(330, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:07<02:24,  7.63s/it]RF Seeds:  10%|█         | 2/20 [00:15<02:17,  7.65s/it]RF Seeds:  15%|█▌        | 3/20 [00:22<02:10,  7.66s/it]RF Seeds:  20%|██        | 4/20 [00:30<02:02,  7.66s/it]RF Seeds:  25%|██▌       | 5/20 [00:38<01:54,  7.66s/it]RF Seeds:  30%|███       | 6/20 [00:45<01:47,  7.68s/it]RF Seeds:  35%|███▌      | 7/20 [00:53<01:39,  7.68s/it]RF Seeds:  40%|████      | 8/20 [01:01<01:32,  7.70s/it]RF Seeds:  45%|████▌     | 9/20 [01:09<01:24,  7.71s/it]RF Seeds:  50%|█████     | 10/20 [01:16<01:17,  7.71s/it]RF Seeds:  55%|█████▌    | 11/20 [01:24<01:09,  7.71s/it]RF Seeds:  60%|██████    | 12/20 [01:32<01:01,  7.73s/it]RF Seeds:  65%|██████▌   | 13/20 [01:40<00:54,  7.74s/it]RF Seeds:  70%|███████   | 14/20 [01:47<00:46,  7.76s/it]RF Seeds:  75%|███████▌  | 15/20 [01:55<00:38,  7.77s/it]RF Seeds:  80%|████████  | 16/20 [02:03<00:31,  7.78s/it]RF Seeds:  85%|████████▌ | 17/20 [02:11<00:23,  7.78s/it]RF Seeds:  90%|█████████ | 18/20 [02:19<00:15,  7.82s/it]RF Seeds:  95%|█████████▌| 19/20 [02:27<00:07,  7.82s/it]RF Seeds: 100%|██████████| 20/20 [02:34<00:00,  7.83s/it]RF Seeds: 100%|██████████| 20/20 [02:34<00:00,  7.74s/it]
400
(0.01, 900, 7, 0.8, 6)
(2798, 777)
(2238, 777)
(330, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:41<13:10, 41.58s/it]XGBoost Seeds:  10%|█         | 2/20 [01:23<12:29, 41.62s/it]XGBoost Seeds:  15%|█▌        | 3/20 [02:04<11:45, 41.52s/it]XGBoost Seeds:  20%|██        | 4/20 [02:45<11:03, 41.46s/it]XGBoost Seeds:  25%|██▌       | 5/20 [03:27<10:22, 41.47s/it]XGBoost Seeds:  30%|███       | 6/20 [04:09<09:40, 41.49s/it]XGBoost Seeds:  35%|███▌      | 7/20 [04:50<08:58, 41.46s/it]XGBoost Seeds:  40%|████      | 8/20 [05:31<08:17, 41.46s/it]XGBoost Seeds:  45%|████▌     | 9/20 [06:13<07:35, 41.45s/it]XGBoost Seeds:  50%|█████     | 10/20 [06:54<06:54, 41.45s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [07:36<06:12, 41.41s/it]XGBoost Seeds:  60%|██████    | 12/20 [08:21<05:41, 42.73s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [09:03<04:56, 42.33s/it]XGBoost Seeds:  70%|███████   | 14/20 [09:44<04:12, 42.10s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [10:26<03:29, 41.95s/it]XGBoost Seeds:  80%|████████  | 16/20 [11:08<02:47, 41.87s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [11:49<02:05, 41.80s/it]XGBoost Seeds:  90%|█████████ | 18/20 [12:31<01:23, 41.75s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [13:12<00:41, 41.69s/it]XGBoost Seeds: 100%|██████████| 20/20 [13:54<00:00, 41.69s/it]XGBoost Seeds: 100%|██████████| 20/20 [13:54<00:00, 41.73s/it]
knn:  98
lr:  77
svm:  100
rf:  100
xgboost:  73
Combining validation predictions is completed
knn:  98
lr:  77
svm:  100
rf:  100
xgboost:  73
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 3s - loss: 1.3718 - acc: 0.6562
448/448 [==============================] - 0s 616us/step - loss: 1.3304 - acc: 0.8259 - val_loss: 1.0895 - val_acc: 0.8214

Epoch 00001: loss improved from inf to 1.33037, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2925 - acc: 0.8438
448/448 [==============================] - 0s 32us/step - loss: 1.1553 - acc: 0.8750 - val_loss: 1.1453 - val_acc: 0.8125

Epoch 00002: loss improved from 1.33037 to 1.15529, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0656 - acc: 0.8438
448/448 [==============================] - 0s 31us/step - loss: 1.0202 - acc: 0.9062 - val_loss: 1.0194 - val_acc: 0.8125

Epoch 00003: loss improved from 1.15529 to 1.02023, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1721 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 0.9678 - acc: 0.9062 - val_loss: 1.0169 - val_acc: 0.8393

Epoch 00004: loss improved from 1.02023 to 0.96779, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1110 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.9386 - acc: 0.9107 - val_loss: 1.0413 - val_acc: 0.8571

Epoch 00005: loss improved from 0.96779 to 0.93863, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9408 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.8324 - acc: 0.9263 - val_loss: 0.9234 - val_acc: 0.8661

Epoch 00006: loss improved from 0.93863 to 0.83235, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0934 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.8524 - acc: 0.9286 - val_loss: 1.1457 - val_acc: 0.8661

Epoch 00007: loss did not improve from 0.83235
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9461 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.7656 - acc: 0.9442 - val_loss: 0.8661 - val_acc: 0.8482

Epoch 00008: loss improved from 0.83235 to 0.76563, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8897 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.7767 - acc: 0.9353 - val_loss: 0.9829 - val_acc: 0.8571

Epoch 00009: loss did not improve from 0.76563
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0448 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.8336 - acc: 0.9286 - val_loss: 1.1054 - val_acc: 0.8393

Epoch 00010: loss did not improve from 0.76563
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1416 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7445 - acc: 0.9286 - val_loss: 0.8554 - val_acc: 0.8571

Epoch 00011: loss improved from 0.76563 to 0.74450, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9253 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6814 - acc: 0.9420 - val_loss: 0.7402 - val_acc: 0.8571

Epoch 00012: loss improved from 0.74450 to 0.68141, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8241 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.6792 - acc: 0.9420 - val_loss: 0.9684 - val_acc: 0.8482

Epoch 00013: loss improved from 0.68141 to 0.67922, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8869 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6571 - acc: 0.9308 - val_loss: 0.9960 - val_acc: 0.8839

Epoch 00014: loss improved from 0.67922 to 0.65711, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6843 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5983 - acc: 0.9464 - val_loss: 0.9051 - val_acc: 0.8661

Epoch 00015: loss improved from 0.65711 to 0.59831, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9423 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6830 - acc: 0.9263 - val_loss: 1.2277 - val_acc: 0.8571

Epoch 00016: loss did not improve from 0.59831
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7735 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.5821 - acc: 0.9442 - val_loss: 0.8804 - val_acc: 0.8839

Epoch 00017: loss improved from 0.59831 to 0.58212, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6773 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5827 - acc: 0.9464 - val_loss: 0.9408 - val_acc: 0.8839

Epoch 00018: loss did not improve from 0.58212
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8372 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5903 - acc: 0.9397 - val_loss: 0.7250 - val_acc: 0.9018

Epoch 00019: loss did not improve from 0.58212
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6197 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5337 - acc: 0.9509 - val_loss: 0.6243 - val_acc: 0.8929

Epoch 00020: loss improved from 0.58212 to 0.53373, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7223 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6343 - acc: 0.9375 - val_loss: 0.8329 - val_acc: 0.8929

Epoch 00021: loss did not improve from 0.53373
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7468 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.4960 - acc: 0.9643 - val_loss: 0.5327 - val_acc: 0.9196

Epoch 00022: loss improved from 0.53373 to 0.49597, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7410 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5063 - acc: 0.9598 - val_loss: 0.5648 - val_acc: 0.8929

Epoch 00023: loss did not improve from 0.49597
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8989 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.5172 - acc: 0.9420 - val_loss: 0.7205 - val_acc: 0.9018

Epoch 00024: loss did not improve from 0.49597
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6110 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.4848 - acc: 0.9554 - val_loss: 0.5970 - val_acc: 0.9018

Epoch 00025: loss improved from 0.49597 to 0.48478, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 26/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5808 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5114 - acc: 0.9554 - val_loss: 0.9138 - val_acc: 0.8929

Epoch 00026: loss did not improve from 0.48478
Epoch 27/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7439 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.4945 - acc: 0.9487 - val_loss: 0.6240 - val_acc: 0.9018

Epoch 00027: loss did not improve from 0.48478
Epoch 28/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6223 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.4662 - acc: 0.9509 - val_loss: 0.7723 - val_acc: 0.8839

Epoch 00028: loss improved from 0.48478 to 0.46617, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 29/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7171 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.4662 - acc: 0.9487 - val_loss: 0.5431 - val_acc: 0.8929

Epoch 00029: loss did not improve from 0.46617
Epoch 30/100

 32/448 [=>............................] - ETA: 0s - loss: 0.4421 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5217 - acc: 0.9353 - val_loss: 0.7175 - val_acc: 0.8839

Epoch 00030: loss did not improve from 0.46617
Epoch 31/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6695 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.4661 - acc: 0.9219 - val_loss: 0.9061 - val_acc: 0.8929

Epoch 00031: loss improved from 0.46617 to 0.46614, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 32/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5257 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.4202 - acc: 0.9531 - val_loss: 0.8328 - val_acc: 0.8929

Epoch 00032: loss improved from 0.46614 to 0.42019, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 33/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5484 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.4719 - acc: 0.9375 - val_loss: 0.7940 - val_acc: 0.8929

Epoch 00033: loss did not improve from 0.42019
Epoch 34/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5812 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.3833 - acc: 0.9665 - val_loss: 0.6429 - val_acc: 0.8839

Epoch 00034: loss improved from 0.42019 to 0.38334, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_6.h5
Epoch 35/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5232 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.4677 - acc: 0.9531 - val_loss: 0.6684 - val_acc: 0.8839

Epoch 00035: loss did not improve from 0.38334
Epoch 36/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6151 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.4248 - acc: 0.9487 - val_loss: 0.5657 - val_acc: 0.8929

Epoch 00036: loss did not improve from 0.38334
Epoch 37/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5370 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.4694 - acc: 0.9509 - val_loss: 0.9924 - val_acc: 0.8750

Epoch 00037: loss did not improve from 0.38334
Epoch 38/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7312 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.5201 - acc: 0.9397 - val_loss: 0.8624 - val_acc: 0.8482

Epoch 00038: loss did not improve from 0.38334
Epoch 39/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5440 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.4448 - acc: 0.9487 - val_loss: 0.8496 - val_acc: 0.8571
DeepAmes+ Weights:   8%|▊         | 1/13 [00:02<00:25,  2.10s/it]
Epoch 00039: loss did not improve from 0.38334
Epoch 00039: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 3s - loss: 1.5423 - acc: 0.6562
448/448 [==============================] - 0s 614us/step - loss: 1.3360 - acc: 0.8304 - val_loss: 1.1898 - val_acc: 0.8214

Epoch 00001: loss improved from inf to 1.33600, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5543 - acc: 0.7500
448/448 [==============================] - 0s 31us/step - loss: 1.1965 - acc: 0.8683 - val_loss: 1.1831 - val_acc: 0.8125

Epoch 00002: loss improved from 1.33600 to 1.19651, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3059 - acc: 0.8438
448/448 [==============================] - 0s 31us/step - loss: 1.0803 - acc: 0.8862 - val_loss: 1.2032 - val_acc: 0.8036

Epoch 00003: loss improved from 1.19651 to 1.08034, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3816 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.0790 - acc: 0.8906 - val_loss: 1.2204 - val_acc: 0.8036

Epoch 00004: loss improved from 1.08034 to 1.07901, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4735 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 0.9522 - acc: 0.8951 - val_loss: 0.9847 - val_acc: 0.8304

Epoch 00005: loss improved from 1.07901 to 0.95215, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8834 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.9076 - acc: 0.9152 - val_loss: 0.9879 - val_acc: 0.8125

Epoch 00006: loss improved from 0.95215 to 0.90763, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0103 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.8816 - acc: 0.9129 - val_loss: 0.7993 - val_acc: 0.8571

Epoch 00007: loss improved from 0.90763 to 0.88159, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9773 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.8016 - acc: 0.9196 - val_loss: 0.9256 - val_acc: 0.8393

Epoch 00008: loss improved from 0.88159 to 0.80162, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1382 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8799 - acc: 0.9018 - val_loss: 0.9891 - val_acc: 0.8482

Epoch 00009: loss did not improve from 0.80162
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0432 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7552 - acc: 0.9196 - val_loss: 0.7972 - val_acc: 0.8304

Epoch 00010: loss improved from 0.80162 to 0.75518, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0853 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.7374 - acc: 0.9152 - val_loss: 1.0061 - val_acc: 0.8661

Epoch 00011: loss improved from 0.75518 to 0.73740, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9812 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6700 - acc: 0.9420 - val_loss: 0.9111 - val_acc: 0.8929

Epoch 00012: loss improved from 0.73740 to 0.67001, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9970 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7265 - acc: 0.9353 - val_loss: 0.9769 - val_acc: 0.8482

Epoch 00013: loss did not improve from 0.67001
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7663 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6826 - acc: 0.9263 - val_loss: 1.0391 - val_acc: 0.8393

Epoch 00014: loss did not improve from 0.67001
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7481 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.5960 - acc: 0.9464 - val_loss: 0.8893 - val_acc: 0.8482

Epoch 00015: loss improved from 0.67001 to 0.59600, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9743 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7967 - acc: 0.9107 - val_loss: 0.9362 - val_acc: 0.8661

Epoch 00016: loss did not improve from 0.59600
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9438 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6535 - acc: 0.9330 - val_loss: 0.6996 - val_acc: 0.8661

Epoch 00017: loss did not improve from 0.59600
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8706 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6428 - acc: 0.9196 - val_loss: 0.8735 - val_acc: 0.8661

Epoch 00018: loss did not improve from 0.59600
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9357 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.6406 - acc: 0.9375 - val_loss: 0.6608 - val_acc: 0.8750

Epoch 00019: loss did not improve from 0.59600
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8232 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.5853 - acc: 0.9397 - val_loss: 0.8749 - val_acc: 0.8482

Epoch 00020: loss improved from 0.59600 to 0.58527, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7303 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6008 - acc: 0.9397 - val_loss: 0.7961 - val_acc: 0.8839

Epoch 00021: loss did not improve from 0.58527
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6527 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5552 - acc: 0.9263 - val_loss: 0.6400 - val_acc: 0.9018

Epoch 00022: loss improved from 0.58527 to 0.55523, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7534 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5455 - acc: 0.9420 - val_loss: 0.6922 - val_acc: 0.8929

Epoch 00023: loss improved from 0.55523 to 0.54554, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8718 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6268 - acc: 0.9241 - val_loss: 0.8787 - val_acc: 0.8571

Epoch 00024: loss did not improve from 0.54554
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9249 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.5472 - acc: 0.9286 - val_loss: 0.8575 - val_acc: 0.8571

Epoch 00025: loss did not improve from 0.54554
Epoch 26/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9033 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.5459 - acc: 0.9330 - val_loss: 0.8280 - val_acc: 0.8571

Epoch 00026: loss did not improve from 0.54554
Epoch 27/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6531 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.5120 - acc: 0.9442 - val_loss: 1.0455 - val_acc: 0.8482

Epoch 00027: loss improved from 0.54554 to 0.51200, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 28/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9495 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.5092 - acc: 0.9420 - val_loss: 0.5889 - val_acc: 0.8750

Epoch 00028: loss improved from 0.51200 to 0.50921, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 29/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7830 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.4954 - acc: 0.9308 - val_loss: 0.5741 - val_acc: 0.8750

Epoch 00029: loss improved from 0.50921 to 0.49541, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 30/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5781 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.4423 - acc: 0.9576 - val_loss: 0.6102 - val_acc: 0.8929

Epoch 00030: loss improved from 0.49541 to 0.44230, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 31/100

 32/448 [=>............................] - ETA: 0s - loss: 0.4617 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.4640 - acc: 0.9554 - val_loss: 0.6078 - val_acc: 0.9018

Epoch 00031: loss did not improve from 0.44230
Epoch 32/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5912 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5202 - acc: 0.9375 - val_loss: 0.6244 - val_acc: 0.8839

Epoch 00032: loss did not improve from 0.44230
Epoch 33/100

 32/448 [=>............................] - ETA: 0s - loss: 0.3307 - acc: 0.9688
448/448 [==============================] - 0s 29us/step - loss: 0.4587 - acc: 0.9576 - val_loss: 0.6161 - val_acc: 0.8661

Epoch 00033: loss did not improve from 0.44230
Epoch 34/100

 32/448 [=>............................] - ETA: 0s - loss: 0.4869 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.4246 - acc: 0.9487 - val_loss: 0.4852 - val_acc: 0.9107

Epoch 00034: loss improved from 0.44230 to 0.42460, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_7.h5
Epoch 35/100

 32/448 [=>............................] - ETA: 0s - loss: 0.3417 - acc: 0.9375
448/448 [==============================] - 0s 30us/step - loss: 0.4315 - acc: 0.9420 - val_loss: 0.6858 - val_acc: 0.8661

Epoch 00035: loss did not improve from 0.42460
Epoch 36/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6834 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.4847 - acc: 0.9375 - val_loss: 0.9763 - val_acc: 0.8125

Epoch 00036: loss did not improve from 0.42460
Epoch 37/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5720 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.4443 - acc: 0.9487 - val_loss: 0.8580 - val_acc: 0.8125

Epoch 00037: loss did not improve from 0.42460
Epoch 38/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6346 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.4615 - acc: 0.9263 - val_loss: 0.5356 - val_acc: 0.8661

Epoch 00038: loss did not improve from 0.42460
Epoch 39/100

 32/448 [=>............................] - ETA: 0s - loss: 0.4906 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5438 - acc: 0.9263 - val_loss: 0.7219 - val_acc: 0.8393
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:04<00:23,  2.15s/it]
Epoch 00039: loss did not improve from 0.42460
Epoch 00039: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 2s - loss: 1.3941 - acc: 0.7188
448/448 [==============================] - 0s 599us/step - loss: 1.4295 - acc: 0.8125 - val_loss: 1.1896 - val_acc: 0.7946

Epoch 00001: loss improved from inf to 1.42948, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3976 - acc: 0.7500
448/448 [==============================] - 0s 31us/step - loss: 1.2102 - acc: 0.8728 - val_loss: 1.2737 - val_acc: 0.7679

Epoch 00002: loss improved from 1.42948 to 1.21019, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4878 - acc: 0.7188
448/448 [==============================] - 0s 30us/step - loss: 1.1790 - acc: 0.8683 - val_loss: 1.3100 - val_acc: 0.7589

Epoch 00003: loss improved from 1.21019 to 1.17904, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3948 - acc: 0.7188
448/448 [==============================] - 0s 31us/step - loss: 1.0171 - acc: 0.8973 - val_loss: 1.0943 - val_acc: 0.8214

Epoch 00004: loss improved from 1.17904 to 1.01709, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0581 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.9863 - acc: 0.8951 - val_loss: 1.1930 - val_acc: 0.8661

Epoch 00005: loss improved from 1.01709 to 0.98630, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4860 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.9350 - acc: 0.9107 - val_loss: 0.9772 - val_acc: 0.8393

Epoch 00006: loss improved from 0.98630 to 0.93497, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0939 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.8658 - acc: 0.9241 - val_loss: 1.0728 - val_acc: 0.8304

Epoch 00007: loss improved from 0.93497 to 0.86579, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9666 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.8544 - acc: 0.9018 - val_loss: 0.9134 - val_acc: 0.8482

Epoch 00008: loss improved from 0.86579 to 0.85443, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8353 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.8762 - acc: 0.9085 - val_loss: 0.9184 - val_acc: 0.8393

Epoch 00009: loss did not improve from 0.85443
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9450 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7786 - acc: 0.9196 - val_loss: 0.8822 - val_acc: 0.8304

Epoch 00010: loss improved from 0.85443 to 0.77860, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8371 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.7687 - acc: 0.9286 - val_loss: 0.8089 - val_acc: 0.8393

Epoch 00011: loss improved from 0.77860 to 0.76868, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9396 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.7289 - acc: 0.9375 - val_loss: 0.9455 - val_acc: 0.8571

Epoch 00012: loss improved from 0.76868 to 0.72888, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8134 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.7644 - acc: 0.9263 - val_loss: 0.8162 - val_acc: 0.8393

Epoch 00013: loss did not improve from 0.72888
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7997 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6892 - acc: 0.9286 - val_loss: 0.8481 - val_acc: 0.8125

Epoch 00014: loss improved from 0.72888 to 0.68921, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8125 - acc: 0.9375
448/448 [==============================] - 0s 30us/step - loss: 0.6371 - acc: 0.9263 - val_loss: 0.8013 - val_acc: 0.8482

Epoch 00015: loss improved from 0.68921 to 0.63707, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8074 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.5807 - acc: 0.9487 - val_loss: 0.7672 - val_acc: 0.8393

Epoch 00016: loss improved from 0.63707 to 0.58072, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7535 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.6174 - acc: 0.9353 - val_loss: 0.9399 - val_acc: 0.8125

Epoch 00017: loss did not improve from 0.58072
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9498 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6177 - acc: 0.9487 - val_loss: 0.7405 - val_acc: 0.8036

Epoch 00018: loss did not improve from 0.58072
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7404 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5814 - acc: 0.9375 - val_loss: 0.7762 - val_acc: 0.8304

Epoch 00019: loss did not improve from 0.58072
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6595 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.6091 - acc: 0.9464 - val_loss: 0.7947 - val_acc: 0.8304

Epoch 00020: loss did not improve from 0.58072
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7493 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.5554 - acc: 0.9442 - val_loss: 1.2240 - val_acc: 0.8571

Epoch 00021: loss improved from 0.58072 to 0.55542, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6847 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.5905 - acc: 0.9330 - val_loss: 1.2327 - val_acc: 0.8214

Epoch 00022: loss did not improve from 0.55542
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7021 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.5784 - acc: 0.9375 - val_loss: 1.2005 - val_acc: 0.8304

Epoch 00023: loss did not improve from 0.55542
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5503 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5386 - acc: 0.9487 - val_loss: 1.2040 - val_acc: 0.8304

Epoch 00024: loss improved from 0.55542 to 0.53860, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8472 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.5514 - acc: 0.9330 - val_loss: 1.0898 - val_acc: 0.8393

Epoch 00025: loss did not improve from 0.53860
Epoch 26/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7346 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5425 - acc: 0.9353 - val_loss: 0.8476 - val_acc: 0.8571

Epoch 00026: loss did not improve from 0.53860
Epoch 27/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6455 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.5608 - acc: 0.9397 - val_loss: 1.1659 - val_acc: 0.8661

Epoch 00027: loss did not improve from 0.53860
Epoch 28/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7724 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.5199 - acc: 0.9509 - val_loss: 0.8008 - val_acc: 0.8482

Epoch 00028: loss improved from 0.53860 to 0.51989, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 29/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7711 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.4677 - acc: 0.9554 - val_loss: 0.5086 - val_acc: 0.9018

Epoch 00029: loss improved from 0.51989 to 0.46766, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 30/100

 32/448 [=>............................] - ETA: 0s - loss: 0.4210 - acc: 0.9688
448/448 [==============================] - 0s 30us/step - loss: 0.6051 - acc: 0.9174 - val_loss: 0.7943 - val_acc: 0.8393

Epoch 00030: loss did not improve from 0.46766
Epoch 31/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9174 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.5044 - acc: 0.9397 - val_loss: 0.8002 - val_acc: 0.8393

Epoch 00031: loss did not improve from 0.46766
Epoch 32/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8193 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.5098 - acc: 0.9397 - val_loss: 1.0539 - val_acc: 0.8214

Epoch 00032: loss did not improve from 0.46766
Epoch 33/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7000 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.4914 - acc: 0.9420 - val_loss: 1.0440 - val_acc: 0.8036

Epoch 00033: loss did not improve from 0.46766
Epoch 34/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5513 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.4163 - acc: 0.9576 - val_loss: 0.9300 - val_acc: 0.8571

Epoch 00034: loss improved from 0.46766 to 0.41629, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 35/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5808 - acc: 0.9375
448/448 [==============================] - 0s 30us/step - loss: 0.4529 - acc: 0.9509 - val_loss: 0.7702 - val_acc: 0.8393

Epoch 00035: loss did not improve from 0.41629
Epoch 36/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6433 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.4714 - acc: 0.9442 - val_loss: 0.8763 - val_acc: 0.8393

Epoch 00036: loss did not improve from 0.41629
Epoch 37/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5936 - acc: 0.9062
448/448 [==============================] - 0s 31us/step - loss: 0.3874 - acc: 0.9509 - val_loss: 0.6732 - val_acc: 0.8750

Epoch 00037: loss improved from 0.41629 to 0.38743, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_8.h5
Epoch 38/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0159 - acc: 0.8750
448/448 [==============================] - 0s 31us/step - loss: 0.5728 - acc: 0.9107 - val_loss: 0.8903 - val_acc: 0.8661

Epoch 00038: loss did not improve from 0.38743
Epoch 39/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6558 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.5198 - acc: 0.9219 - val_loss: 0.7720 - val_acc: 0.8661

Epoch 00039: loss did not improve from 0.38743
Epoch 40/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7393 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.4716 - acc: 0.9554 - val_loss: 0.8435 - val_acc: 0.8750

Epoch 00040: loss did not improve from 0.38743
Epoch 41/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6732 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.4744 - acc: 0.9464 - val_loss: 0.9667 - val_acc: 0.8929

Epoch 00041: loss did not improve from 0.38743
Epoch 42/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6190 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.3972 - acc: 0.9576 - val_loss: 0.8845 - val_acc: 0.8839
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:06<00:21,  2.19s/it]
Epoch 00042: loss did not improve from 0.38743
Epoch 00042: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 2s - loss: 1.4805 - acc: 0.6562
448/448 [==============================] - 0s 591us/step - loss: 1.4227 - acc: 0.8259 - val_loss: 1.4560 - val_acc: 0.7857

Epoch 00001: loss improved from inf to 1.42267, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5215 - acc: 0.7188
448/448 [==============================] - 0s 31us/step - loss: 1.1715 - acc: 0.8571 - val_loss: 1.2832 - val_acc: 0.8393

Epoch 00002: loss improved from 1.42267 to 1.17152, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3763 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.1407 - acc: 0.8772 - val_loss: 1.0778 - val_acc: 0.8304

Epoch 00003: loss improved from 1.17152 to 1.14071, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3028 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.0725 - acc: 0.8795 - val_loss: 0.9942 - val_acc: 0.8214

Epoch 00004: loss improved from 1.14071 to 1.07252, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5492 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.0499 - acc: 0.8839 - val_loss: 1.0984 - val_acc: 0.8125

Epoch 00005: loss improved from 1.07252 to 1.04994, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2314 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.9064 - acc: 0.9152 - val_loss: 1.0678 - val_acc: 0.8661

Epoch 00006: loss improved from 1.04994 to 0.90636, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2556 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8869 - acc: 0.9040 - val_loss: 0.8032 - val_acc: 0.8661

Epoch 00007: loss improved from 0.90636 to 0.88694, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0393 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8289 - acc: 0.9308 - val_loss: 0.7986 - val_acc: 0.8661

Epoch 00008: loss improved from 0.88694 to 0.82889, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4929 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8968 - acc: 0.9062 - val_loss: 1.0200 - val_acc: 0.8571

Epoch 00009: loss did not improve from 0.82889
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0314 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.8210 - acc: 0.9129 - val_loss: 0.9839 - val_acc: 0.8214

Epoch 00010: loss improved from 0.82889 to 0.82105, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0582 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8348 - acc: 0.9085 - val_loss: 0.9273 - val_acc: 0.8393

Epoch 00011: loss did not improve from 0.82105
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9461 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8863 - acc: 0.9196 - val_loss: 0.9743 - val_acc: 0.8393

Epoch 00012: loss did not improve from 0.82105
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0423 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7149 - acc: 0.9397 - val_loss: 0.9487 - val_acc: 0.8393

Epoch 00013: loss improved from 0.82105 to 0.71489, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0833 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8157 - acc: 0.9018 - val_loss: 0.8721 - val_acc: 0.8304

Epoch 00014: loss did not improve from 0.71489
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9178 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7456 - acc: 0.9107 - val_loss: 0.8088 - val_acc: 0.8036

Epoch 00015: loss did not improve from 0.71489
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8452 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6539 - acc: 0.9174 - val_loss: 0.8117 - val_acc: 0.8036

Epoch 00016: loss improved from 0.71489 to 0.65390, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9199 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6671 - acc: 0.9107 - val_loss: 0.8609 - val_acc: 0.8571

Epoch 00017: loss did not improve from 0.65390
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8098 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.5807 - acc: 0.9420 - val_loss: 0.7237 - val_acc: 0.8929

Epoch 00018: loss improved from 0.65390 to 0.58073, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8330 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5595 - acc: 0.9420 - val_loss: 0.6076 - val_acc: 0.9018

Epoch 00019: loss improved from 0.58073 to 0.55951, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_9.h5
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7558 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.6204 - acc: 0.9420 - val_loss: 0.9639 - val_acc: 0.8571

Epoch 00020: loss did not improve from 0.55951
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8208 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.6298 - acc: 0.9420 - val_loss: 0.9579 - val_acc: 0.8393

Epoch 00021: loss did not improve from 0.55951
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9080 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6137 - acc: 0.9330 - val_loss: 1.1971 - val_acc: 0.8304

Epoch 00022: loss did not improve from 0.55951
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6827 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.6409 - acc: 0.9263 - val_loss: 1.2013 - val_acc: 0.8214

Epoch 00023: loss did not improve from 0.55951
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8102 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.6495 - acc: 0.9174 - val_loss: 0.9072 - val_acc: 0.8393
DeepAmes+ Weights:  31%|███       | 4/13 [00:08<00:18,  2.04s/it]
Epoch 00024: loss did not improve from 0.55951
Epoch 00024: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 3s - loss: 1.6675 - acc: 0.5938
448/448 [==============================] - 0s 611us/step - loss: 1.6153 - acc: 0.8237 - val_loss: 1.5789 - val_acc: 0.7768

Epoch 00001: loss improved from inf to 1.61529, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.7435 - acc: 0.6875
448/448 [==============================] - 0s 31us/step - loss: 1.3674 - acc: 0.8571 - val_loss: 1.4098 - val_acc: 0.7857

Epoch 00002: loss improved from 1.61529 to 1.36745, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.6866 - acc: 0.8125
448/448 [==============================] - 0s 31us/step - loss: 1.2542 - acc: 0.8638 - val_loss: 1.2724 - val_acc: 0.8125

Epoch 00003: loss improved from 1.36745 to 1.25418, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5444 - acc: 0.7812
448/448 [==============================] - 0s 31us/step - loss: 1.1812 - acc: 0.8906 - val_loss: 1.2585 - val_acc: 0.8036

Epoch 00004: loss improved from 1.25418 to 1.18122, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2868 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 1.2365 - acc: 0.8750 - val_loss: 1.2482 - val_acc: 0.7946

Epoch 00005: loss did not improve from 1.18122
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3685 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.0703 - acc: 0.8929 - val_loss: 1.1638 - val_acc: 0.8393

Epoch 00006: loss improved from 1.18122 to 1.07034, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3201 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.9856 - acc: 0.9040 - val_loss: 1.0318 - val_acc: 0.8750

Epoch 00007: loss improved from 1.07034 to 0.98557, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2460 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 1.0477 - acc: 0.9040 - val_loss: 1.1790 - val_acc: 0.8304

Epoch 00008: loss did not improve from 0.98557
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1665 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.0348 - acc: 0.8951 - val_loss: 1.0516 - val_acc: 0.8393

Epoch 00009: loss did not improve from 0.98557
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1092 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.9503 - acc: 0.9040 - val_loss: 1.0572 - val_acc: 0.8125

Epoch 00010: loss improved from 0.98557 to 0.95029, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0101 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.8548 - acc: 0.9085 - val_loss: 0.9110 - val_acc: 0.8393

Epoch 00011: loss improved from 0.95029 to 0.85482, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9334 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.9662 - acc: 0.9241 - val_loss: 1.2912 - val_acc: 0.7857

Epoch 00012: loss did not improve from 0.85482
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1734 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8474 - acc: 0.9219 - val_loss: 1.0734 - val_acc: 0.8214

Epoch 00013: loss improved from 0.85482 to 0.84740, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0210 - acc: 0.9375
448/448 [==============================] - 0s 30us/step - loss: 0.8882 - acc: 0.9152 - val_loss: 1.2458 - val_acc: 0.8125

Epoch 00014: loss did not improve from 0.84740
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8886 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7940 - acc: 0.9263 - val_loss: 0.9787 - val_acc: 0.8304

Epoch 00015: loss improved from 0.84740 to 0.79404, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8401 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.7797 - acc: 0.9062 - val_loss: 1.1193 - val_acc: 0.8214

Epoch 00016: loss improved from 0.79404 to 0.77969, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0311 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.7019 - acc: 0.9330 - val_loss: 1.0019 - val_acc: 0.8482

Epoch 00017: loss improved from 0.77969 to 0.70192, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7015 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.7806 - acc: 0.9196 - val_loss: 0.9527 - val_acc: 0.8125

Epoch 00018: loss did not improve from 0.70192
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9090 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.6515 - acc: 0.9397 - val_loss: 0.7930 - val_acc: 0.8750

Epoch 00019: loss improved from 0.70192 to 0.65149, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9107 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.6765 - acc: 0.9330 - val_loss: 0.8818 - val_acc: 0.8750

Epoch 00020: loss did not improve from 0.65149
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8979 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.8373 - acc: 0.9174 - val_loss: 0.8447 - val_acc: 0.8482

Epoch 00021: loss did not improve from 0.65149
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7575 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.7501 - acc: 0.9129 - val_loss: 0.8869 - val_acc: 0.8661

Epoch 00022: loss did not improve from 0.65149
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0304 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6369 - acc: 0.9487 - val_loss: 0.7012 - val_acc: 0.8929

Epoch 00023: loss improved from 0.65149 to 0.63693, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7046 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.6888 - acc: 0.9129 - val_loss: 0.7273 - val_acc: 0.8571

Epoch 00024: loss did not improve from 0.63693
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1210 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.7266 - acc: 0.9353 - val_loss: 0.8461 - val_acc: 0.8482

Epoch 00025: loss did not improve from 0.63693
Epoch 26/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0141 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.5524 - acc: 0.9487 - val_loss: 0.7115 - val_acc: 0.8661

Epoch 00026: loss improved from 0.63693 to 0.55244, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 27/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6974 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.5733 - acc: 0.9420 - val_loss: 0.9730 - val_acc: 0.8393

Epoch 00027: loss did not improve from 0.55244
Epoch 28/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9965 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6650 - acc: 0.9152 - val_loss: 1.1180 - val_acc: 0.8393

Epoch 00028: loss did not improve from 0.55244
Epoch 29/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1429 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 0.6596 - acc: 0.9174 - val_loss: 1.1009 - val_acc: 0.8482

Epoch 00029: loss did not improve from 0.55244
Epoch 30/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8357 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.5602 - acc: 0.9509 - val_loss: 1.0230 - val_acc: 0.8482

Epoch 00030: loss did not improve from 0.55244
Epoch 31/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6397 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5375 - acc: 0.9420 - val_loss: 0.9797 - val_acc: 0.8393

Epoch 00031: loss improved from 0.55244 to 0.53747, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 32/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0737 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6197 - acc: 0.9129 - val_loss: 1.0256 - val_acc: 0.8571

Epoch 00032: loss did not improve from 0.53747
Epoch 33/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6113 - acc: 0.9375
448/448 [==============================] - 0s 30us/step - loss: 0.5337 - acc: 0.9464 - val_loss: 0.7633 - val_acc: 0.8661

Epoch 00033: loss improved from 0.53747 to 0.53368, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 34/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6241 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.5154 - acc: 0.9442 - val_loss: 0.7522 - val_acc: 0.8661

Epoch 00034: loss improved from 0.53368 to 0.51535, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_10.h5
Epoch 35/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9205 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.6617 - acc: 0.9129 - val_loss: 1.1699 - val_acc: 0.8036

Epoch 00035: loss did not improve from 0.51535
Epoch 36/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8763 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6207 - acc: 0.9308 - val_loss: 0.6976 - val_acc: 0.8036

Epoch 00036: loss did not improve from 0.51535
Epoch 37/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9122 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6392 - acc: 0.9174 - val_loss: 0.6198 - val_acc: 0.8571

Epoch 00037: loss did not improve from 0.51535
Epoch 38/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8024 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.5413 - acc: 0.9330 - val_loss: 0.4502 - val_acc: 0.9107

Epoch 00038: loss did not improve from 0.51535
Epoch 39/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5378 - acc: 0.9688
448/448 [==============================] - 0s 29us/step - loss: 0.5469 - acc: 0.9442 - val_loss: 0.7467 - val_acc: 0.8393
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:10<00:16,  2.10s/it]
Epoch 00039: loss did not improve from 0.51535
Epoch 00039: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 2s - loss: 1.4417 - acc: 0.6250
448/448 [==============================] - 0s 596us/step - loss: 1.4476 - acc: 0.8080 - val_loss: 1.3438 - val_acc: 0.6518

Epoch 00001: loss improved from inf to 1.44757, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1971 - acc: 0.6875
448/448 [==============================] - 0s 31us/step - loss: 1.2228 - acc: 0.8393 - val_loss: 1.2564 - val_acc: 0.8036

Epoch 00002: loss improved from 1.44757 to 1.22282, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.6913 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.2281 - acc: 0.8661 - val_loss: 1.3781 - val_acc: 0.7768

Epoch 00003: loss did not improve from 1.22282
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4167 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.0450 - acc: 0.8817 - val_loss: 1.2764 - val_acc: 0.7857

Epoch 00004: loss improved from 1.22282 to 1.04501, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0808 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 1.0409 - acc: 0.9040 - val_loss: 1.2250 - val_acc: 0.8214

Epoch 00005: loss improved from 1.04501 to 1.04086, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3955 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 1.0306 - acc: 0.8862 - val_loss: 1.2541 - val_acc: 0.8125

Epoch 00006: loss improved from 1.04086 to 1.03058, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2365 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 1.0738 - acc: 0.8996 - val_loss: 1.2529 - val_acc: 0.8125

Epoch 00007: loss did not improve from 1.03058
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2516 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.9191 - acc: 0.8929 - val_loss: 1.0145 - val_acc: 0.8125

Epoch 00008: loss improved from 1.03058 to 0.91911, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0978 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.8662 - acc: 0.9196 - val_loss: 1.0138 - val_acc: 0.8036

Epoch 00009: loss improved from 0.91911 to 0.86618, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2404 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.7901 - acc: 0.9085 - val_loss: 0.8604 - val_acc: 0.8482

Epoch 00010: loss improved from 0.86618 to 0.79013, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7954 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7316 - acc: 0.9397 - val_loss: 1.0061 - val_acc: 0.8571

Epoch 00011: loss improved from 0.79013 to 0.73161, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1333 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.8053 - acc: 0.9263 - val_loss: 0.8215 - val_acc: 0.8214

Epoch 00012: loss did not improve from 0.73161
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3232 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7250 - acc: 0.9308 - val_loss: 0.7322 - val_acc: 0.8661

Epoch 00013: loss improved from 0.73161 to 0.72500, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8226 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7281 - acc: 0.9308 - val_loss: 0.7994 - val_acc: 0.8929

Epoch 00014: loss did not improve from 0.72500
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8430 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.8932 - acc: 0.9018 - val_loss: 1.4022 - val_acc: 0.8036

Epoch 00015: loss did not improve from 0.72500
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0917 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7698 - acc: 0.9152 - val_loss: 1.1744 - val_acc: 0.8125

Epoch 00016: loss did not improve from 0.72500
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2565 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.6918 - acc: 0.9375 - val_loss: 0.6913 - val_acc: 0.8661

Epoch 00017: loss improved from 0.72500 to 0.69179, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8638 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6296 - acc: 0.9420 - val_loss: 0.6950 - val_acc: 0.8929

Epoch 00018: loss improved from 0.69179 to 0.62958, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8577 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7238 - acc: 0.9375 - val_loss: 1.0032 - val_acc: 0.8661

Epoch 00019: loss did not improve from 0.62958
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7352 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7358 - acc: 0.9174 - val_loss: 1.2402 - val_acc: 0.8393

Epoch 00020: loss did not improve from 0.62958
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0812 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 0.7495 - acc: 0.9018 - val_loss: 1.0777 - val_acc: 0.8750

Epoch 00021: loss did not improve from 0.62958
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8930 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6472 - acc: 0.9174 - val_loss: 1.1621 - val_acc: 0.8839

Epoch 00022: loss did not improve from 0.62958
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9586 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6016 - acc: 0.9397 - val_loss: 0.9118 - val_acc: 0.8839

Epoch 00023: loss improved from 0.62958 to 0.60159, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7634 - acc: 0.9375
448/448 [==============================] - 0s 30us/step - loss: 0.5935 - acc: 0.9464 - val_loss: 0.7978 - val_acc: 0.8929

Epoch 00024: loss improved from 0.60159 to 0.59354, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_11.h5
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8502 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6013 - acc: 0.9241 - val_loss: 0.9370 - val_acc: 0.8571

Epoch 00025: loss did not improve from 0.59354
Epoch 26/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9169 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.9474 - acc: 0.9040 - val_loss: 1.3545 - val_acc: 0.8482

Epoch 00026: loss did not improve from 0.59354
Epoch 27/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1516 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.6864 - acc: 0.9263 - val_loss: 1.2402 - val_acc: 0.8393

Epoch 00027: loss did not improve from 0.59354
Epoch 28/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0283 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7027 - acc: 0.9286 - val_loss: 1.0213 - val_acc: 0.8125

Epoch 00028: loss did not improve from 0.59354
Epoch 29/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0114 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7080 - acc: 0.9107 - val_loss: 1.0062 - val_acc: 0.8393
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:12<00:14,  2.06s/it]
Epoch 00029: loss did not improve from 0.59354
Epoch 00029: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 2s - loss: 1.4301 - acc: 0.6562
448/448 [==============================] - 0s 598us/step - loss: 1.4861 - acc: 0.8103 - val_loss: 1.4802 - val_acc: 0.7857

Epoch 00001: loss improved from inf to 1.48611, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.7549 - acc: 0.7188
448/448 [==============================] - 0s 31us/step - loss: 1.2659 - acc: 0.8281 - val_loss: 1.2635 - val_acc: 0.7857

Epoch 00002: loss improved from 1.48611 to 1.26585, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4087 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 1.3148 - acc: 0.8460 - val_loss: 1.2924 - val_acc: 0.7857

Epoch 00003: loss did not improve from 1.26585
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5386 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 1.1305 - acc: 0.8683 - val_loss: 1.1965 - val_acc: 0.8304

Epoch 00004: loss improved from 1.26585 to 1.13051, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5137 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 1.1263 - acc: 0.8817 - val_loss: 1.0651 - val_acc: 0.8036

Epoch 00005: loss improved from 1.13051 to 1.12630, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3119 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.1158 - acc: 0.8616 - val_loss: 1.0550 - val_acc: 0.8125

Epoch 00006: loss improved from 1.12630 to 1.11582, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3264 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 0.9884 - acc: 0.8862 - val_loss: 0.9545 - val_acc: 0.7946

Epoch 00007: loss improved from 1.11582 to 0.98835, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0700 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 1.1231 - acc: 0.8929 - val_loss: 1.1964 - val_acc: 0.8125

Epoch 00008: loss did not improve from 0.98835
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5479 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 1.0063 - acc: 0.8839 - val_loss: 1.0364 - val_acc: 0.8571

Epoch 00009: loss did not improve from 0.98835
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1876 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.9577 - acc: 0.8996 - val_loss: 1.3861 - val_acc: 0.8036

Epoch 00010: loss improved from 0.98835 to 0.95771, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4540 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 0.9668 - acc: 0.9062 - val_loss: 1.2778 - val_acc: 0.7857

Epoch 00011: loss did not improve from 0.95771
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0197 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 0.8561 - acc: 0.8884 - val_loss: 1.1403 - val_acc: 0.8036

Epoch 00012: loss improved from 0.95771 to 0.85612, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9418 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7878 - acc: 0.9152 - val_loss: 1.1268 - val_acc: 0.8125

Epoch 00013: loss improved from 0.85612 to 0.78781, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2338 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.8852 - acc: 0.9040 - val_loss: 0.8360 - val_acc: 0.7857

Epoch 00014: loss did not improve from 0.78781
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4363 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 0.7435 - acc: 0.9107 - val_loss: 0.8343 - val_acc: 0.8125

Epoch 00015: loss improved from 0.78781 to 0.74348, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8602 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7564 - acc: 0.9196 - val_loss: 0.9036 - val_acc: 0.8571

Epoch 00016: loss did not improve from 0.74348
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0184 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.6796 - acc: 0.9263 - val_loss: 0.9196 - val_acc: 0.8750

Epoch 00017: loss improved from 0.74348 to 0.67965, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0371 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7530 - acc: 0.9286 - val_loss: 0.8204 - val_acc: 0.8571

Epoch 00018: loss did not improve from 0.67965
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8316 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7456 - acc: 0.9152 - val_loss: 0.8175 - val_acc: 0.8125

Epoch 00019: loss did not improve from 0.67965
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1134 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6549 - acc: 0.9397 - val_loss: 0.7307 - val_acc: 0.8661

Epoch 00020: loss improved from 0.67965 to 0.65492, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7275 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6978 - acc: 0.9241 - val_loss: 0.8888 - val_acc: 0.8482

Epoch 00021: loss did not improve from 0.65492
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9567 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6809 - acc: 0.9196 - val_loss: 0.9551 - val_acc: 0.8125

Epoch 00022: loss did not improve from 0.65492
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8988 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6434 - acc: 0.9308 - val_loss: 1.0867 - val_acc: 0.8125

Epoch 00023: loss improved from 0.65492 to 0.64343, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2850 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.5716 - acc: 0.9464 - val_loss: 0.9625 - val_acc: 0.8036

Epoch 00024: loss improved from 0.64343 to 0.57160, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7835 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7227 - acc: 0.9085 - val_loss: 1.0956 - val_acc: 0.8304

Epoch 00025: loss did not improve from 0.57160
Epoch 26/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1931 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7228 - acc: 0.8906 - val_loss: 0.8287 - val_acc: 0.8393

Epoch 00026: loss did not improve from 0.57160
Epoch 27/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8293 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.6467 - acc: 0.9174 - val_loss: 0.8585 - val_acc: 0.8304

Epoch 00027: loss did not improve from 0.57160
Epoch 28/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0239 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.5675 - acc: 0.9375 - val_loss: 0.7146 - val_acc: 0.8661

Epoch 00028: loss improved from 0.57160 to 0.56747, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 29/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6785 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.6381 - acc: 0.9040 - val_loss: 0.8837 - val_acc: 0.8661

Epoch 00029: loss did not improve from 0.56747
Epoch 30/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1343 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.5538 - acc: 0.9241 - val_loss: 0.7392 - val_acc: 0.8482

Epoch 00030: loss improved from 0.56747 to 0.55376, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_12.h5
Epoch 31/100

 32/448 [=>............................] - ETA: 0s - loss: 0.5288 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.5549 - acc: 0.9375 - val_loss: 0.7557 - val_acc: 0.8929

Epoch 00031: loss did not improve from 0.55376
Epoch 32/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8300 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.5578 - acc: 0.9353 - val_loss: 1.0765 - val_acc: 0.8839

Epoch 00032: loss did not improve from 0.55376
Epoch 33/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2966 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7912 - acc: 0.9018 - val_loss: 1.3673 - val_acc: 0.8482

Epoch 00033: loss did not improve from 0.55376
Epoch 34/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9381 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6160 - acc: 0.9219 - val_loss: 1.1292 - val_acc: 0.8393

Epoch 00034: loss did not improve from 0.55376
Epoch 35/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9297 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6377 - acc: 0.9308 - val_loss: 0.8761 - val_acc: 0.8304
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:14<00:12,  2.04s/it]
Epoch 00035: loss did not improve from 0.55376
Epoch 00035: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 2s - loss: 1.6132 - acc: 0.6562
448/448 [==============================] - 0s 609us/step - loss: 1.7533 - acc: 0.8013 - val_loss: 1.6123 - val_acc: 0.7589

Epoch 00001: loss improved from inf to 1.75332, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.8774 - acc: 0.6875
448/448 [==============================] - 0s 32us/step - loss: 1.4701 - acc: 0.8259 - val_loss: 1.4699 - val_acc: 0.7857

Epoch 00002: loss improved from 1.75332 to 1.47012, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.7006 - acc: 0.7500
448/448 [==============================] - 0s 31us/step - loss: 1.3201 - acc: 0.8549 - val_loss: 1.3664 - val_acc: 0.7857

Epoch 00003: loss improved from 1.47012 to 1.32011, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4338 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.3298 - acc: 0.8661 - val_loss: 1.5083 - val_acc: 0.7946

Epoch 00004: loss did not improve from 1.32011
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.6490 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.2532 - acc: 0.8750 - val_loss: 1.2860 - val_acc: 0.8214

Epoch 00005: loss improved from 1.32011 to 1.25319, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5011 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.1998 - acc: 0.8772 - val_loss: 1.1619 - val_acc: 0.8125

Epoch 00006: loss improved from 1.25319 to 1.19985, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5581 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 1.1360 - acc: 0.8750 - val_loss: 1.1775 - val_acc: 0.8214

Epoch 00007: loss improved from 1.19985 to 1.13604, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2141 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 1.1107 - acc: 0.8906 - val_loss: 1.1027 - val_acc: 0.8393

Epoch 00008: loss improved from 1.13604 to 1.11067, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9911 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.9865 - acc: 0.9196 - val_loss: 1.1566 - val_acc: 0.7946

Epoch 00009: loss improved from 1.11067 to 0.98649, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1924 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 1.0628 - acc: 0.8973 - val_loss: 1.2110 - val_acc: 0.8036

Epoch 00010: loss did not improve from 0.98649
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2413 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.9956 - acc: 0.8817 - val_loss: 1.0007 - val_acc: 0.8036

Epoch 00011: loss did not improve from 0.98649
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2450 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.9561 - acc: 0.8996 - val_loss: 0.9769 - val_acc: 0.8393

Epoch 00012: loss improved from 0.98649 to 0.95605, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1575 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.9340 - acc: 0.9085 - val_loss: 1.1325 - val_acc: 0.8304

Epoch 00013: loss improved from 0.95605 to 0.93400, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0709 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8361 - acc: 0.9107 - val_loss: 0.9790 - val_acc: 0.8393

Epoch 00014: loss improved from 0.93400 to 0.83613, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1480 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8131 - acc: 0.9196 - val_loss: 0.9078 - val_acc: 0.7946

Epoch 00015: loss improved from 0.83613 to 0.81314, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9823 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.9543 - acc: 0.8951 - val_loss: 0.8816 - val_acc: 0.8393

Epoch 00016: loss did not improve from 0.81314
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1468 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8625 - acc: 0.9129 - val_loss: 1.3750 - val_acc: 0.8036

Epoch 00017: loss did not improve from 0.81314
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0698 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 1.0878 - acc: 0.8929 - val_loss: 1.3727 - val_acc: 0.8393

Epoch 00018: loss did not improve from 0.81314
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0734 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.9018 - acc: 0.9040 - val_loss: 1.3324 - val_acc: 0.8393

Epoch 00019: loss did not improve from 0.81314
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8650 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7644 - acc: 0.9107 - val_loss: 1.0131 - val_acc: 0.8571

Epoch 00020: loss improved from 0.81314 to 0.76435, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0407 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.7866 - acc: 0.9196 - val_loss: 0.9254 - val_acc: 0.8839

Epoch 00021: loss did not improve from 0.76435
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9552 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7572 - acc: 0.9330 - val_loss: 1.0126 - val_acc: 0.8839

Epoch 00022: loss improved from 0.76435 to 0.75723, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2049 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.7754 - acc: 0.9018 - val_loss: 0.8141 - val_acc: 0.8482

Epoch 00023: loss did not improve from 0.75723
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7371 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.7540 - acc: 0.9018 - val_loss: 0.9211 - val_acc: 0.8125

Epoch 00024: loss improved from 0.75723 to 0.75404, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8153 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.6779 - acc: 0.9308 - val_loss: 0.9098 - val_acc: 0.8571

Epoch 00025: loss improved from 0.75404 to 0.67790, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 26/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6949 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.7487 - acc: 0.9241 - val_loss: 0.8384 - val_acc: 0.8661

Epoch 00026: loss did not improve from 0.67790
Epoch 27/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8670 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.7297 - acc: 0.9330 - val_loss: 1.1102 - val_acc: 0.8125

Epoch 00027: loss did not improve from 0.67790
Epoch 28/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9327 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 0.6520 - acc: 0.9196 - val_loss: 0.8604 - val_acc: 0.8571

Epoch 00028: loss improved from 0.67790 to 0.65196, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 29/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8743 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.6438 - acc: 0.9330 - val_loss: 0.7310 - val_acc: 0.8750

Epoch 00029: loss improved from 0.65196 to 0.64384, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 30/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0906 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.7403 - acc: 0.9152 - val_loss: 0.9668 - val_acc: 0.8393

Epoch 00030: loss did not improve from 0.64384
Epoch 31/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8796 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6423 - acc: 0.9107 - val_loss: 0.9345 - val_acc: 0.8482

Epoch 00031: loss improved from 0.64384 to 0.64232, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 32/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6628 - acc: 0.9688
448/448 [==============================] - 0s 29us/step - loss: 0.5488 - acc: 0.9397 - val_loss: 0.6547 - val_acc: 0.8482

Epoch 00032: loss improved from 0.64232 to 0.54880, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_13.h5
Epoch 33/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6539 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7076 - acc: 0.9196 - val_loss: 0.9019 - val_acc: 0.8036

Epoch 00033: loss did not improve from 0.54880
Epoch 34/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7534 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.6326 - acc: 0.9330 - val_loss: 0.9285 - val_acc: 0.8482

Epoch 00034: loss did not improve from 0.54880
Epoch 35/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9817 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.6810 - acc: 0.9263 - val_loss: 0.6644 - val_acc: 0.8393

Epoch 00035: loss did not improve from 0.54880
Epoch 36/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6486 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.7136 - acc: 0.9129 - val_loss: 1.1545 - val_acc: 0.8036

Epoch 00036: loss did not improve from 0.54880
Epoch 37/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7875 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.6377 - acc: 0.9286 - val_loss: 0.7970 - val_acc: 0.8036
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:16<00:10,  2.09s/it]
Epoch 00037: loss did not improve from 0.54880
Epoch 00037: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 3s - loss: 1.5392 - acc: 0.6562
448/448 [==============================] - 0s 616us/step - loss: 1.6341 - acc: 0.8281 - val_loss: 1.5998 - val_acc: 0.7768

Epoch 00001: loss improved from inf to 1.63405, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.7676 - acc: 0.6875
448/448 [==============================] - 0s 32us/step - loss: 1.3779 - acc: 0.8214 - val_loss: 1.5355 - val_acc: 0.7679

Epoch 00002: loss improved from 1.63405 to 1.37787, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5288 - acc: 0.7812
448/448 [==============================] - 0s 31us/step - loss: 1.2265 - acc: 0.8504 - val_loss: 1.2446 - val_acc: 0.7946

Epoch 00003: loss improved from 1.37787 to 1.22651, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4712 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.1968 - acc: 0.8616 - val_loss: 1.3743 - val_acc: 0.7857

Epoch 00004: loss improved from 1.22651 to 1.19685, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.7276 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 1.1881 - acc: 0.8616 - val_loss: 1.1367 - val_acc: 0.8304

Epoch 00005: loss improved from 1.19685 to 1.18806, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.6806 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.1108 - acc: 0.8772 - val_loss: 1.1170 - val_acc: 0.8036

Epoch 00006: loss improved from 1.18806 to 1.11085, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.6087 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.0714 - acc: 0.8527 - val_loss: 1.2891 - val_acc: 0.8036

Epoch 00007: loss improved from 1.11085 to 1.07142, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3131 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.0812 - acc: 0.8929 - val_loss: 1.1787 - val_acc: 0.8393

Epoch 00008: loss did not improve from 1.07142
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4735 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 1.0684 - acc: 0.8772 - val_loss: 1.0870 - val_acc: 0.8750

Epoch 00009: loss improved from 1.07142 to 1.06840, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5258 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.9104 - acc: 0.9062 - val_loss: 1.0260 - val_acc: 0.8125

Epoch 00010: loss improved from 1.06840 to 0.91035, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1131 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 0.9093 - acc: 0.9040 - val_loss: 0.9774 - val_acc: 0.8214

Epoch 00011: loss improved from 0.91035 to 0.90930, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0107 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.9437 - acc: 0.8772 - val_loss: 1.0123 - val_acc: 0.8304

Epoch 00012: loss did not improve from 0.90930
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4127 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.8282 - acc: 0.9129 - val_loss: 1.0110 - val_acc: 0.8393

Epoch 00013: loss improved from 0.90930 to 0.82817, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1238 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.8228 - acc: 0.9085 - val_loss: 0.9516 - val_acc: 0.8304

Epoch 00014: loss improved from 0.82817 to 0.82280, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9965 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.7153 - acc: 0.9241 - val_loss: 0.9000 - val_acc: 0.8304

Epoch 00015: loss improved from 0.82280 to 0.71532, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9935 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 0.8273 - acc: 0.8906 - val_loss: 1.0550 - val_acc: 0.8393

Epoch 00016: loss did not improve from 0.71532
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1795 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7600 - acc: 0.9062 - val_loss: 1.0245 - val_acc: 0.8571

Epoch 00017: loss did not improve from 0.71532
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8161 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7450 - acc: 0.9308 - val_loss: 0.9612 - val_acc: 0.8482

Epoch 00018: loss did not improve from 0.71532
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0184 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6534 - acc: 0.9397 - val_loss: 0.7023 - val_acc: 0.8929

Epoch 00019: loss improved from 0.71532 to 0.65343, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_14.h5
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0098 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.7787 - acc: 0.9040 - val_loss: 1.0756 - val_acc: 0.8125

Epoch 00020: loss did not improve from 0.65343
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8424 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8290 - acc: 0.9152 - val_loss: 1.1920 - val_acc: 0.8036

Epoch 00021: loss did not improve from 0.65343
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2366 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7747 - acc: 0.9040 - val_loss: 0.9560 - val_acc: 0.8482

Epoch 00022: loss did not improve from 0.65343
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9173 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6553 - acc: 0.9330 - val_loss: 0.8825 - val_acc: 0.8214

Epoch 00023: loss did not improve from 0.65343
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9161 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.8930 - acc: 0.8973 - val_loss: 1.2911 - val_acc: 0.8125
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:18<00:08,  2.04s/it]
Epoch 00024: loss did not improve from 0.65343
Epoch 00024: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 2s - loss: 1.8092 - acc: 0.6250
448/448 [==============================] - 0s 597us/step - loss: 1.7701 - acc: 0.8170 - val_loss: 1.6705 - val_acc: 0.7768

Epoch 00001: loss improved from inf to 1.77014, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.8635 - acc: 0.6562
448/448 [==============================] - 0s 32us/step - loss: 1.3880 - acc: 0.8237 - val_loss: 1.4446 - val_acc: 0.7768

Epoch 00002: loss improved from 1.77014 to 1.38802, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5236 - acc: 0.7500
448/448 [==============================] - 0s 31us/step - loss: 1.3817 - acc: 0.8281 - val_loss: 1.3756 - val_acc: 0.7857

Epoch 00003: loss improved from 1.38802 to 1.38168, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5294 - acc: 0.7812
448/448 [==============================] - 0s 31us/step - loss: 1.2166 - acc: 0.8549 - val_loss: 1.1897 - val_acc: 0.7857

Epoch 00004: loss improved from 1.38168 to 1.21657, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2305 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 1.1448 - acc: 0.8705 - val_loss: 1.1334 - val_acc: 0.8036

Epoch 00005: loss improved from 1.21657 to 1.14476, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3939 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 1.0551 - acc: 0.8795 - val_loss: 0.9993 - val_acc: 0.8125

Epoch 00006: loss improved from 1.14476 to 1.05515, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1163 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.0168 - acc: 0.8795 - val_loss: 1.1973 - val_acc: 0.8214

Epoch 00007: loss improved from 1.05515 to 1.01682, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2309 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 1.0177 - acc: 0.8795 - val_loss: 1.0912 - val_acc: 0.8214

Epoch 00008: loss did not improve from 1.01682
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3381 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.9624 - acc: 0.8795 - val_loss: 1.1031 - val_acc: 0.8304

Epoch 00009: loss improved from 1.01682 to 0.96237, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0084 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 1.1185 - acc: 0.8728 - val_loss: 1.4850 - val_acc: 0.8125

Epoch 00010: loss did not improve from 0.96237
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3202 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 1.0013 - acc: 0.8705 - val_loss: 1.0879 - val_acc: 0.8125

Epoch 00011: loss did not improve from 0.96237
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9970 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8791 - acc: 0.9107 - val_loss: 0.9904 - val_acc: 0.8214

Epoch 00012: loss improved from 0.96237 to 0.87909, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0660 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.8007 - acc: 0.9040 - val_loss: 0.9767 - val_acc: 0.8214

Epoch 00013: loss improved from 0.87909 to 0.80072, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8835 - acc: 0.9375
448/448 [==============================] - 0s 30us/step - loss: 0.7998 - acc: 0.9196 - val_loss: 0.9545 - val_acc: 0.8036

Epoch 00014: loss improved from 0.80072 to 0.79980, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9766 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.8352 - acc: 0.8951 - val_loss: 0.8941 - val_acc: 0.8214

Epoch 00015: loss did not improve from 0.79980
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8863 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7583 - acc: 0.9018 - val_loss: 1.1346 - val_acc: 0.7946

Epoch 00016: loss improved from 0.79980 to 0.75827, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8179 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.7759 - acc: 0.9107 - val_loss: 0.8933 - val_acc: 0.8125

Epoch 00017: loss did not improve from 0.75827
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8863 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7556 - acc: 0.9196 - val_loss: 0.8918 - val_acc: 0.8214

Epoch 00018: loss improved from 0.75827 to 0.75555, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.6503 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.6664 - acc: 0.9353 - val_loss: 0.7801 - val_acc: 0.8304

Epoch 00019: loss improved from 0.75555 to 0.66645, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9391 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.6489 - acc: 0.9375 - val_loss: 0.8779 - val_acc: 0.8393

Epoch 00020: loss improved from 0.66645 to 0.64894, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_15.h5
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8486 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.6862 - acc: 0.9263 - val_loss: 1.2737 - val_acc: 0.7857

Epoch 00021: loss did not improve from 0.64894
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8501 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8658 - acc: 0.9107 - val_loss: 1.3891 - val_acc: 0.8304

Epoch 00022: loss did not improve from 0.64894
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8030 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.8027 - acc: 0.9174 - val_loss: 1.4689 - val_acc: 0.7946

Epoch 00023: loss did not improve from 0.64894
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0133 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.7827 - acc: 0.9152 - val_loss: 1.2818 - val_acc: 0.7768

Epoch 00024: loss did not improve from 0.64894
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1938 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7305 - acc: 0.8996 - val_loss: 1.0505 - val_acc: 0.8214
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:20<00:06,  2.02s/it]
Epoch 00025: loss did not improve from 0.64894
Epoch 00025: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 2s - loss: 1.5164 - acc: 0.6562
448/448 [==============================] - 0s 600us/step - loss: 1.8247 - acc: 0.7946 - val_loss: 1.4370 - val_acc: 0.7679

Epoch 00001: loss improved from inf to 1.82465, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.7561 - acc: 0.6875
448/448 [==============================] - 0s 31us/step - loss: 1.3478 - acc: 0.8214 - val_loss: 1.2310 - val_acc: 0.7768

Epoch 00002: loss improved from 1.82465 to 1.34784, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.6020 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 1.2675 - acc: 0.8393 - val_loss: 1.4459 - val_acc: 0.7857

Epoch 00003: loss improved from 1.34784 to 1.26752, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5675 - acc: 0.7500
448/448 [==============================] - 0s 30us/step - loss: 1.1598 - acc: 0.8527 - val_loss: 1.2095 - val_acc: 0.7946

Epoch 00004: loss improved from 1.26752 to 1.15982, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3320 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.0559 - acc: 0.8705 - val_loss: 1.1511 - val_acc: 0.7768

Epoch 00005: loss improved from 1.15982 to 1.05591, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2962 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.1587 - acc: 0.8571 - val_loss: 1.3734 - val_acc: 0.7679

Epoch 00006: loss did not improve from 1.05591
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3752 - acc: 0.7188
448/448 [==============================] - 0s 29us/step - loss: 1.0392 - acc: 0.8638 - val_loss: 1.0019 - val_acc: 0.7857

Epoch 00007: loss improved from 1.05591 to 1.03924, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2916 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 1.0151 - acc: 0.8661 - val_loss: 1.0111 - val_acc: 0.8125

Epoch 00008: loss improved from 1.03924 to 1.01510, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_16.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2275 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 1.0213 - acc: 0.8772 - val_loss: 0.8524 - val_acc: 0.8214

Epoch 00009: loss did not improve from 1.01510
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3553 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 0.8481 - acc: 0.9062 - val_loss: 0.8913 - val_acc: 0.8304

Epoch 00010: loss improved from 1.01510 to 0.84815, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9592 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 1.0612 - acc: 0.8884 - val_loss: 1.2951 - val_acc: 0.8571

Epoch 00011: loss did not improve from 0.84815
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3515 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 1.0101 - acc: 0.8906 - val_loss: 0.8850 - val_acc: 0.8125

Epoch 00012: loss did not improve from 0.84815
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3906 - acc: 0.7500
448/448 [==============================] - 0s 29us/step - loss: 0.8837 - acc: 0.8906 - val_loss: 0.9523 - val_acc: 0.8304

Epoch 00013: loss did not improve from 0.84815
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0796 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.8947 - acc: 0.8929 - val_loss: 0.8350 - val_acc: 0.8393

Epoch 00014: loss did not improve from 0.84815
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1092 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 1.1308 - acc: 0.8862 - val_loss: 1.4740 - val_acc: 0.8304
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:22<00:03,  1.91s/it]
Epoch 00015: loss did not improve from 0.84815
Epoch 00015: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 3s - loss: 1.5203 - acc: 0.6875
448/448 [==============================] - 0s 613us/step - loss: 1.7692 - acc: 0.8058 - val_loss: 1.5432 - val_acc: 0.7589

Epoch 00001: loss improved from inf to 1.76917, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.7629 - acc: 0.6875
448/448 [==============================] - 0s 32us/step - loss: 1.3998 - acc: 0.8080 - val_loss: 1.4368 - val_acc: 0.7589

Epoch 00002: loss improved from 1.76917 to 1.39980, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3302 - acc: 0.7812
448/448 [==============================] - 0s 31us/step - loss: 1.2262 - acc: 0.8594 - val_loss: 1.3905 - val_acc: 0.7857

Epoch 00003: loss improved from 1.39980 to 1.22620, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5823 - acc: 0.7500
448/448 [==============================] - 0s 31us/step - loss: 1.2202 - acc: 0.8438 - val_loss: 1.2483 - val_acc: 0.7946

Epoch 00004: loss improved from 1.22620 to 1.22021, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5452 - acc: 0.7812
448/448 [==============================] - 0s 31us/step - loss: 1.1106 - acc: 0.8482 - val_loss: 1.1629 - val_acc: 0.8036

Epoch 00005: loss improved from 1.22021 to 1.11056, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1818 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 1.0368 - acc: 0.8772 - val_loss: 1.1491 - val_acc: 0.7857

Epoch 00006: loss improved from 1.11056 to 1.03679, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1464 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 1.0974 - acc: 0.8705 - val_loss: 1.4021 - val_acc: 0.7768

Epoch 00007: loss did not improve from 1.03679
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1861 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.9586 - acc: 0.8884 - val_loss: 1.1564 - val_acc: 0.8125

Epoch 00008: loss improved from 1.03679 to 0.95862, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2764 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 1.0825 - acc: 0.9018 - val_loss: 1.1137 - val_acc: 0.7857

Epoch 00009: loss did not improve from 0.95862
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0747 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.8888 - acc: 0.8951 - val_loss: 1.0288 - val_acc: 0.8304

Epoch 00010: loss improved from 0.95862 to 0.88879, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2337 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.8876 - acc: 0.8929 - val_loss: 1.0293 - val_acc: 0.8393

Epoch 00011: loss improved from 0.88879 to 0.88757, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2420 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 1.0221 - acc: 0.8817 - val_loss: 1.0274 - val_acc: 0.7946

Epoch 00012: loss did not improve from 0.88757
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0345 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.8076 - acc: 0.9129 - val_loss: 0.9587 - val_acc: 0.8125

Epoch 00013: loss improved from 0.88757 to 0.80756, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1286 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.7882 - acc: 0.9152 - val_loss: 1.2969 - val_acc: 0.8214

Epoch 00014: loss improved from 0.80756 to 0.78825, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9569 - acc: 0.8750
448/448 [==============================] - 0s 30us/step - loss: 0.8765 - acc: 0.8906 - val_loss: 1.1511 - val_acc: 0.8036

Epoch 00015: loss did not improve from 0.78825
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2311 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8167 - acc: 0.8996 - val_loss: 1.3330 - val_acc: 0.8125

Epoch 00016: loss did not improve from 0.78825
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0031 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8524 - acc: 0.9018 - val_loss: 1.0559 - val_acc: 0.8125

Epoch 00017: loss did not improve from 0.78825
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0123 - acc: 0.9062
448/448 [==============================] - 0s 29us/step - loss: 0.7408 - acc: 0.9263 - val_loss: 0.9346 - val_acc: 0.8571

Epoch 00018: loss improved from 0.78825 to 0.74080, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3085 - acc: 0.9062
448/448 [==============================] - 0s 30us/step - loss: 0.9633 - acc: 0.8973 - val_loss: 0.9634 - val_acc: 0.8304

Epoch 00019: loss did not improve from 0.74080
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1022 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7259 - acc: 0.9107 - val_loss: 0.7987 - val_acc: 0.8125

Epoch 00020: loss improved from 0.74080 to 0.72585, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_17.h5
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8114 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7941 - acc: 0.9152 - val_loss: 1.0735 - val_acc: 0.7857

Epoch 00021: loss did not improve from 0.72585
Epoch 22/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0322 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8062 - acc: 0.8996 - val_loss: 1.1446 - val_acc: 0.8214

Epoch 00022: loss did not improve from 0.72585
Epoch 23/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8829 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.8479 - acc: 0.9040 - val_loss: 1.2097 - val_acc: 0.8214

Epoch 00023: loss did not improve from 0.72585
Epoch 24/100

 32/448 [=>............................] - ETA: 0s - loss: 0.8849 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8489 - acc: 0.8839 - val_loss: 0.9913 - val_acc: 0.8125

Epoch 00024: loss did not improve from 0.72585
Epoch 25/100

 32/448 [=>............................] - ETA: 0s - loss: 1.7584 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.8587 - acc: 0.8929 - val_loss: 0.9722 - val_acc: 0.8571
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:24<00:01,  1.93s/it]
Epoch 00025: loss did not improve from 0.72585
Epoch 00025: early stopping
Train on 448 samples, validate on 112 samples
Epoch 1/100

 32/448 [=>............................] - ETA: 2s - loss: 1.4751 - acc: 0.5938
448/448 [==============================] - 0s 597us/step - loss: 1.7314 - acc: 0.7746 - val_loss: 1.6105 - val_acc: 0.7500

Epoch 00001: loss improved from inf to 1.73140, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/448 [=>............................] - ETA: 0s - loss: 1.9008 - acc: 0.6875
448/448 [==============================] - 0s 31us/step - loss: 1.4318 - acc: 0.7991 - val_loss: 1.3374 - val_acc: 0.7589

Epoch 00002: loss improved from 1.73140 to 1.43181, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/448 [=>............................] - ETA: 0s - loss: 1.6379 - acc: 0.6875
448/448 [==============================] - 0s 30us/step - loss: 1.3531 - acc: 0.8237 - val_loss: 1.3566 - val_acc: 0.7768

Epoch 00003: loss improved from 1.43181 to 1.35314, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4734 - acc: 0.6562
448/448 [==============================] - 0s 30us/step - loss: 1.3205 - acc: 0.8237 - val_loss: 1.3419 - val_acc: 0.7946

Epoch 00004: loss improved from 1.35314 to 1.32052, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/448 [=>............................] - ETA: 0s - loss: 1.6693 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.3050 - acc: 0.8460 - val_loss: 1.2565 - val_acc: 0.8036

Epoch 00005: loss improved from 1.32052 to 1.30498, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/448 [=>............................] - ETA: 0s - loss: 1.8088 - acc: 0.7812
448/448 [==============================] - 0s 30us/step - loss: 1.1892 - acc: 0.8549 - val_loss: 1.2071 - val_acc: 0.8036

Epoch 00006: loss improved from 1.30498 to 1.18924, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/448 [=>............................] - ETA: 0s - loss: 1.4137 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.1544 - acc: 0.8817 - val_loss: 1.1571 - val_acc: 0.7857

Epoch 00007: loss improved from 1.18924 to 1.15442, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3828 - acc: 0.8125
448/448 [==============================] - 0s 30us/step - loss: 1.0886 - acc: 0.8705 - val_loss: 1.4501 - val_acc: 0.7768

Epoch 00008: loss improved from 1.15442 to 1.08860, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/448 [=>............................] - ETA: 0s - loss: 1.5750 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 1.1099 - acc: 0.8371 - val_loss: 1.1987 - val_acc: 0.7768

Epoch 00009: loss did not improve from 1.08860
Epoch 10/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2834 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.9744 - acc: 0.8728 - val_loss: 1.0485 - val_acc: 0.7768

Epoch 00010: loss improved from 1.08860 to 0.97438, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0956 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.8961 - acc: 0.8839 - val_loss: 0.9136 - val_acc: 0.8214

Epoch 00011: loss improved from 0.97438 to 0.89613, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9106 - acc: 0.8438
448/448 [==============================] - 0s 30us/step - loss: 0.8581 - acc: 0.9040 - val_loss: 0.9582 - val_acc: 0.8214

Epoch 00012: loss improved from 0.89613 to 0.85809, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 13/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3499 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.9312 - acc: 0.8772 - val_loss: 0.8517 - val_acc: 0.8304

Epoch 00013: loss did not improve from 0.85809
Epoch 14/100

 32/448 [=>............................] - ETA: 0s - loss: 1.1508 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.8986 - acc: 0.8996 - val_loss: 1.2078 - val_acc: 0.8125

Epoch 00014: loss did not improve from 0.85809
Epoch 15/100

 32/448 [=>............................] - ETA: 0s - loss: 1.2886 - acc: 0.8125
448/448 [==============================] - 0s 29us/step - loss: 0.8990 - acc: 0.9040 - val_loss: 0.9218 - val_acc: 0.8036

Epoch 00015: loss did not improve from 0.85809
Epoch 16/100

 32/448 [=>............................] - ETA: 0s - loss: 0.7992 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.7164 - acc: 0.9107 - val_loss: 0.9831 - val_acc: 0.8750

Epoch 00016: loss improved from 0.85809 to 0.71637, saving model to ./results_TA1537_with_S9/DeepAmes_models/weight_18.h5
Epoch 17/100

 32/448 [=>............................] - ETA: 0s - loss: 1.9595 - acc: 0.8438
448/448 [==============================] - 0s 29us/step - loss: 0.9594 - acc: 0.8772 - val_loss: 1.0391 - val_acc: 0.8036

Epoch 00017: loss did not improve from 0.71637
Epoch 18/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0354 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 0.9693 - acc: 0.8728 - val_loss: 0.9186 - val_acc: 0.8036

Epoch 00018: loss did not improve from 0.71637
Epoch 19/100

 32/448 [=>............................] - ETA: 0s - loss: 0.9536 - acc: 0.8750
448/448 [==============================] - 0s 29us/step - loss: 0.7180 - acc: 0.9174 - val_loss: 0.8697 - val_acc: 0.8750

Epoch 00019: loss did not improve from 0.71637
Epoch 20/100

 32/448 [=>............................] - ETA: 0s - loss: 1.0050 - acc: 0.9375
448/448 [==============================] - 0s 29us/step - loss: 0.8150 - acc: 0.8973 - val_loss: 0.7972 - val_acc: 0.7946

Epoch 00020: loss did not improve from 0.71637
Epoch 21/100

 32/448 [=>............................] - ETA: 0s - loss: 1.3159 - acc: 0.7812
448/448 [==============================] - 0s 29us/step - loss: 0.8219 - acc: 0.8996 - val_loss: 0.9207 - val_acc: 0.8036
DeepAmes+ Weights: 100%|██████████| 13/13 [00:26<00:00,  1.91s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:26<00:00,  2.01s/it]

Epoch 00021: loss did not improve from 0.71637
Epoch 00021: early stopping
--- 2845.6161983013153 seconds ---

Generating metrics report for TA1537_with_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 330 samples.
Processing weight 7...
  Done. 330 samples.
Processing weight 8...
  Done. 330 samples.
Processing weight 9...
  Done. 330 samples.
Processing weight 10...
  Done. 330 samples.
Processing weight 11...
  Done. 330 samples.
Processing weight 12...
  Done. 330 samples.
Processing weight 13...
  Done. 330 samples.
Processing weight 14...
  Done. 330 samples.
Processing weight 15...
  Done. 330 samples.
Processing weight 16...
  Done. 330 samples.
Processing weight 17...
  Done. 330 samples.
Processing weight 18...
  Done. 330 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA1537_with_S9/metrics_report_TA1537_with_S9.txt

Done!

Completed TA1537_with_S9 in 2845.62 seconds

================================================================================
[10/16] Processing: TA1537_without_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA1537_without_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA1537_without_S9_Test_mold2.csv
(2902, 777)
(2321, 777)
(338, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:11<03:47, 11.98s/it]KNN Seeds:  10%|█         | 2/20 [00:23<03:35, 11.98s/it]KNN Seeds:  15%|█▌        | 3/20 [00:35<03:23, 11.98s/it]KNN Seeds:  20%|██        | 4/20 [00:47<03:11, 11.99s/it]KNN Seeds:  25%|██▌       | 5/20 [01:00<03:01, 12.13s/it]KNN Seeds:  30%|███       | 6/20 [01:12<02:49, 12.10s/it]KNN Seeds:  35%|███▌      | 7/20 [01:24<02:37, 12.11s/it]KNN Seeds:  40%|████      | 8/20 [01:36<02:25, 12.14s/it]KNN Seeds:  45%|████▌     | 9/20 [01:48<02:13, 12.13s/it]KNN Seeds:  50%|█████     | 10/20 [02:00<02:01, 12.14s/it]KNN Seeds:  55%|█████▌    | 11/20 [02:13<01:49, 12.14s/it]KNN Seeds:  60%|██████    | 12/20 [02:25<01:37, 12.20s/it]KNN Seeds:  65%|██████▌   | 13/20 [02:37<01:25, 12.20s/it]KNN Seeds:  70%|███████   | 14/20 [02:49<01:13, 12.23s/it]KNN Seeds:  75%|███████▌  | 15/20 [03:02<01:01, 12.23s/it]KNN Seeds:  80%|████████  | 16/20 [03:14<00:49, 12.26s/it]KNN Seeds:  85%|████████▌ | 17/20 [03:26<00:36, 12.30s/it]KNN Seeds:  90%|█████████ | 18/20 [03:39<00:24, 12.34s/it]KNN Seeds:  95%|█████████▌| 19/20 [03:51<00:12, 12.32s/it]KNN Seeds: 100%|██████████| 20/20 [04:03<00:00, 12.28s/it]KNN Seeds: 100%|██████████| 20/20 [04:03<00:00, 12.19s/it]
24
(100, None, 'lbfgs')
(2902, 777)
(2321, 777)
(338, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:02<00:42,  2.25s/it]LR Seeds:  10%|█         | 2/20 [00:04<00:40,  2.28s/it]LR Seeds:  15%|█▌        | 3/20 [00:06<00:38,  2.28s/it]LR Seeds:  20%|██        | 4/20 [00:09<00:36,  2.29s/it]LR Seeds:  25%|██▌       | 5/20 [00:11<00:34,  2.31s/it]LR Seeds:  30%|███       | 6/20 [00:13<00:32,  2.34s/it]LR Seeds:  35%|███▌      | 7/20 [00:16<00:30,  2.33s/it]LR Seeds:  40%|████      | 8/20 [00:18<00:28,  2.34s/it]LR Seeds:  45%|████▌     | 9/20 [00:20<00:25,  2.34s/it]LR Seeds:  50%|█████     | 10/20 [00:23<00:23,  2.34s/it]LR Seeds:  55%|█████▌    | 11/20 [00:25<00:21,  2.36s/it]LR Seeds:  60%|██████    | 12/20 [00:28<00:18,  2.36s/it]LR Seeds:  65%|██████▌   | 13/20 [00:30<00:16,  2.38s/it]LR Seeds:  70%|███████   | 14/20 [00:32<00:14,  2.39s/it]LR Seeds:  75%|███████▌  | 15/20 [00:35<00:12,  2.40s/it]LR Seeds:  80%|████████  | 16/20 [00:37<00:09,  2.41s/it]LR Seeds:  85%|████████▌ | 17/20 [00:40<00:07,  2.42s/it]LR Seeds:  90%|█████████ | 18/20 [00:42<00:04,  2.47s/it]LR Seeds:  95%|█████████▌| 19/20 [00:45<00:02,  2.48s/it]LR Seeds: 100%|██████████| 20/20 [00:47<00:00,  2.49s/it]LR Seeds: 100%|██████████| 20/20 [00:47<00:00,  2.39s/it]
96
('rbf', 1, 1)
(2902, 777)
(2321, 777)
(338, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [01:19<25:19, 80.00s/it]SVM Seeds:  10%|█         | 2/20 [02:40<24:01, 80.11s/it]SVM Seeds:  15%|█▌        | 3/20 [04:00<22:41, 80.06s/it]SVM Seeds:  20%|██        | 4/20 [05:20<21:21, 80.10s/it]SVM Seeds:  25%|██▌       | 5/20 [06:40<20:01, 80.09s/it]SVM Seeds:  30%|███       | 6/20 [08:00<18:41, 80.09s/it]SVM Seeds:  35%|███▌      | 7/20 [09:20<17:20, 80.05s/it]SVM Seeds:  40%|████      | 8/20 [10:40<16:01, 80.10s/it]SVM Seeds:  45%|████▌     | 9/20 [12:00<14:41, 80.13s/it]SVM Seeds:  50%|█████     | 10/20 [13:21<13:21, 80.15s/it]SVM Seeds:  55%|█████▌    | 11/20 [14:41<12:01, 80.17s/it]SVM Seeds:  60%|██████    | 12/20 [16:01<10:41, 80.16s/it]SVM Seeds:  65%|██████▌   | 13/20 [17:22<09:22, 80.32s/it]SVM Seeds:  70%|███████   | 14/20 [18:42<08:01, 80.25s/it]SVM Seeds:  75%|███████▌  | 15/20 [20:02<06:41, 80.26s/it]SVM Seeds:  80%|████████  | 16/20 [21:22<05:20, 80.22s/it]SVM Seeds:  85%|████████▌ | 17/20 [22:42<04:00, 80.21s/it]SVM Seeds:  90%|█████████ | 18/20 [24:02<02:40, 80.19s/it]SVM Seeds:  95%|█████████▌| 19/20 [25:23<01:20, 80.27s/it]SVM Seeds: 100%|██████████| 20/20 [26:43<00:00, 80.31s/it]SVM Seeds: 100%|██████████| 20/20 [26:43<00:00, 80.19s/it]
200
(500, None, 70, 1, 'balanced')
(2902, 777)
(2321, 777)
(338, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:07<02:31,  7.97s/it]RF Seeds:  10%|█         | 2/20 [00:15<02:23,  7.96s/it]RF Seeds:  15%|█▌        | 3/20 [00:23<02:15,  7.98s/it]RF Seeds:  20%|██        | 4/20 [00:31<02:07,  7.99s/it]RF Seeds:  25%|██▌       | 5/20 [00:39<01:59,  7.99s/it]RF Seeds:  30%|███       | 6/20 [00:47<01:51,  8.00s/it]RF Seeds:  35%|███▌      | 7/20 [00:55<01:44,  8.02s/it]RF Seeds:  40%|████      | 8/20 [01:04<01:36,  8.02s/it]RF Seeds:  45%|████▌     | 9/20 [01:12<01:28,  8.03s/it]RF Seeds:  50%|█████     | 10/20 [01:20<01:20,  8.03s/it]RF Seeds:  55%|█████▌    | 11/20 [01:28<01:12,  8.04s/it]RF Seeds:  60%|██████    | 12/20 [01:36<01:04,  8.05s/it]RF Seeds:  65%|██████▌   | 13/20 [01:44<00:56,  8.05s/it]RF Seeds:  70%|███████   | 14/20 [01:52<00:48,  8.07s/it]RF Seeds:  75%|███████▌  | 15/20 [02:00<00:40,  8.08s/it]RF Seeds:  80%|████████  | 16/20 [02:08<00:32,  8.10s/it]RF Seeds:  85%|████████▌ | 17/20 [02:16<00:24,  8.13s/it]RF Seeds:  90%|█████████ | 18/20 [02:24<00:16,  8.13s/it]RF Seeds:  95%|█████████▌| 19/20 [02:33<00:08,  8.13s/it]RF Seeds: 100%|██████████| 20/20 [02:41<00:00,  8.14s/it]RF Seeds: 100%|██████████| 20/20 [02:41<00:00,  8.06s/it]
400
(0.01, 900, 7, 0.8, 6)
(2902, 777)
(2321, 777)
(338, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:40<12:54, 40.75s/it]XGBoost Seeds:  10%|█         | 2/20 [01:21<12:12, 40.70s/it]XGBoost Seeds:  15%|█▌        | 3/20 [02:02<11:31, 40.69s/it]XGBoost Seeds:  20%|██        | 4/20 [02:42<10:50, 40.64s/it]XGBoost Seeds:  25%|██▌       | 5/20 [03:23<10:09, 40.66s/it]XGBoost Seeds:  30%|███       | 6/20 [04:04<09:29, 40.69s/it]XGBoost Seeds:  35%|███▌      | 7/20 [04:44<08:49, 40.71s/it]XGBoost Seeds:  40%|████      | 8/20 [05:25<08:09, 40.79s/it]XGBoost Seeds:  45%|████▌     | 9/20 [06:06<07:28, 40.81s/it]XGBoost Seeds:  50%|█████     | 10/20 [06:47<06:47, 40.76s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [07:27<06:06, 40.71s/it]XGBoost Seeds:  60%|██████    | 12/20 [08:08<05:25, 40.72s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [08:49<04:44, 40.69s/it]XGBoost Seeds:  70%|███████   | 14/20 [09:29<04:04, 40.68s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [10:10<03:23, 40.74s/it]XGBoost Seeds:  80%|████████  | 16/20 [10:51<02:43, 40.76s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [11:32<02:02, 40.75s/it]XGBoost Seeds:  90%|█████████ | 18/20 [12:13<01:21, 40.80s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [12:53<00:40, 40.77s/it]XGBoost Seeds: 100%|██████████| 20/20 [13:34<00:00, 40.77s/it]XGBoost Seeds: 100%|██████████| 20/20 [13:34<00:00, 40.74s/it]
knn:  96
lr:  75
svm:  98
rf:  99
xgboost:  81
Combining validation predictions is completed
knn:  96
lr:  75
svm:  98
rf:  99
xgboost:  81
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.6505 - acc: 0.6250
464/464 [==============================] - 0s 616us/step - loss: 1.3033 - acc: 0.8147 - val_loss: 1.0192 - val_acc: 0.8632

Epoch 00001: loss improved from inf to 1.30332, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6836 - acc: 0.6875
464/464 [==============================] - 0s 34us/step - loss: 1.2182 - acc: 0.8858 - val_loss: 0.9761 - val_acc: 0.8889

Epoch 00002: loss improved from 1.30332 to 1.21825, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5005 - acc: 0.7500
464/464 [==============================] - 0s 32us/step - loss: 1.0662 - acc: 0.9030 - val_loss: 0.8584 - val_acc: 0.9231

Epoch 00003: loss improved from 1.21825 to 1.06618, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4358 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 1.0480 - acc: 0.9052 - val_loss: 0.7791 - val_acc: 0.9402

Epoch 00004: loss improved from 1.06618 to 1.04798, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1066 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 0.9590 - acc: 0.9224 - val_loss: 0.7388 - val_acc: 0.9402

Epoch 00005: loss improved from 1.04798 to 0.95903, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2152 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 0.9052 - acc: 0.9289 - val_loss: 0.7047 - val_acc: 0.9402

Epoch 00006: loss improved from 0.95903 to 0.90522, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1059 - acc: 0.8438
464/464 [==============================] - 0s 31us/step - loss: 0.8994 - acc: 0.9310 - val_loss: 0.6848 - val_acc: 0.9316

Epoch 00007: loss improved from 0.90522 to 0.89936, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3808 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.8623 - acc: 0.9203 - val_loss: 0.6434 - val_acc: 0.9316

Epoch 00008: loss improved from 0.89936 to 0.86231, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0228 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8188 - acc: 0.9159 - val_loss: 0.6577 - val_acc: 0.9060

Epoch 00009: loss improved from 0.86231 to 0.81881, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1546 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8916 - acc: 0.8944 - val_loss: 0.6894 - val_acc: 0.9316

Epoch 00010: loss did not improve from 0.81881
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0217 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.8075 - acc: 0.9224 - val_loss: 0.6666 - val_acc: 0.9231

Epoch 00011: loss improved from 0.81881 to 0.80754, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2050 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9048 - acc: 0.9138 - val_loss: 0.6270 - val_acc: 0.9231

Epoch 00012: loss did not improve from 0.80754
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1493 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.7785 - acc: 0.9203 - val_loss: 0.5890 - val_acc: 0.9316

Epoch 00013: loss improved from 0.80754 to 0.77848, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0180 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.7571 - acc: 0.9181 - val_loss: 0.5141 - val_acc: 0.9402

Epoch 00014: loss improved from 0.77848 to 0.75707, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8173 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.6692 - acc: 0.9246 - val_loss: 0.4810 - val_acc: 0.9402

Epoch 00015: loss improved from 0.75707 to 0.66923, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7766 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 0.7076 - acc: 0.9289 - val_loss: 0.5327 - val_acc: 0.9316

Epoch 00016: loss did not improve from 0.66923
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2498 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.7704 - acc: 0.9073 - val_loss: 0.5255 - val_acc: 0.9402

Epoch 00017: loss did not improve from 0.66923
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2623 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.6741 - acc: 0.9181 - val_loss: 0.4850 - val_acc: 0.9316

Epoch 00018: loss did not improve from 0.66923
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0097 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7075 - acc: 0.9138 - val_loss: 0.4853 - val_acc: 0.9316

Epoch 00019: loss did not improve from 0.66923
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0059 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.6181 - acc: 0.9332 - val_loss: 0.5653 - val_acc: 0.9316

Epoch 00020: loss improved from 0.66923 to 0.61809, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 0.6994 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.6406 - acc: 0.9289 - val_loss: 0.5168 - val_acc: 0.9231

Epoch 00021: loss did not improve from 0.61809
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8522 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.5842 - acc: 0.9418 - val_loss: 0.5323 - val_acc: 0.9145

Epoch 00022: loss improved from 0.61809 to 0.58423, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9313 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.6854 - acc: 0.8987 - val_loss: 0.5014 - val_acc: 0.9231

Epoch 00023: loss did not improve from 0.58423
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7698 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.5693 - acc: 0.9332 - val_loss: 0.4693 - val_acc: 0.9231

Epoch 00024: loss improved from 0.58423 to 0.56925, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7389 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.5892 - acc: 0.9332 - val_loss: 0.4246 - val_acc: 0.9316

Epoch 00025: loss did not improve from 0.56925
Epoch 26/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7416 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.5507 - acc: 0.9310 - val_loss: 0.4698 - val_acc: 0.9316

Epoch 00026: loss improved from 0.56925 to 0.55067, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 27/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8306 - acc: 0.8438
464/464 [==============================] - 0s 31us/step - loss: 0.5543 - acc: 0.9246 - val_loss: 0.4298 - val_acc: 0.9231

Epoch 00027: loss did not improve from 0.55067
Epoch 28/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7347 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.5698 - acc: 0.9181 - val_loss: 0.4148 - val_acc: 0.9316

Epoch 00028: loss did not improve from 0.55067
Epoch 29/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7473 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.5690 - acc: 0.9310 - val_loss: 0.4019 - val_acc: 0.9402

Epoch 00029: loss did not improve from 0.55067
Epoch 30/100

 32/464 [=>............................] - ETA: 0s - loss: 0.6751 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.5381 - acc: 0.9353 - val_loss: 0.4872 - val_acc: 0.9145

Epoch 00030: loss improved from 0.55067 to 0.53805, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 31/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8158 - acc: 0.8750
464/464 [==============================] - 0s 31us/step - loss: 0.5231 - acc: 0.9397 - val_loss: 0.5255 - val_acc: 0.9060

Epoch 00031: loss improved from 0.53805 to 0.52312, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 32/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7325 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.5154 - acc: 0.9310 - val_loss: 0.4877 - val_acc: 0.8974

Epoch 00032: loss improved from 0.52312 to 0.51537, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 33/100

 32/464 [=>............................] - ETA: 0s - loss: 0.5328 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 0.4552 - acc: 0.9461 - val_loss: 0.4121 - val_acc: 0.9145

Epoch 00033: loss improved from 0.51537 to 0.45520, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_6.h5
Epoch 34/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7535 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.5211 - acc: 0.9246 - val_loss: 0.4256 - val_acc: 0.9145

Epoch 00034: loss did not improve from 0.45520
Epoch 35/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9999 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.5014 - acc: 0.9181 - val_loss: 0.3456 - val_acc: 0.9402

Epoch 00035: loss did not improve from 0.45520
Epoch 36/100

 32/464 [=>............................] - ETA: 0s - loss: 0.5949 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.5013 - acc: 0.9504 - val_loss: 0.4202 - val_acc: 0.9231

Epoch 00036: loss did not improve from 0.45520
Epoch 37/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8270 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.4575 - acc: 0.9375 - val_loss: 0.4626 - val_acc: 0.9231

Epoch 00037: loss did not improve from 0.45520
Epoch 38/100

 32/464 [=>............................] - ETA: 0s - loss: 0.6805 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.4960 - acc: 0.9353 - val_loss: 0.4742 - val_acc: 0.9316
DeepAmes+ Weights:   8%|▊         | 1/13 [00:02<00:25,  2.17s/it]
Epoch 00038: loss did not improve from 0.45520
Epoch 00038: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.7960 - acc: 0.5312
464/464 [==============================] - 0s 594us/step - loss: 1.3819 - acc: 0.8211 - val_loss: 1.0069 - val_acc: 0.8974

Epoch 00001: loss improved from inf to 1.38189, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 1.7144 - acc: 0.7500
464/464 [==============================] - 0s 32us/step - loss: 1.1792 - acc: 0.8901 - val_loss: 0.9730 - val_acc: 0.8803

Epoch 00002: loss improved from 1.38189 to 1.17921, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4265 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.1273 - acc: 0.9138 - val_loss: 0.8703 - val_acc: 0.9060

Epoch 00003: loss improved from 1.17921 to 1.12727, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1374 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.0528 - acc: 0.8987 - val_loss: 0.8297 - val_acc: 0.8974

Epoch 00004: loss improved from 1.12727 to 1.05282, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3182 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.0228 - acc: 0.8944 - val_loss: 0.7647 - val_acc: 0.9316

Epoch 00005: loss improved from 1.05282 to 1.02278, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1179 - acc: 0.8750
464/464 [==============================] - 0s 31us/step - loss: 0.9532 - acc: 0.9181 - val_loss: 0.7690 - val_acc: 0.9231

Epoch 00006: loss improved from 1.02278 to 0.95319, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2553 - acc: 0.8438
464/464 [==============================] - 0s 31us/step - loss: 0.9270 - acc: 0.9181 - val_loss: 0.6622 - val_acc: 0.9402

Epoch 00007: loss improved from 0.95319 to 0.92698, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3536 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.9729 - acc: 0.9095 - val_loss: 0.6359 - val_acc: 0.9316

Epoch 00008: loss did not improve from 0.92698
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3691 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9073 - acc: 0.8987 - val_loss: 0.6485 - val_acc: 0.9316

Epoch 00009: loss improved from 0.92698 to 0.90733, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8535 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 0.8194 - acc: 0.9138 - val_loss: 0.6344 - val_acc: 0.9316

Epoch 00010: loss improved from 0.90733 to 0.81937, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0325 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8390 - acc: 0.9224 - val_loss: 0.7175 - val_acc: 0.9060

Epoch 00011: loss did not improve from 0.81937
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1233 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9109 - acc: 0.9095 - val_loss: 0.6454 - val_acc: 0.9060

Epoch 00012: loss did not improve from 0.81937
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1190 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.7782 - acc: 0.9181 - val_loss: 0.7647 - val_acc: 0.9060

Epoch 00013: loss improved from 0.81937 to 0.77823, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0965 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7406 - acc: 0.9353 - val_loss: 0.5860 - val_acc: 0.9145

Epoch 00014: loss improved from 0.77823 to 0.74056, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 0.5636 - acc: 0.9062
464/464 [==============================] - 0s 31us/step - loss: 0.7402 - acc: 0.9246 - val_loss: 0.7136 - val_acc: 0.9060

Epoch 00015: loss improved from 0.74056 to 0.74020, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1722 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 0.7139 - acc: 0.9289 - val_loss: 0.6129 - val_acc: 0.9231

Epoch 00016: loss improved from 0.74020 to 0.71385, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 0.6210 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.7121 - acc: 0.9332 - val_loss: 0.6212 - val_acc: 0.9231

Epoch 00017: loss improved from 0.71385 to 0.71208, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8959 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 0.7333 - acc: 0.9397 - val_loss: 0.6449 - val_acc: 0.8974

Epoch 00018: loss did not improve from 0.71208
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1637 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7954 - acc: 0.9116 - val_loss: 0.5591 - val_acc: 0.9316

Epoch 00019: loss did not improve from 0.71208
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2273 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7004 - acc: 0.9310 - val_loss: 0.5123 - val_acc: 0.9316

Epoch 00020: loss improved from 0.71208 to 0.70038, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7908 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.6413 - acc: 0.9375 - val_loss: 0.5483 - val_acc: 0.9316

Epoch 00021: loss improved from 0.70038 to 0.64126, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8806 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.5950 - acc: 0.9397 - val_loss: 0.4819 - val_acc: 0.9145

Epoch 00022: loss improved from 0.64126 to 0.59504, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2462 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.5831 - acc: 0.9289 - val_loss: 0.4453 - val_acc: 0.9402

Epoch 00023: loss improved from 0.59504 to 0.58307, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7658 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.6458 - acc: 0.9353 - val_loss: 0.4689 - val_acc: 0.9402

Epoch 00024: loss did not improve from 0.58307
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0426 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.6742 - acc: 0.9159 - val_loss: 0.4480 - val_acc: 0.9402

Epoch 00025: loss did not improve from 0.58307
Epoch 26/100

 32/464 [=>............................] - ETA: 0s - loss: 0.5830 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.5284 - acc: 0.9267 - val_loss: 0.4845 - val_acc: 0.9316

Epoch 00026: loss improved from 0.58307 to 0.52838, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 27/100

 32/464 [=>............................] - ETA: 0s - loss: 0.6616 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.6516 - acc: 0.9203 - val_loss: 0.5096 - val_acc: 0.9145

Epoch 00027: loss did not improve from 0.52838
Epoch 28/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9685 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 0.6384 - acc: 0.9052 - val_loss: 0.5149 - val_acc: 0.9060

Epoch 00028: loss did not improve from 0.52838
Epoch 29/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8081 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 0.5879 - acc: 0.9289 - val_loss: 0.4572 - val_acc: 0.9231

Epoch 00029: loss did not improve from 0.52838
Epoch 30/100

 32/464 [=>............................] - ETA: 0s - loss: 0.6459 - acc: 0.9062
464/464 [==============================] - 0s 31us/step - loss: 0.5241 - acc: 0.9353 - val_loss: 0.4649 - val_acc: 0.9231

Epoch 00030: loss improved from 0.52838 to 0.52406, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 31/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7170 - acc: 0.9062
464/464 [==============================] - 0s 31us/step - loss: 0.5211 - acc: 0.9353 - val_loss: 0.5084 - val_acc: 0.9316

Epoch 00031: loss improved from 0.52406 to 0.52108, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 32/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2676 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 0.5973 - acc: 0.9267 - val_loss: 0.4868 - val_acc: 0.9231

Epoch 00032: loss did not improve from 0.52108
Epoch 33/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8618 - acc: 0.8750
464/464 [==============================] - 0s 31us/step - loss: 0.4782 - acc: 0.9504 - val_loss: 0.4391 - val_acc: 0.9145

Epoch 00033: loss improved from 0.52108 to 0.47817, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_7.h5
Epoch 34/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7370 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 0.5374 - acc: 0.9267 - val_loss: 0.5170 - val_acc: 0.9060

Epoch 00034: loss did not improve from 0.47817
Epoch 35/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8240 - acc: 0.9062
464/464 [==============================] - 0s 31us/step - loss: 0.5350 - acc: 0.9332 - val_loss: 0.4383 - val_acc: 0.9231

Epoch 00035: loss did not improve from 0.47817
Epoch 36/100

 32/464 [=>............................] - ETA: 0s - loss: 0.3815 - acc: 0.9062
464/464 [==============================] - 0s 31us/step - loss: 0.4909 - acc: 0.9440 - val_loss: 0.4049 - val_acc: 0.9145

Epoch 00036: loss did not improve from 0.47817
Epoch 37/100

 32/464 [=>............................] - ETA: 0s - loss: 0.4590 - acc: 0.9062
464/464 [==============================] - 0s 31us/step - loss: 0.5885 - acc: 0.9224 - val_loss: 0.5542 - val_acc: 0.8974

Epoch 00037: loss did not improve from 0.47817
Epoch 38/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7975 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 0.5288 - acc: 0.9310 - val_loss: 0.4824 - val_acc: 0.9060
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:04<00:24,  2.20s/it]
Epoch 00038: loss did not improve from 0.47817
Epoch 00038: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.7948 - acc: 0.5312
464/464 [==============================] - 0s 577us/step - loss: 1.5485 - acc: 0.8168 - val_loss: 1.0429 - val_acc: 0.8803

Epoch 00001: loss improved from inf to 1.54853, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8405 - acc: 0.7812
464/464 [==============================] - 0s 32us/step - loss: 1.2416 - acc: 0.8879 - val_loss: 0.9396 - val_acc: 0.9060

Epoch 00002: loss improved from 1.54853 to 1.24158, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6965 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.1728 - acc: 0.8879 - val_loss: 0.9419 - val_acc: 0.8974

Epoch 00003: loss improved from 1.24158 to 1.17278, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4292 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 1.0513 - acc: 0.9009 - val_loss: 0.9407 - val_acc: 0.9060

Epoch 00004: loss improved from 1.17278 to 1.05132, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2441 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 0.9983 - acc: 0.9009 - val_loss: 0.8017 - val_acc: 0.9231

Epoch 00005: loss improved from 1.05132 to 0.99831, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1867 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.0941 - acc: 0.8772 - val_loss: 0.8113 - val_acc: 0.8803

Epoch 00006: loss did not improve from 0.99831
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1863 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.0204 - acc: 0.9116 - val_loss: 0.7944 - val_acc: 0.9060

Epoch 00007: loss did not improve from 0.99831
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3546 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.0384 - acc: 0.9009 - val_loss: 0.7503 - val_acc: 0.8803

Epoch 00008: loss did not improve from 0.99831
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4088 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 0.9997 - acc: 0.8815 - val_loss: 0.7361 - val_acc: 0.9060

Epoch 00009: loss did not improve from 0.99831
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4768 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9186 - acc: 0.9116 - val_loss: 0.6781 - val_acc: 0.9231

Epoch 00010: loss improved from 0.99831 to 0.91862, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1591 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.8516 - acc: 0.9181 - val_loss: 0.7176 - val_acc: 0.9060

Epoch 00011: loss improved from 0.91862 to 0.85160, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5597 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.8569 - acc: 0.9030 - val_loss: 0.6577 - val_acc: 0.9060

Epoch 00012: loss did not improve from 0.85160
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2175 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8622 - acc: 0.8987 - val_loss: 0.5910 - val_acc: 0.9231

Epoch 00013: loss did not improve from 0.85160
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8139 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.7479 - acc: 0.9095 - val_loss: 0.5588 - val_acc: 0.9231

Epoch 00014: loss improved from 0.85160 to 0.74788, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9054 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.7167 - acc: 0.9138 - val_loss: 0.5726 - val_acc: 0.9231

Epoch 00015: loss improved from 0.74788 to 0.71667, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0413 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.6763 - acc: 0.9332 - val_loss: 0.5718 - val_acc: 0.9145

Epoch 00016: loss improved from 0.71667 to 0.67627, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0867 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.7338 - acc: 0.9224 - val_loss: 0.6132 - val_acc: 0.9145

Epoch 00017: loss did not improve from 0.67627
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2052 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7940 - acc: 0.9116 - val_loss: 0.7361 - val_acc: 0.8974

Epoch 00018: loss did not improve from 0.67627
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3806 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.7782 - acc: 0.9095 - val_loss: 0.5616 - val_acc: 0.9060

Epoch 00019: loss did not improve from 0.67627
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8007 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.6057 - acc: 0.9310 - val_loss: 0.5596 - val_acc: 0.9060

Epoch 00020: loss improved from 0.67627 to 0.60567, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_8.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2316 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.6850 - acc: 0.9332 - val_loss: 0.4671 - val_acc: 0.9231

Epoch 00021: loss did not improve from 0.60567
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8295 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7193 - acc: 0.9073 - val_loss: 0.5727 - val_acc: 0.9145

Epoch 00022: loss did not improve from 0.60567
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2850 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.7086 - acc: 0.9095 - val_loss: 0.5083 - val_acc: 0.9316

Epoch 00023: loss did not improve from 0.60567
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7977 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.6515 - acc: 0.9418 - val_loss: 0.5326 - val_acc: 0.9145

Epoch 00024: loss did not improve from 0.60567
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1383 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.6824 - acc: 0.9116 - val_loss: 0.5802 - val_acc: 0.9316
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:06<00:20,  2.08s/it]
Epoch 00025: loss did not improve from 0.60567
Epoch 00025: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.8168 - acc: 0.5625
464/464 [==============================] - 0s 582us/step - loss: 1.5208 - acc: 0.8147 - val_loss: 1.0154 - val_acc: 0.9316

Epoch 00001: loss improved from inf to 1.52084, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5613 - acc: 0.7500
464/464 [==============================] - 0s 32us/step - loss: 1.2218 - acc: 0.8836 - val_loss: 1.0187 - val_acc: 0.9145

Epoch 00002: loss improved from 1.52084 to 1.22182, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8001 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.2717 - acc: 0.8836 - val_loss: 0.8951 - val_acc: 0.8974

Epoch 00003: loss did not improve from 1.22182
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5677 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.1475 - acc: 0.8901 - val_loss: 0.7825 - val_acc: 0.9145

Epoch 00004: loss improved from 1.22182 to 1.14751, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3476 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.0239 - acc: 0.9073 - val_loss: 0.8025 - val_acc: 0.9060

Epoch 00005: loss improved from 1.14751 to 1.02389, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5843 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.0721 - acc: 0.8966 - val_loss: 0.7810 - val_acc: 0.9231

Epoch 00006: loss did not improve from 1.02389
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1830 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9808 - acc: 0.8944 - val_loss: 0.6996 - val_acc: 0.9316

Epoch 00007: loss improved from 1.02389 to 0.98084, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3437 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.0699 - acc: 0.9073 - val_loss: 0.7631 - val_acc: 0.9145

Epoch 00008: loss did not improve from 0.98084
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4466 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9579 - acc: 0.9138 - val_loss: 0.7397 - val_acc: 0.8974

Epoch 00009: loss improved from 0.98084 to 0.95794, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9754 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9665 - acc: 0.8858 - val_loss: 0.7195 - val_acc: 0.9060

Epoch 00010: loss did not improve from 0.95794
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0546 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8967 - acc: 0.9073 - val_loss: 0.7142 - val_acc: 0.8974

Epoch 00011: loss improved from 0.95794 to 0.89666, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0170 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8333 - acc: 0.9181 - val_loss: 0.7212 - val_acc: 0.9060

Epoch 00012: loss improved from 0.89666 to 0.83332, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1226 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9148 - acc: 0.9095 - val_loss: 0.6984 - val_acc: 0.8803

Epoch 00013: loss did not improve from 0.83332
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1046 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8416 - acc: 0.8987 - val_loss: 0.7319 - val_acc: 0.8889

Epoch 00014: loss did not improve from 0.83332
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0491 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.8105 - acc: 0.9095 - val_loss: 0.6589 - val_acc: 0.8974

Epoch 00015: loss improved from 0.83332 to 0.81047, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0585 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7563 - acc: 0.9203 - val_loss: 0.5588 - val_acc: 0.9145

Epoch 00016: loss improved from 0.81047 to 0.75633, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7564 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 0.7478 - acc: 0.9224 - val_loss: 0.6434 - val_acc: 0.8803

Epoch 00017: loss improved from 0.75633 to 0.74776, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9879 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.7861 - acc: 0.8901 - val_loss: 0.6175 - val_acc: 0.9145

Epoch 00018: loss did not improve from 0.74776
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0169 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7071 - acc: 0.9138 - val_loss: 0.5395 - val_acc: 0.9145

Epoch 00019: loss improved from 0.74776 to 0.70711, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8566 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.6321 - acc: 0.9289 - val_loss: 0.5496 - val_acc: 0.9231

Epoch 00020: loss improved from 0.70711 to 0.63208, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8690 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.7231 - acc: 0.9224 - val_loss: 0.5684 - val_acc: 0.8974

Epoch 00021: loss did not improve from 0.63208
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8844 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.6725 - acc: 0.9073 - val_loss: 0.5652 - val_acc: 0.9316

Epoch 00022: loss did not improve from 0.63208
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1200 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.6899 - acc: 0.9116 - val_loss: 0.5817 - val_acc: 0.9145

Epoch 00023: loss did not improve from 0.63208
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2117 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.7312 - acc: 0.9073 - val_loss: 0.5575 - val_acc: 0.8889

Epoch 00024: loss did not improve from 0.63208
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7741 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.6036 - acc: 0.9310 - val_loss: 0.5208 - val_acc: 0.9145

Epoch 00025: loss improved from 0.63208 to 0.60364, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 26/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7242 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 0.5924 - acc: 0.9353 - val_loss: 0.4884 - val_acc: 0.9145

Epoch 00026: loss improved from 0.60364 to 0.59244, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 27/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8312 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.5443 - acc: 0.9332 - val_loss: 0.4508 - val_acc: 0.9145

Epoch 00027: loss improved from 0.59244 to 0.54427, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_9.h5
Epoch 28/100

 32/464 [=>............................] - ETA: 0s - loss: 0.6752 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.5712 - acc: 0.9289 - val_loss: 0.5429 - val_acc: 0.8889

Epoch 00028: loss did not improve from 0.54427
Epoch 29/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3856 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7084 - acc: 0.9116 - val_loss: 0.5925 - val_acc: 0.8889

Epoch 00029: loss did not improve from 0.54427
Epoch 30/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7954 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.7360 - acc: 0.8944 - val_loss: 0.5507 - val_acc: 0.8803

Epoch 00030: loss did not improve from 0.54427
Epoch 31/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1452 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.7026 - acc: 0.9073 - val_loss: 0.5782 - val_acc: 0.8889

Epoch 00031: loss did not improve from 0.54427
Epoch 32/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1045 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 0.5928 - acc: 0.9095 - val_loss: 0.4896 - val_acc: 0.9231
DeepAmes+ Weights:  31%|███       | 4/13 [00:08<00:18,  2.04s/it]
Epoch 00032: loss did not improve from 0.54427
Epoch 00032: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.7545 - acc: 0.5000
464/464 [==============================] - 0s 594us/step - loss: 1.7714 - acc: 0.8060 - val_loss: 1.1665 - val_acc: 0.8889

Epoch 00001: loss improved from inf to 1.77144, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 1.9808 - acc: 0.7500
464/464 [==============================] - 0s 32us/step - loss: 1.4199 - acc: 0.8815 - val_loss: 1.1146 - val_acc: 0.8632

Epoch 00002: loss improved from 1.77144 to 1.41990, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6406 - acc: 0.7188
464/464 [==============================] - 0s 32us/step - loss: 1.3231 - acc: 0.8836 - val_loss: 1.0716 - val_acc: 0.8632

Epoch 00003: loss improved from 1.41990 to 1.32309, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5499 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.2994 - acc: 0.8750 - val_loss: 0.9948 - val_acc: 0.8547

Epoch 00004: loss improved from 1.32309 to 1.29935, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4888 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.1640 - acc: 0.8879 - val_loss: 0.9427 - val_acc: 0.8889

Epoch 00005: loss improved from 1.29935 to 1.16400, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3223 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.1368 - acc: 0.8944 - val_loss: 0.8919 - val_acc: 0.8974

Epoch 00006: loss improved from 1.16400 to 1.13679, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3382 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.1438 - acc: 0.8901 - val_loss: 0.8618 - val_acc: 0.8974

Epoch 00007: loss did not improve from 1.13679
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2003 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.0772 - acc: 0.9009 - val_loss: 0.8440 - val_acc: 0.8974

Epoch 00008: loss improved from 1.13679 to 1.07715, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1511 - acc: 0.8438
464/464 [==============================] - 0s 31us/step - loss: 1.0762 - acc: 0.9052 - val_loss: 0.8185 - val_acc: 0.8889

Epoch 00009: loss improved from 1.07715 to 1.07618, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4646 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0305 - acc: 0.8772 - val_loss: 0.8533 - val_acc: 0.8974

Epoch 00010: loss improved from 1.07618 to 1.03049, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3851 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.0325 - acc: 0.8966 - val_loss: 0.7407 - val_acc: 0.9060

Epoch 00011: loss did not improve from 1.03049
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2355 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9445 - acc: 0.9030 - val_loss: 0.7406 - val_acc: 0.9060

Epoch 00012: loss improved from 1.03049 to 0.94450, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2971 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8928 - acc: 0.9138 - val_loss: 0.7115 - val_acc: 0.9060

Epoch 00013: loss improved from 0.94450 to 0.89284, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1088 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8263 - acc: 0.9181 - val_loss: 0.6855 - val_acc: 0.9145

Epoch 00014: loss improved from 0.89284 to 0.82625, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1106 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8749 - acc: 0.9224 - val_loss: 0.7022 - val_acc: 0.9060

Epoch 00015: loss did not improve from 0.82625
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9166 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 0.7761 - acc: 0.9246 - val_loss: 0.6953 - val_acc: 0.8974

Epoch 00016: loss improved from 0.82625 to 0.77610, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0447 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.7649 - acc: 0.9224 - val_loss: 0.7011 - val_acc: 0.9060

Epoch 00017: loss improved from 0.77610 to 0.76490, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3402 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7749 - acc: 0.9181 - val_loss: 0.6129 - val_acc: 0.9145

Epoch 00018: loss did not improve from 0.76490
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8585 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7080 - acc: 0.9353 - val_loss: 0.7289 - val_acc: 0.8889

Epoch 00019: loss improved from 0.76490 to 0.70804, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7362 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 0.6667 - acc: 0.9224 - val_loss: 0.6830 - val_acc: 0.8974

Epoch 00020: loss improved from 0.70804 to 0.66670, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_10.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8464 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8471 - acc: 0.9116 - val_loss: 0.6810 - val_acc: 0.8974

Epoch 00021: loss did not improve from 0.66670
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8575 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.6910 - acc: 0.9375 - val_loss: 0.5743 - val_acc: 0.9060

Epoch 00022: loss did not improve from 0.66670
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8085 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.8338 - acc: 0.9073 - val_loss: 0.6204 - val_acc: 0.8974

Epoch 00023: loss did not improve from 0.66670
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4119 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.8799 - acc: 0.9030 - val_loss: 0.7557 - val_acc: 0.8889

Epoch 00024: loss did not improve from 0.66670
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2248 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.7535 - acc: 0.9138 - val_loss: 0.6859 - val_acc: 0.8803
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:10<00:16,  2.04s/it]
Epoch 00025: loss did not improve from 0.66670
Epoch 00025: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.6011 - acc: 0.5938
464/464 [==============================] - 0s 576us/step - loss: 1.7464 - acc: 0.7909 - val_loss: 1.1457 - val_acc: 0.8205

Epoch 00001: loss improved from inf to 1.74645, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1170 - acc: 0.6875
464/464 [==============================] - 0s 32us/step - loss: 1.3916 - acc: 0.8405 - val_loss: 0.9608 - val_acc: 0.8632

Epoch 00002: loss improved from 1.74645 to 1.39159, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4649 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.1802 - acc: 0.8793 - val_loss: 0.9689 - val_acc: 0.8632

Epoch 00003: loss improved from 1.39159 to 1.18025, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4525 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.1765 - acc: 0.8793 - val_loss: 0.9598 - val_acc: 0.8547

Epoch 00004: loss improved from 1.18025 to 1.17647, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3177 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.0962 - acc: 0.8922 - val_loss: 0.9383 - val_acc: 0.8889

Epoch 00005: loss improved from 1.17647 to 1.09616, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4573 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.0079 - acc: 0.9095 - val_loss: 0.8764 - val_acc: 0.8718

Epoch 00006: loss improved from 1.09616 to 1.00790, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2841 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0220 - acc: 0.8858 - val_loss: 0.8126 - val_acc: 0.8889

Epoch 00007: loss did not improve from 1.00790
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2967 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.9324 - acc: 0.9095 - val_loss: 0.7527 - val_acc: 0.8803

Epoch 00008: loss improved from 1.00790 to 0.93238, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9432 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.9647 - acc: 0.9159 - val_loss: 0.7426 - val_acc: 0.9060

Epoch 00009: loss did not improve from 0.93238
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9165 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8493 - acc: 0.9310 - val_loss: 1.2217 - val_acc: 0.8803

Epoch 00010: loss improved from 0.93238 to 0.84927, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5312 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9388 - acc: 0.9159 - val_loss: 0.9600 - val_acc: 0.8974

Epoch 00011: loss did not improve from 0.84927
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4151 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 0.9830 - acc: 0.9073 - val_loss: 0.8448 - val_acc: 0.8889

Epoch 00012: loss did not improve from 0.84927
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0251 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.9549 - acc: 0.9030 - val_loss: 0.7756 - val_acc: 0.9145

Epoch 00013: loss did not improve from 0.84927
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2596 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9937 - acc: 0.9052 - val_loss: 0.6367 - val_acc: 0.9316

Epoch 00014: loss did not improve from 0.84927
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8949 - acc: 0.8750
464/464 [==============================] - 0s 29us/step - loss: 0.8350 - acc: 0.9181 - val_loss: 0.6692 - val_acc: 0.8974

Epoch 00015: loss improved from 0.84927 to 0.83495, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1103 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7812 - acc: 0.9203 - val_loss: 0.6676 - val_acc: 0.8974

Epoch 00016: loss improved from 0.83495 to 0.78116, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0320 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.9341 - acc: 0.8966 - val_loss: 0.7105 - val_acc: 0.9060

Epoch 00017: loss did not improve from 0.78116
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0508 - acc: 0.8125
464/464 [==============================] - 0s 29us/step - loss: 0.8798 - acc: 0.9095 - val_loss: 0.6827 - val_acc: 0.9060

Epoch 00018: loss did not improve from 0.78116
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9209 - acc: 0.8438
464/464 [==============================] - 0s 29us/step - loss: 0.8090 - acc: 0.9181 - val_loss: 0.6368 - val_acc: 0.8974

Epoch 00019: loss did not improve from 0.78116
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9314 - acc: 0.8438
464/464 [==============================] - 0s 29us/step - loss: 0.7431 - acc: 0.9224 - val_loss: 0.5917 - val_acc: 0.9145

Epoch 00020: loss improved from 0.78116 to 0.74315, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9197 - acc: 0.8438
464/464 [==============================] - 0s 29us/step - loss: 0.6926 - acc: 0.9267 - val_loss: 0.5757 - val_acc: 0.8974

Epoch 00021: loss improved from 0.74315 to 0.69259, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0756 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 0.8705 - acc: 0.9073 - val_loss: 0.6210 - val_acc: 0.9145

Epoch 00022: loss did not improve from 0.69259
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1204 - acc: 0.7812
464/464 [==============================] - 0s 29us/step - loss: 0.7918 - acc: 0.8966 - val_loss: 0.5213 - val_acc: 0.9316

Epoch 00023: loss did not improve from 0.69259
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9100 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.6720 - acc: 0.9375 - val_loss: 0.5527 - val_acc: 0.9231

Epoch 00024: loss improved from 0.69259 to 0.67201, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0906 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7406 - acc: 0.9224 - val_loss: 0.5185 - val_acc: 0.9316

Epoch 00025: loss did not improve from 0.67201
Epoch 26/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8547 - acc: 0.8750
464/464 [==============================] - 0s 29us/step - loss: 0.7366 - acc: 0.9375 - val_loss: 0.6126 - val_acc: 0.9231

Epoch 00026: loss did not improve from 0.67201
Epoch 27/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8422 - acc: 0.8750
464/464 [==============================] - 0s 29us/step - loss: 0.7328 - acc: 0.9267 - val_loss: 0.7073 - val_acc: 0.8974

Epoch 00027: loss did not improve from 0.67201
Epoch 28/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3481 - acc: 0.7812
464/464 [==============================] - 0s 29us/step - loss: 0.7556 - acc: 0.9181 - val_loss: 0.6060 - val_acc: 0.8974

Epoch 00028: loss did not improve from 0.67201
Epoch 29/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8076 - acc: 0.8438
464/464 [==============================] - 0s 29us/step - loss: 0.6306 - acc: 0.9310 - val_loss: 0.6746 - val_acc: 0.8803

Epoch 00029: loss improved from 0.67201 to 0.63059, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_11.h5
Epoch 30/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9255 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7917 - acc: 0.8966 - val_loss: 0.6818 - val_acc: 0.8803

Epoch 00030: loss did not improve from 0.63059
Epoch 31/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2033 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 0.7586 - acc: 0.9030 - val_loss: 0.5700 - val_acc: 0.8974

Epoch 00031: loss did not improve from 0.63059
Epoch 32/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9690 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.6847 - acc: 0.9052 - val_loss: 0.5461 - val_acc: 0.9145

Epoch 00032: loss did not improve from 0.63059
Epoch 33/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2532 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 0.7662 - acc: 0.9159 - val_loss: 0.5985 - val_acc: 0.8889

Epoch 00033: loss did not improve from 0.63059
Epoch 34/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2382 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.6883 - acc: 0.9073 - val_loss: 0.4860 - val_acc: 0.9060
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:12<00:14,  2.06s/it]
Epoch 00034: loss did not improve from 0.63059
Epoch 00034: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.8111 - acc: 0.5312
464/464 [==============================] - 0s 579us/step - loss: 1.5980 - acc: 0.7953 - val_loss: 1.0675 - val_acc: 0.8462

Epoch 00001: loss improved from inf to 1.59805, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8152 - acc: 0.6562
464/464 [==============================] - 0s 32us/step - loss: 1.3362 - acc: 0.8556 - val_loss: 1.0009 - val_acc: 0.8632

Epoch 00002: loss improved from 1.59805 to 1.33620, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8222 - acc: 0.6875
464/464 [==============================] - 0s 31us/step - loss: 1.3470 - acc: 0.8427 - val_loss: 1.0171 - val_acc: 0.8718

Epoch 00003: loss did not improve from 1.33620
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6987 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.1978 - acc: 0.8858 - val_loss: 0.9338 - val_acc: 0.9060

Epoch 00004: loss improved from 1.33620 to 1.19781, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3292 - acc: 0.8125
464/464 [==============================] - 0s 31us/step - loss: 1.1072 - acc: 0.8858 - val_loss: 0.8788 - val_acc: 0.9231

Epoch 00005: loss improved from 1.19781 to 1.10723, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5632 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 1.1330 - acc: 0.8879 - val_loss: 0.8728 - val_acc: 0.8974

Epoch 00006: loss did not improve from 1.10723
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4870 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.0538 - acc: 0.8879 - val_loss: 0.7934 - val_acc: 0.8718

Epoch 00007: loss improved from 1.10723 to 1.05383, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3486 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0159 - acc: 0.8836 - val_loss: 0.8192 - val_acc: 0.8632

Epoch 00008: loss improved from 1.05383 to 1.01586, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5757 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.0285 - acc: 0.8901 - val_loss: 0.7755 - val_acc: 0.8889

Epoch 00009: loss did not improve from 1.01586
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4011 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.8934 - acc: 0.9095 - val_loss: 0.6826 - val_acc: 0.9060

Epoch 00010: loss improved from 1.01586 to 0.89345, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0414 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.8893 - acc: 0.9116 - val_loss: 0.7312 - val_acc: 0.8889

Epoch 00011: loss improved from 0.89345 to 0.88933, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0676 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7798 - acc: 0.9267 - val_loss: 0.6160 - val_acc: 0.9316

Epoch 00012: loss improved from 0.88933 to 0.77982, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9964 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8508 - acc: 0.9073 - val_loss: 0.6751 - val_acc: 0.9060

Epoch 00013: loss did not improve from 0.77982
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1890 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.9091 - acc: 0.9095 - val_loss: 0.7297 - val_acc: 0.9145

Epoch 00014: loss did not improve from 0.77982
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3831 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9129 - acc: 0.9052 - val_loss: 0.6800 - val_acc: 0.9060

Epoch 00015: loss did not improve from 0.77982
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2840 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9533 - acc: 0.9052 - val_loss: 0.8670 - val_acc: 0.8974

Epoch 00016: loss did not improve from 0.77982
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.7356 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.0452 - acc: 0.8987 - val_loss: 0.7824 - val_acc: 0.8803
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:14<00:11,  1.94s/it]
Epoch 00017: loss did not improve from 0.77982
Epoch 00017: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.6320 - acc: 0.6250
464/464 [==============================] - 0s 591us/step - loss: 1.7403 - acc: 0.8147 - val_loss: 1.1776 - val_acc: 0.8291

Epoch 00001: loss improved from inf to 1.74027, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 1.9050 - acc: 0.7500
464/464 [==============================] - 0s 32us/step - loss: 1.4261 - acc: 0.8707 - val_loss: 1.1959 - val_acc: 0.8291

Epoch 00002: loss improved from 1.74027 to 1.42611, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 2.0371 - acc: 0.6875
464/464 [==============================] - 0s 31us/step - loss: 1.2977 - acc: 0.8556 - val_loss: 1.0554 - val_acc: 0.8718

Epoch 00003: loss improved from 1.42611 to 1.29770, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6012 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.3093 - acc: 0.8664 - val_loss: 1.0558 - val_acc: 0.8632

Epoch 00004: loss did not improve from 1.29770
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.9342 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.2998 - acc: 0.8685 - val_loss: 0.9924 - val_acc: 0.8718

Epoch 00005: loss did not improve from 1.29770
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5300 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.1217 - acc: 0.8772 - val_loss: 0.9062 - val_acc: 0.8889

Epoch 00006: loss improved from 1.29770 to 1.12173, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3092 - acc: 0.8438
464/464 [==============================] - 0s 31us/step - loss: 1.0784 - acc: 0.8944 - val_loss: 0.8846 - val_acc: 0.8632

Epoch 00007: loss improved from 1.12173 to 1.07844, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3047 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.1403 - acc: 0.8815 - val_loss: 1.0141 - val_acc: 0.8462

Epoch 00008: loss did not improve from 1.07844
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4191 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.0540 - acc: 0.8707 - val_loss: 0.8928 - val_acc: 0.8632

Epoch 00009: loss improved from 1.07844 to 1.05404, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4734 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0739 - acc: 0.8578 - val_loss: 0.7673 - val_acc: 0.8889

Epoch 00010: loss did not improve from 1.05404
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2204 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9850 - acc: 0.8858 - val_loss: 0.7012 - val_acc: 0.8974

Epoch 00011: loss improved from 1.05404 to 0.98501, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5300 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.9696 - acc: 0.8944 - val_loss: 0.6968 - val_acc: 0.8803

Epoch 00012: loss improved from 0.98501 to 0.96965, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0148 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8969 - acc: 0.8901 - val_loss: 0.7909 - val_acc: 0.8889

Epoch 00013: loss improved from 0.96965 to 0.89689, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3374 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9980 - acc: 0.8944 - val_loss: 0.7854 - val_acc: 0.8718

Epoch 00014: loss did not improve from 0.89689
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1676 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.9052 - acc: 0.8858 - val_loss: 0.7549 - val_acc: 0.8632

Epoch 00015: loss did not improve from 0.89689
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0474 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8501 - acc: 0.9052 - val_loss: 0.7438 - val_acc: 0.8632

Epoch 00016: loss improved from 0.89689 to 0.85010, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8956 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.0109 - acc: 0.8879 - val_loss: 0.7297 - val_acc: 0.8974

Epoch 00017: loss did not improve from 0.85010
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2760 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7990 - acc: 0.9181 - val_loss: 0.6385 - val_acc: 0.9060

Epoch 00018: loss improved from 0.85010 to 0.79901, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_13.h5
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1751 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.8276 - acc: 0.9310 - val_loss: 0.7270 - val_acc: 0.8718

Epoch 00019: loss did not improve from 0.79901
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8690 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.0336 - acc: 0.8987 - val_loss: 0.7877 - val_acc: 0.8632

Epoch 00020: loss did not improve from 0.79901
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4398 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 0.9190 - acc: 0.8987 - val_loss: 0.7529 - val_acc: 0.8718

Epoch 00021: loss did not improve from 0.79901
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3130 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8767 - acc: 0.9052 - val_loss: 0.6350 - val_acc: 0.9060

Epoch 00022: loss did not improve from 0.79901
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0203 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.8202 - acc: 0.9203 - val_loss: 0.8407 - val_acc: 0.8632
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:16<00:09,  1.94s/it]
Epoch 00023: loss did not improve from 0.79901
Epoch 00023: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.6826 - acc: 0.5625
464/464 [==============================] - 0s 599us/step - loss: 1.7336 - acc: 0.8060 - val_loss: 1.1769 - val_acc: 0.8547

Epoch 00001: loss improved from inf to 1.73364, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 2.2009 - acc: 0.7812
464/464 [==============================] - 0s 32us/step - loss: 1.4306 - acc: 0.8728 - val_loss: 1.1407 - val_acc: 0.8547

Epoch 00002: loss improved from 1.73364 to 1.43059, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.9394 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.3648 - acc: 0.8685 - val_loss: 1.1448 - val_acc: 0.8376

Epoch 00003: loss improved from 1.43059 to 1.36481, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.9213 - acc: 0.6875
464/464 [==============================] - 0s 31us/step - loss: 1.3569 - acc: 0.8621 - val_loss: 1.0440 - val_acc: 0.8547

Epoch 00004: loss improved from 1.36481 to 1.35691, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8477 - acc: 0.6875
464/464 [==============================] - 0s 31us/step - loss: 1.2755 - acc: 0.8642 - val_loss: 0.9712 - val_acc: 0.8632

Epoch 00005: loss improved from 1.35691 to 1.27550, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6649 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.1600 - acc: 0.8728 - val_loss: 0.8850 - val_acc: 0.8718

Epoch 00006: loss improved from 1.27550 to 1.15995, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4629 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.1455 - acc: 0.8815 - val_loss: 0.9003 - val_acc: 0.8803

Epoch 00007: loss improved from 1.15995 to 1.14555, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6641 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0656 - acc: 0.8858 - val_loss: 0.8138 - val_acc: 0.8803

Epoch 00008: loss improved from 1.14555 to 1.06564, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0106 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 1.0965 - acc: 0.8966 - val_loss: 0.9151 - val_acc: 0.8205

Epoch 00009: loss did not improve from 1.06564
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3892 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0398 - acc: 0.8815 - val_loss: 0.7733 - val_acc: 0.8718

Epoch 00010: loss improved from 1.06564 to 1.03979, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3638 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 0.9526 - acc: 0.8966 - val_loss: 0.7382 - val_acc: 0.8803

Epoch 00011: loss improved from 1.03979 to 0.95259, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4328 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0153 - acc: 0.8922 - val_loss: 0.6650 - val_acc: 0.8889

Epoch 00012: loss did not improve from 0.95259
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 0.7980 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.9459 - acc: 0.9030 - val_loss: 0.8115 - val_acc: 0.8803

Epoch 00013: loss improved from 0.95259 to 0.94589, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1971 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 0.9293 - acc: 0.8901 - val_loss: 0.7086 - val_acc: 0.8889

Epoch 00014: loss improved from 0.94589 to 0.92931, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4211 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.0018 - acc: 0.8836 - val_loss: 0.6505 - val_acc: 0.8974

Epoch 00015: loss did not improve from 0.92931
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3979 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.0526 - acc: 0.9052 - val_loss: 0.7099 - val_acc: 0.9060

Epoch 00016: loss did not improve from 0.92931
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2189 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.8464 - acc: 0.9181 - val_loss: 0.6790 - val_acc: 0.8803

Epoch 00017: loss improved from 0.92931 to 0.84638, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4239 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.2445 - acc: 0.8664 - val_loss: 0.8094 - val_acc: 0.8803

Epoch 00018: loss did not improve from 0.84638
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6464 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.9887 - acc: 0.8944 - val_loss: 0.6662 - val_acc: 0.8974

Epoch 00019: loss did not improve from 0.84638
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2076 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.8354 - acc: 0.9224 - val_loss: 0.6162 - val_acc: 0.8889

Epoch 00020: loss improved from 0.84638 to 0.83541, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8837 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.8835 - acc: 0.9073 - val_loss: 0.6506 - val_acc: 0.8803

Epoch 00021: loss did not improve from 0.83541
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4664 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.7918 - acc: 0.9095 - val_loss: 0.5867 - val_acc: 0.9060

Epoch 00022: loss improved from 0.83541 to 0.79177, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9650 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.7082 - acc: 0.9310 - val_loss: 0.4729 - val_acc: 0.9145

Epoch 00023: loss improved from 0.79177 to 0.70818, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1683 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.6799 - acc: 0.9095 - val_loss: 0.5593 - val_acc: 0.8889

Epoch 00024: loss improved from 0.70818 to 0.67988, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_14.h5
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 0.8947 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8743 - acc: 0.9052 - val_loss: 0.6185 - val_acc: 0.8889

Epoch 00025: loss did not improve from 0.67988
Epoch 26/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9706 - acc: 0.8750
464/464 [==============================] - 0s 30us/step - loss: 0.7473 - acc: 0.9246 - val_loss: 0.5732 - val_acc: 0.8974

Epoch 00026: loss did not improve from 0.67988
Epoch 27/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9038 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8069 - acc: 0.9052 - val_loss: 0.7458 - val_acc: 0.8974

Epoch 00027: loss did not improve from 0.67988
Epoch 28/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2335 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.8227 - acc: 0.8966 - val_loss: 0.6434 - val_acc: 0.8974

Epoch 00028: loss did not improve from 0.67988
Epoch 29/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9849 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.7941 - acc: 0.9095 - val_loss: 0.8027 - val_acc: 0.8718
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:18<00:07,  1.98s/it]
Epoch 00029: loss did not improve from 0.67988
Epoch 00029: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.7594 - acc: 0.5000
464/464 [==============================] - 0s 578us/step - loss: 1.8716 - acc: 0.7953 - val_loss: 1.3348 - val_acc: 0.8205

Epoch 00001: loss improved from inf to 1.87157, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1654 - acc: 0.6562
464/464 [==============================] - 0s 32us/step - loss: 1.5171 - acc: 0.8341 - val_loss: 1.1497 - val_acc: 0.8462

Epoch 00002: loss improved from 1.87157 to 1.51708, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 1.9494 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.4451 - acc: 0.8384 - val_loss: 1.2420 - val_acc: 0.8547

Epoch 00003: loss improved from 1.51708 to 1.44512, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1034 - acc: 0.6875
464/464 [==============================] - 0s 31us/step - loss: 1.3752 - acc: 0.8578 - val_loss: 1.0181 - val_acc: 0.8718

Epoch 00004: loss improved from 1.44512 to 1.37524, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6003 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 1.2421 - acc: 0.8578 - val_loss: 1.0135 - val_acc: 0.8718

Epoch 00005: loss improved from 1.37524 to 1.24207, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4935 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.2924 - acc: 0.8728 - val_loss: 0.9379 - val_acc: 0.8632

Epoch 00006: loss did not improve from 1.24207
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2496 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.1924 - acc: 0.8836 - val_loss: 0.9650 - val_acc: 0.8547

Epoch 00007: loss improved from 1.24207 to 1.19235, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6165 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.2015 - acc: 0.8750 - val_loss: 0.8541 - val_acc: 0.9145

Epoch 00008: loss did not improve from 1.19235
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3290 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.2558 - acc: 0.8901 - val_loss: 0.8938 - val_acc: 0.8547

Epoch 00009: loss did not improve from 1.19235
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8000 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.2545 - acc: 0.8879 - val_loss: 0.8754 - val_acc: 0.8376

Epoch 00010: loss did not improve from 1.19235
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8066 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 1.2103 - acc: 0.8642 - val_loss: 0.7980 - val_acc: 0.8889

Epoch 00011: loss did not improve from 1.19235
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6264 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.1024 - acc: 0.8772 - val_loss: 0.7477 - val_acc: 0.9060

Epoch 00012: loss improved from 1.19235 to 1.10241, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1305 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.9935 - acc: 0.9009 - val_loss: 0.7412 - val_acc: 0.8889

Epoch 00013: loss improved from 1.10241 to 0.99346, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.0434 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.0653 - acc: 0.8987 - val_loss: 0.7673 - val_acc: 0.8889

Epoch 00014: loss did not improve from 0.99346
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2965 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9221 - acc: 0.9009 - val_loss: 0.7060 - val_acc: 0.8889

Epoch 00015: loss improved from 0.99346 to 0.92205, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_15.h5
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2610 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9719 - acc: 0.9181 - val_loss: 0.7573 - val_acc: 0.8462

Epoch 00016: loss did not improve from 0.92205
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1397 - acc: 0.6250
464/464 [==============================] - 0s 30us/step - loss: 1.0682 - acc: 0.8621 - val_loss: 0.6980 - val_acc: 0.8889

Epoch 00017: loss did not improve from 0.92205
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5895 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.9842 - acc: 0.8664 - val_loss: 0.6854 - val_acc: 0.8974

Epoch 00018: loss did not improve from 0.92205
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.1653 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.9223 - acc: 0.9052 - val_loss: 0.6156 - val_acc: 0.8889

Epoch 00019: loss did not improve from 0.92205
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4199 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9615 - acc: 0.9009 - val_loss: 0.7013 - val_acc: 0.9145
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:19<00:05,  1.94s/it]
Epoch 00020: loss did not improve from 0.92205
Epoch 00020: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.7737 - acc: 0.5938
464/464 [==============================] - 0s 583us/step - loss: 1.7920 - acc: 0.7780 - val_loss: 1.2538 - val_acc: 0.8291

Epoch 00001: loss improved from inf to 1.79202, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1606 - acc: 0.6562
464/464 [==============================] - 0s 32us/step - loss: 1.5183 - acc: 0.8427 - val_loss: 1.2170 - val_acc: 0.7949

Epoch 00002: loss improved from 1.79202 to 1.51826, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1042 - acc: 0.6875
464/464 [==============================] - 0s 32us/step - loss: 1.3892 - acc: 0.8297 - val_loss: 1.0378 - val_acc: 0.8718

Epoch 00003: loss improved from 1.51826 to 1.38918, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.7664 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.3807 - acc: 0.8664 - val_loss: 1.0568 - val_acc: 0.8632

Epoch 00004: loss improved from 1.38918 to 1.38067, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 2.0559 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.3849 - acc: 0.8621 - val_loss: 0.9700 - val_acc: 0.8718

Epoch 00005: loss did not improve from 1.38067
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8181 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.3443 - acc: 0.8534 - val_loss: 0.9327 - val_acc: 0.8803

Epoch 00006: loss improved from 1.38067 to 1.34427, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.7754 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.1846 - acc: 0.8642 - val_loss: 0.8625 - val_acc: 0.8803

Epoch 00007: loss improved from 1.34427 to 1.18464, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3945 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.1172 - acc: 0.8879 - val_loss: 0.8603 - val_acc: 0.8803

Epoch 00008: loss improved from 1.18464 to 1.11716, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5447 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.0717 - acc: 0.8772 - val_loss: 0.7976 - val_acc: 0.9060

Epoch 00009: loss improved from 1.11716 to 1.07167, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 0.9186 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.1375 - acc: 0.8987 - val_loss: 0.7988 - val_acc: 0.8889

Epoch 00010: loss did not improve from 1.07167
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3669 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.0769 - acc: 0.8879 - val_loss: 0.7586 - val_acc: 0.8803

Epoch 00011: loss did not improve from 1.07167
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2134 - acc: 0.7812
464/464 [==============================] - 0s 32us/step - loss: 1.0125 - acc: 0.8642 - val_loss: 0.8557 - val_acc: 0.8547

Epoch 00012: loss improved from 1.07167 to 1.01250, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6017 - acc: 0.7500
464/464 [==============================] - 0s 32us/step - loss: 1.0398 - acc: 0.8685 - val_loss: 0.7640 - val_acc: 0.8974

Epoch 00013: loss did not improve from 1.01250
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2671 - acc: 0.8750
464/464 [==============================] - 0s 32us/step - loss: 1.0441 - acc: 0.8858 - val_loss: 0.7328 - val_acc: 0.8889

Epoch 00014: loss did not improve from 1.01250
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3304 - acc: 0.7500
464/464 [==============================] - 0s 32us/step - loss: 0.9628 - acc: 0.8707 - val_loss: 0.7733 - val_acc: 0.8803

Epoch 00015: loss improved from 1.01250 to 0.96277, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4332 - acc: 0.7812
464/464 [==============================] - 0s 32us/step - loss: 1.0807 - acc: 0.8664 - val_loss: 0.7695 - val_acc: 0.9060

Epoch 00016: loss did not improve from 0.96277
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2969 - acc: 0.7812
464/464 [==============================] - 0s 31us/step - loss: 0.9799 - acc: 0.9073 - val_loss: 0.8202 - val_acc: 0.8632

Epoch 00017: loss did not improve from 0.96277
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3794 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.1105 - acc: 0.8879 - val_loss: 0.8264 - val_acc: 0.8889

Epoch 00018: loss did not improve from 0.96277
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4158 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9629 - acc: 0.9009 - val_loss: 0.7456 - val_acc: 0.8803

Epoch 00019: loss did not improve from 0.96277
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2561 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.8310 - acc: 0.9073 - val_loss: 0.6497 - val_acc: 0.8974

Epoch 00020: loss improved from 0.96277 to 0.83102, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_16.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2728 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.1159 - acc: 0.8858 - val_loss: 0.8895 - val_acc: 0.8462

Epoch 00021: loss did not improve from 0.83102
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8526 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 1.0350 - acc: 0.8707 - val_loss: 0.6969 - val_acc: 0.8974

Epoch 00022: loss did not improve from 0.83102
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3836 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.1685 - acc: 0.8707 - val_loss: 0.6518 - val_acc: 0.8462

Epoch 00023: loss did not improve from 0.83102
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3449 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9479 - acc: 0.8836 - val_loss: 0.6450 - val_acc: 0.8718

Epoch 00024: loss did not improve from 0.83102
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6295 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.1148 - acc: 0.8772 - val_loss: 0.6951 - val_acc: 0.8803
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:21<00:03,  1.92s/it]
Epoch 00025: loss did not improve from 0.83102
Epoch 00025: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 1.6543 - acc: 0.5938
464/464 [==============================] - 0s 595us/step - loss: 2.1149 - acc: 0.7931 - val_loss: 1.3051 - val_acc: 0.8547

Epoch 00001: loss improved from inf to 2.11486, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 2.5436 - acc: 0.6875
464/464 [==============================] - 0s 32us/step - loss: 1.6133 - acc: 0.8491 - val_loss: 1.1624 - val_acc: 0.8547

Epoch 00002: loss improved from 2.11486 to 1.61328, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1111 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.4042 - acc: 0.8772 - val_loss: 1.0889 - val_acc: 0.8632

Epoch 00003: loss improved from 1.61328 to 1.40420, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8868 - acc: 0.7500
464/464 [==============================] - 0s 31us/step - loss: 1.4319 - acc: 0.8750 - val_loss: 1.2094 - val_acc: 0.8205

Epoch 00004: loss did not improve from 1.40420
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1655 - acc: 0.6250
464/464 [==============================] - 0s 31us/step - loss: 1.4254 - acc: 0.8103 - val_loss: 0.9834 - val_acc: 0.8547

Epoch 00005: loss did not improve from 1.40420
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4656 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.2176 - acc: 0.8728 - val_loss: 0.9790 - val_acc: 0.8547

Epoch 00006: loss improved from 1.40420 to 1.21759, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4647 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.2644 - acc: 0.8858 - val_loss: 1.0000 - val_acc: 0.8462

Epoch 00007: loss did not improve from 1.21759
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5951 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.1289 - acc: 0.8707 - val_loss: 0.9503 - val_acc: 0.8632

Epoch 00008: loss improved from 1.21759 to 1.12889, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3513 - acc: 0.8750
464/464 [==============================] - 0s 31us/step - loss: 1.1872 - acc: 0.8879 - val_loss: 0.9462 - val_acc: 0.8632

Epoch 00009: loss did not improve from 1.12889
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3895 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.0289 - acc: 0.9009 - val_loss: 0.9610 - val_acc: 0.8462

Epoch 00010: loss improved from 1.12889 to 1.02894, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5484 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0508 - acc: 0.8836 - val_loss: 0.9488 - val_acc: 0.8462

Epoch 00011: loss did not improve from 1.02894
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5372 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.2683 - acc: 0.8728 - val_loss: 0.9180 - val_acc: 0.8632

Epoch 00012: loss did not improve from 1.02894
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8324 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.0924 - acc: 0.8793 - val_loss: 0.7847 - val_acc: 0.8718

Epoch 00013: loss did not improve from 1.02894
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4796 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.0023 - acc: 0.8858 - val_loss: 0.7574 - val_acc: 0.8718

Epoch 00014: loss improved from 1.02894 to 1.00228, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3650 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.1511 - acc: 0.8858 - val_loss: 0.7696 - val_acc: 0.8889

Epoch 00015: loss did not improve from 1.00228
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3230 - acc: 0.9062
464/464 [==============================] - 0s 30us/step - loss: 1.0092 - acc: 0.9116 - val_loss: 0.7512 - val_acc: 0.8803

Epoch 00016: loss did not improve from 1.00228
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3194 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.9901 - acc: 0.9267 - val_loss: 0.8208 - val_acc: 0.8632

Epoch 00017: loss improved from 1.00228 to 0.99012, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4031 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 0.9798 - acc: 0.8815 - val_loss: 0.7720 - val_acc: 0.8547

Epoch 00018: loss improved from 0.99012 to 0.97984, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4426 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 0.9004 - acc: 0.8944 - val_loss: 0.6633 - val_acc: 0.8974

Epoch 00019: loss improved from 0.97984 to 0.90040, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 1.2209 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 0.8857 - acc: 0.9052 - val_loss: 1.1278 - val_acc: 0.8291

Epoch 00020: loss improved from 0.90040 to 0.88573, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_17.h5
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 2.2489 - acc: 0.6250
464/464 [==============================] - 0s 30us/step - loss: 1.0707 - acc: 0.8728 - val_loss: 0.8930 - val_acc: 0.8547

Epoch 00021: loss did not improve from 0.88573
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4224 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.0009 - acc: 0.8987 - val_loss: 1.3246 - val_acc: 0.7607

Epoch 00022: loss did not improve from 0.88573
Epoch 23/100

 32/464 [=>............................] - ETA: 0s - loss: 2.7497 - acc: 0.5312
464/464 [==============================] - 0s 30us/step - loss: 1.2640 - acc: 0.8470 - val_loss: 1.2470 - val_acc: 0.8034

Epoch 00023: loss did not improve from 0.88573
Epoch 24/100

 32/464 [=>............................] - ETA: 0s - loss: 2.5714 - acc: 0.6562
464/464 [==============================] - 0s 30us/step - loss: 1.1787 - acc: 0.8470 - val_loss: 0.8935 - val_acc: 0.8547

Epoch 00024: loss did not improve from 0.88573
Epoch 25/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3311 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9372 - acc: 0.8944 - val_loss: 1.0383 - val_acc: 0.7692
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:23<00:01,  1.94s/it]
Epoch 00025: loss did not improve from 0.88573
Epoch 00025: early stopping
Train on 464 samples, validate on 117 samples
Epoch 1/100

 32/464 [=>............................] - ETA: 3s - loss: 2.0185 - acc: 0.4688
464/464 [==============================] - 0s 570us/step - loss: 2.2820 - acc: 0.7888 - val_loss: 1.6153 - val_acc: 0.8376

Epoch 00001: loss improved from inf to 2.28205, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/464 [=>............................] - ETA: 0s - loss: 2.7963 - acc: 0.5938
464/464 [==============================] - 0s 32us/step - loss: 1.8244 - acc: 0.8470 - val_loss: 1.3724 - val_acc: 0.8120

Epoch 00002: loss improved from 2.28205 to 1.82439, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/464 [=>............................] - ETA: 0s - loss: 2.5303 - acc: 0.5938
464/464 [==============================] - 0s 31us/step - loss: 1.7078 - acc: 0.8211 - val_loss: 1.2720 - val_acc: 0.8462

Epoch 00003: loss improved from 1.82439 to 1.70783, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/464 [=>............................] - ETA: 0s - loss: 2.1642 - acc: 0.7188
464/464 [==============================] - 0s 31us/step - loss: 1.5559 - acc: 0.8405 - val_loss: 1.2130 - val_acc: 0.8632

Epoch 00004: loss improved from 1.70783 to 1.55594, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/464 [=>............................] - ETA: 0s - loss: 2.0429 - acc: 0.6875
464/464 [==============================] - 0s 31us/step - loss: 1.5562 - acc: 0.8297 - val_loss: 1.1174 - val_acc: 0.8632

Epoch 00005: loss did not improve from 1.55594
Epoch 6/100

 32/464 [=>............................] - ETA: 0s - loss: 1.7773 - acc: 0.6562
464/464 [==============================] - 0s 31us/step - loss: 1.4096 - acc: 0.8405 - val_loss: 1.1242 - val_acc: 0.8803

Epoch 00006: loss improved from 1.55594 to 1.40963, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6715 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.4498 - acc: 0.8750 - val_loss: 1.1319 - val_acc: 0.8632

Epoch 00007: loss did not improve from 1.40963
Epoch 8/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8674 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 1.3572 - acc: 0.8556 - val_loss: 1.0754 - val_acc: 0.8718

Epoch 00008: loss improved from 1.40963 to 1.35718, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5181 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.1949 - acc: 0.8793 - val_loss: 0.9863 - val_acc: 0.8974

Epoch 00009: loss improved from 1.35718 to 1.19493, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4946 - acc: 0.8125
464/464 [==============================] - 0s 30us/step - loss: 1.4088 - acc: 0.8858 - val_loss: 1.0937 - val_acc: 0.8547

Epoch 00010: loss did not improve from 1.19493
Epoch 11/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5492 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.1856 - acc: 0.8879 - val_loss: 1.0247 - val_acc: 0.8632

Epoch 00011: loss improved from 1.19493 to 1.18557, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

 32/464 [=>............................] - ETA: 0s - loss: 1.6600 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.1914 - acc: 0.8707 - val_loss: 1.2179 - val_acc: 0.8632

Epoch 00012: loss did not improve from 1.18557
Epoch 13/100

 32/464 [=>............................] - ETA: 0s - loss: 2.3188 - acc: 0.7500
464/464 [==============================] - 0s 30us/step - loss: 1.4025 - acc: 0.8642 - val_loss: 0.9780 - val_acc: 0.8462

Epoch 00013: loss did not improve from 1.18557
Epoch 14/100

 32/464 [=>............................] - ETA: 0s - loss: 1.7431 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 1.3301 - acc: 0.8621 - val_loss: 0.9360 - val_acc: 0.8462

Epoch 00014: loss did not improve from 1.18557
Epoch 15/100

 32/464 [=>............................] - ETA: 0s - loss: 1.5642 - acc: 0.7188
464/464 [==============================] - 0s 30us/step - loss: 1.0604 - acc: 0.8836 - val_loss: 0.9117 - val_acc: 0.8632

Epoch 00015: loss improved from 1.18557 to 1.06042, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4639 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.0648 - acc: 0.8858 - val_loss: 0.9959 - val_acc: 0.8632

Epoch 00016: loss did not improve from 1.06042
Epoch 17/100

 32/464 [=>............................] - ETA: 0s - loss: 1.3148 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 0.9375 - acc: 0.9116 - val_loss: 0.9199 - val_acc: 0.8803

Epoch 00017: loss improved from 1.06042 to 0.93754, saving model to ./results_TA1537_without_S9/DeepAmes_models/weight_18.h5
Epoch 18/100

 32/464 [=>............................] - ETA: 0s - loss: 1.4197 - acc: 0.8438
464/464 [==============================] - 0s 30us/step - loss: 1.1824 - acc: 0.8707 - val_loss: 1.0389 - val_acc: 0.8462

Epoch 00018: loss did not improve from 0.93754
Epoch 19/100

 32/464 [=>............................] - ETA: 0s - loss: 1.7489 - acc: 0.7812
464/464 [==============================] - 0s 30us/step - loss: 1.2767 - acc: 0.8621 - val_loss: 0.9619 - val_acc: 0.8376

Epoch 00019: loss did not improve from 0.93754
Epoch 20/100

 32/464 [=>............................] - ETA: 0s - loss: 1.8387 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 1.1317 - acc: 0.8664 - val_loss: 1.1130 - val_acc: 0.8205

Epoch 00020: loss did not improve from 0.93754
Epoch 21/100

 32/464 [=>............................] - ETA: 0s - loss: 2.0283 - acc: 0.6875
464/464 [==============================] - 0s 30us/step - loss: 1.1289 - acc: 0.8728 - val_loss: 1.4702 - val_acc: 0.8120

Epoch 00021: loss did not improve from 0.93754
Epoch 22/100

 32/464 [=>............................] - ETA: 0s - loss: 2.7653 - acc: 0.5938
464/464 [==============================] - 0s 30us/step - loss: 1.3413 - acc: 0.8405 - val_loss: 0.9027 - val_acc: 0.8803
DeepAmes+ Weights: 100%|██████████| 13/13 [00:25<00:00,  1.92s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:25<00:00,  1.98s/it]

Epoch 00022: loss did not improve from 0.93754
Epoch 00022: early stopping
--- 2947.4358928203583 seconds ---

Generating metrics report for TA1537_without_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 338 samples.
Processing weight 7...
  Done. 338 samples.
Processing weight 8...
  Done. 338 samples.
Processing weight 9...
  Done. 338 samples.
Processing weight 10...
  Done. 338 samples.
Processing weight 11...
  Done. 338 samples.
Processing weight 12...
  Done. 338 samples.
Processing weight 13...
  Done. 338 samples.
Processing weight 14...
  Done. 338 samples.
Processing weight 15...
  Done. 338 samples.
Processing weight 16...
  Done. 338 samples.
Processing weight 17...
  Done. 338 samples.
Processing weight 18...
  Done. 338 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA1537_without_S9/metrics_report_TA1537_without_S9.txt

Done!

Completed TA1537_without_S9 in 2947.44 seconds

================================================================================
[11/16] Processing: TA1538_with_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA1538_with_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA1538_with_S9_Test_mold2.csv
(1631, 777)
(1304, 777)
(178, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:04<01:25,  4.49s/it]KNN Seeds:  10%|█         | 2/20 [00:09<01:21,  4.55s/it]KNN Seeds:  15%|█▌        | 3/20 [00:13<01:17,  4.56s/it]KNN Seeds:  20%|██        | 4/20 [00:18<01:12,  4.55s/it]KNN Seeds:  25%|██▌       | 5/20 [00:22<01:08,  4.56s/it]KNN Seeds:  30%|███       | 6/20 [00:27<01:03,  4.55s/it]KNN Seeds:  35%|███▌      | 7/20 [00:31<00:59,  4.56s/it]KNN Seeds:  40%|████      | 8/20 [00:36<00:54,  4.55s/it]KNN Seeds:  45%|████▌     | 9/20 [00:41<00:50,  4.57s/it]KNN Seeds:  50%|█████     | 10/20 [00:45<00:45,  4.59s/it]KNN Seeds:  55%|█████▌    | 11/20 [00:50<00:41,  4.59s/it]KNN Seeds:  60%|██████    | 12/20 [00:54<00:36,  4.60s/it]KNN Seeds:  65%|██████▌   | 13/20 [00:59<00:32,  4.60s/it]KNN Seeds:  70%|███████   | 14/20 [01:04<00:27,  4.61s/it]KNN Seeds:  75%|███████▌  | 15/20 [01:08<00:23,  4.63s/it]KNN Seeds:  80%|████████  | 16/20 [01:13<00:18,  4.62s/it]KNN Seeds:  85%|████████▌ | 17/20 [01:18<00:13,  4.64s/it]KNN Seeds:  90%|█████████ | 18/20 [01:22<00:09,  4.65s/it]KNN Seeds:  95%|█████████▌| 19/20 [01:27<00:04,  4.67s/it]KNN Seeds: 100%|██████████| 20/20 [01:32<00:00,  4.68s/it]KNN Seeds: 100%|██████████| 20/20 [01:32<00:00,  4.61s/it]
24
(100, None, 'lbfgs')
(1631, 777)
(1304, 777)
(178, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:01<00:35,  1.85s/it]LR Seeds:  10%|█         | 2/20 [00:03<00:33,  1.85s/it]LR Seeds:  15%|█▌        | 3/20 [00:05<00:31,  1.86s/it]LR Seeds:  20%|██        | 4/20 [00:07<00:30,  1.88s/it]LR Seeds:  25%|██▌       | 5/20 [00:09<00:28,  1.89s/it]LR Seeds:  30%|███       | 6/20 [00:11<00:26,  1.90s/it]LR Seeds:  35%|███▌      | 7/20 [00:13<00:24,  1.91s/it]LR Seeds:  40%|████      | 8/20 [00:15<00:23,  1.92s/it]LR Seeds:  45%|████▌     | 9/20 [00:17<00:21,  1.93s/it]LR Seeds:  50%|█████     | 10/20 [00:19<00:19,  1.95s/it]LR Seeds:  55%|█████▌    | 11/20 [00:21<00:17,  1.97s/it]LR Seeds:  60%|██████    | 12/20 [00:23<00:15,  1.97s/it]LR Seeds:  65%|██████▌   | 13/20 [00:25<00:13,  1.98s/it]LR Seeds:  70%|███████   | 14/20 [00:27<00:11,  1.99s/it]LR Seeds:  75%|███████▌  | 15/20 [00:29<00:09,  2.00s/it]LR Seeds:  80%|████████  | 16/20 [00:31<00:08,  2.01s/it]LR Seeds:  85%|████████▌ | 17/20 [00:33<00:06,  2.02s/it]LR Seeds:  90%|█████████ | 18/20 [00:35<00:04,  2.07s/it]LR Seeds:  95%|█████████▌| 19/20 [00:37<00:02,  2.07s/it]LR Seeds: 100%|██████████| 20/20 [00:39<00:00,  2.07s/it]LR Seeds: 100%|██████████| 20/20 [00:39<00:00,  1.98s/it]
96
('rbf', 1, 1)
(1631, 777)
(1304, 777)
(178, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [00:26<08:18, 26.24s/it]SVM Seeds:  10%|█         | 2/20 [00:52<07:51, 26.21s/it]SVM Seeds:  15%|█▌        | 3/20 [01:18<07:25, 26.21s/it]SVM Seeds:  20%|██        | 4/20 [01:44<06:59, 26.22s/it]SVM Seeds:  25%|██▌       | 5/20 [02:11<06:33, 26.25s/it]SVM Seeds:  30%|███       | 6/20 [02:37<06:07, 26.26s/it]SVM Seeds:  35%|███▌      | 7/20 [03:03<05:41, 26.29s/it]SVM Seeds:  40%|████      | 8/20 [03:30<05:15, 26.29s/it]SVM Seeds:  45%|████▌     | 9/20 [03:56<04:49, 26.31s/it]SVM Seeds:  50%|█████     | 10/20 [04:22<04:23, 26.30s/it]SVM Seeds:  55%|█████▌    | 11/20 [04:49<03:56, 26.30s/it]SVM Seeds:  60%|██████    | 12/20 [05:15<03:30, 26.32s/it]SVM Seeds:  65%|██████▌   | 13/20 [05:41<03:04, 26.33s/it]SVM Seeds:  70%|███████   | 14/20 [06:08<02:38, 26.33s/it]SVM Seeds:  75%|███████▌  | 15/20 [06:34<02:11, 26.34s/it]SVM Seeds:  80%|████████  | 16/20 [07:00<01:45, 26.36s/it]SVM Seeds:  85%|████████▌ | 17/20 [07:27<01:19, 26.38s/it]SVM Seeds:  90%|█████████ | 18/20 [07:53<00:52, 26.39s/it]SVM Seeds:  95%|█████████▌| 19/20 [08:20<00:26, 26.40s/it]SVM Seeds: 100%|██████████| 20/20 [08:46<00:00, 26.41s/it]SVM Seeds: 100%|██████████| 20/20 [08:46<00:00, 26.33s/it]
200
(500, None, 70, 1, 'balanced')
(1631, 777)
(1304, 777)
(178, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:04<01:23,  4.41s/it]RF Seeds:  10%|█         | 2/20 [00:08<01:19,  4.42s/it]RF Seeds:  15%|█▌        | 3/20 [00:13<01:15,  4.43s/it]RF Seeds:  20%|██        | 4/20 [00:17<01:11,  4.44s/it]RF Seeds:  25%|██▌       | 5/20 [00:22<01:06,  4.45s/it]RF Seeds:  30%|███       | 6/20 [00:26<01:02,  4.46s/it]RF Seeds:  35%|███▌      | 7/20 [00:31<00:58,  4.47s/it]RF Seeds:  40%|████      | 8/20 [00:35<00:53,  4.48s/it]RF Seeds:  45%|████▌     | 9/20 [00:40<00:49,  4.51s/it]RF Seeds:  50%|█████     | 10/20 [00:44<00:45,  4.52s/it]RF Seeds:  55%|█████▌    | 11/20 [00:49<00:40,  4.52s/it]RF Seeds:  60%|██████    | 12/20 [00:53<00:36,  4.53s/it]RF Seeds:  65%|██████▌   | 13/20 [00:58<00:31,  4.53s/it]RF Seeds:  70%|███████   | 14/20 [01:02<00:27,  4.54s/it]RF Seeds:  75%|███████▌  | 15/20 [01:07<00:22,  4.55s/it]RF Seeds:  80%|████████  | 16/20 [01:12<00:18,  4.57s/it]RF Seeds:  85%|████████▌ | 17/20 [01:16<00:13,  4.59s/it]RF Seeds:  90%|█████████ | 18/20 [01:21<00:09,  4.60s/it]RF Seeds:  95%|█████████▌| 19/20 [01:26<00:04,  4.61s/it]RF Seeds: 100%|██████████| 20/20 [01:30<00:00,  4.61s/it]RF Seeds: 100%|██████████| 20/20 [01:30<00:00,  4.53s/it]
400
(0.01, 900, 7, 0.8, 6)
(1631, 777)
(1304, 777)
(178, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:32<10:17, 32.52s/it]XGBoost Seeds:  10%|█         | 2/20 [01:05<09:45, 32.51s/it]XGBoost Seeds:  15%|█▌        | 3/20 [01:37<09:14, 32.59s/it]XGBoost Seeds:  20%|██        | 4/20 [02:09<08:38, 32.43s/it]XGBoost Seeds:  25%|██▌       | 5/20 [02:41<08:04, 32.28s/it]XGBoost Seeds:  30%|███       | 6/20 [03:13<07:29, 32.11s/it]XGBoost Seeds:  35%|███▌      | 7/20 [03:45<06:54, 31.91s/it]XGBoost Seeds:  40%|████      | 8/20 [04:16<06:21, 31.82s/it]XGBoost Seeds:  45%|████▌     | 9/20 [04:48<05:49, 31.74s/it]XGBoost Seeds:  50%|█████     | 10/20 [05:19<05:16, 31.69s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [05:51<04:44, 31.65s/it]XGBoost Seeds:  60%|██████    | 12/20 [06:23<04:13, 31.63s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [06:54<03:41, 31.64s/it]XGBoost Seeds:  70%|███████   | 14/20 [07:26<03:09, 31.65s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [07:58<02:38, 31.64s/it]XGBoost Seeds:  80%|████████  | 16/20 [08:29<02:06, 31.65s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [09:01<01:34, 31.62s/it]XGBoost Seeds:  90%|█████████ | 18/20 [09:32<01:03, 31.62s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [10:04<00:31, 31.63s/it]XGBoost Seeds: 100%|██████████| 20/20 [10:36<00:00, 31.62s/it]XGBoost Seeds: 100%|██████████| 20/20 [10:36<00:00, 31.81s/it]
knn:  99
lr:  89
svm:  85
rf:  98
xgboost:  74
Combining validation predictions is completed
knn:  99
lr:  89
svm:  85
rf:  98
xgboost:  74
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.2858 - acc: 0.6875
261/261 [==============================] - 0s 1ms/step - loss: 1.4027 - acc: 0.8008 - val_loss: 1.1696 - val_acc: 0.8485

Epoch 00001: loss improved from inf to 1.40272, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2243 - acc: 0.8750
261/261 [==============================] - 0s 37us/step - loss: 1.2747 - acc: 0.8659 - val_loss: 1.1027 - val_acc: 0.8636

Epoch 00002: loss improved from 1.40272 to 1.27471, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1982 - acc: 0.9062
261/261 [==============================] - 0s 35us/step - loss: 1.1595 - acc: 0.9042 - val_loss: 1.0329 - val_acc: 0.8788

Epoch 00003: loss improved from 1.27471 to 1.15948, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9135 - acc: 0.9375
261/261 [==============================] - 0s 36us/step - loss: 1.0693 - acc: 0.8889 - val_loss: 1.0510 - val_acc: 0.8636

Epoch 00004: loss improved from 1.15948 to 1.06931, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9274 - acc: 0.9375
261/261 [==============================] - 0s 35us/step - loss: 1.0275 - acc: 0.8851 - val_loss: 1.0013 - val_acc: 0.8636

Epoch 00005: loss improved from 1.06931 to 1.02754, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9106 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.0339 - acc: 0.8851 - val_loss: 0.9772 - val_acc: 0.8636

Epoch 00006: loss did not improve from 1.02754
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8787 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.9563 - acc: 0.9080 - val_loss: 1.0142 - val_acc: 0.8636

Epoch 00007: loss improved from 1.02754 to 0.95629, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8066 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.9014 - acc: 0.9157 - val_loss: 0.9744 - val_acc: 0.8788

Epoch 00008: loss improved from 0.95629 to 0.90139, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7102 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8852 - acc: 0.9119 - val_loss: 1.0511 - val_acc: 0.8636

Epoch 00009: loss improved from 0.90139 to 0.88522, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7215 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8409 - acc: 0.9195 - val_loss: 1.0661 - val_acc: 0.8485

Epoch 00010: loss improved from 0.88522 to 0.84089, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6999 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.7707 - acc: 0.9310 - val_loss: 0.9639 - val_acc: 0.8939

Epoch 00011: loss improved from 0.84089 to 0.77071, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7242 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.8385 - acc: 0.9157 - val_loss: 0.9249 - val_acc: 0.8939

Epoch 00012: loss did not improve from 0.77071
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5887 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7056 - acc: 0.9502 - val_loss: 0.9328 - val_acc: 0.8788

Epoch 00013: loss improved from 0.77071 to 0.70557, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7047 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.7652 - acc: 0.9349 - val_loss: 1.0140 - val_acc: 0.8788

Epoch 00014: loss did not improve from 0.70557
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5731 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7038 - acc: 0.9425 - val_loss: 0.9524 - val_acc: 0.8939

Epoch 00015: loss improved from 0.70557 to 0.70375, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6119 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.8085 - acc: 0.9195 - val_loss: 0.9227 - val_acc: 0.8788

Epoch 00016: loss did not improve from 0.70375
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5814 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7201 - acc: 0.9349 - val_loss: 0.9428 - val_acc: 0.8788

Epoch 00017: loss did not improve from 0.70375
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4904 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7278 - acc: 0.9387 - val_loss: 0.9529 - val_acc: 0.8636

Epoch 00018: loss did not improve from 0.70375
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5774 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6520 - acc: 0.9272 - val_loss: 0.8724 - val_acc: 0.8636

Epoch 00019: loss improved from 0.70375 to 0.65201, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5591 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.6059 - acc: 0.9425 - val_loss: 0.9162 - val_acc: 0.8636

Epoch 00020: loss improved from 0.65201 to 0.60593, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5593 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.6751 - acc: 0.9310 - val_loss: 0.9736 - val_acc: 0.8636

Epoch 00021: loss did not improve from 0.60593
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6134 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.6808 - acc: 0.9349 - val_loss: 0.9559 - val_acc: 0.8788

Epoch 00022: loss did not improve from 0.60593
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7120 - acc: 1.0000
261/261 [==============================] - 0s 32us/step - loss: 0.7471 - acc: 0.9234 - val_loss: 0.9518 - val_acc: 0.8636

Epoch 00023: loss did not improve from 0.60593
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4086 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6003 - acc: 0.9195 - val_loss: 0.8300 - val_acc: 0.8485

Epoch 00024: loss improved from 0.60593 to 0.60027, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4552 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.5136 - acc: 0.9579 - val_loss: 0.8596 - val_acc: 0.8636

Epoch 00025: loss improved from 0.60027 to 0.51365, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_6.h5
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4065 - acc: 1.0000
261/261 [==============================] - 0s 33us/step - loss: 0.5524 - acc: 0.9617 - val_loss: 1.1117 - val_acc: 0.8788

Epoch 00026: loss did not improve from 0.51365
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.3617 - acc: 1.0000
261/261 [==============================] - 0s 32us/step - loss: 0.5527 - acc: 0.9579 - val_loss: 0.9481 - val_acc: 0.8788

Epoch 00027: loss did not improve from 0.51365
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4661 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6087 - acc: 0.9502 - val_loss: 1.0057 - val_acc: 0.9091

Epoch 00028: loss did not improve from 0.51365
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4814 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.7289 - acc: 0.9195 - val_loss: 0.9374 - val_acc: 0.8939

Epoch 00029: loss did not improve from 0.51365
Epoch 30/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4308 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.5497 - acc: 0.9464 - val_loss: 0.9910 - val_acc: 0.8939
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:21,  1.77s/it]
Epoch 00030: loss did not improve from 0.51365
Epoch 00030: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.5848 - acc: 0.7188
261/261 [==============================] - 0s 1ms/step - loss: 1.6114 - acc: 0.8199 - val_loss: 1.2240 - val_acc: 0.8333

Epoch 00001: loss improved from inf to 1.61138, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9513 - acc: 0.9375
261/261 [==============================] - 0s 36us/step - loss: 1.3322 - acc: 0.8352 - val_loss: 1.1652 - val_acc: 0.8333

Epoch 00002: loss improved from 1.61138 to 1.33222, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9072 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.2105 - acc: 0.8506 - val_loss: 1.1192 - val_acc: 0.8485

Epoch 00003: loss improved from 1.33222 to 1.21054, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0779 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.1164 - acc: 0.8927 - val_loss: 1.0837 - val_acc: 0.8333

Epoch 00004: loss improved from 1.21054 to 1.11641, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9769 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0711 - acc: 0.8966 - val_loss: 1.1976 - val_acc: 0.8788

Epoch 00005: loss improved from 1.11641 to 1.07112, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8446 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0783 - acc: 0.9004 - val_loss: 1.0901 - val_acc: 0.8636

Epoch 00006: loss did not improve from 1.07112
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8298 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.0239 - acc: 0.8927 - val_loss: 1.0389 - val_acc: 0.8485

Epoch 00007: loss improved from 1.07112 to 1.02391, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8056 - acc: 0.9375
261/261 [==============================] - 0s 35us/step - loss: 0.9326 - acc: 0.9119 - val_loss: 1.0222 - val_acc: 0.8788

Epoch 00008: loss improved from 1.02391 to 0.93258, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7610 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.8605 - acc: 0.9387 - val_loss: 1.0457 - val_acc: 0.8788

Epoch 00009: loss improved from 0.93258 to 0.86050, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7057 - acc: 0.9688
261/261 [==============================] - 0s 34us/step - loss: 0.9036 - acc: 0.9042 - val_loss: 1.1284 - val_acc: 0.8636

Epoch 00010: loss did not improve from 0.86050
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7373 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 0.8915 - acc: 0.8889 - val_loss: 1.0499 - val_acc: 0.8939

Epoch 00011: loss did not improve from 0.86050
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6428 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8369 - acc: 0.9310 - val_loss: 1.0271 - val_acc: 0.8788

Epoch 00012: loss improved from 0.86050 to 0.83689, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7158 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8025 - acc: 0.9349 - val_loss: 1.0156 - val_acc: 0.8788

Epoch 00013: loss improved from 0.83689 to 0.80247, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6726 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.8206 - acc: 0.9195 - val_loss: 1.1060 - val_acc: 0.8485

Epoch 00014: loss did not improve from 0.80247
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7035 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.7412 - acc: 0.9234 - val_loss: 1.0063 - val_acc: 0.8939

Epoch 00015: loss improved from 0.80247 to 0.74121, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6322 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8124 - acc: 0.9042 - val_loss: 0.9642 - val_acc: 0.8485

Epoch 00016: loss did not improve from 0.74121
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6036 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8414 - acc: 0.9234 - val_loss: 1.1075 - val_acc: 0.8788

Epoch 00017: loss did not improve from 0.74121
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4952 - acc: 1.0000
261/261 [==============================] - 0s 32us/step - loss: 0.7171 - acc: 0.9540 - val_loss: 0.9971 - val_acc: 0.8788

Epoch 00018: loss improved from 0.74121 to 0.71707, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5284 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6662 - acc: 0.9272 - val_loss: 0.9049 - val_acc: 0.8636

Epoch 00019: loss improved from 0.71707 to 0.66625, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0570 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 0.7486 - acc: 0.9234 - val_loss: 0.8895 - val_acc: 0.8636

Epoch 00020: loss did not improve from 0.66625
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5279 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8166 - acc: 0.9004 - val_loss: 1.0063 - val_acc: 0.8636

Epoch 00021: loss did not improve from 0.66625
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4474 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6483 - acc: 0.9272 - val_loss: 0.9762 - val_acc: 0.8788

Epoch 00022: loss improved from 0.66625 to 0.64833, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5154 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.6593 - acc: 0.9387 - val_loss: 0.8920 - val_acc: 0.8485

Epoch 00023: loss did not improve from 0.64833
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5886 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6955 - acc: 0.9425 - val_loss: 1.0673 - val_acc: 0.8788

Epoch 00024: loss did not improve from 0.64833
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5026 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.5709 - acc: 0.9349 - val_loss: 1.0167 - val_acc: 0.8636

Epoch 00025: loss improved from 0.64833 to 0.57095, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_7.h5
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4165 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.6368 - acc: 0.9387 - val_loss: 1.0320 - val_acc: 0.8788

Epoch 00026: loss did not improve from 0.57095
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5266 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.5736 - acc: 0.9579 - val_loss: 1.1099 - val_acc: 0.8788

Epoch 00027: loss did not improve from 0.57095
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6007 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.7024 - acc: 0.9234 - val_loss: 0.9127 - val_acc: 0.8788

Epoch 00028: loss did not improve from 0.57095
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5533 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6348 - acc: 0.9387 - val_loss: 0.6900 - val_acc: 0.8788

Epoch 00029: loss did not improve from 0.57095
Epoch 30/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5883 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.6836 - acc: 0.9310 - val_loss: 0.7727 - val_acc: 0.8333
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:03<00:20,  1.82s/it]
Epoch 00030: loss did not improve from 0.57095
Epoch 00030: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.2819 - acc: 0.8125
261/261 [==============================] - 0s 1ms/step - loss: 1.4779 - acc: 0.8084 - val_loss: 1.2353 - val_acc: 0.8485

Epoch 00001: loss improved from inf to 1.47794, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1282 - acc: 0.9062
261/261 [==============================] - 0s 35us/step - loss: 1.3675 - acc: 0.8391 - val_loss: 1.1752 - val_acc: 0.8182

Epoch 00002: loss improved from 1.47794 to 1.36750, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9467 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.2124 - acc: 0.8659 - val_loss: 1.2089 - val_acc: 0.8333

Epoch 00003: loss improved from 1.36750 to 1.21244, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9693 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.1199 - acc: 0.8851 - val_loss: 1.1537 - val_acc: 0.8333

Epoch 00004: loss improved from 1.21244 to 1.11994, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9747 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.0976 - acc: 0.8774 - val_loss: 1.6151 - val_acc: 0.8788

Epoch 00005: loss improved from 1.11994 to 1.09759, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0130 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.2848 - acc: 0.8582 - val_loss: 1.1812 - val_acc: 0.7727

Epoch 00006: loss did not improve from 1.09759
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9027 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.0487 - acc: 0.9272 - val_loss: 1.1253 - val_acc: 0.8182

Epoch 00007: loss improved from 1.09759 to 1.04867, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0729 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.1000 - acc: 0.8851 - val_loss: 1.0541 - val_acc: 0.8485

Epoch 00008: loss did not improve from 1.04867
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8195 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 0.9221 - acc: 0.9234 - val_loss: 1.0355 - val_acc: 0.8485

Epoch 00009: loss improved from 1.04867 to 0.92212, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7611 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9858 - acc: 0.9195 - val_loss: 1.4246 - val_acc: 0.8939

Epoch 00010: loss did not improve from 0.92212
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9201 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.1088 - acc: 0.9119 - val_loss: 1.0889 - val_acc: 0.8333

Epoch 00011: loss did not improve from 0.92212
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0206 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0166 - acc: 0.9195 - val_loss: 0.9576 - val_acc: 0.8485

Epoch 00012: loss did not improve from 0.92212
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7990 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9132 - acc: 0.9234 - val_loss: 1.3238 - val_acc: 0.8333

Epoch 00013: loss improved from 0.92212 to 0.91323, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8268 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 0.9420 - acc: 0.9195 - val_loss: 1.1106 - val_acc: 0.8333

Epoch 00014: loss did not improve from 0.91323
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8884 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9924 - acc: 0.9157 - val_loss: 1.0846 - val_acc: 0.8939

Epoch 00015: loss did not improve from 0.91323
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7219 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9820 - acc: 0.9080 - val_loss: 0.8884 - val_acc: 0.8939

Epoch 00016: loss did not improve from 0.91323
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6873 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8472 - acc: 0.9195 - val_loss: 0.8773 - val_acc: 0.8788

Epoch 00017: loss improved from 0.91323 to 0.84715, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6737 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9422 - acc: 0.8966 - val_loss: 1.0944 - val_acc: 0.8485

Epoch 00018: loss did not improve from 0.84715
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9391 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8851 - acc: 0.9042 - val_loss: 1.0376 - val_acc: 0.8636

Epoch 00019: loss did not improve from 0.84715
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6285 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8172 - acc: 0.9042 - val_loss: 1.0093 - val_acc: 0.8485

Epoch 00020: loss improved from 0.84715 to 0.81720, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6902 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.8490 - acc: 0.9272 - val_loss: 1.3059 - val_acc: 0.9091

Epoch 00021: loss did not improve from 0.81720
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6346 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8614 - acc: 0.9080 - val_loss: 0.9589 - val_acc: 0.8636

Epoch 00022: loss did not improve from 0.81720
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6416 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.7939 - acc: 0.9234 - val_loss: 0.9848 - val_acc: 0.8485

Epoch 00023: loss improved from 0.81720 to 0.79391, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5530 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.7998 - acc: 0.9195 - val_loss: 1.0037 - val_acc: 0.8636

Epoch 00024: loss did not improve from 0.79391
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6932 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6797 - acc: 0.9425 - val_loss: 0.9373 - val_acc: 0.8636

Epoch 00025: loss improved from 0.79391 to 0.67967, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_8.h5
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5353 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6834 - acc: 0.9349 - val_loss: 0.9355 - val_acc: 0.8485

Epoch 00026: loss did not improve from 0.67967
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5558 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8870 - acc: 0.9042 - val_loss: 0.7509 - val_acc: 0.8636

Epoch 00027: loss did not improve from 0.67967
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6616 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7050 - acc: 0.9387 - val_loss: 0.9770 - val_acc: 0.8788

Epoch 00028: loss did not improve from 0.67967
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5238 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8293 - acc: 0.9272 - val_loss: 1.1426 - val_acc: 0.8939

Epoch 00029: loss did not improve from 0.67967
Epoch 30/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6734 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0626 - acc: 0.9042 - val_loss: 1.0157 - val_acc: 0.8939
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:05<00:18,  1.82s/it]
Epoch 00030: loss did not improve from 0.67967
Epoch 00030: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.3083 - acc: 0.7812
261/261 [==============================] - 0s 1ms/step - loss: 1.7449 - acc: 0.8046 - val_loss: 1.2351 - val_acc: 0.8333

Epoch 00001: loss improved from inf to 1.74495, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0736 - acc: 0.9062
261/261 [==============================] - 0s 36us/step - loss: 1.3171 - acc: 0.8506 - val_loss: 1.1178 - val_acc: 0.8788

Epoch 00002: loss improved from 1.74495 to 1.31711, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0170 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.3008 - acc: 0.8774 - val_loss: 1.1258 - val_acc: 0.8485

Epoch 00003: loss improved from 1.31711 to 1.30084, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9324 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.2168 - acc: 0.8621 - val_loss: 1.0418 - val_acc: 0.8939

Epoch 00004: loss improved from 1.30084 to 1.21678, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8516 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.1635 - acc: 0.8659 - val_loss: 1.0440 - val_acc: 0.8788

Epoch 00005: loss improved from 1.21678 to 1.16351, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8377 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.1849 - acc: 0.8736 - val_loss: 1.0265 - val_acc: 0.8485

Epoch 00006: loss did not improve from 1.16351
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9614 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.0386 - acc: 0.9042 - val_loss: 0.9821 - val_acc: 0.8636

Epoch 00007: loss improved from 1.16351 to 1.03862, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9449 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.0950 - acc: 0.8659 - val_loss: 1.0106 - val_acc: 0.8485

Epoch 00008: loss did not improve from 1.03862
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8864 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0009 - acc: 0.8927 - val_loss: 1.0284 - val_acc: 0.8788

Epoch 00009: loss improved from 1.03862 to 1.00088, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7683 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.9702 - acc: 0.9119 - val_loss: 1.0890 - val_acc: 0.8485

Epoch 00010: loss improved from 1.00088 to 0.97018, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0819 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.1106 - acc: 0.8736 - val_loss: 1.0260 - val_acc: 0.8030

Epoch 00011: loss did not improve from 0.97018
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0172 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.0426 - acc: 0.8774 - val_loss: 1.0985 - val_acc: 0.8485

Epoch 00012: loss did not improve from 0.97018
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7826 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0639 - acc: 0.8812 - val_loss: 0.9776 - val_acc: 0.8333

Epoch 00013: loss did not improve from 0.97018
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9933 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.0381 - acc: 0.8736 - val_loss: 0.9847 - val_acc: 0.8485

Epoch 00014: loss did not improve from 0.97018
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7230 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.8650 - acc: 0.8927 - val_loss: 1.1323 - val_acc: 0.8939

Epoch 00015: loss improved from 0.97018 to 0.86499, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8030 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0227 - acc: 0.8851 - val_loss: 1.0104 - val_acc: 0.8333

Epoch 00016: loss did not improve from 0.86499
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0648 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9102 - acc: 0.9004 - val_loss: 1.0455 - val_acc: 0.8636

Epoch 00017: loss did not improve from 0.86499
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7035 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.7543 - acc: 0.9349 - val_loss: 0.9967 - val_acc: 0.8636

Epoch 00018: loss improved from 0.86499 to 0.75433, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6654 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.7842 - acc: 0.9387 - val_loss: 1.3064 - val_acc: 0.8485

Epoch 00019: loss did not improve from 0.75433
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6895 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9483 - acc: 0.8774 - val_loss: 1.1112 - val_acc: 0.8333

Epoch 00020: loss did not improve from 0.75433
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6276 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8219 - acc: 0.9234 - val_loss: 1.2133 - val_acc: 0.8030

Epoch 00021: loss did not improve from 0.75433
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6198 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7392 - acc: 0.9195 - val_loss: 1.4222 - val_acc: 0.8939

Epoch 00022: loss improved from 0.75433 to 0.73924, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7057 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9619 - acc: 0.8927 - val_loss: 1.0818 - val_acc: 0.8636

Epoch 00023: loss did not improve from 0.73924
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8747 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.8968 - acc: 0.8966 - val_loss: 1.0176 - val_acc: 0.8485

Epoch 00024: loss did not improve from 0.73924
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5788 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.7170 - acc: 0.9119 - val_loss: 0.9373 - val_acc: 0.8485

Epoch 00025: loss improved from 0.73924 to 0.71698, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6660 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.9416 - acc: 0.9080 - val_loss: 1.0763 - val_acc: 0.8788

Epoch 00026: loss did not improve from 0.71698
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9464 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.8907 - acc: 0.9004 - val_loss: 1.0508 - val_acc: 0.8636

Epoch 00027: loss did not improve from 0.71698
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6017 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7261 - acc: 0.9310 - val_loss: 1.0435 - val_acc: 0.8939

Epoch 00028: loss did not improve from 0.71698
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6033 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8053 - acc: 0.9195 - val_loss: 1.1669 - val_acc: 0.8636

Epoch 00029: loss did not improve from 0.71698
Epoch 30/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5402 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6759 - acc: 0.9349 - val_loss: 1.0472 - val_acc: 0.8636

Epoch 00030: loss improved from 0.71698 to 0.67594, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 31/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5514 - acc: 0.9688
261/261 [==============================] - 0s 34us/step - loss: 0.6631 - acc: 0.9272 - val_loss: 0.8720 - val_acc: 0.8788

Epoch 00031: loss improved from 0.67594 to 0.66312, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 32/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6759 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.6745 - acc: 0.9310 - val_loss: 0.9297 - val_acc: 0.8939

Epoch 00032: loss did not improve from 0.66312
Epoch 33/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5166 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.7167 - acc: 0.9310 - val_loss: 0.9364 - val_acc: 0.8636

Epoch 00033: loss did not improve from 0.66312
Epoch 34/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8923 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.7003 - acc: 0.9310 - val_loss: 0.9226 - val_acc: 0.8788

Epoch 00034: loss did not improve from 0.66312
Epoch 35/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5163 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6007 - acc: 0.9349 - val_loss: 1.1673 - val_acc: 0.8788

Epoch 00035: loss improved from 0.66312 to 0.60066, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 36/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5326 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.6085 - acc: 0.9617 - val_loss: 0.8694 - val_acc: 0.8636

Epoch 00036: loss did not improve from 0.60066
Epoch 37/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4545 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.5994 - acc: 0.9387 - val_loss: 1.1228 - val_acc: 0.9091

Epoch 00037: loss improved from 0.60066 to 0.59936, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 38/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6029 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 0.6565 - acc: 0.9157 - val_loss: 1.2821 - val_acc: 0.8636

Epoch 00038: loss did not improve from 0.59936
Epoch 39/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6887 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.6791 - acc: 0.9387 - val_loss: 1.0402 - val_acc: 0.8788

Epoch 00039: loss did not improve from 0.59936
Epoch 40/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.3763 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.5919 - acc: 0.9349 - val_loss: 1.1214 - val_acc: 0.8333

Epoch 00040: loss improved from 0.59936 to 0.59194, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 41/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4417 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.5243 - acc: 0.9579 - val_loss: 0.9927 - val_acc: 0.8636

Epoch 00041: loss improved from 0.59194 to 0.52432, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 42/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.3167 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.3975 - acc: 0.9808 - val_loss: 0.9179 - val_acc: 0.8485

Epoch 00042: loss improved from 0.52432 to 0.39746, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_9.h5
Epoch 43/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.3838 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.4982 - acc: 0.9579 - val_loss: 0.9997 - val_acc: 0.8636

Epoch 00043: loss did not improve from 0.39746
Epoch 44/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.3319 - acc: 1.0000
261/261 [==============================] - 0s 33us/step - loss: 0.9408 - acc: 0.8966 - val_loss: 1.2178 - val_acc: 0.9091

Epoch 00044: loss did not improve from 0.39746
Epoch 45/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4336 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.5893 - acc: 0.9425 - val_loss: 1.0600 - val_acc: 0.8939

Epoch 00045: loss did not improve from 0.39746
Epoch 46/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.3489 - acc: 1.0000
261/261 [==============================] - 0s 33us/step - loss: 0.5929 - acc: 0.9349 - val_loss: 0.9968 - val_acc: 0.8788

Epoch 00046: loss did not improve from 0.39746
Epoch 47/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4903 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.6827 - acc: 0.9080 - val_loss: 1.0397 - val_acc: 0.8636
DeepAmes+ Weights:  31%|███       | 4/13 [00:07<00:16,  1.87s/it]
Epoch 00047: loss did not improve from 0.39746
Epoch 00047: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.6549 - acc: 0.8125
261/261 [==============================] - 0s 1ms/step - loss: 1.9328 - acc: 0.8084 - val_loss: 1.6457 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 1.93280, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3400 - acc: 0.8750
261/261 [==============================] - 0s 36us/step - loss: 1.6175 - acc: 0.8352 - val_loss: 1.4283 - val_acc: 0.8333

Epoch 00002: loss improved from 1.93280 to 1.61747, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3558 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.6049 - acc: 0.8429 - val_loss: 1.3242 - val_acc: 0.8636

Epoch 00003: loss improved from 1.61747 to 1.60493, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3034 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.4332 - acc: 0.8659 - val_loss: 1.3676 - val_acc: 0.8636

Epoch 00004: loss improved from 1.60493 to 1.43318, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2301 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.4947 - acc: 0.8621 - val_loss: 1.3177 - val_acc: 0.8636

Epoch 00005: loss did not improve from 1.43318
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1554 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.3412 - acc: 0.8889 - val_loss: 1.2891 - val_acc: 0.8939

Epoch 00006: loss improved from 1.43318 to 1.34116, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1302 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.3172 - acc: 0.8889 - val_loss: 1.2214 - val_acc: 0.8636

Epoch 00007: loss improved from 1.34116 to 1.31724, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1867 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.3742 - acc: 0.8582 - val_loss: 1.2872 - val_acc: 0.8182

Epoch 00008: loss did not improve from 1.31724
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.4771 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.3610 - acc: 0.8659 - val_loss: 1.1964 - val_acc: 0.8485

Epoch 00009: loss did not improve from 1.31724
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9873 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.1619 - acc: 0.9157 - val_loss: 1.2449 - val_acc: 0.8636

Epoch 00010: loss improved from 1.31724 to 1.16194, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0782 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.1134 - acc: 0.8966 - val_loss: 1.2103 - val_acc: 0.8485

Epoch 00011: loss improved from 1.16194 to 1.11344, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0896 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.1844 - acc: 0.9080 - val_loss: 1.2484 - val_acc: 0.8485

Epoch 00012: loss did not improve from 1.11344
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0182 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.1947 - acc: 0.8851 - val_loss: 1.2486 - val_acc: 0.8788

Epoch 00013: loss did not improve from 1.11344
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9725 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.0423 - acc: 0.9195 - val_loss: 1.1196 - val_acc: 0.8788

Epoch 00014: loss improved from 1.11344 to 1.04226, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9363 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.2532 - acc: 0.8736 - val_loss: 1.3085 - val_acc: 0.8182

Epoch 00015: loss did not improve from 1.04226
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0369 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.1060 - acc: 0.8927 - val_loss: 1.3004 - val_acc: 0.7879

Epoch 00016: loss did not improve from 1.04226
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8788 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9594 - acc: 0.9310 - val_loss: 1.2547 - val_acc: 0.8030

Epoch 00017: loss improved from 1.04226 to 0.95943, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9141 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.0518 - acc: 0.9119 - val_loss: 1.5936 - val_acc: 0.7727

Epoch 00018: loss did not improve from 0.95943
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8180 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9405 - acc: 0.9310 - val_loss: 1.4395 - val_acc: 0.7727

Epoch 00019: loss improved from 0.95943 to 0.94054, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7907 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9507 - acc: 0.9080 - val_loss: 1.3889 - val_acc: 0.8939

Epoch 00020: loss did not improve from 0.94054
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7571 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0858 - acc: 0.8774 - val_loss: 1.0233 - val_acc: 0.8333

Epoch 00021: loss did not improve from 0.94054
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8381 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.9337 - acc: 0.9234 - val_loss: 1.0532 - val_acc: 0.8636

Epoch 00022: loss improved from 0.94054 to 0.93372, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7681 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8797 - acc: 0.9195 - val_loss: 1.0056 - val_acc: 0.8636

Epoch 00023: loss improved from 0.93372 to 0.87971, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7249 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.9256 - acc: 0.9004 - val_loss: 1.1319 - val_acc: 0.8636

Epoch 00024: loss did not improve from 0.87971
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6578 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8247 - acc: 0.9157 - val_loss: 1.1783 - val_acc: 0.8030

Epoch 00025: loss improved from 0.87971 to 0.82467, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9729 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.7990 - acc: 0.9272 - val_loss: 1.1544 - val_acc: 0.8636

Epoch 00026: loss improved from 0.82467 to 0.79895, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5971 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.7448 - acc: 0.9310 - val_loss: 0.9975 - val_acc: 0.8636

Epoch 00027: loss improved from 0.79895 to 0.74484, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6593 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.7321 - acc: 0.9080 - val_loss: 0.9352 - val_acc: 0.8636

Epoch 00028: loss improved from 0.74484 to 0.73214, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6323 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.6838 - acc: 0.9502 - val_loss: 1.1766 - val_acc: 0.8788

Epoch 00029: loss improved from 0.73214 to 0.68376, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_10.h5
Epoch 30/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6763 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.7349 - acc: 0.9387 - val_loss: 1.0946 - val_acc: 0.8939

Epoch 00030: loss did not improve from 0.68376
Epoch 31/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7917 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8580 - acc: 0.9119 - val_loss: 1.0047 - val_acc: 0.8939

Epoch 00031: loss did not improve from 0.68376
Epoch 32/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8077 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9068 - acc: 0.9004 - val_loss: 1.4231 - val_acc: 0.7879

Epoch 00032: loss did not improve from 0.68376
Epoch 33/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5461 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.8054 - acc: 0.9157 - val_loss: 1.1387 - val_acc: 0.8788

Epoch 00033: loss did not improve from 0.68376
Epoch 34/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5938 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8149 - acc: 0.9119 - val_loss: 1.5541 - val_acc: 0.8939
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:09<00:15,  1.89s/it]
Epoch 00034: loss did not improve from 0.68376
Epoch 00034: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.5484 - acc: 0.7500
261/261 [==============================] - 0s 1ms/step - loss: 1.7346 - acc: 0.7893 - val_loss: 1.1382 - val_acc: 0.8333

Epoch 00001: loss improved from inf to 1.73461, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2372 - acc: 0.8750
261/261 [==============================] - 0s 36us/step - loss: 1.4838 - acc: 0.8238 - val_loss: 1.1856 - val_acc: 0.8333

Epoch 00002: loss improved from 1.73461 to 1.48376, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1185 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.3272 - acc: 0.8391 - val_loss: 1.1505 - val_acc: 0.8485

Epoch 00003: loss improved from 1.48376 to 1.32724, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2128 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.3232 - acc: 0.8467 - val_loss: 1.1293 - val_acc: 0.8485

Epoch 00004: loss improved from 1.32724 to 1.32321, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0168 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.2481 - acc: 0.8544 - val_loss: 1.1552 - val_acc: 0.8788

Epoch 00005: loss improved from 1.32321 to 1.24812, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9910 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.1831 - acc: 0.8544 - val_loss: 1.0610 - val_acc: 0.8636

Epoch 00006: loss improved from 1.24812 to 1.18310, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9434 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.0986 - acc: 0.8736 - val_loss: 1.0299 - val_acc: 0.8636

Epoch 00007: loss improved from 1.18310 to 1.09862, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0628 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.1747 - acc: 0.8582 - val_loss: 1.0909 - val_acc: 0.8636

Epoch 00008: loss did not improve from 1.09862
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7639 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.1439 - acc: 0.8736 - val_loss: 1.0627 - val_acc: 0.8333

Epoch 00009: loss did not improve from 1.09862
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9216 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.0789 - acc: 0.8812 - val_loss: 1.0583 - val_acc: 0.8485

Epoch 00010: loss improved from 1.09862 to 1.07893, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8415 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9784 - acc: 0.8774 - val_loss: 0.9833 - val_acc: 0.8636

Epoch 00011: loss improved from 1.07893 to 0.97844, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8966 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0299 - acc: 0.8889 - val_loss: 0.9867 - val_acc: 0.8485

Epoch 00012: loss did not improve from 0.97844
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1082 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0019 - acc: 0.8927 - val_loss: 1.0914 - val_acc: 0.8636

Epoch 00013: loss did not improve from 0.97844
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8131 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9058 - acc: 0.9080 - val_loss: 0.9697 - val_acc: 0.8636

Epoch 00014: loss improved from 0.97844 to 0.90578, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9310 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0030 - acc: 0.8851 - val_loss: 1.1126 - val_acc: 0.8333

Epoch 00015: loss did not improve from 0.90578
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7749 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9399 - acc: 0.8582 - val_loss: 0.9369 - val_acc: 0.8788

Epoch 00016: loss did not improve from 0.90578
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6870 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.9473 - acc: 0.9195 - val_loss: 1.6396 - val_acc: 0.7727

Epoch 00017: loss did not improve from 0.90578
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8465 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.9377 - acc: 0.8851 - val_loss: 1.1883 - val_acc: 0.8030

Epoch 00018: loss did not improve from 0.90578
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8827 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7838 - acc: 0.9310 - val_loss: 1.2417 - val_acc: 0.7879

Epoch 00019: loss improved from 0.90578 to 0.78380, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_11.h5
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6139 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8871 - acc: 0.9080 - val_loss: 1.6117 - val_acc: 0.8030

Epoch 00020: loss did not improve from 0.78380
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8091 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8938 - acc: 0.9272 - val_loss: 1.4177 - val_acc: 0.8485

Epoch 00021: loss did not improve from 0.78380
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7725 - acc: 0.8750
261/261 [==============================] - 0s 32us/step - loss: 0.8651 - acc: 0.9042 - val_loss: 1.4552 - val_acc: 0.8636

Epoch 00022: loss did not improve from 0.78380
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7332 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8175 - acc: 0.9119 - val_loss: 1.2067 - val_acc: 0.8485

Epoch 00023: loss did not improve from 0.78380
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7385 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9252 - acc: 0.9004 - val_loss: 1.5386 - val_acc: 0.7727
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:11<00:12,  1.85s/it]
Epoch 00024: loss did not improve from 0.78380
Epoch 00024: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.5320 - acc: 0.7500
261/261 [==============================] - 0s 1ms/step - loss: 1.8425 - acc: 0.7356 - val_loss: 1.3552 - val_acc: 0.7879

Epoch 00001: loss improved from inf to 1.84255, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0880 - acc: 0.9062
261/261 [==============================] - 0s 36us/step - loss: 1.5039 - acc: 0.8123 - val_loss: 1.2020 - val_acc: 0.8333

Epoch 00002: loss improved from 1.84255 to 1.50386, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0153 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.4740 - acc: 0.8429 - val_loss: 1.1900 - val_acc: 0.8333

Epoch 00003: loss improved from 1.50386 to 1.47400, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0737 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.3442 - acc: 0.8697 - val_loss: 1.1983 - val_acc: 0.8182

Epoch 00004: loss improved from 1.47400 to 1.34422, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0139 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.3236 - acc: 0.8582 - val_loss: 1.1019 - val_acc: 0.8485

Epoch 00005: loss improved from 1.34422 to 1.32357, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3316 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.2209 - acc: 0.8774 - val_loss: 1.4487 - val_acc: 0.8333

Epoch 00006: loss improved from 1.32357 to 1.22093, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1419 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.3374 - acc: 0.8506 - val_loss: 1.0462 - val_acc: 0.8485

Epoch 00007: loss did not improve from 1.22093
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0873 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.2549 - acc: 0.8467 - val_loss: 1.0147 - val_acc: 0.8636

Epoch 00008: loss did not improve from 1.22093
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0714 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.1316 - acc: 0.8812 - val_loss: 1.0738 - val_acc: 0.8333

Epoch 00009: loss improved from 1.22093 to 1.13162, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8693 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.1422 - acc: 0.8812 - val_loss: 1.1888 - val_acc: 0.8333

Epoch 00010: loss did not improve from 1.13162
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8551 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.0092 - acc: 0.9042 - val_loss: 1.1561 - val_acc: 0.8636

Epoch 00011: loss improved from 1.13162 to 1.00919, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8028 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0428 - acc: 0.8774 - val_loss: 1.0650 - val_acc: 0.8636

Epoch 00012: loss did not improve from 1.00919
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8040 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.2373 - acc: 0.8659 - val_loss: 1.2261 - val_acc: 0.7879

Epoch 00013: loss did not improve from 1.00919
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7547 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0069 - acc: 0.8966 - val_loss: 1.1895 - val_acc: 0.8182

Epoch 00014: loss improved from 1.00919 to 1.00685, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7405 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.9602 - acc: 0.9080 - val_loss: 1.1392 - val_acc: 0.7879

Epoch 00015: loss improved from 1.00685 to 0.96015, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8891 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 0.8971 - acc: 0.9157 - val_loss: 1.0515 - val_acc: 0.8788

Epoch 00016: loss improved from 0.96015 to 0.89714, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7011 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9411 - acc: 0.9080 - val_loss: 1.0278 - val_acc: 0.8788

Epoch 00017: loss did not improve from 0.89714
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6189 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8743 - acc: 0.9119 - val_loss: 1.2158 - val_acc: 0.7727

Epoch 00018: loss improved from 0.89714 to 0.87429, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8474 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9012 - acc: 0.8966 - val_loss: 1.2954 - val_acc: 0.8030

Epoch 00019: loss did not improve from 0.87429
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2275 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0018 - acc: 0.9080 - val_loss: 1.0886 - val_acc: 0.7879

Epoch 00020: loss did not improve from 0.87429
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6596 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8455 - acc: 0.8851 - val_loss: 1.0859 - val_acc: 0.8636

Epoch 00021: loss improved from 0.87429 to 0.84547, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6883 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8859 - acc: 0.8851 - val_loss: 1.2144 - val_acc: 0.8030

Epoch 00022: loss did not improve from 0.84547
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6971 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.8156 - acc: 0.9042 - val_loss: 1.0946 - val_acc: 0.8788

Epoch 00023: loss improved from 0.84547 to 0.81558, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9214 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.8599 - acc: 0.9042 - val_loss: 0.9842 - val_acc: 0.8485

Epoch 00024: loss did not improve from 0.81558
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5972 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8852 - acc: 0.9195 - val_loss: 1.0129 - val_acc: 0.8939

Epoch 00025: loss did not improve from 0.81558
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6365 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8601 - acc: 0.8927 - val_loss: 0.8334 - val_acc: 0.8485

Epoch 00026: loss did not improve from 0.81558
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6142 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9379 - acc: 0.8582 - val_loss: 0.9863 - val_acc: 0.8788

Epoch 00027: loss did not improve from 0.81558
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6372 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7315 - acc: 0.9234 - val_loss: 0.9916 - val_acc: 0.8636

Epoch 00028: loss improved from 0.81558 to 0.73152, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5391 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8151 - acc: 0.9042 - val_loss: 0.9493 - val_acc: 0.8788

Epoch 00029: loss did not improve from 0.73152
Epoch 30/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8431 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6864 - acc: 0.9234 - val_loss: 0.9990 - val_acc: 0.8636

Epoch 00030: loss improved from 0.73152 to 0.68641, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 31/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5194 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7204 - acc: 0.9195 - val_loss: 0.9868 - val_acc: 0.8788

Epoch 00031: loss did not improve from 0.68641
Epoch 32/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5052 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8493 - acc: 0.8851 - val_loss: 1.0324 - val_acc: 0.8788

Epoch 00032: loss did not improve from 0.68641
Epoch 33/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7993 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8327 - acc: 0.8927 - val_loss: 1.1011 - val_acc: 0.8485

Epoch 00033: loss did not improve from 0.68641
Epoch 34/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5979 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.6325 - acc: 0.9080 - val_loss: 0.9177 - val_acc: 0.8636

Epoch 00034: loss improved from 0.68641 to 0.63253, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 35/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7651 - acc: 1.0000
261/261 [==============================] - 0s 33us/step - loss: 0.8766 - acc: 0.9042 - val_loss: 0.8543 - val_acc: 0.8636

Epoch 00035: loss did not improve from 0.63253
Epoch 36/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4201 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.5890 - acc: 0.9349 - val_loss: 0.8524 - val_acc: 0.8333

Epoch 00036: loss improved from 0.63253 to 0.58902, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 37/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5572 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.5816 - acc: 0.9349 - val_loss: 0.9415 - val_acc: 0.8788

Epoch 00037: loss improved from 0.58902 to 0.58159, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 38/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4263 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6767 - acc: 0.9272 - val_loss: 0.8131 - val_acc: 0.8788

Epoch 00038: loss did not improve from 0.58159
Epoch 39/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7665 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7532 - acc: 0.9157 - val_loss: 0.9188 - val_acc: 0.7727

Epoch 00039: loss did not improve from 0.58159
Epoch 40/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.3895 - acc: 1.0000
261/261 [==============================] - 0s 32us/step - loss: 0.8435 - acc: 0.9195 - val_loss: 0.8983 - val_acc: 0.8636

Epoch 00040: loss did not improve from 0.58159
Epoch 41/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5744 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.5607 - acc: 0.9387 - val_loss: 0.8189 - val_acc: 0.8333

Epoch 00041: loss improved from 0.58159 to 0.56067, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_12.h5
Epoch 42/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4110 - acc: 1.0000
261/261 [==============================] - 0s 33us/step - loss: 0.6671 - acc: 0.9387 - val_loss: 1.4396 - val_acc: 0.8333

Epoch 00042: loss did not improve from 0.56067
Epoch 43/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5215 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.6576 - acc: 0.9310 - val_loss: 1.2906 - val_acc: 0.8788

Epoch 00043: loss did not improve from 0.56067
Epoch 44/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4528 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7689 - acc: 0.9195 - val_loss: 1.2165 - val_acc: 0.8636

Epoch 00044: loss did not improve from 0.56067
Epoch 45/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.4767 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7314 - acc: 0.8966 - val_loss: 1.1777 - val_acc: 0.8636

Epoch 00045: loss did not improve from 0.56067
Epoch 46/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5076 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.6315 - acc: 0.9425 - val_loss: 1.4089 - val_acc: 0.8636
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:13<00:11,  1.87s/it]
Epoch 00046: loss did not improve from 0.56067
Epoch 00046: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.4483 - acc: 0.7500
261/261 [==============================] - 0s 1ms/step - loss: 1.6651 - acc: 0.8046 - val_loss: 1.2393 - val_acc: 0.8333

Epoch 00001: loss improved from inf to 1.66514, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1409 - acc: 0.9375
261/261 [==============================] - 0s 36us/step - loss: 1.5490 - acc: 0.8429 - val_loss: 1.3402 - val_acc: 0.8333

Epoch 00002: loss improved from 1.66514 to 1.54895, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0487 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.4533 - acc: 0.8314 - val_loss: 1.1623 - val_acc: 0.8333

Epoch 00003: loss improved from 1.54895 to 1.45326, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1552 - acc: 0.8750
261/261 [==============================] - 0s 34us/step - loss: 1.3364 - acc: 0.8314 - val_loss: 1.1042 - val_acc: 0.8636

Epoch 00004: loss improved from 1.45326 to 1.33642, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9738 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.3234 - acc: 0.8506 - val_loss: 1.0865 - val_acc: 0.8333

Epoch 00005: loss improved from 1.33642 to 1.32342, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9682 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.2730 - acc: 0.8659 - val_loss: 1.0319 - val_acc: 0.8333

Epoch 00006: loss improved from 1.32342 to 1.27300, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1152 - acc: 0.8750
261/261 [==============================] - 0s 33us/step - loss: 1.2092 - acc: 0.8544 - val_loss: 1.0322 - val_acc: 0.8636

Epoch 00007: loss improved from 1.27300 to 1.20924, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9319 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.1293 - acc: 0.8851 - val_loss: 1.1792 - val_acc: 0.8939

Epoch 00008: loss improved from 1.20924 to 1.12931, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7747 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.1226 - acc: 0.8812 - val_loss: 1.0775 - val_acc: 0.8485

Epoch 00009: loss improved from 1.12931 to 1.12259, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9059 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.1263 - acc: 0.8582 - val_loss: 1.0034 - val_acc: 0.8636

Epoch 00010: loss did not improve from 1.12259
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2068 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.1294 - acc: 0.8736 - val_loss: 1.0126 - val_acc: 0.8485

Epoch 00011: loss did not improve from 1.12259
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8644 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.1144 - acc: 0.8812 - val_loss: 0.9290 - val_acc: 0.8636

Epoch 00012: loss improved from 1.12259 to 1.11439, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8250 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0305 - acc: 0.8889 - val_loss: 0.9912 - val_acc: 0.8939

Epoch 00013: loss improved from 1.11439 to 1.03055, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1166 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.0991 - acc: 0.8659 - val_loss: 1.0369 - val_acc: 0.8030

Epoch 00014: loss did not improve from 1.03055
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8229 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.0024 - acc: 0.8812 - val_loss: 1.0810 - val_acc: 0.8030

Epoch 00015: loss improved from 1.03055 to 1.00244, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7903 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9747 - acc: 0.8889 - val_loss: 1.0206 - val_acc: 0.8182

Epoch 00016: loss improved from 1.00244 to 0.97468, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6625 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9742 - acc: 0.8774 - val_loss: 0.9961 - val_acc: 0.8636

Epoch 00017: loss improved from 0.97468 to 0.97415, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7895 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0828 - acc: 0.8774 - val_loss: 1.0700 - val_acc: 0.8788

Epoch 00018: loss did not improve from 0.97415
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7382 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9811 - acc: 0.8697 - val_loss: 0.9352 - val_acc: 0.8788

Epoch 00019: loss did not improve from 0.97415
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5860 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7243 - acc: 0.9234 - val_loss: 0.8884 - val_acc: 0.8788

Epoch 00020: loss improved from 0.97415 to 0.72435, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_13.h5
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6027 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8380 - acc: 0.9042 - val_loss: 0.9449 - val_acc: 0.8939

Epoch 00021: loss did not improve from 0.72435
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5253 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.9345 - acc: 0.8966 - val_loss: 1.1866 - val_acc: 0.8636

Epoch 00022: loss did not improve from 0.72435
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6367 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7716 - acc: 0.9157 - val_loss: 0.9489 - val_acc: 0.8788

Epoch 00023: loss did not improve from 0.72435
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6515 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9616 - acc: 0.8851 - val_loss: 1.1269 - val_acc: 0.8636

Epoch 00024: loss did not improve from 0.72435
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5413 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.7352 - acc: 0.9195 - val_loss: 1.0579 - val_acc: 0.8485
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:14<00:09,  1.86s/it]
Epoch 00025: loss did not improve from 0.72435
Epoch 00025: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 2s - loss: 2.0824 - acc: 0.6875
261/261 [==============================] - 0s 1ms/step - loss: 1.9773 - acc: 0.7854 - val_loss: 1.2599 - val_acc: 0.8030

Epoch 00001: loss improved from inf to 1.97729, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1153 - acc: 0.8750
261/261 [==============================] - 0s 36us/step - loss: 1.5472 - acc: 0.8238 - val_loss: 1.3004 - val_acc: 0.8030

Epoch 00002: loss improved from 1.97729 to 1.54722, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0860 - acc: 0.9375
261/261 [==============================] - 0s 35us/step - loss: 1.4508 - acc: 0.8544 - val_loss: 1.2759 - val_acc: 0.8030

Epoch 00003: loss improved from 1.54722 to 1.45077, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0951 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.4230 - acc: 0.8429 - val_loss: 1.2305 - val_acc: 0.8182

Epoch 00004: loss improved from 1.45077 to 1.42296, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0300 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.3531 - acc: 0.8429 - val_loss: 1.2150 - val_acc: 0.8182

Epoch 00005: loss improved from 1.42296 to 1.35307, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0070 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.2432 - acc: 0.8697 - val_loss: 1.2016 - val_acc: 0.7727

Epoch 00006: loss improved from 1.35307 to 1.24318, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0581 - acc: 0.9688
261/261 [==============================] - 0s 34us/step - loss: 1.2034 - acc: 0.8544 - val_loss: 1.1165 - val_acc: 0.8333

Epoch 00007: loss improved from 1.24318 to 1.20339, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9580 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.3222 - acc: 0.8276 - val_loss: 1.1848 - val_acc: 0.8182

Epoch 00008: loss did not improve from 1.20339
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8217 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.1440 - acc: 0.8851 - val_loss: 1.0050 - val_acc: 0.8485

Epoch 00009: loss improved from 1.20339 to 1.14401, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9208 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.1134 - acc: 0.8659 - val_loss: 1.0156 - val_acc: 0.8636

Epoch 00010: loss improved from 1.14401 to 1.11340, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9426 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.2010 - acc: 0.8659 - val_loss: 1.0941 - val_acc: 0.8636

Epoch 00011: loss did not improve from 1.11340
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7693 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.0527 - acc: 0.9004 - val_loss: 1.1008 - val_acc: 0.8485

Epoch 00012: loss improved from 1.11340 to 1.05269, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8409 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 0.9866 - acc: 0.8966 - val_loss: 1.0824 - val_acc: 0.8636

Epoch 00013: loss improved from 1.05269 to 0.98659, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2515 - acc: 0.8750
261/261 [==============================] - 0s 33us/step - loss: 1.0048 - acc: 0.8851 - val_loss: 1.3208 - val_acc: 0.8636

Epoch 00014: loss did not improve from 0.98659
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9407 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 1.2541 - acc: 0.8736 - val_loss: 1.1189 - val_acc: 0.8182

Epoch 00015: loss did not improve from 0.98659
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8866 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.1354 - acc: 0.8927 - val_loss: 1.3132 - val_acc: 0.8636

Epoch 00016: loss did not improve from 0.98659
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7640 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0310 - acc: 0.9004 - val_loss: 1.3196 - val_acc: 0.8030

Epoch 00017: loss did not improve from 0.98659
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7923 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9995 - acc: 0.9042 - val_loss: 1.2368 - val_acc: 0.8030
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:16<00:07,  1.82s/it]
Epoch 00018: loss did not improve from 0.98659
Epoch 00018: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.5054 - acc: 0.6875
261/261 [==============================] - 0s 1ms/step - loss: 1.8336 - acc: 0.7471 - val_loss: 1.3093 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 1.83360, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0866 - acc: 0.8750
261/261 [==============================] - 0s 36us/step - loss: 1.5229 - acc: 0.8084 - val_loss: 1.2674 - val_acc: 0.8182

Epoch 00002: loss improved from 1.83360 to 1.52292, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0895 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.4221 - acc: 0.8276 - val_loss: 1.1831 - val_acc: 0.8182

Epoch 00003: loss improved from 1.52292 to 1.42212, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0718 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.3747 - acc: 0.8429 - val_loss: 1.2009 - val_acc: 0.8182

Epoch 00004: loss improved from 1.42212 to 1.37471, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1265 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.3307 - acc: 0.8544 - val_loss: 1.1941 - val_acc: 0.8182

Epoch 00005: loss improved from 1.37471 to 1.33068, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1019 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.2751 - acc: 0.8544 - val_loss: 1.1738 - val_acc: 0.7727

Epoch 00006: loss improved from 1.33068 to 1.27506, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9147 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.2130 - acc: 0.8697 - val_loss: 1.0071 - val_acc: 0.7576

Epoch 00007: loss improved from 1.27506 to 1.21304, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0563 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.2734 - acc: 0.8506 - val_loss: 0.9992 - val_acc: 0.8030

Epoch 00008: loss did not improve from 1.21304
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1095 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.1171 - acc: 0.8697 - val_loss: 0.9771 - val_acc: 0.8636

Epoch 00009: loss improved from 1.21304 to 1.11710, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8697 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.2256 - acc: 0.8582 - val_loss: 1.0752 - val_acc: 0.7879

Epoch 00010: loss did not improve from 1.11710
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8457 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.1554 - acc: 0.8774 - val_loss: 0.9017 - val_acc: 0.8636

Epoch 00011: loss did not improve from 1.11710
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7461 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.1503 - acc: 0.8697 - val_loss: 1.0155 - val_acc: 0.8030

Epoch 00012: loss did not improve from 1.11710
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9227 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.0100 - acc: 0.8812 - val_loss: 1.0400 - val_acc: 0.8333

Epoch 00013: loss improved from 1.11710 to 1.01002, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9120 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.2530 - acc: 0.8774 - val_loss: 1.2393 - val_acc: 0.7576

Epoch 00014: loss did not improve from 1.01002
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1000 - acc: 0.8438
261/261 [==============================] - 0s 33us/step - loss: 1.2216 - acc: 0.8429 - val_loss: 1.0253 - val_acc: 0.7727

Epoch 00015: loss did not improve from 1.01002
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0600 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0869 - acc: 0.8927 - val_loss: 1.1113 - val_acc: 0.8182

Epoch 00016: loss did not improve from 1.01002
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6923 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9545 - acc: 0.9004 - val_loss: 1.1613 - val_acc: 0.8485

Epoch 00017: loss improved from 1.01002 to 0.95450, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6871 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.1264 - acc: 0.8697 - val_loss: 1.3298 - val_acc: 0.8333

Epoch 00018: loss did not improve from 0.95450
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7003 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0126 - acc: 0.8812 - val_loss: 1.2989 - val_acc: 0.8182

Epoch 00019: loss did not improve from 0.95450
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7192 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8607 - acc: 0.9195 - val_loss: 1.2451 - val_acc: 0.8333

Epoch 00020: loss improved from 0.95450 to 0.86070, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6453 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8888 - acc: 0.9042 - val_loss: 1.1606 - val_acc: 0.8636

Epoch 00021: loss did not improve from 0.86070
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7371 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8947 - acc: 0.9119 - val_loss: 1.1968 - val_acc: 0.7879

Epoch 00022: loss did not improve from 0.86070
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6502 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.8095 - acc: 0.9004 - val_loss: 1.3364 - val_acc: 0.7576

Epoch 00023: loss improved from 0.86070 to 0.80952, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0336 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.9655 - acc: 0.8927 - val_loss: 1.0981 - val_acc: 0.8333

Epoch 00024: loss did not improve from 0.80952
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7387 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.9915 - acc: 0.9004 - val_loss: 1.3091 - val_acc: 0.8788

Epoch 00025: loss did not improve from 0.80952
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7539 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.9853 - acc: 0.8736 - val_loss: 1.1140 - val_acc: 0.8485

Epoch 00026: loss did not improve from 0.80952
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6958 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8695 - acc: 0.8927 - val_loss: 1.1458 - val_acc: 0.7727

Epoch 00027: loss did not improve from 0.80952
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5438 - acc: 0.9688
261/261 [==============================] - 0s 34us/step - loss: 0.7821 - acc: 0.9080 - val_loss: 1.0659 - val_acc: 0.8485

Epoch 00028: loss improved from 0.80952 to 0.78212, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_15.h5
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5970 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8253 - acc: 0.8966 - val_loss: 1.0025 - val_acc: 0.8788

Epoch 00029: loss did not improve from 0.78212
Epoch 30/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5156 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8652 - acc: 0.8851 - val_loss: 0.9957 - val_acc: 0.8182

Epoch 00030: loss did not improve from 0.78212
Epoch 31/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6714 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9427 - acc: 0.8927 - val_loss: 1.0695 - val_acc: 0.8182

Epoch 00031: loss did not improve from 0.78212
Epoch 32/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.5225 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8075 - acc: 0.9004 - val_loss: 1.1383 - val_acc: 0.7273

Epoch 00032: loss did not improve from 0.78212
Epoch 33/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9320 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 0.8788 - acc: 0.8966 - val_loss: 0.9543 - val_acc: 0.8333
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:18<00:05,  1.83s/it]
Epoch 00033: loss did not improve from 0.78212
Epoch 00033: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.8923 - acc: 0.7188
261/261 [==============================] - 0s 1ms/step - loss: 2.1373 - acc: 0.7701 - val_loss: 1.5019 - val_acc: 0.8182

Epoch 00001: loss improved from inf to 2.13729, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2776 - acc: 0.9062
261/261 [==============================] - 0s 35us/step - loss: 1.8536 - acc: 0.8199 - val_loss: 1.4422 - val_acc: 0.7879

Epoch 00002: loss improved from 2.13729 to 1.85361, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3118 - acc: 0.8750
261/261 [==============================] - 0s 34us/step - loss: 1.7243 - acc: 0.8123 - val_loss: 1.4225 - val_acc: 0.7879

Epoch 00003: loss improved from 1.85361 to 1.72429, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2710 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.6121 - acc: 0.8352 - val_loss: 1.3111 - val_acc: 0.8030

Epoch 00004: loss improved from 1.72429 to 1.61214, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3007 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.6069 - acc: 0.8582 - val_loss: 1.2878 - val_acc: 0.8030

Epoch 00005: loss improved from 1.61214 to 1.60694, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1529 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.5276 - acc: 0.8429 - val_loss: 1.2533 - val_acc: 0.7879

Epoch 00006: loss improved from 1.60694 to 1.52764, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3539 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.4887 - acc: 0.8429 - val_loss: 1.2907 - val_acc: 0.7727

Epoch 00007: loss improved from 1.52764 to 1.48874, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2693 - acc: 0.8438
261/261 [==============================] - 0s 33us/step - loss: 1.5790 - acc: 0.8314 - val_loss: 1.2589 - val_acc: 0.7727

Epoch 00008: loss did not improve from 1.48874
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2661 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.4270 - acc: 0.8314 - val_loss: 1.1819 - val_acc: 0.8333

Epoch 00009: loss improved from 1.48874 to 1.42695, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0678 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.3357 - acc: 0.8582 - val_loss: 1.2401 - val_acc: 0.7727

Epoch 00010: loss improved from 1.42695 to 1.33573, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1952 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.4214 - acc: 0.8391 - val_loss: 1.2178 - val_acc: 0.8485

Epoch 00011: loss did not improve from 1.33573
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0595 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.3602 - acc: 0.8659 - val_loss: 1.1817 - val_acc: 0.7879

Epoch 00012: loss did not improve from 1.33573
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0550 - acc: 0.8750
261/261 [==============================] - 0s 32us/step - loss: 1.2255 - acc: 0.8812 - val_loss: 1.1629 - val_acc: 0.8333

Epoch 00013: loss improved from 1.33573 to 1.22548, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2330 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.2978 - acc: 0.8697 - val_loss: 1.2132 - val_acc: 0.8636

Epoch 00014: loss did not improve from 1.22548
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8439 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.1962 - acc: 0.8812 - val_loss: 1.1425 - val_acc: 0.8030

Epoch 00015: loss improved from 1.22548 to 1.19616, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0374 - acc: 0.8750
261/261 [==============================] - 0s 32us/step - loss: 1.1647 - acc: 0.8889 - val_loss: 1.1497 - val_acc: 0.7727

Epoch 00016: loss improved from 1.19616 to 1.16472, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9398 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.1716 - acc: 0.8697 - val_loss: 1.1667 - val_acc: 0.7576

Epoch 00017: loss did not improve from 1.16472
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1412 - acc: 0.8750
261/261 [==============================] - 0s 32us/step - loss: 1.1457 - acc: 0.8659 - val_loss: 1.1324 - val_acc: 0.7879

Epoch 00018: loss improved from 1.16472 to 1.14573, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9692 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.2220 - acc: 0.8506 - val_loss: 1.3029 - val_acc: 0.8030

Epoch 00019: loss did not improve from 1.14573
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9455 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.1943 - acc: 0.8621 - val_loss: 1.4066 - val_acc: 0.8182

Epoch 00020: loss did not improve from 1.14573
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8754 - acc: 0.8750
261/261 [==============================] - 0s 32us/step - loss: 1.1290 - acc: 0.8621 - val_loss: 1.1205 - val_acc: 0.8333

Epoch 00021: loss improved from 1.14573 to 1.12896, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8547 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.9465 - acc: 0.9080 - val_loss: 1.1015 - val_acc: 0.8485

Epoch 00022: loss improved from 1.12896 to 0.94652, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8382 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0531 - acc: 0.8774 - val_loss: 1.2813 - val_acc: 0.8636

Epoch 00023: loss did not improve from 0.94652
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8314 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.1189 - acc: 0.8736 - val_loss: 1.0591 - val_acc: 0.8636

Epoch 00024: loss did not improve from 0.94652
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7948 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9393 - acc: 0.9004 - val_loss: 1.0200 - val_acc: 0.8636

Epoch 00025: loss improved from 0.94652 to 0.93935, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9927 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.8539 - acc: 0.9042 - val_loss: 1.0181 - val_acc: 0.8485

Epoch 00026: loss improved from 0.93935 to 0.85389, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_16.h5
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6719 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.0383 - acc: 0.9080 - val_loss: 1.3842 - val_acc: 0.7727

Epoch 00027: loss did not improve from 0.85389
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9066 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0448 - acc: 0.9157 - val_loss: 1.5315 - val_acc: 0.8333

Epoch 00028: loss did not improve from 0.85389
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6328 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9096 - acc: 0.8774 - val_loss: 1.2267 - val_acc: 0.8333

Epoch 00029: loss did not improve from 0.85389
Epoch 30/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1557 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 0.9617 - acc: 0.8966 - val_loss: 1.3984 - val_acc: 0.8030

Epoch 00030: loss did not improve from 0.85389
Epoch 31/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0329 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.2126 - acc: 0.8506 - val_loss: 1.2797 - val_acc: 0.8030
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:20<00:03,  1.81s/it]
Epoch 00031: loss did not improve from 0.85389
Epoch 00031: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 1.6107 - acc: 0.7500
261/261 [==============================] - 0s 1ms/step - loss: 1.9624 - acc: 0.7739 - val_loss: 1.3582 - val_acc: 0.7576

Epoch 00001: loss improved from inf to 1.96244, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3352 - acc: 0.8438
261/261 [==============================] - 0s 36us/step - loss: 1.6689 - acc: 0.7778 - val_loss: 1.3368 - val_acc: 0.8030

Epoch 00002: loss improved from 1.96244 to 1.66887, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1978 - acc: 0.8750
261/261 [==============================] - 0s 35us/step - loss: 1.6123 - acc: 0.8084 - val_loss: 1.3317 - val_acc: 0.8333

Epoch 00003: loss improved from 1.66887 to 1.61227, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1058 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.4917 - acc: 0.8276 - val_loss: 1.3327 - val_acc: 0.8333

Epoch 00004: loss improved from 1.61227 to 1.49172, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0114 - acc: 0.8750
261/261 [==============================] - 0s 34us/step - loss: 1.4250 - acc: 0.8506 - val_loss: 1.3625 - val_acc: 0.8182

Epoch 00005: loss improved from 1.49172 to 1.42497, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0875 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.4221 - acc: 0.8544 - val_loss: 1.4281 - val_acc: 0.7879

Epoch 00006: loss improved from 1.42497 to 1.42211, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2366 - acc: 0.8750
261/261 [==============================] - 0s 34us/step - loss: 1.4452 - acc: 0.8238 - val_loss: 1.4119 - val_acc: 0.7879

Epoch 00007: loss did not improve from 1.42211
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1539 - acc: 0.8750
261/261 [==============================] - 0s 33us/step - loss: 1.2258 - acc: 0.8544 - val_loss: 1.3648 - val_acc: 0.8030

Epoch 00008: loss improved from 1.42211 to 1.22577, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0212 - acc: 0.8750
261/261 [==============================] - 0s 34us/step - loss: 1.2697 - acc: 0.8659 - val_loss: 1.3798 - val_acc: 0.8182

Epoch 00009: loss did not improve from 1.22577
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0544 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.2609 - acc: 0.8582 - val_loss: 1.5711 - val_acc: 0.7727

Epoch 00010: loss did not improve from 1.22577
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.6972 - acc: 0.8125
261/261 [==============================] - 0s 33us/step - loss: 1.4978 - acc: 0.8352 - val_loss: 1.2583 - val_acc: 0.8788

Epoch 00011: loss did not improve from 1.22577
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8837 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.3336 - acc: 0.8544 - val_loss: 1.1052 - val_acc: 0.8333

Epoch 00012: loss did not improve from 1.22577
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9214 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.1707 - acc: 0.8697 - val_loss: 1.1402 - val_acc: 0.8788

Epoch 00013: loss improved from 1.22577 to 1.17068, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9693 - acc: 0.9688
261/261 [==============================] - 0s 33us/step - loss: 1.2104 - acc: 0.8736 - val_loss: 1.2271 - val_acc: 0.7727

Epoch 00014: loss did not improve from 1.17068
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8038 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0613 - acc: 0.8851 - val_loss: 1.2400 - val_acc: 0.8636

Epoch 00015: loss improved from 1.17068 to 1.06132, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9923 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0998 - acc: 0.8889 - val_loss: 1.1702 - val_acc: 0.8636

Epoch 00016: loss did not improve from 1.06132
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8821 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0615 - acc: 0.8927 - val_loss: 1.3236 - val_acc: 0.8788

Epoch 00017: loss did not improve from 1.06132
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8525 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0631 - acc: 0.8851 - val_loss: 1.2360 - val_acc: 0.8182

Epoch 00018: loss did not improve from 1.06132
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9316 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.0873 - acc: 0.8774 - val_loss: 1.1170 - val_acc: 0.8485

Epoch 00019: loss did not improve from 1.06132
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8119 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.0468 - acc: 0.8889 - val_loss: 1.1945 - val_acc: 0.8333

Epoch 00020: loss improved from 1.06132 to 1.04677, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7993 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0285 - acc: 0.9157 - val_loss: 1.2789 - val_acc: 0.8030

Epoch 00021: loss improved from 1.04677 to 1.02845, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8642 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 0.8839 - acc: 0.9119 - val_loss: 1.0913 - val_acc: 0.8636

Epoch 00022: loss improved from 1.02845 to 0.88388, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_17.h5
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.7629 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0342 - acc: 0.8889 - val_loss: 1.1157 - val_acc: 0.8636

Epoch 00023: loss did not improve from 0.88388
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6566 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.0667 - acc: 0.8966 - val_loss: 1.1065 - val_acc: 0.8636

Epoch 00024: loss did not improve from 0.88388
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9237 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.0980 - acc: 0.8812 - val_loss: 0.9698 - val_acc: 0.8788

Epoch 00025: loss did not improve from 0.88388
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8553 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 0.9297 - acc: 0.8889 - val_loss: 1.0036 - val_acc: 0.8788

Epoch 00026: loss did not improve from 0.88388
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.6300 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.0588 - acc: 0.8927 - val_loss: 0.9971 - val_acc: 0.8788
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:22<00:01,  1.82s/it]
Epoch 00027: loss did not improve from 0.88388
Epoch 00027: early stopping
Train on 261 samples, validate on 66 samples
Epoch 1/100

 32/261 [==>...........................] - ETA: 1s - loss: 2.0635 - acc: 0.7500
261/261 [==============================] - 0s 1ms/step - loss: 2.5639 - acc: 0.7893 - val_loss: 2.0488 - val_acc: 0.8030

Epoch 00001: loss improved from inf to 2.56391, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.7603 - acc: 0.9062
261/261 [==============================] - 0s 36us/step - loss: 2.1609 - acc: 0.8008 - val_loss: 1.8286 - val_acc: 0.8333

Epoch 00002: loss improved from 2.56391 to 2.16093, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.7133 - acc: 0.9062
261/261 [==============================] - 0s 35us/step - loss: 2.0728 - acc: 0.8238 - val_loss: 1.7830 - val_acc: 0.8182

Epoch 00003: loss improved from 2.16093 to 2.07283, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.7013 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.9643 - acc: 0.8314 - val_loss: 1.7723 - val_acc: 0.8030

Epoch 00004: loss improved from 2.07283 to 1.96433, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.5404 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.9748 - acc: 0.8429 - val_loss: 1.8614 - val_acc: 0.8333

Epoch 00005: loss did not improve from 1.96433
Epoch 6/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.6936 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.9104 - acc: 0.8238 - val_loss: 1.7729 - val_acc: 0.7879

Epoch 00006: loss improved from 1.96433 to 1.91036, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3375 - acc: 0.9375
261/261 [==============================] - 0s 34us/step - loss: 1.7863 - acc: 0.8429 - val_loss: 1.5974 - val_acc: 0.8030

Epoch 00007: loss improved from 1.91036 to 1.78625, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3968 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.7258 - acc: 0.8544 - val_loss: 1.5013 - val_acc: 0.8333

Epoch 00008: loss improved from 1.78625 to 1.72581, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.5685 - acc: 0.9062
261/261 [==============================] - 0s 34us/step - loss: 1.7454 - acc: 0.8276 - val_loss: 1.7548 - val_acc: 0.8030

Epoch 00009: loss did not improve from 1.72581
Epoch 10/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.3905 - acc: 0.8750
261/261 [==============================] - 0s 33us/step - loss: 1.5849 - acc: 0.8582 - val_loss: 1.5563 - val_acc: 0.8485

Epoch 00010: loss improved from 1.72581 to 1.58488, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.4148 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.6058 - acc: 0.8544 - val_loss: 1.4272 - val_acc: 0.8636

Epoch 00011: loss did not improve from 1.58488
Epoch 12/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2813 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.4731 - acc: 0.8851 - val_loss: 1.6736 - val_acc: 0.8030

Epoch 00012: loss improved from 1.58488 to 1.47313, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 13/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.5200 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.6097 - acc: 0.8621 - val_loss: 1.7211 - val_acc: 0.8636

Epoch 00013: loss did not improve from 1.47313
Epoch 14/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1848 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.4625 - acc: 0.8927 - val_loss: 1.5107 - val_acc: 0.8485

Epoch 00014: loss improved from 1.47313 to 1.46250, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 15/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1517 - acc: 0.9688
261/261 [==============================] - 0s 32us/step - loss: 1.3901 - acc: 0.9119 - val_loss: 1.8931 - val_acc: 0.8030

Epoch 00015: loss improved from 1.46250 to 1.39014, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1413 - acc: 0.9062
261/261 [==============================] - 0s 33us/step - loss: 1.5840 - acc: 0.8621 - val_loss: 1.7180 - val_acc: 0.7727

Epoch 00016: loss did not improve from 1.39014
Epoch 17/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2323 - acc: 0.8125
261/261 [==============================] - 0s 32us/step - loss: 1.6770 - acc: 0.8352 - val_loss: 1.5854 - val_acc: 0.7879

Epoch 00017: loss did not improve from 1.39014
Epoch 18/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1669 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.3319 - acc: 0.8582 - val_loss: 1.3537 - val_acc: 0.8636

Epoch 00018: loss improved from 1.39014 to 1.33186, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 19/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9616 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.2829 - acc: 0.8927 - val_loss: 1.4250 - val_acc: 0.7879

Epoch 00019: loss improved from 1.33186 to 1.28288, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 20/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0717 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.5207 - acc: 0.8582 - val_loss: 1.5786 - val_acc: 0.8030

Epoch 00020: loss did not improve from 1.28288
Epoch 21/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0978 - acc: 0.8750
261/261 [==============================] - 0s 32us/step - loss: 1.3416 - acc: 0.8621 - val_loss: 1.4981 - val_acc: 0.8485

Epoch 00021: loss did not improve from 1.28288
Epoch 22/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0302 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.4171 - acc: 0.8851 - val_loss: 1.5959 - val_acc: 0.7121

Epoch 00022: loss did not improve from 1.28288
Epoch 23/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.1233 - acc: 0.8750
261/261 [==============================] - 0s 32us/step - loss: 1.4324 - acc: 0.8429 - val_loss: 1.3812 - val_acc: 0.7424

Epoch 00023: loss did not improve from 1.28288
Epoch 24/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9693 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.1567 - acc: 0.8697 - val_loss: 1.1781 - val_acc: 0.8788

Epoch 00024: loss improved from 1.28288 to 1.15669, saving model to ./results_TA1538_with_S9/DeepAmes_models/weight_18.h5
Epoch 25/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.8196 - acc: 0.9375
261/261 [==============================] - 0s 33us/step - loss: 1.4388 - acc: 0.8927 - val_loss: 1.6431 - val_acc: 0.8030

Epoch 00025: loss did not improve from 1.15669
Epoch 26/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0029 - acc: 0.8750
261/261 [==============================] - 0s 32us/step - loss: 1.1821 - acc: 0.9042 - val_loss: 1.3732 - val_acc: 0.8485

Epoch 00026: loss did not improve from 1.15669
Epoch 27/100

 32/261 [==>...........................] - ETA: 0s - loss: 0.9344 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.5116 - acc: 0.8276 - val_loss: 1.3643 - val_acc: 0.7879

Epoch 00027: loss did not improve from 1.15669
Epoch 28/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.0115 - acc: 0.9375
261/261 [==============================] - 0s 32us/step - loss: 1.2296 - acc: 0.8659 - val_loss: 1.5878 - val_acc: 0.8939

Epoch 00028: loss did not improve from 1.15669
Epoch 29/100

 32/261 [==>...........................] - ETA: 0s - loss: 1.2457 - acc: 0.9062
261/261 [==============================] - 0s 32us/step - loss: 1.8115 - acc: 0.8506 - val_loss: 1.3405 - val_acc: 0.8636
DeepAmes+ Weights: 100%|██████████| 13/13 [00:23<00:00,  1.82s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:23<00:00,  1.83s/it]

Epoch 00029: loss did not improve from 1.15669
Epoch 00029: early stopping
--- 1457.5267107486725 seconds ---

Generating metrics report for TA1538_with_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 178 samples.
Processing weight 7...
  Done. 178 samples.
Processing weight 8...
  Done. 178 samples.
Processing weight 9...
  Done. 178 samples.
Processing weight 10...
  Done. 178 samples.
Processing weight 11...
  Done. 178 samples.
Processing weight 12...
  Done. 178 samples.
Processing weight 13...
  Done. 178 samples.
Processing weight 14...
  Done. 178 samples.
Processing weight 15...
  Done. 178 samples.
Processing weight 16...
  Done. 178 samples.
Processing weight 17...
  Done. 178 samples.
Processing weight 18...
  Done. 178 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA1538_with_S9/metrics_report_TA1538_with_S9.txt

Done!

Completed TA1538_with_S9 in 1457.53 seconds

================================================================================
[12/16] Processing: TA1538_without_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA1538_without_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA1538_without_S9_Test_mold2.csv
(1738, 777)
(1390, 777)
(185, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:04<01:32,  4.89s/it]KNN Seeds:  10%|█         | 2/20 [00:09<01:28,  4.90s/it]KNN Seeds:  15%|█▌        | 3/20 [00:14<01:23,  4.92s/it]KNN Seeds:  20%|██        | 4/20 [00:19<01:18,  4.90s/it]KNN Seeds:  25%|██▌       | 5/20 [00:24<01:13,  4.93s/it]KNN Seeds:  30%|███       | 6/20 [00:29<01:09,  4.94s/it]KNN Seeds:  35%|███▌      | 7/20 [00:34<01:04,  4.94s/it]KNN Seeds:  40%|████      | 8/20 [00:39<00:59,  4.96s/it]KNN Seeds:  45%|████▌     | 9/20 [00:44<00:54,  4.98s/it]KNN Seeds:  50%|█████     | 10/20 [00:49<00:49,  4.99s/it]KNN Seeds:  55%|█████▌    | 11/20 [00:54<00:45,  5.00s/it]KNN Seeds:  60%|██████    | 12/20 [00:59<00:40,  5.00s/it]KNN Seeds:  65%|██████▌   | 13/20 [01:04<00:35,  5.00s/it]KNN Seeds:  70%|███████   | 14/20 [01:09<00:29,  5.00s/it]KNN Seeds:  75%|███████▌  | 15/20 [01:14<00:25,  5.01s/it]KNN Seeds:  80%|████████  | 16/20 [01:19<00:20,  5.02s/it]KNN Seeds:  85%|████████▌ | 17/20 [01:24<00:15,  5.05s/it]KNN Seeds:  90%|█████████ | 18/20 [01:29<00:10,  5.07s/it]KNN Seeds:  95%|█████████▌| 19/20 [01:34<00:05,  5.06s/it]KNN Seeds: 100%|██████████| 20/20 [01:39<00:00,  5.06s/it]KNN Seeds: 100%|██████████| 20/20 [01:39<00:00,  5.00s/it]
24
(100, None, 'lbfgs')
(1738, 777)
(1390, 777)
(185, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:02<00:48,  2.55s/it]LR Seeds:  10%|█         | 2/20 [00:04<00:38,  2.15s/it]LR Seeds:  15%|█▌        | 3/20 [00:06<00:34,  2.06s/it]LR Seeds:  20%|██        | 4/20 [00:08<00:32,  2.03s/it]LR Seeds:  25%|██▌       | 5/20 [00:10<00:30,  2.02s/it]LR Seeds:  30%|███       | 6/20 [00:12<00:27,  1.99s/it]LR Seeds:  35%|███▌      | 7/20 [00:14<00:25,  1.97s/it]LR Seeds:  40%|████      | 8/20 [00:16<00:23,  1.97s/it]LR Seeds:  45%|████▌     | 9/20 [00:18<00:21,  1.97s/it]LR Seeds:  50%|█████     | 10/20 [00:20<00:19,  1.97s/it]LR Seeds:  55%|█████▌    | 11/20 [00:22<00:17,  1.98s/it]LR Seeds:  60%|██████    | 12/20 [00:24<00:15,  1.98s/it]LR Seeds:  65%|██████▌   | 13/20 [00:26<00:13,  1.99s/it]LR Seeds:  70%|███████   | 14/20 [00:28<00:12,  2.01s/it]LR Seeds:  75%|███████▌  | 15/20 [00:30<00:10,  2.03s/it]LR Seeds:  80%|████████  | 16/20 [00:32<00:08,  2.04s/it]LR Seeds:  85%|████████▌ | 17/20 [00:34<00:06,  2.04s/it]LR Seeds:  90%|█████████ | 18/20 [00:36<00:04,  2.06s/it]LR Seeds:  95%|█████████▌| 19/20 [00:38<00:02,  2.07s/it]LR Seeds: 100%|██████████| 20/20 [00:40<00:00,  2.13s/it]LR Seeds: 100%|██████████| 20/20 [00:40<00:00,  2.04s/it]
96
('rbf', 1, 1)
(1738, 777)
(1390, 777)
(185, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [00:29<09:25, 29.74s/it]SVM Seeds:  10%|█         | 2/20 [00:59<08:55, 29.77s/it]SVM Seeds:  15%|█▌        | 3/20 [01:29<08:26, 29.80s/it]SVM Seeds:  20%|██        | 4/20 [01:59<07:56, 29.80s/it]SVM Seeds:  25%|██▌       | 5/20 [02:28<07:26, 29.80s/it]SVM Seeds:  30%|███       | 6/20 [02:58<06:57, 29.80s/it]SVM Seeds:  35%|███▌      | 7/20 [03:28<06:27, 29.80s/it]SVM Seeds:  40%|████      | 8/20 [03:58<05:57, 29.78s/it]SVM Seeds:  45%|████▌     | 9/20 [04:28<05:27, 29.80s/it]SVM Seeds:  50%|█████     | 10/20 [04:57<04:58, 29.80s/it]SVM Seeds:  55%|█████▌    | 11/20 [05:27<04:28, 29.83s/it]SVM Seeds:  60%|██████    | 12/20 [05:57<03:58, 29.82s/it]SVM Seeds:  65%|██████▌   | 13/20 [06:27<03:28, 29.81s/it]SVM Seeds:  70%|███████   | 14/20 [06:57<02:59, 29.84s/it]SVM Seeds:  75%|███████▌  | 15/20 [07:27<02:29, 29.85s/it]SVM Seeds:  80%|████████  | 16/20 [07:57<01:59, 29.86s/it]SVM Seeds:  85%|████████▌ | 17/20 [08:26<01:29, 29.86s/it]SVM Seeds:  90%|█████████ | 18/20 [08:56<00:59, 29.87s/it]SVM Seeds:  95%|█████████▌| 19/20 [09:26<00:29, 29.87s/it]SVM Seeds: 100%|██████████| 20/20 [09:56<00:00, 29.88s/it]SVM Seeds: 100%|██████████| 20/20 [09:56<00:00, 29.83s/it]
200
(500, None, 70, 1, 'balanced')
(1738, 777)
(1390, 777)
(185, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:04<01:30,  4.75s/it]RF Seeds:  10%|█         | 2/20 [00:09<01:25,  4.75s/it]RF Seeds:  15%|█▌        | 3/20 [00:14<01:20,  4.76s/it]RF Seeds:  20%|██        | 4/20 [00:19<01:16,  4.77s/it]RF Seeds:  25%|██▌       | 5/20 [00:23<01:11,  4.80s/it]RF Seeds:  30%|███       | 6/20 [00:28<01:07,  4.80s/it]RF Seeds:  35%|███▌      | 7/20 [00:33<01:02,  4.80s/it]RF Seeds:  40%|████      | 8/20 [00:38<00:57,  4.81s/it]RF Seeds:  45%|████▌     | 9/20 [00:43<00:52,  4.82s/it]RF Seeds:  50%|█████     | 10/20 [00:48<00:48,  4.84s/it]RF Seeds:  55%|█████▌    | 11/20 [00:52<00:43,  4.84s/it]RF Seeds:  60%|██████    | 12/20 [00:57<00:38,  4.85s/it]RF Seeds:  65%|██████▌   | 13/20 [01:02<00:33,  4.85s/it]RF Seeds:  70%|███████   | 14/20 [01:07<00:29,  4.87s/it]RF Seeds:  75%|███████▌  | 15/20 [01:12<00:24,  4.87s/it]RF Seeds:  80%|████████  | 16/20 [01:17<00:19,  4.89s/it]RF Seeds:  85%|████████▌ | 17/20 [01:22<00:14,  4.91s/it]RF Seeds:  90%|█████████ | 18/20 [01:27<00:09,  4.96s/it]RF Seeds:  95%|█████████▌| 19/20 [01:32<00:04,  4.96s/it]RF Seeds: 100%|██████████| 20/20 [01:37<00:00,  4.96s/it]RF Seeds: 100%|██████████| 20/20 [01:37<00:00,  4.87s/it]
400
(0.01, 900, 7, 0.8, 6)
(1738, 777)
(1390, 777)
(185, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:32<10:13, 32.26s/it]XGBoost Seeds:  10%|█         | 2/20 [01:04<09:41, 32.30s/it]XGBoost Seeds:  15%|█▌        | 3/20 [01:36<09:09, 32.31s/it]XGBoost Seeds:  20%|██        | 4/20 [02:09<08:36, 32.31s/it]XGBoost Seeds:  25%|██▌       | 5/20 [02:41<08:05, 32.34s/it]XGBoost Seeds:  30%|███       | 6/20 [03:14<07:33, 32.39s/it]XGBoost Seeds:  35%|███▌      | 7/20 [03:46<07:01, 32.39s/it]XGBoost Seeds:  40%|████      | 8/20 [04:18<06:28, 32.41s/it]XGBoost Seeds:  45%|████▌     | 9/20 [04:51<05:56, 32.39s/it]XGBoost Seeds:  50%|█████     | 10/20 [05:23<05:24, 32.43s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [05:56<04:52, 32.45s/it]XGBoost Seeds:  60%|██████    | 12/20 [06:28<04:19, 32.47s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [07:01<03:47, 32.48s/it]XGBoost Seeds:  70%|███████   | 14/20 [07:33<03:14, 32.46s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [08:06<02:42, 32.44s/it]XGBoost Seeds:  80%|████████  | 16/20 [08:38<02:09, 32.43s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [09:11<01:37, 32.47s/it]XGBoost Seeds:  90%|█████████ | 18/20 [09:43<01:04, 32.47s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [10:16<00:32, 32.47s/it]XGBoost Seeds: 100%|██████████| 20/20 [10:48<00:00, 32.46s/it]XGBoost Seeds: 100%|██████████| 20/20 [10:48<00:00, 32.42s/it]
knn:  89
lr:  92
svm:  92
rf:  99
xgboost:  78
Combining validation predictions is completed
knn:  89
lr:  92
svm:  92
rf:  99
xgboost:  78
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.7385 - acc: 0.7500
278/278 [==============================] - 0s 974us/step - loss: 1.6477 - acc: 0.8345 - val_loss: 1.0629 - val_acc: 0.8714

Epoch 00001: loss improved from inf to 1.64772, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2642 - acc: 0.8750
278/278 [==============================] - 0s 34us/step - loss: 1.4650 - acc: 0.8597 - val_loss: 1.0833 - val_acc: 0.8429

Epoch 00002: loss improved from 1.64772 to 1.46504, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0929 - acc: 0.9375
278/278 [==============================] - 0s 32us/step - loss: 1.3883 - acc: 0.8597 - val_loss: 1.0218 - val_acc: 0.8429

Epoch 00003: loss improved from 1.46504 to 1.38833, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0593 - acc: 0.9375
278/278 [==============================] - 0s 32us/step - loss: 1.2634 - acc: 0.8849 - val_loss: 0.9025 - val_acc: 0.8714

Epoch 00004: loss improved from 1.38833 to 1.26342, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9719 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.2263 - acc: 0.8885 - val_loss: 0.8470 - val_acc: 0.8714

Epoch 00005: loss improved from 1.26342 to 1.22627, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8913 - acc: 0.9375
278/278 [==============================] - 0s 32us/step - loss: 1.1812 - acc: 0.8885 - val_loss: 0.8589 - val_acc: 0.8714

Epoch 00006: loss improved from 1.22627 to 1.18122, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9012 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.1307 - acc: 0.8921 - val_loss: 0.8557 - val_acc: 0.9286

Epoch 00007: loss improved from 1.18122 to 1.13067, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9003 - acc: 0.9688
278/278 [==============================] - 0s 32us/step - loss: 1.0423 - acc: 0.9209 - val_loss: 0.9053 - val_acc: 0.8857

Epoch 00008: loss improved from 1.13067 to 1.04229, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9182 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.0612 - acc: 0.9065 - val_loss: 0.8803 - val_acc: 0.9000

Epoch 00009: loss did not improve from 1.04229
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7732 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.9914 - acc: 0.9173 - val_loss: 0.8355 - val_acc: 0.8857

Epoch 00010: loss improved from 1.04229 to 0.99136, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9237 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.0821 - acc: 0.8993 - val_loss: 0.9251 - val_acc: 0.8714

Epoch 00011: loss did not improve from 0.99136
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7997 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.9559 - acc: 0.9281 - val_loss: 0.7703 - val_acc: 0.9000

Epoch 00012: loss improved from 0.99136 to 0.95587, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7741 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.9577 - acc: 0.9245 - val_loss: 0.7955 - val_acc: 0.8714

Epoch 00013: loss did not improve from 0.95587
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7065 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.9136 - acc: 0.9353 - val_loss: 0.7353 - val_acc: 0.8857

Epoch 00014: loss improved from 0.95587 to 0.91361, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7399 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.8790 - acc: 0.9281 - val_loss: 0.8284 - val_acc: 0.9286

Epoch 00015: loss improved from 0.91361 to 0.87897, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6845 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.8916 - acc: 0.9424 - val_loss: 0.8210 - val_acc: 0.8857

Epoch 00016: loss did not improve from 0.87897
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6220 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.7995 - acc: 0.9424 - val_loss: 0.7102 - val_acc: 0.9000

Epoch 00017: loss improved from 0.87897 to 0.79950, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6124 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.9148 - acc: 0.9137 - val_loss: 0.6276 - val_acc: 0.9000

Epoch 00018: loss did not improve from 0.79950
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6381 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.8354 - acc: 0.9460 - val_loss: 0.6250 - val_acc: 0.9143

Epoch 00019: loss did not improve from 0.79950
Epoch 20/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6471 - acc: 1.0000
278/278 [==============================] - 0s 31us/step - loss: 0.7986 - acc: 0.9604 - val_loss: 0.6773 - val_acc: 0.9286

Epoch 00020: loss improved from 0.79950 to 0.79856, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 21/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6035 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.7722 - acc: 0.9568 - val_loss: 0.7661 - val_acc: 0.8857

Epoch 00021: loss improved from 0.79856 to 0.77216, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 22/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5321 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.7855 - acc: 0.9496 - val_loss: 0.6646 - val_acc: 0.9143

Epoch 00022: loss did not improve from 0.77216
Epoch 23/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6392 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.9168 - acc: 0.9353 - val_loss: 1.0608 - val_acc: 0.8714

Epoch 00023: loss did not improve from 0.77216
Epoch 24/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6651 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.8142 - acc: 0.9424 - val_loss: 0.6868 - val_acc: 0.9000

Epoch 00024: loss did not improve from 0.77216
Epoch 25/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6080 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.7307 - acc: 0.9388 - val_loss: 0.6138 - val_acc: 0.9000

Epoch 00025: loss improved from 0.77216 to 0.73066, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 26/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7192 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.7648 - acc: 0.9388 - val_loss: 0.5829 - val_acc: 0.9143

Epoch 00026: loss did not improve from 0.73066
Epoch 27/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5455 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.6914 - acc: 0.9676 - val_loss: 0.7357 - val_acc: 0.9143

Epoch 00027: loss improved from 0.73066 to 0.69142, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 28/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5723 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.8480 - acc: 0.9353 - val_loss: 0.9752 - val_acc: 0.8857

Epoch 00028: loss did not improve from 0.69142
Epoch 29/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5538 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.7809 - acc: 0.9317 - val_loss: 0.6639 - val_acc: 0.9143

Epoch 00029: loss did not improve from 0.69142
Epoch 30/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5058 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.6627 - acc: 0.9281 - val_loss: 0.6721 - val_acc: 0.8857

Epoch 00030: loss improved from 0.69142 to 0.66270, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_6.h5
Epoch 31/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.4570 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.7167 - acc: 0.9424 - val_loss: 0.7798 - val_acc: 0.8857

Epoch 00031: loss did not improve from 0.66270
Epoch 32/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.4983 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.6896 - acc: 0.9317 - val_loss: 1.0187 - val_acc: 0.6714

Epoch 00032: loss did not improve from 0.66270
Epoch 33/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6842 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.7549 - acc: 0.9317 - val_loss: 0.9577 - val_acc: 0.8571

Epoch 00033: loss did not improve from 0.66270
Epoch 34/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5445 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.9713 - acc: 0.9065 - val_loss: 0.6169 - val_acc: 0.9000

Epoch 00034: loss did not improve from 0.66270
Epoch 35/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6863 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.7861 - acc: 0.9281 - val_loss: 0.6387 - val_acc: 0.9143
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:22,  1.83s/it]
Epoch 00035: loss did not improve from 0.66270
Epoch 00035: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.6791 - acc: 0.7188
278/278 [==============================] - 0s 983us/step - loss: 1.7362 - acc: 0.7518 - val_loss: 1.0998 - val_acc: 0.8429

Epoch 00001: loss improved from inf to 1.73622, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2420 - acc: 0.9062
278/278 [==============================] - 0s 35us/step - loss: 1.4382 - acc: 0.8561 - val_loss: 0.9961 - val_acc: 0.8429

Epoch 00002: loss improved from 1.73622 to 1.43824, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0964 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.3386 - acc: 0.8669 - val_loss: 0.9367 - val_acc: 0.8571

Epoch 00003: loss improved from 1.43824 to 1.33857, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9860 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.2356 - acc: 0.8957 - val_loss: 0.8322 - val_acc: 0.9000

Epoch 00004: loss improved from 1.33857 to 1.23562, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1550 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.2104 - acc: 0.8849 - val_loss: 0.8652 - val_acc: 0.8857

Epoch 00005: loss improved from 1.23562 to 1.21037, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0913 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.1629 - acc: 0.9101 - val_loss: 0.8346 - val_acc: 0.9000

Epoch 00006: loss improved from 1.21037 to 1.16288, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9736 - acc: 0.9062
278/278 [==============================] - 0s 33us/step - loss: 1.1604 - acc: 0.9029 - val_loss: 0.8602 - val_acc: 0.9000

Epoch 00007: loss improved from 1.16288 to 1.16043, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9221 - acc: 0.9062
278/278 [==============================] - 0s 33us/step - loss: 1.1330 - acc: 0.9137 - val_loss: 0.8478 - val_acc: 0.8714

Epoch 00008: loss improved from 1.16043 to 1.13298, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9901 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.0960 - acc: 0.9209 - val_loss: 0.8681 - val_acc: 0.8857

Epoch 00009: loss improved from 1.13298 to 1.09605, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8722 - acc: 0.9375
278/278 [==============================] - 0s 32us/step - loss: 1.1655 - acc: 0.9137 - val_loss: 0.9742 - val_acc: 0.8571

Epoch 00010: loss did not improve from 1.09605
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9943 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.1689 - acc: 0.9065 - val_loss: 0.8267 - val_acc: 0.8714

Epoch 00011: loss did not improve from 1.09605
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9595 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.0528 - acc: 0.9029 - val_loss: 0.7618 - val_acc: 0.9143

Epoch 00012: loss improved from 1.09605 to 1.05285, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4957 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.1486 - acc: 0.9065 - val_loss: 0.8317 - val_acc: 0.8714

Epoch 00013: loss did not improve from 1.05285
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7418 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 0.9171 - acc: 0.9173 - val_loss: 0.7507 - val_acc: 0.9000

Epoch 00014: loss improved from 1.05285 to 0.91707, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7609 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.8690 - acc: 0.9281 - val_loss: 0.7976 - val_acc: 0.8857

Epoch 00015: loss improved from 0.91707 to 0.86902, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6044 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.9767 - acc: 0.9281 - val_loss: 0.9260 - val_acc: 0.8429

Epoch 00016: loss did not improve from 0.86902
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7242 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.0728 - acc: 0.8957 - val_loss: 1.2522 - val_acc: 0.8143

Epoch 00017: loss did not improve from 0.86902
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8674 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.0465 - acc: 0.9137 - val_loss: 1.0723 - val_acc: 0.8286

Epoch 00018: loss did not improve from 0.86902
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7058 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.0082 - acc: 0.9029 - val_loss: 0.8883 - val_acc: 0.8857

Epoch 00019: loss did not improve from 0.86902
Epoch 20/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6293 - acc: 0.9688
278/278 [==============================] - 0s 30us/step - loss: 0.9097 - acc: 0.9317 - val_loss: 0.7735 - val_acc: 0.8714
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:03<00:19,  1.79s/it]
Epoch 00020: loss did not improve from 0.86902
Epoch 00020: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.7512 - acc: 0.6875
278/278 [==============================] - 0s 949us/step - loss: 1.7750 - acc: 0.7914 - val_loss: 1.0626 - val_acc: 0.8286

Epoch 00001: loss improved from inf to 1.77503, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2814 - acc: 0.8438
278/278 [==============================] - 0s 34us/step - loss: 1.4689 - acc: 0.8417 - val_loss: 1.0991 - val_acc: 0.8286

Epoch 00002: loss improved from 1.77503 to 1.46888, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3568 - acc: 0.7812
278/278 [==============================] - 0s 32us/step - loss: 1.3962 - acc: 0.8525 - val_loss: 1.1074 - val_acc: 0.8429

Epoch 00003: loss improved from 1.46888 to 1.39617, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2000 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.4316 - acc: 0.8561 - val_loss: 1.0368 - val_acc: 0.8429

Epoch 00004: loss did not improve from 1.39617
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1999 - acc: 0.8438
278/278 [==============================] - 0s 31us/step - loss: 1.2374 - acc: 0.8669 - val_loss: 0.9865 - val_acc: 0.8857

Epoch 00005: loss improved from 1.39617 to 1.23737, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2124 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.3436 - acc: 0.8525 - val_loss: 0.9149 - val_acc: 0.8714

Epoch 00006: loss did not improve from 1.23737
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1037 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.3846 - acc: 0.8741 - val_loss: 0.9219 - val_acc: 0.8571

Epoch 00007: loss did not improve from 1.23737
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1079 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.2403 - acc: 0.8849 - val_loss: 0.8654 - val_acc: 0.8714

Epoch 00008: loss did not improve from 1.23737
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9423 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2019 - acc: 0.9101 - val_loss: 0.8841 - val_acc: 0.8714

Epoch 00009: loss improved from 1.23737 to 1.20191, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8741 - acc: 0.9375
278/278 [==============================] - 0s 32us/step - loss: 1.1278 - acc: 0.9245 - val_loss: 0.8280 - val_acc: 0.8714

Epoch 00010: loss improved from 1.20191 to 1.12780, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7457 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.1775 - acc: 0.8957 - val_loss: 0.9501 - val_acc: 0.8571

Epoch 00011: loss did not improve from 1.12780
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9195 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.1838 - acc: 0.8957 - val_loss: 0.8598 - val_acc: 0.8714

Epoch 00012: loss did not improve from 1.12780
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9263 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 1.0835 - acc: 0.8993 - val_loss: 0.7719 - val_acc: 0.8571

Epoch 00013: loss improved from 1.12780 to 1.08350, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7779 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.0263 - acc: 0.8921 - val_loss: 0.7667 - val_acc: 0.8857

Epoch 00014: loss improved from 1.08350 to 1.02632, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7628 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.0857 - acc: 0.9101 - val_loss: 0.9761 - val_acc: 0.8714

Epoch 00015: loss did not improve from 1.02632
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8520 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.0004 - acc: 0.9029 - val_loss: 0.7831 - val_acc: 0.8714

Epoch 00016: loss improved from 1.02632 to 1.00040, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7658 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 0.9725 - acc: 0.9281 - val_loss: 1.1761 - val_acc: 0.5571

Epoch 00017: loss improved from 1.00040 to 0.97251, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8440 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.0847 - acc: 0.9029 - val_loss: 0.8812 - val_acc: 0.8429

Epoch 00018: loss did not improve from 0.97251
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7069 - acc: 0.9688
278/278 [==============================] - 0s 30us/step - loss: 0.9716 - acc: 0.9137 - val_loss: 0.7370 - val_acc: 0.8714

Epoch 00019: loss improved from 0.97251 to 0.97163, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 20/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7828 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.9926 - acc: 0.9065 - val_loss: 0.9206 - val_acc: 0.8571

Epoch 00020: loss did not improve from 0.97163
Epoch 21/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7264 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.0748 - acc: 0.8921 - val_loss: 1.0002 - val_acc: 0.8714

Epoch 00021: loss did not improve from 0.97163
Epoch 22/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9834 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.1235 - acc: 0.8921 - val_loss: 0.8160 - val_acc: 0.8429

Epoch 00022: loss did not improve from 0.97163
Epoch 23/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8469 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.0287 - acc: 0.8921 - val_loss: 0.8496 - val_acc: 0.8571

Epoch 00023: loss did not improve from 0.97163
Epoch 24/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8557 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 0.9458 - acc: 0.9101 - val_loss: 0.7512 - val_acc: 0.9000

Epoch 00024: loss improved from 0.97163 to 0.94582, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 25/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7325 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.9369 - acc: 0.9101 - val_loss: 0.6818 - val_acc: 0.9000

Epoch 00025: loss improved from 0.94582 to 0.93691, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 26/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6818 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.9439 - acc: 0.9173 - val_loss: 0.7783 - val_acc: 0.8571

Epoch 00026: loss did not improve from 0.93691
Epoch 27/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7794 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.9624 - acc: 0.8993 - val_loss: 0.7950 - val_acc: 0.8571

Epoch 00027: loss did not improve from 0.93691
Epoch 28/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5968 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.8765 - acc: 0.9101 - val_loss: 0.7058 - val_acc: 0.9000

Epoch 00028: loss improved from 0.93691 to 0.87655, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 29/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6233 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.8905 - acc: 0.9137 - val_loss: 0.6791 - val_acc: 0.9143

Epoch 00029: loss did not improve from 0.87655
Epoch 30/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7163 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 0.8354 - acc: 0.9317 - val_loss: 0.7441 - val_acc: 0.8857

Epoch 00030: loss improved from 0.87655 to 0.83545, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 31/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5468 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.0305 - acc: 0.8993 - val_loss: 0.9577 - val_acc: 0.8714

Epoch 00031: loss did not improve from 0.83545
Epoch 32/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6196 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 0.8829 - acc: 0.9173 - val_loss: 0.6309 - val_acc: 0.9000

Epoch 00032: loss did not improve from 0.83545
Epoch 33/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6096 - acc: 0.9688
278/278 [==============================] - 0s 30us/step - loss: 0.8041 - acc: 0.9353 - val_loss: 0.7872 - val_acc: 0.8857

Epoch 00033: loss improved from 0.83545 to 0.80409, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 34/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5269 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.7570 - acc: 0.9532 - val_loss: 0.6589 - val_acc: 0.9143

Epoch 00034: loss improved from 0.80409 to 0.75696, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_8.h5
Epoch 35/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.4600 - acc: 0.9688
278/278 [==============================] - 0s 31us/step - loss: 0.8351 - acc: 0.9209 - val_loss: 0.6124 - val_acc: 0.8857

Epoch 00035: loss did not improve from 0.75696
Epoch 36/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7188 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 0.9442 - acc: 0.9137 - val_loss: 0.6007 - val_acc: 0.9286

Epoch 00036: loss did not improve from 0.75696
Epoch 37/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6900 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.7734 - acc: 0.9281 - val_loss: 0.5935 - val_acc: 0.9143

Epoch 00037: loss did not improve from 0.75696
Epoch 38/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7296 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.0312 - acc: 0.8885 - val_loss: 0.7983 - val_acc: 0.8714

Epoch 00038: loss did not improve from 0.75696
Epoch 39/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7315 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 0.8429 - acc: 0.9209 - val_loss: 0.6523 - val_acc: 0.9286
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:05<00:18,  1.87s/it]
Epoch 00039: loss did not improve from 0.75696
Epoch 00039: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.5363 - acc: 0.7500
278/278 [==============================] - 0s 956us/step - loss: 1.7749 - acc: 0.8058 - val_loss: 1.1725 - val_acc: 0.8286

Epoch 00001: loss improved from inf to 1.77486, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4911 - acc: 0.8750
278/278 [==============================] - 0s 33us/step - loss: 1.5729 - acc: 0.8273 - val_loss: 1.1215 - val_acc: 0.8286

Epoch 00002: loss improved from 1.77486 to 1.57288, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2210 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.4415 - acc: 0.8417 - val_loss: 1.0169 - val_acc: 0.8571

Epoch 00003: loss improved from 1.57288 to 1.44152, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1898 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.3085 - acc: 0.8885 - val_loss: 0.9504 - val_acc: 0.8714

Epoch 00004: loss improved from 1.44152 to 1.30845, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1088 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.5115 - acc: 0.8453 - val_loss: 1.2843 - val_acc: 0.8143

Epoch 00005: loss did not improve from 1.30845
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1038 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2946 - acc: 0.8921 - val_loss: 0.8025 - val_acc: 0.8857

Epoch 00006: loss improved from 1.30845 to 1.29462, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9529 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.3104 - acc: 0.8993 - val_loss: 0.9306 - val_acc: 0.8714

Epoch 00007: loss did not improve from 1.29462
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2190 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.3236 - acc: 0.8849 - val_loss: 0.9284 - val_acc: 0.8857

Epoch 00008: loss did not improve from 1.29462
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0403 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2243 - acc: 0.8993 - val_loss: 0.8735 - val_acc: 0.8571

Epoch 00009: loss improved from 1.29462 to 1.22433, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9224 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.2102 - acc: 0.8777 - val_loss: 0.9460 - val_acc: 0.8714

Epoch 00010: loss improved from 1.22433 to 1.21021, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9022 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.1113 - acc: 0.8957 - val_loss: 0.8532 - val_acc: 0.8714

Epoch 00011: loss improved from 1.21021 to 1.11127, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9216 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.0730 - acc: 0.8993 - val_loss: 0.8517 - val_acc: 0.8714

Epoch 00012: loss improved from 1.11127 to 1.07305, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9460 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.2155 - acc: 0.8813 - val_loss: 0.8117 - val_acc: 0.8714

Epoch 00013: loss did not improve from 1.07305
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8117 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.2735 - acc: 0.8921 - val_loss: 0.9758 - val_acc: 0.8714

Epoch 00014: loss did not improve from 1.07305
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7698 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.0985 - acc: 0.9029 - val_loss: 1.0349 - val_acc: 0.8714

Epoch 00015: loss did not improve from 1.07305
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7851 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 1.1659 - acc: 0.8921 - val_loss: 0.9467 - val_acc: 0.8714

Epoch 00016: loss did not improve from 1.07305
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7065 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 0.9531 - acc: 0.9137 - val_loss: 0.9012 - val_acc: 0.8714

Epoch 00017: loss improved from 1.07305 to 0.95308, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7179 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.0944 - acc: 0.9137 - val_loss: 0.8265 - val_acc: 0.9143

Epoch 00018: loss did not improve from 0.95308
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6934 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 0.9534 - acc: 0.9137 - val_loss: 0.7305 - val_acc: 0.9286

Epoch 00019: loss did not improve from 0.95308
Epoch 20/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7435 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 0.9513 - acc: 0.9317 - val_loss: 1.1149 - val_acc: 0.8857

Epoch 00020: loss improved from 0.95308 to 0.95128, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 21/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6616 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.9619 - acc: 0.9281 - val_loss: 0.8233 - val_acc: 0.8857

Epoch 00021: loss did not improve from 0.95128
Epoch 22/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6753 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 0.9741 - acc: 0.9137 - val_loss: 0.9283 - val_acc: 0.8714

Epoch 00022: loss did not improve from 0.95128
Epoch 23/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6989 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 0.9625 - acc: 0.8993 - val_loss: 0.8329 - val_acc: 0.8857

Epoch 00023: loss did not improve from 0.95128
Epoch 24/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6700 - acc: 0.9688
278/278 [==============================] - 0s 30us/step - loss: 1.0014 - acc: 0.9173 - val_loss: 0.7646 - val_acc: 0.8571

Epoch 00024: loss did not improve from 0.95128
Epoch 25/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5895 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 0.9104 - acc: 0.9137 - val_loss: 0.7507 - val_acc: 0.8714

Epoch 00025: loss improved from 0.95128 to 0.91043, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_9.h5
Epoch 26/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6066 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 0.9305 - acc: 0.9209 - val_loss: 0.8998 - val_acc: 0.8857

Epoch 00026: loss did not improve from 0.91043
Epoch 27/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8916 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.0602 - acc: 0.9245 - val_loss: 1.4185 - val_acc: 0.8714

Epoch 00027: loss did not improve from 0.91043
Epoch 28/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9588 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 0.9277 - acc: 0.9173 - val_loss: 0.8009 - val_acc: 0.8714

Epoch 00028: loss did not improve from 0.91043
Epoch 29/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8170 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.0492 - acc: 0.9137 - val_loss: 0.9955 - val_acc: 0.8571

Epoch 00029: loss did not improve from 0.91043
Epoch 30/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.5858 - acc: 0.9688
278/278 [==============================] - 0s 30us/step - loss: 0.9335 - acc: 0.9065 - val_loss: 0.9422 - val_acc: 0.8571
DeepAmes+ Weights:  31%|███       | 4/13 [00:07<00:16,  1.81s/it]
Epoch 00030: loss did not improve from 0.91043
Epoch 00030: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.4773 - acc: 0.7500
278/278 [==============================] - 0s 959us/step - loss: 1.8036 - acc: 0.7842 - val_loss: 1.0600 - val_acc: 0.8571

Epoch 00001: loss improved from inf to 1.80365, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4066 - acc: 0.7812
278/278 [==============================] - 0s 33us/step - loss: 1.5741 - acc: 0.8165 - val_loss: 0.9232 - val_acc: 0.8429

Epoch 00002: loss improved from 1.80365 to 1.57411, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.5222 - acc: 0.8125
278/278 [==============================] - 0s 32us/step - loss: 1.4782 - acc: 0.8489 - val_loss: 0.9347 - val_acc: 0.8429

Epoch 00003: loss improved from 1.57411 to 1.47817, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2067 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.3936 - acc: 0.8705 - val_loss: 0.9677 - val_acc: 0.8429

Epoch 00004: loss improved from 1.47817 to 1.39362, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0497 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.3741 - acc: 0.8741 - val_loss: 1.0493 - val_acc: 0.8286

Epoch 00005: loss improved from 1.39362 to 1.37411, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1773 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.4310 - acc: 0.8669 - val_loss: 0.9121 - val_acc: 0.8143

Epoch 00006: loss did not improve from 1.37411
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1263 - acc: 0.8438
278/278 [==============================] - 0s 31us/step - loss: 1.2891 - acc: 0.8813 - val_loss: 1.1022 - val_acc: 0.8143

Epoch 00007: loss improved from 1.37411 to 1.28912, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0387 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.3901 - acc: 0.8777 - val_loss: 1.5691 - val_acc: 0.8286

Epoch 00008: loss did not improve from 1.28912
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1263 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.3453 - acc: 0.8993 - val_loss: 1.0942 - val_acc: 0.8286

Epoch 00009: loss did not improve from 1.28912
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9946 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.1791 - acc: 0.8957 - val_loss: 1.0572 - val_acc: 0.8571

Epoch 00010: loss improved from 1.28912 to 1.17908, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8131 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2171 - acc: 0.9101 - val_loss: 1.1227 - val_acc: 0.8286

Epoch 00011: loss did not improve from 1.17908
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9444 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2396 - acc: 0.9029 - val_loss: 1.1231 - val_acc: 0.6143

Epoch 00012: loss did not improve from 1.17908
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8139 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.1591 - acc: 0.8921 - val_loss: 1.1024 - val_acc: 0.8571

Epoch 00013: loss improved from 1.17908 to 1.15910, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9080 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.1710 - acc: 0.8993 - val_loss: 1.3293 - val_acc: 0.5143

Epoch 00014: loss did not improve from 1.15910
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7985 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 1.0640 - acc: 0.9137 - val_loss: 0.9237 - val_acc: 0.8429

Epoch 00015: loss improved from 1.15910 to 1.06399, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7801 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2668 - acc: 0.8885 - val_loss: 1.7626 - val_acc: 0.8429

Epoch 00016: loss did not improve from 1.06399
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3053 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.4635 - acc: 0.8777 - val_loss: 0.9219 - val_acc: 0.8571

Epoch 00017: loss did not improve from 1.06399
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9204 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.1051 - acc: 0.9137 - val_loss: 0.9201 - val_acc: 0.8714

Epoch 00018: loss did not improve from 1.06399
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3428 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.2709 - acc: 0.8993 - val_loss: 0.9555 - val_acc: 0.8571

Epoch 00019: loss did not improve from 1.06399
Epoch 20/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7382 - acc: 1.0000
278/278 [==============================] - 0s 30us/step - loss: 1.0350 - acc: 0.9281 - val_loss: 1.0308 - val_acc: 0.8429

Epoch 00020: loss improved from 1.06399 to 1.03496, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_10.h5
Epoch 21/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9557 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.1379 - acc: 0.8921 - val_loss: 0.9818 - val_acc: 0.8571

Epoch 00021: loss did not improve from 1.03496
Epoch 22/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.6795 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 1.1064 - acc: 0.9173 - val_loss: 1.0667 - val_acc: 0.8571

Epoch 00022: loss did not improve from 1.03496
Epoch 23/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0064 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.1828 - acc: 0.9101 - val_loss: 0.8482 - val_acc: 0.8857

Epoch 00023: loss did not improve from 1.03496
Epoch 24/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0100 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.1867 - acc: 0.8849 - val_loss: 0.8316 - val_acc: 0.9000

Epoch 00024: loss did not improve from 1.03496
Epoch 25/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7069 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 1.0698 - acc: 0.9101 - val_loss: 0.8068 - val_acc: 0.8857
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:09<00:14,  1.81s/it]
Epoch 00025: loss did not improve from 1.03496
Epoch 00025: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.6788 - acc: 0.7188
278/278 [==============================] - 0s 977us/step - loss: 1.8793 - acc: 0.7698 - val_loss: 1.1557 - val_acc: 0.7857

Epoch 00001: loss improved from inf to 1.87933, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4835 - acc: 0.7500
278/278 [==============================] - 0s 34us/step - loss: 1.6187 - acc: 0.8309 - val_loss: 1.1672 - val_acc: 0.8143

Epoch 00002: loss improved from 1.87933 to 1.61868, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3223 - acc: 0.9062
278/278 [==============================] - 0s 33us/step - loss: 1.6658 - acc: 0.8489 - val_loss: 1.2233 - val_acc: 0.8000

Epoch 00003: loss did not improve from 1.61868
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3523 - acc: 0.8125
278/278 [==============================] - 0s 32us/step - loss: 1.5194 - acc: 0.8273 - val_loss: 1.0588 - val_acc: 0.8143

Epoch 00004: loss improved from 1.61868 to 1.51945, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1651 - acc: 0.9062
278/278 [==============================] - 0s 33us/step - loss: 1.5129 - acc: 0.8633 - val_loss: 1.1891 - val_acc: 0.8286

Epoch 00005: loss improved from 1.51945 to 1.51286, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2171 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.3051 - acc: 0.8849 - val_loss: 0.9735 - val_acc: 0.8286

Epoch 00006: loss improved from 1.51286 to 1.30511, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1026 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.4335 - acc: 0.8633 - val_loss: 1.0429 - val_acc: 0.8143

Epoch 00007: loss did not improve from 1.30511
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0489 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.3238 - acc: 0.9101 - val_loss: 0.9692 - val_acc: 0.8571

Epoch 00008: loss did not improve from 1.30511
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9483 - acc: 0.9375
278/278 [==============================] - 0s 32us/step - loss: 1.4302 - acc: 0.8813 - val_loss: 1.5370 - val_acc: 0.8000

Epoch 00009: loss did not improve from 1.30511
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2190 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.4362 - acc: 0.8597 - val_loss: 1.0217 - val_acc: 0.8143

Epoch 00010: loss did not improve from 1.30511
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1025 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.3506 - acc: 0.8813 - val_loss: 0.9759 - val_acc: 0.8429
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:10<00:12,  1.75s/it]
Epoch 00011: loss did not improve from 1.30511
Epoch 00011: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.6037 - acc: 0.6875
278/278 [==============================] - 0s 954us/step - loss: 1.7421 - acc: 0.8022 - val_loss: 1.2896 - val_acc: 0.6143

Epoch 00001: loss improved from inf to 1.74205, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.8092 - acc: 0.6562
278/278 [==============================] - 0s 34us/step - loss: 1.8186 - acc: 0.7734 - val_loss: 1.4094 - val_acc: 0.8429

Epoch 00002: loss did not improve from 1.74205
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3040 - acc: 0.8750
278/278 [==============================] - 0s 33us/step - loss: 1.5598 - acc: 0.8273 - val_loss: 1.2465 - val_acc: 0.8143

Epoch 00003: loss improved from 1.74205 to 1.55979, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3043 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.5521 - acc: 0.8489 - val_loss: 1.1458 - val_acc: 0.8143

Epoch 00004: loss improved from 1.55979 to 1.55207, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0756 - acc: 0.8125
278/278 [==============================] - 0s 32us/step - loss: 1.4235 - acc: 0.8453 - val_loss: 1.1177 - val_acc: 0.8143

Epoch 00005: loss improved from 1.55207 to 1.42354, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1751 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.4540 - acc: 0.8597 - val_loss: 1.0109 - val_acc: 0.8143

Epoch 00006: loss did not improve from 1.42354
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0999 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.3433 - acc: 0.8741 - val_loss: 1.0082 - val_acc: 0.8286

Epoch 00007: loss improved from 1.42354 to 1.34331, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1465 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.2905 - acc: 0.8705 - val_loss: 1.1177 - val_acc: 0.8286

Epoch 00008: loss improved from 1.34331 to 1.29049, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0347 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.3839 - acc: 0.8885 - val_loss: 1.0568 - val_acc: 0.8429

Epoch 00009: loss did not improve from 1.29049
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8639 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.1742 - acc: 0.8885 - val_loss: 0.8912 - val_acc: 0.8429

Epoch 00010: loss improved from 1.29049 to 1.17422, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8997 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.1776 - acc: 0.9029 - val_loss: 1.3208 - val_acc: 0.8429

Epoch 00011: loss did not improve from 1.17422
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8650 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.1831 - acc: 0.9029 - val_loss: 0.9593 - val_acc: 0.8286

Epoch 00012: loss did not improve from 1.17422
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9161 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.3377 - acc: 0.8921 - val_loss: 1.1108 - val_acc: 0.8286

Epoch 00013: loss did not improve from 1.17422
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0544 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.2946 - acc: 0.9065 - val_loss: 1.5690 - val_acc: 0.8429

Epoch 00014: loss did not improve from 1.17422
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0992 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.6822 - acc: 0.8777 - val_loss: 1.6061 - val_acc: 0.8286
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:12<00:10,  1.69s/it]
Epoch 00015: loss did not improve from 1.17422
Epoch 00015: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.5627 - acc: 0.7500
278/278 [==============================] - 0s 972us/step - loss: 2.0290 - acc: 0.7698 - val_loss: 1.1717 - val_acc: 0.8571

Epoch 00001: loss improved from inf to 2.02902, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4191 - acc: 0.7500
278/278 [==============================] - 0s 34us/step - loss: 1.6289 - acc: 0.8058 - val_loss: 1.1490 - val_acc: 0.8286

Epoch 00002: loss improved from 2.02902 to 1.62892, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3100 - acc: 0.7500
278/278 [==============================] - 0s 33us/step - loss: 1.5798 - acc: 0.8165 - val_loss: 1.0720 - val_acc: 0.8143

Epoch 00003: loss improved from 1.62892 to 1.57978, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0908 - acc: 0.8750
278/278 [==============================] - 0s 33us/step - loss: 1.4965 - acc: 0.8525 - val_loss: 1.0501 - val_acc: 0.8286

Epoch 00004: loss improved from 1.57978 to 1.49655, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0911 - acc: 0.9375
278/278 [==============================] - 0s 32us/step - loss: 1.4507 - acc: 0.8921 - val_loss: 0.9830 - val_acc: 0.8143

Epoch 00005: loss improved from 1.49655 to 1.45074, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0388 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.3156 - acc: 0.8705 - val_loss: 0.9167 - val_acc: 0.8714

Epoch 00006: loss improved from 1.45074 to 1.31561, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9697 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.2931 - acc: 0.8813 - val_loss: 1.3576 - val_acc: 0.5286

Epoch 00007: loss improved from 1.31561 to 1.29307, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9525 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.2043 - acc: 0.8957 - val_loss: 1.1071 - val_acc: 0.8571

Epoch 00008: loss improved from 1.29307 to 1.20430, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7785 - acc: 0.9375
278/278 [==============================] - 0s 32us/step - loss: 1.2498 - acc: 0.8921 - val_loss: 1.3534 - val_acc: 0.8714

Epoch 00009: loss did not improve from 1.20430
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0850 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.2248 - acc: 0.8993 - val_loss: 1.3578 - val_acc: 0.3000

Epoch 00010: loss did not improve from 1.20430
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1895 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.4110 - acc: 0.9065 - val_loss: 1.4088 - val_acc: 0.8286

Epoch 00011: loss did not improve from 1.20430
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1845 - acc: 0.8438
278/278 [==============================] - 0s 31us/step - loss: 1.3155 - acc: 0.8525 - val_loss: 1.0618 - val_acc: 0.8714

Epoch 00012: loss did not improve from 1.20430
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9623 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.2203 - acc: 0.8993 - val_loss: 0.9117 - val_acc: 0.8857
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:13<00:08,  1.69s/it]
Epoch 00013: loss did not improve from 1.20430
Epoch 00013: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.6402 - acc: 0.6875
278/278 [==============================] - 0s 981us/step - loss: 2.1752 - acc: 0.7590 - val_loss: 1.3229 - val_acc: 0.8143

Epoch 00001: loss improved from inf to 2.17517, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.6270 - acc: 0.7812
278/278 [==============================] - 0s 34us/step - loss: 1.7753 - acc: 0.7446 - val_loss: 1.3188 - val_acc: 0.8000

Epoch 00002: loss improved from 2.17517 to 1.77529, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3938 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.5344 - acc: 0.8273 - val_loss: 1.1506 - val_acc: 0.8143

Epoch 00003: loss improved from 1.77529 to 1.53440, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2579 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.5247 - acc: 0.8669 - val_loss: 1.1343 - val_acc: 0.8143

Epoch 00004: loss improved from 1.53440 to 1.52474, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1874 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.6129 - acc: 0.8381 - val_loss: 1.3314 - val_acc: 0.8143

Epoch 00005: loss did not improve from 1.52474
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2742 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.6590 - acc: 0.8489 - val_loss: 0.9877 - val_acc: 0.8857

Epoch 00006: loss did not improve from 1.52474
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3984 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.4710 - acc: 0.8309 - val_loss: 0.9236 - val_acc: 0.8714

Epoch 00007: loss improved from 1.52474 to 1.47100, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.7494 - acc: 0.8125
278/278 [==============================] - 0s 32us/step - loss: 1.4956 - acc: 0.8453 - val_loss: 1.1535 - val_acc: 0.8143

Epoch 00008: loss did not improve from 1.47100
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9727 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.3117 - acc: 0.8885 - val_loss: 1.0274 - val_acc: 0.8714

Epoch 00009: loss improved from 1.47100 to 1.31169, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9498 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.2638 - acc: 0.9065 - val_loss: 0.9157 - val_acc: 0.8429

Epoch 00010: loss improved from 1.31169 to 1.26385, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8865 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.1889 - acc: 0.8885 - val_loss: 1.0529 - val_acc: 0.8429

Epoch 00011: loss improved from 1.26385 to 1.18891, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0556 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.2075 - acc: 0.8849 - val_loss: 0.9042 - val_acc: 0.8571

Epoch 00012: loss did not improve from 1.18891
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7657 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2499 - acc: 0.9065 - val_loss: 1.6967 - val_acc: 0.8286

Epoch 00013: loss did not improve from 1.18891
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1709 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.4308 - acc: 0.8741 - val_loss: 1.1534 - val_acc: 0.8286

Epoch 00014: loss did not improve from 1.18891
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9863 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.1456 - acc: 0.8849 - val_loss: 1.0311 - val_acc: 0.8571

Epoch 00015: loss improved from 1.18891 to 1.14556, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_14.h5
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8948 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.2343 - acc: 0.8849 - val_loss: 0.9206 - val_acc: 0.8571

Epoch 00016: loss did not improve from 1.14556
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9026 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2883 - acc: 0.8813 - val_loss: 1.0807 - val_acc: 0.8429

Epoch 00017: loss did not improve from 1.14556
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7948 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.5903 - acc: 0.8525 - val_loss: 2.0142 - val_acc: 0.8714

Epoch 00018: loss did not improve from 1.14556
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1863 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.6081 - acc: 0.8777 - val_loss: 1.4215 - val_acc: 0.8571

Epoch 00019: loss did not improve from 1.14556
Epoch 20/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3639 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.4595 - acc: 0.8813 - val_loss: 1.0096 - val_acc: 0.8714
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:15<00:06,  1.70s/it]
Epoch 00020: loss did not improve from 1.14556
Epoch 00020: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 2.3775 - acc: 0.6875
278/278 [==============================] - 0s 941us/step - loss: 2.0999 - acc: 0.7914 - val_loss: 1.3283 - val_acc: 0.8429

Epoch 00001: loss improved from inf to 2.09990, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.5335 - acc: 0.8750
278/278 [==============================] - 0s 34us/step - loss: 1.8173 - acc: 0.8273 - val_loss: 1.2871 - val_acc: 0.8429

Epoch 00002: loss improved from 2.09990 to 1.81727, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.5226 - acc: 0.8125
278/278 [==============================] - 0s 33us/step - loss: 1.7618 - acc: 0.8022 - val_loss: 1.3555 - val_acc: 0.7857

Epoch 00003: loss improved from 1.81727 to 1.76179, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3007 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.5815 - acc: 0.8381 - val_loss: 1.3162 - val_acc: 0.8000

Epoch 00004: loss improved from 1.76179 to 1.58147, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3212 - acc: 0.9062
278/278 [==============================] - 0s 32us/step - loss: 1.7318 - acc: 0.8597 - val_loss: 1.4722 - val_acc: 0.8000

Epoch 00005: loss did not improve from 1.58147
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3824 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.5999 - acc: 0.8525 - val_loss: 1.0674 - val_acc: 0.8143

Epoch 00006: loss did not improve from 1.58147
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2855 - acc: 0.8438
278/278 [==============================] - 0s 31us/step - loss: 1.5953 - acc: 0.8489 - val_loss: 1.3267 - val_acc: 0.8000

Epoch 00007: loss did not improve from 1.58147
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2039 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.6052 - acc: 0.8669 - val_loss: 1.4397 - val_acc: 0.7857

Epoch 00008: loss did not improve from 1.58147
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3081 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.4724 - acc: 0.8633 - val_loss: 1.4170 - val_acc: 0.4857

Epoch 00009: loss improved from 1.58147 to 1.47240, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1688 - acc: 0.7812
278/278 [==============================] - 0s 32us/step - loss: 1.5449 - acc: 0.8309 - val_loss: 1.3264 - val_acc: 0.8286

Epoch 00010: loss did not improve from 1.47240
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3517 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.7807 - acc: 0.8597 - val_loss: 0.8307 - val_acc: 0.9000

Epoch 00011: loss did not improve from 1.47240
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4418 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.5882 - acc: 0.8453 - val_loss: 0.8756 - val_acc: 0.8571

Epoch 00012: loss did not improve from 1.47240
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2281 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.3756 - acc: 0.8273 - val_loss: 0.8642 - val_acc: 0.8857

Epoch 00013: loss improved from 1.47240 to 1.37558, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9821 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.5904 - acc: 0.8489 - val_loss: 1.3940 - val_acc: 0.8571

Epoch 00014: loss did not improve from 1.37558
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3210 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.6115 - acc: 0.8525 - val_loss: 0.9167 - val_acc: 0.8571

Epoch 00015: loss did not improve from 1.37558
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1960 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.4134 - acc: 0.8885 - val_loss: 0.8506 - val_acc: 0.8429

Epoch 00016: loss did not improve from 1.37558
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0558 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2650 - acc: 0.8741 - val_loss: 0.8208 - val_acc: 0.8429

Epoch 00017: loss improved from 1.37558 to 1.26498, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9835 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.2825 - acc: 0.9065 - val_loss: 1.2043 - val_acc: 0.8571

Epoch 00018: loss did not improve from 1.26498
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9566 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.2646 - acc: 0.8705 - val_loss: 0.9504 - val_acc: 0.8857

Epoch 00019: loss improved from 1.26498 to 1.26455, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 20/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8926 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.2479 - acc: 0.8885 - val_loss: 1.1149 - val_acc: 0.8571

Epoch 00020: loss improved from 1.26455 to 1.24790, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 21/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0778 - acc: 0.8438
278/278 [==============================] - 0s 31us/step - loss: 1.2349 - acc: 0.9101 - val_loss: 0.9249 - val_acc: 0.8571

Epoch 00021: loss improved from 1.24790 to 1.23487, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 22/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8302 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.3267 - acc: 0.8993 - val_loss: 0.8800 - val_acc: 0.8714

Epoch 00022: loss did not improve from 1.23487
Epoch 23/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.7971 - acc: 0.9375
278/278 [==============================] - 0s 30us/step - loss: 1.2239 - acc: 0.9065 - val_loss: 0.8575 - val_acc: 0.8857

Epoch 00023: loss improved from 1.23487 to 1.22389, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_15.h5
Epoch 24/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.8357 - acc: 0.8438
278/278 [==============================] - 0s 31us/step - loss: 1.6564 - acc: 0.8705 - val_loss: 1.0303 - val_acc: 0.8429

Epoch 00024: loss did not improve from 1.22389
Epoch 25/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8769 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.2454 - acc: 0.8813 - val_loss: 1.1433 - val_acc: 0.8571

Epoch 00025: loss did not improve from 1.22389
Epoch 26/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9214 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.2929 - acc: 0.8777 - val_loss: 1.2012 - val_acc: 0.8714

Epoch 00026: loss did not improve from 1.22389
Epoch 27/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1119 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.3964 - acc: 0.8597 - val_loss: 1.4730 - val_acc: 0.8286

Epoch 00027: loss did not improve from 1.22389
Epoch 28/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2018 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.2974 - acc: 0.8957 - val_loss: 0.9943 - val_acc: 0.8429
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:17<00:05,  1.73s/it]
Epoch 00028: loss did not improve from 1.22389
Epoch 00028: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.6439 - acc: 0.6875
278/278 [==============================] - 0s 957us/step - loss: 2.2052 - acc: 0.7518 - val_loss: 1.5209 - val_acc: 0.8143

Epoch 00001: loss improved from inf to 2.20518, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3671 - acc: 0.8750
278/278 [==============================] - 0s 34us/step - loss: 1.8271 - acc: 0.8201 - val_loss: 1.3716 - val_acc: 0.5857

Epoch 00002: loss improved from 2.20518 to 1.82713, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4312 - acc: 0.7500
278/278 [==============================] - 0s 32us/step - loss: 1.7204 - acc: 0.7806 - val_loss: 1.6675 - val_acc: 0.7857

Epoch 00003: loss improved from 1.82713 to 1.72037, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.5155 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.8412 - acc: 0.8165 - val_loss: 1.0185 - val_acc: 0.8429

Epoch 00004: loss did not improve from 1.72037
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.5027 - acc: 0.8125
278/278 [==============================] - 0s 31us/step - loss: 1.5498 - acc: 0.8237 - val_loss: 1.1635 - val_acc: 0.8286

Epoch 00005: loss improved from 1.72037 to 1.54984, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2037 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.5879 - acc: 0.8525 - val_loss: 1.2531 - val_acc: 0.7857

Epoch 00006: loss did not improve from 1.54984
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2352 - acc: 0.8438
278/278 [==============================] - 0s 31us/step - loss: 1.6059 - acc: 0.8129 - val_loss: 1.4342 - val_acc: 0.8429

Epoch 00007: loss did not improve from 1.54984
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.5359 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.7523 - acc: 0.8669 - val_loss: 1.1221 - val_acc: 0.8286

Epoch 00008: loss did not improve from 1.54984
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4809 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.5494 - acc: 0.8345 - val_loss: 0.9296 - val_acc: 0.8857

Epoch 00009: loss improved from 1.54984 to 1.54942, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.6077 - acc: 0.8125
278/278 [==============================] - 0s 31us/step - loss: 1.5629 - acc: 0.8561 - val_loss: 1.0529 - val_acc: 0.8286

Epoch 00010: loss did not improve from 1.54942
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0723 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.3722 - acc: 0.8489 - val_loss: 1.0425 - val_acc: 0.8000

Epoch 00011: loss improved from 1.54942 to 1.37223, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_16.h5
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1204 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.5374 - acc: 0.8705 - val_loss: 1.0864 - val_acc: 0.8286

Epoch 00012: loss did not improve from 1.37223
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0116 - acc: 0.8750
278/278 [==============================] - 0s 32us/step - loss: 1.3623 - acc: 0.8849 - val_loss: 1.1187 - val_acc: 0.7429

Epoch 00013: loss improved from 1.37223 to 1.36232, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_16.h5
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1998 - acc: 0.7188
278/278 [==============================] - 0s 31us/step - loss: 1.2340 - acc: 0.8489 - val_loss: 0.9361 - val_acc: 0.8286

Epoch 00014: loss improved from 1.36232 to 1.23403, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_16.h5
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9007 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.2757 - acc: 0.8849 - val_loss: 1.4481 - val_acc: 0.8000

Epoch 00015: loss did not improve from 1.23403
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2871 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.5859 - acc: 0.8237 - val_loss: 0.9595 - val_acc: 0.8286

Epoch 00016: loss did not improve from 1.23403
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9979 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.4573 - acc: 0.8417 - val_loss: 1.2615 - val_acc: 0.8286

Epoch 00017: loss did not improve from 1.23403
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1593 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.5105 - acc: 0.8525 - val_loss: 1.7037 - val_acc: 0.8000

Epoch 00018: loss did not improve from 1.23403
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1752 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.3868 - acc: 0.8525 - val_loss: 1.2222 - val_acc: 0.8286
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:19<00:03,  1.69s/it]
Epoch 00019: loss did not improve from 1.23403
Epoch 00019: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.5476 - acc: 0.6875
278/278 [==============================] - 0s 977us/step - loss: 2.2863 - acc: 0.7374 - val_loss: 1.5556 - val_acc: 0.7000

Epoch 00001: loss improved from inf to 2.28631, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.6340 - acc: 0.6875
278/278 [==============================] - 0s 34us/step - loss: 1.9017 - acc: 0.7806 - val_loss: 1.2175 - val_acc: 0.8143

Epoch 00002: loss improved from 2.28631 to 1.90170, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4619 - acc: 0.8125
278/278 [==============================] - 0s 32us/step - loss: 1.6846 - acc: 0.7878 - val_loss: 1.2738 - val_acc: 0.8143

Epoch 00003: loss improved from 1.90170 to 1.68462, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3497 - acc: 0.7812
278/278 [==============================] - 0s 32us/step - loss: 1.7573 - acc: 0.8094 - val_loss: 1.5444 - val_acc: 0.8000

Epoch 00004: loss did not improve from 1.68462
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4843 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.8310 - acc: 0.8165 - val_loss: 1.2151 - val_acc: 0.8429

Epoch 00005: loss did not improve from 1.68462
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3054 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.5733 - acc: 0.8237 - val_loss: 1.0860 - val_acc: 0.8143

Epoch 00006: loss improved from 1.68462 to 1.57327, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2327 - acc: 0.8438
278/278 [==============================] - 0s 32us/step - loss: 1.5435 - acc: 0.8813 - val_loss: 1.0204 - val_acc: 0.8429

Epoch 00007: loss improved from 1.57327 to 1.54352, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1555 - acc: 0.8125
278/278 [==============================] - 0s 32us/step - loss: 1.6622 - acc: 0.8309 - val_loss: 0.9639 - val_acc: 0.8000

Epoch 00008: loss did not improve from 1.54352
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2773 - acc: 0.7812
278/278 [==============================] - 0s 31us/step - loss: 1.5176 - acc: 0.8058 - val_loss: 1.2713 - val_acc: 0.8000

Epoch 00009: loss improved from 1.54352 to 1.51765, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3391 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.4917 - acc: 0.8453 - val_loss: 1.1825 - val_acc: 0.8000

Epoch 00010: loss improved from 1.51765 to 1.49166, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0215 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.4101 - acc: 0.8741 - val_loss: 1.1840 - val_acc: 0.8000

Epoch 00011: loss improved from 1.49166 to 1.41012, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1608 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.3018 - acc: 0.8921 - val_loss: 0.9898 - val_acc: 0.8429

Epoch 00012: loss improved from 1.41012 to 1.30181, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_17.h5
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0337 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.4196 - acc: 0.8813 - val_loss: 1.1124 - val_acc: 0.8143

Epoch 00013: loss did not improve from 1.30181
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0318 - acc: 0.9375
278/278 [==============================] - 0s 31us/step - loss: 1.3876 - acc: 0.8777 - val_loss: 1.1792 - val_acc: 0.8143

Epoch 00014: loss did not improve from 1.30181
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1646 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.3659 - acc: 0.8561 - val_loss: 1.5182 - val_acc: 0.8429

Epoch 00015: loss did not improve from 1.30181
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0902 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.4177 - acc: 0.8633 - val_loss: 0.9916 - val_acc: 0.8571

Epoch 00016: loss did not improve from 1.30181
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0799 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.4314 - acc: 0.8597 - val_loss: 0.9864 - val_acc: 0.8571
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:20<00:01,  1.70s/it]
Epoch 00017: loss did not improve from 1.30181
Epoch 00017: early stopping
Train on 278 samples, validate on 70 samples
Epoch 1/100

 32/278 [==>...........................] - ETA: 1s - loss: 1.6323 - acc: 0.7500
278/278 [==============================] - 0s 949us/step - loss: 2.0450 - acc: 0.7914 - val_loss: 1.0617 - val_acc: 0.8571

Epoch 00001: loss improved from inf to 2.04496, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4981 - acc: 0.7812
278/278 [==============================] - 0s 33us/step - loss: 1.9446 - acc: 0.7482 - val_loss: 1.2639 - val_acc: 0.8571

Epoch 00002: loss improved from 2.04496 to 1.94455, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.5384 - acc: 0.8125
278/278 [==============================] - 0s 32us/step - loss: 1.7781 - acc: 0.7662 - val_loss: 1.0838 - val_acc: 0.8143

Epoch 00003: loss improved from 1.94455 to 1.77805, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.4022 - acc: 0.7812
278/278 [==============================] - 0s 32us/step - loss: 1.6046 - acc: 0.7842 - val_loss: 1.0151 - val_acc: 0.8571

Epoch 00004: loss improved from 1.77805 to 1.60463, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2945 - acc: 0.8125
278/278 [==============================] - 0s 31us/step - loss: 1.6806 - acc: 0.8237 - val_loss: 1.0311 - val_acc: 0.8429

Epoch 00005: loss did not improve from 1.60463
Epoch 6/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2471 - acc: 0.8438
278/278 [==============================] - 0s 31us/step - loss: 1.5305 - acc: 0.8525 - val_loss: 1.0547 - val_acc: 0.8571

Epoch 00006: loss improved from 1.60463 to 1.53051, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1903 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.6046 - acc: 0.8237 - val_loss: 1.1062 - val_acc: 0.8143

Epoch 00007: loss did not improve from 1.53051
Epoch 8/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0981 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.5147 - acc: 0.8633 - val_loss: 1.1748 - val_acc: 0.8143

Epoch 00008: loss improved from 1.53051 to 1.51469, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.3820 - acc: 0.8125
278/278 [==============================] - 0s 31us/step - loss: 1.4149 - acc: 0.8201 - val_loss: 1.0625 - val_acc: 0.8571

Epoch 00009: loss improved from 1.51469 to 1.41488, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2618 - acc: 0.9062
278/278 [==============================] - 0s 31us/step - loss: 1.5314 - acc: 0.8597 - val_loss: 1.2687 - val_acc: 0.8286

Epoch 00010: loss did not improve from 1.41488
Epoch 11/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.2215 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.6113 - acc: 0.8489 - val_loss: 1.0541 - val_acc: 0.8571

Epoch 00011: loss did not improve from 1.41488
Epoch 12/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1461 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.3554 - acc: 0.8957 - val_loss: 1.0217 - val_acc: 0.8571

Epoch 00012: loss improved from 1.41488 to 1.35543, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 13/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.0377 - acc: 0.8750
278/278 [==============================] - 0s 31us/step - loss: 1.4663 - acc: 0.8705 - val_loss: 1.5420 - val_acc: 0.8571

Epoch 00013: loss did not improve from 1.35543
Epoch 14/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.8928 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.2147 - acc: 0.8705 - val_loss: 1.1650 - val_acc: 0.8286

Epoch 00014: loss improved from 1.35543 to 1.21465, saving model to ./results_TA1538_without_S9/DeepAmes_models/weight_18.h5
Epoch 15/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9881 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.5208 - acc: 0.8489 - val_loss: 2.1272 - val_acc: 0.8286

Epoch 00015: loss did not improve from 1.21465
Epoch 16/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.6269 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.6731 - acc: 0.8489 - val_loss: 1.7653 - val_acc: 0.2857

Epoch 00016: loss did not improve from 1.21465
Epoch 17/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.1434 - acc: 0.8750
278/278 [==============================] - 0s 30us/step - loss: 1.4201 - acc: 0.8417 - val_loss: 1.6098 - val_acc: 0.6429

Epoch 00017: loss did not improve from 1.21465
Epoch 18/100

 32/278 [==>...........................] - ETA: 0s - loss: 0.9170 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.5383 - acc: 0.8777 - val_loss: 2.2683 - val_acc: 0.8429

Epoch 00018: loss did not improve from 1.21465
Epoch 19/100

 32/278 [==>...........................] - ETA: 0s - loss: 1.5566 - acc: 0.9062
278/278 [==============================] - 0s 30us/step - loss: 1.9801 - acc: 0.8849 - val_loss: 2.1627 - val_acc: 0.8143
DeepAmes+ Weights: 100%|██████████| 13/13 [00:22<00:00,  1.70s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:22<00:00,  1.73s/it]

Epoch 00019: loss did not improve from 1.21465
Epoch 00019: early stopping
--- 1554.7747535705566 seconds ---

Generating metrics report for TA1538_without_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 185 samples.
Processing weight 7...
  Done. 185 samples.
Processing weight 8...
  Done. 185 samples.
Processing weight 9...
  Done. 185 samples.
Processing weight 10...
  Done. 185 samples.
Processing weight 11...
  Done. 185 samples.
Processing weight 12...
  Done. 185 samples.
Processing weight 13...
  Done. 185 samples.
Processing weight 14...
  Done. 185 samples.
Processing weight 15...
  Done. 185 samples.
Processing weight 16...
  Done. 185 samples.
Processing weight 17...
  Done. 185 samples.
Processing weight 18...
  Done. 185 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA1538_without_S9/metrics_report_TA1538_without_S9.txt

Done!

Completed TA1538_without_S9 in 1554.77 seconds

================================================================================
[13/16] Processing: TA97_with_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA97_with_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA97_with_S9_Test_mold2.csv
(1391, 777)
(1112, 777)
(134, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:02<00:55,  2.91s/it]KNN Seeds:  10%|█         | 2/20 [00:05<00:52,  2.91s/it]KNN Seeds:  15%|█▌        | 3/20 [00:08<00:49,  2.93s/it]KNN Seeds:  20%|██        | 4/20 [00:11<00:46,  2.93s/it]KNN Seeds:  25%|██▌       | 5/20 [00:14<00:44,  2.96s/it]KNN Seeds:  30%|███       | 6/20 [00:17<00:41,  2.95s/it]KNN Seeds:  35%|███▌      | 7/20 [00:20<00:38,  2.96s/it]KNN Seeds:  40%|████      | 8/20 [00:23<00:35,  2.97s/it]KNN Seeds:  45%|████▌     | 9/20 [00:26<00:32,  2.97s/it]KNN Seeds:  50%|█████     | 10/20 [00:29<00:29,  2.99s/it]KNN Seeds:  55%|█████▌    | 11/20 [00:32<00:27,  3.01s/it]KNN Seeds:  60%|██████    | 12/20 [00:35<00:24,  3.02s/it]KNN Seeds:  65%|██████▌   | 13/20 [00:38<00:21,  3.02s/it]KNN Seeds:  70%|███████   | 14/20 [00:41<00:18,  3.03s/it]KNN Seeds:  75%|███████▌  | 15/20 [00:44<00:15,  3.04s/it]KNN Seeds:  80%|████████  | 16/20 [00:47<00:12,  3.04s/it]KNN Seeds:  85%|████████▌ | 17/20 [00:50<00:09,  3.05s/it]KNN Seeds:  90%|█████████ | 18/20 [00:54<00:06,  3.07s/it]KNN Seeds:  95%|█████████▌| 19/20 [00:57<00:03,  3.07s/it]KNN Seeds: 100%|██████████| 20/20 [01:00<00:00,  3.09s/it]KNN Seeds: 100%|██████████| 20/20 [01:00<00:00,  3.02s/it]
24
(100, None, 'lbfgs')
(1391, 777)
(1112, 777)
(134, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:01<00:32,  1.69s/it]LR Seeds:  10%|█         | 2/20 [00:03<00:31,  1.73s/it]LR Seeds:  15%|█▌        | 3/20 [00:05<00:29,  1.74s/it]LR Seeds:  20%|██        | 4/20 [00:07<00:28,  1.77s/it]LR Seeds:  25%|██▌       | 5/20 [00:08<00:26,  1.79s/it]LR Seeds:  30%|███       | 6/20 [00:10<00:25,  1.82s/it]LR Seeds:  35%|███▌      | 7/20 [00:12<00:24,  1.88s/it]LR Seeds:  40%|████      | 8/20 [00:14<00:22,  1.84s/it]LR Seeds:  45%|████▌     | 9/20 [00:16<00:20,  1.85s/it]LR Seeds:  50%|█████     | 10/20 [00:18<00:18,  1.86s/it]LR Seeds:  55%|█████▌    | 11/20 [00:20<00:16,  1.88s/it]LR Seeds:  60%|██████    | 12/20 [00:22<00:15,  1.89s/it]LR Seeds:  65%|██████▌   | 13/20 [00:23<00:13,  1.90s/it]LR Seeds:  70%|███████   | 14/20 [00:25<00:11,  1.90s/it]LR Seeds:  75%|███████▌  | 15/20 [00:27<00:09,  1.94s/it]LR Seeds:  80%|████████  | 16/20 [00:29<00:07,  1.95s/it]LR Seeds:  85%|████████▌ | 17/20 [00:31<00:05,  1.96s/it]LR Seeds:  90%|█████████ | 18/20 [00:34<00:04,  2.01s/it]LR Seeds:  95%|█████████▌| 19/20 [00:36<00:02,  2.02s/it]LR Seeds: 100%|██████████| 20/20 [00:38<00:00,  2.04s/it]LR Seeds: 100%|██████████| 20/20 [00:38<00:00,  1.91s/it]
96
('rbf', 1, 1)
(1391, 777)
(1112, 777)
(134, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [00:18<06:00, 18.96s/it]SVM Seeds:  10%|█         | 2/20 [00:37<05:41, 18.95s/it]SVM Seeds:  15%|█▌        | 3/20 [00:56<05:22, 18.96s/it]SVM Seeds:  20%|██        | 4/20 [01:15<05:03, 18.98s/it]SVM Seeds:  25%|██▌       | 5/20 [01:34<04:44, 18.98s/it]SVM Seeds:  30%|███       | 6/20 [01:53<04:25, 18.98s/it]SVM Seeds:  35%|███▌      | 7/20 [02:12<04:06, 18.99s/it]SVM Seeds:  40%|████      | 8/20 [02:31<03:47, 19.00s/it]SVM Seeds:  45%|████▌     | 9/20 [02:50<03:29, 19.01s/it]SVM Seeds:  50%|█████     | 10/20 [03:09<03:10, 19.01s/it]SVM Seeds:  55%|█████▌    | 11/20 [03:29<02:51, 19.03s/it]SVM Seeds:  60%|██████    | 12/20 [03:48<02:32, 19.05s/it]SVM Seeds:  65%|██████▌   | 13/20 [04:07<02:13, 19.06s/it]SVM Seeds:  70%|███████   | 14/20 [04:26<01:54, 19.07s/it]SVM Seeds:  75%|███████▌  | 15/20 [04:45<01:35, 19.09s/it]SVM Seeds:  80%|████████  | 16/20 [05:04<01:16, 19.09s/it]SVM Seeds:  85%|████████▌ | 17/20 [05:23<00:57, 19.11s/it]SVM Seeds:  90%|█████████ | 18/20 [05:42<00:38, 19.13s/it]SVM Seeds:  95%|█████████▌| 19/20 [06:01<00:19, 19.13s/it]SVM Seeds: 100%|██████████| 20/20 [06:21<00:00, 19.14s/it]SVM Seeds: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it]
200
(500, None, 70, 1, 'balanced')
(1391, 777)
(1112, 777)
(134, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:03<01:13,  3.89s/it]RF Seeds:  10%|█         | 2/20 [00:07<01:11,  3.96s/it]RF Seeds:  15%|█▌        | 3/20 [00:11<01:06,  3.93s/it]RF Seeds:  20%|██        | 4/20 [00:15<01:02,  3.92s/it]RF Seeds:  25%|██▌       | 5/20 [00:19<00:59,  3.94s/it]RF Seeds:  30%|███       | 6/20 [00:23<00:55,  3.94s/it]RF Seeds:  35%|███▌      | 7/20 [00:27<00:51,  3.94s/it]RF Seeds:  40%|████      | 8/20 [00:31<00:47,  3.95s/it]RF Seeds:  45%|████▌     | 9/20 [00:35<00:43,  3.95s/it]RF Seeds:  50%|█████     | 10/20 [00:39<00:39,  3.97s/it]RF Seeds:  55%|█████▌    | 11/20 [00:43<00:35,  3.98s/it]RF Seeds:  60%|██████    | 12/20 [00:47<00:31,  3.99s/it]RF Seeds:  65%|██████▌   | 13/20 [00:51<00:27,  4.00s/it]RF Seeds:  70%|███████   | 14/20 [00:55<00:24,  4.00s/it]RF Seeds:  75%|███████▌  | 15/20 [00:59<00:20,  4.01s/it]RF Seeds:  80%|████████  | 16/20 [01:03<00:16,  4.02s/it]RF Seeds:  85%|████████▌ | 17/20 [01:07<00:12,  4.06s/it]RF Seeds:  90%|█████████ | 18/20 [01:11<00:08,  4.07s/it]RF Seeds:  95%|█████████▌| 19/20 [01:15<00:04,  4.07s/it]RF Seeds: 100%|██████████| 20/20 [01:20<00:00,  4.08s/it]RF Seeds: 100%|██████████| 20/20 [01:20<00:00,  4.00s/it]
400
(0.01, 900, 7, 0.8, 6)
(1391, 777)
(1112, 777)
(134, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:30<09:48, 30.96s/it]XGBoost Seeds:  10%|█         | 2/20 [01:01<09:18, 31.00s/it]XGBoost Seeds:  15%|█▌        | 3/20 [01:33<08:48, 31.10s/it]XGBoost Seeds:  20%|██        | 4/20 [02:04<08:17, 31.10s/it]XGBoost Seeds:  25%|██▌       | 5/20 [02:35<07:48, 31.22s/it]XGBoost Seeds:  30%|███       | 6/20 [03:07<07:17, 31.28s/it]XGBoost Seeds:  35%|███▌      | 7/20 [03:38<06:47, 31.33s/it]XGBoost Seeds:  40%|████      | 8/20 [04:09<06:15, 31.33s/it]XGBoost Seeds:  45%|████▌     | 9/20 [04:41<05:44, 31.33s/it]XGBoost Seeds:  50%|█████     | 10/20 [05:12<05:13, 31.36s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [05:44<04:43, 31.46s/it]XGBoost Seeds:  60%|██████    | 12/20 [06:15<04:11, 31.43s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [06:47<03:39, 31.42s/it]XGBoost Seeds:  70%|███████   | 14/20 [07:18<03:08, 31.38s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [07:50<02:37, 31.50s/it]XGBoost Seeds:  80%|████████  | 16/20 [08:22<02:06, 31.64s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [08:53<01:34, 31.57s/it]XGBoost Seeds:  90%|█████████ | 18/20 [09:25<01:03, 31.56s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [09:56<00:31, 31.55s/it]XGBoost Seeds: 100%|██████████| 20/20 [10:28<00:00, 31.58s/it]XGBoost Seeds: 100%|██████████| 20/20 [10:28<00:00, 31.41s/it]
knn:  85
lr:  84
svm:  77
rf:  97
xgboost:  88
Combining validation predictions is completed
knn:  85
lr:  84
svm:  77
rf:  97
xgboost:  88
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.4710 - acc: 0.6875
223/223 [==============================] - 0s 1ms/step - loss: 1.5831 - acc: 0.6996 - val_loss: 1.1601 - val_acc: 0.7321

Epoch 00001: loss improved from inf to 1.58310, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5178 - acc: 0.6562
223/223 [==============================] - 0s 33us/step - loss: 1.4001 - acc: 0.7937 - val_loss: 1.0433 - val_acc: 0.7500

Epoch 00002: loss improved from 1.58310 to 1.40011, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5271 - acc: 0.6875
223/223 [==============================] - 0s 32us/step - loss: 1.3376 - acc: 0.8251 - val_loss: 0.9582 - val_acc: 0.8036

Epoch 00003: loss improved from 1.40011 to 1.33755, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4031 - acc: 0.7188
223/223 [==============================] - 0s 32us/step - loss: 1.2527 - acc: 0.8341 - val_loss: 0.8993 - val_acc: 0.8214

Epoch 00004: loss improved from 1.33755 to 1.25269, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2274 - acc: 0.7500
223/223 [==============================] - 0s 31us/step - loss: 1.2380 - acc: 0.8520 - val_loss: 0.8959 - val_acc: 0.8214

Epoch 00005: loss improved from 1.25269 to 1.23796, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1915 - acc: 0.7188
223/223 [==============================] - 0s 31us/step - loss: 1.1861 - acc: 0.8565 - val_loss: 0.8883 - val_acc: 0.8036

Epoch 00006: loss improved from 1.23796 to 1.18606, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2097 - acc: 0.7500
223/223 [==============================] - 0s 31us/step - loss: 1.1066 - acc: 0.8610 - val_loss: 0.9336 - val_acc: 0.8036

Epoch 00007: loss improved from 1.18606 to 1.10659, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9818 - acc: 0.7188
223/223 [==============================] - 0s 31us/step - loss: 1.0781 - acc: 0.8924 - val_loss: 0.9152 - val_acc: 0.7857

Epoch 00008: loss improved from 1.10659 to 1.07810, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9028 - acc: 0.8438
223/223 [==============================] - 0s 31us/step - loss: 1.0052 - acc: 0.9058 - val_loss: 0.8657 - val_acc: 0.8036

Epoch 00009: loss improved from 1.07810 to 1.00516, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8248 - acc: 0.8438
223/223 [==============================] - 0s 31us/step - loss: 0.9928 - acc: 0.9013 - val_loss: 0.9090 - val_acc: 0.8214

Epoch 00010: loss improved from 1.00516 to 0.99277, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0277 - acc: 0.8125
223/223 [==============================] - 0s 31us/step - loss: 1.1201 - acc: 0.8789 - val_loss: 0.8022 - val_acc: 0.8214

Epoch 00011: loss did not improve from 0.99277
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0851 - acc: 0.7812
223/223 [==============================] - 0s 30us/step - loss: 1.0208 - acc: 0.9193 - val_loss: 0.7713 - val_acc: 0.8214

Epoch 00012: loss did not improve from 0.99277
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9749 - acc: 0.7812
223/223 [==============================] - 0s 31us/step - loss: 1.0086 - acc: 0.8789 - val_loss: 0.7343 - val_acc: 0.8571

Epoch 00013: loss did not improve from 0.99277
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8446 - acc: 0.8438
223/223 [==============================] - 0s 30us/step - loss: 0.9238 - acc: 0.9103 - val_loss: 0.7272 - val_acc: 0.8750

Epoch 00014: loss improved from 0.99277 to 0.92378, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9878 - acc: 0.8125
223/223 [==============================] - 0s 30us/step - loss: 0.9579 - acc: 0.8924 - val_loss: 0.7426 - val_acc: 0.8393

Epoch 00015: loss did not improve from 0.92378
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8700 - acc: 0.8750
223/223 [==============================] - 0s 30us/step - loss: 0.9455 - acc: 0.8924 - val_loss: 0.7117 - val_acc: 0.8393

Epoch 00016: loss did not improve from 0.92378
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8216 - acc: 0.8125
223/223 [==============================] - 0s 30us/step - loss: 0.9186 - acc: 0.9058 - val_loss: 0.8769 - val_acc: 0.8929

Epoch 00017: loss improved from 0.92378 to 0.91857, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9343 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 0.9271 - acc: 0.8834 - val_loss: 1.0215 - val_acc: 0.7679

Epoch 00018: loss did not improve from 0.91857
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0827 - acc: 0.7500
223/223 [==============================] - 0s 30us/step - loss: 0.8630 - acc: 0.8924 - val_loss: 0.7231 - val_acc: 0.7857

Epoch 00019: loss improved from 0.91857 to 0.86301, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 20/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9430 - acc: 0.8438
223/223 [==============================] - 0s 30us/step - loss: 0.9083 - acc: 0.9013 - val_loss: 0.8688 - val_acc: 0.7679

Epoch 00020: loss did not improve from 0.86301
Epoch 21/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0093 - acc: 0.7812
223/223 [==============================] - 0s 30us/step - loss: 0.8865 - acc: 0.8969 - val_loss: 0.8372 - val_acc: 0.7857

Epoch 00021: loss did not improve from 0.86301
Epoch 22/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1454 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 0.9048 - acc: 0.8834 - val_loss: 0.7263 - val_acc: 0.8036

Epoch 00022: loss did not improve from 0.86301
Epoch 23/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.6838 - acc: 0.9062
223/223 [==============================] - 0s 30us/step - loss: 0.7874 - acc: 0.9283 - val_loss: 0.8489 - val_acc: 0.7679

Epoch 00023: loss improved from 0.86301 to 0.78735, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 24/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7495 - acc: 0.8125
223/223 [==============================] - 0s 30us/step - loss: 0.7814 - acc: 0.9327 - val_loss: 0.8260 - val_acc: 0.7857

Epoch 00024: loss improved from 0.78735 to 0.78143, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 25/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9167 - acc: 0.8438
223/223 [==============================] - 0s 30us/step - loss: 0.8561 - acc: 0.9058 - val_loss: 0.7787 - val_acc: 0.8393

Epoch 00025: loss did not improve from 0.78143
Epoch 26/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8744 - acc: 0.8750
223/223 [==============================] - 0s 30us/step - loss: 0.8569 - acc: 0.9238 - val_loss: 0.6562 - val_acc: 0.8929

Epoch 00026: loss did not improve from 0.78143
Epoch 27/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.6306 - acc: 0.9062
223/223 [==============================] - 0s 30us/step - loss: 0.7353 - acc: 0.9372 - val_loss: 0.5811 - val_acc: 0.9464

Epoch 00027: loss improved from 0.78143 to 0.73528, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 28/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7325 - acc: 0.8125
223/223 [==============================] - 0s 30us/step - loss: 0.6709 - acc: 0.9327 - val_loss: 0.6026 - val_acc: 0.8929

Epoch 00028: loss improved from 0.73528 to 0.67086, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 29/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8028 - acc: 0.8438
223/223 [==============================] - 0s 30us/step - loss: 0.7733 - acc: 0.9193 - val_loss: 0.6616 - val_acc: 0.8393

Epoch 00029: loss did not improve from 0.67086
Epoch 30/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.5762 - acc: 0.9062
223/223 [==============================] - 0s 30us/step - loss: 0.6672 - acc: 0.9372 - val_loss: 0.5394 - val_acc: 0.8929

Epoch 00030: loss improved from 0.67086 to 0.66721, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 31/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8248 - acc: 0.8438
223/223 [==============================] - 0s 30us/step - loss: 0.6875 - acc: 0.9507 - val_loss: 0.4919 - val_acc: 0.9464

Epoch 00031: loss did not improve from 0.66721
Epoch 32/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7753 - acc: 0.7812
223/223 [==============================] - 0s 30us/step - loss: 0.7155 - acc: 0.9238 - val_loss: 0.4972 - val_acc: 0.9464

Epoch 00032: loss did not improve from 0.66721
Epoch 33/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1679 - acc: 0.7812
223/223 [==============================] - 0s 30us/step - loss: 0.6929 - acc: 0.9327 - val_loss: 0.5276 - val_acc: 0.9286

Epoch 00033: loss did not improve from 0.66721
Epoch 34/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.6251 - acc: 0.8750
223/223 [==============================] - 0s 30us/step - loss: 0.6540 - acc: 0.9372 - val_loss: 0.6565 - val_acc: 0.8929

Epoch 00034: loss improved from 0.66721 to 0.65401, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 35/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7255 - acc: 0.9062
223/223 [==============================] - 0s 30us/step - loss: 0.7334 - acc: 0.9552 - val_loss: 0.5963 - val_acc: 0.8929

Epoch 00035: loss did not improve from 0.65401
Epoch 36/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8734 - acc: 0.7812
223/223 [==============================] - 0s 30us/step - loss: 0.6838 - acc: 0.9238 - val_loss: 0.5480 - val_acc: 0.9107

Epoch 00036: loss did not improve from 0.65401
Epoch 37/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7173 - acc: 0.9062
223/223 [==============================] - 0s 30us/step - loss: 0.6191 - acc: 0.9596 - val_loss: 0.5385 - val_acc: 0.9107

Epoch 00037: loss improved from 0.65401 to 0.61907, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_6.h5
Epoch 38/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.6687 - acc: 0.9062
223/223 [==============================] - 0s 30us/step - loss: 0.6426 - acc: 0.9417 - val_loss: 0.5482 - val_acc: 0.8929

Epoch 00038: loss did not improve from 0.61907
Epoch 39/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8354 - acc: 0.8750
223/223 [==============================] - 0s 29us/step - loss: 0.8834 - acc: 0.8789 - val_loss: 0.7231 - val_acc: 0.8750

Epoch 00039: loss did not improve from 0.61907
Epoch 40/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4510 - acc: 0.7812
223/223 [==============================] - 0s 30us/step - loss: 0.8864 - acc: 0.8969 - val_loss: 0.5489 - val_acc: 0.9464

Epoch 00040: loss did not improve from 0.61907
Epoch 41/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8123 - acc: 0.7500
223/223 [==============================] - 0s 30us/step - loss: 0.8820 - acc: 0.8789 - val_loss: 0.5421 - val_acc: 0.9464

Epoch 00041: loss did not improve from 0.61907
Epoch 42/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7406 - acc: 0.8125
223/223 [==============================] - 0s 30us/step - loss: 0.8819 - acc: 0.9013 - val_loss: 0.4723 - val_acc: 0.9464
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:21,  1.83s/it]
Epoch 00042: loss did not improve from 0.61907
Epoch 00042: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.7391 - acc: 0.5625
223/223 [==============================] - 0s 1ms/step - loss: 1.7717 - acc: 0.7265 - val_loss: 1.1542 - val_acc: 0.6964

Epoch 00001: loss improved from inf to 1.77172, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4957 - acc: 0.5625
223/223 [==============================] - 0s 33us/step - loss: 1.4715 - acc: 0.7534 - val_loss: 1.0650 - val_acc: 0.7500

Epoch 00002: loss improved from 1.77172 to 1.47150, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5676 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.4199 - acc: 0.7892 - val_loss: 1.0137 - val_acc: 0.7500

Epoch 00003: loss improved from 1.47150 to 1.41994, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4522 - acc: 0.7188
223/223 [==============================] - 0s 31us/step - loss: 1.3318 - acc: 0.8386 - val_loss: 0.9979 - val_acc: 0.7500

Epoch 00004: loss improved from 1.41994 to 1.33184, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4344 - acc: 0.6875
223/223 [==============================] - 0s 31us/step - loss: 1.3709 - acc: 0.8072 - val_loss: 1.0566 - val_acc: 0.7143

Epoch 00005: loss did not improve from 1.33184
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4697 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.2534 - acc: 0.8520 - val_loss: 0.9871 - val_acc: 0.7679

Epoch 00006: loss improved from 1.33184 to 1.25336, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1051 - acc: 0.7188
223/223 [==============================] - 0s 31us/step - loss: 1.1937 - acc: 0.8744 - val_loss: 0.9385 - val_acc: 0.7500

Epoch 00007: loss improved from 1.25336 to 1.19366, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1971 - acc: 0.6562
223/223 [==============================] - 0s 31us/step - loss: 1.1979 - acc: 0.8341 - val_loss: 0.8961 - val_acc: 0.7679

Epoch 00008: loss did not improve from 1.19366
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1381 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.1150 - acc: 0.8610 - val_loss: 0.8411 - val_acc: 0.8214

Epoch 00009: loss improved from 1.19366 to 1.11496, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3014 - acc: 0.7188
223/223 [==============================] - 0s 31us/step - loss: 1.1823 - acc: 0.8341 - val_loss: 0.8894 - val_acc: 0.7857

Epoch 00010: loss did not improve from 1.11496
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1818 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.1014 - acc: 0.8789 - val_loss: 0.9070 - val_acc: 0.7321

Epoch 00011: loss improved from 1.11496 to 1.10135, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0393 - acc: 0.7500
223/223 [==============================] - 0s 30us/step - loss: 1.2386 - acc: 0.8251 - val_loss: 0.7820 - val_acc: 0.8393

Epoch 00012: loss did not improve from 1.10135
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0666 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.0931 - acc: 0.8475 - val_loss: 0.7556 - val_acc: 0.8750

Epoch 00013: loss improved from 1.10135 to 1.09306, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0879 - acc: 0.6875
223/223 [==============================] - 0s 38us/step - loss: 1.0288 - acc: 0.8700 - val_loss: 0.7414 - val_acc: 0.8571

Epoch 00014: loss improved from 1.09306 to 1.02875, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0672 - acc: 0.7188
223/223 [==============================] - 0s 39us/step - loss: 1.0684 - acc: 0.8744 - val_loss: 0.8068 - val_acc: 0.7679

Epoch 00015: loss did not improve from 1.02875
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2975 - acc: 0.6875
223/223 [==============================] - 0s 38us/step - loss: 1.0750 - acc: 0.8655 - val_loss: 0.8332 - val_acc: 0.8036

Epoch 00016: loss did not improve from 1.02875
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9791 - acc: 0.8438
223/223 [==============================] - 0s 38us/step - loss: 0.9225 - acc: 0.9103 - val_loss: 0.7959 - val_acc: 0.8036

Epoch 00017: loss improved from 1.02875 to 0.92248, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8831 - acc: 0.8125
223/223 [==============================] - 0s 39us/step - loss: 0.9786 - acc: 0.9013 - val_loss: 0.7172 - val_acc: 0.8393

Epoch 00018: loss did not improve from 0.92248
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7556 - acc: 0.9062
223/223 [==============================] - 0s 38us/step - loss: 0.9330 - acc: 0.9283 - val_loss: 0.7455 - val_acc: 0.8214

Epoch 00019: loss did not improve from 0.92248
Epoch 20/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9615 - acc: 0.7812
223/223 [==============================] - 0s 38us/step - loss: 0.8848 - acc: 0.9103 - val_loss: 0.7635 - val_acc: 0.8571

Epoch 00020: loss improved from 0.92248 to 0.88480, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 21/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2442 - acc: 0.6562
223/223 [==============================] - 0s 39us/step - loss: 0.9856 - acc: 0.8610 - val_loss: 0.7182 - val_acc: 0.8214

Epoch 00021: loss did not improve from 0.88480
Epoch 22/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9805 - acc: 0.7500
223/223 [==============================] - 0s 38us/step - loss: 0.8100 - acc: 0.8969 - val_loss: 0.6853 - val_acc: 0.8571

Epoch 00022: loss improved from 0.88480 to 0.80999, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 23/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8491 - acc: 0.7812
223/223 [==============================] - 0s 38us/step - loss: 0.7750 - acc: 0.9327 - val_loss: 0.6857 - val_acc: 0.8571

Epoch 00023: loss improved from 0.80999 to 0.77497, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_7.h5
Epoch 24/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8648 - acc: 0.8438
223/223 [==============================] - 0s 38us/step - loss: 0.9320 - acc: 0.9013 - val_loss: 0.8022 - val_acc: 0.8214

Epoch 00024: loss did not improve from 0.77497
Epoch 25/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9201 - acc: 0.7812
223/223 [==============================] - 0s 38us/step - loss: 0.9255 - acc: 0.8924 - val_loss: 0.8640 - val_acc: 0.7857

Epoch 00025: loss did not improve from 0.77497
Epoch 26/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9429 - acc: 0.7500
223/223 [==============================] - 0s 37us/step - loss: 0.7851 - acc: 0.8969 - val_loss: 0.7036 - val_acc: 0.8571

Epoch 00026: loss did not improve from 0.77497
Epoch 27/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8588 - acc: 0.8125
223/223 [==============================] - 0s 38us/step - loss: 0.9239 - acc: 0.8969 - val_loss: 0.6096 - val_acc: 0.8750

Epoch 00027: loss did not improve from 0.77497
Epoch 28/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7040 - acc: 0.8750
223/223 [==============================] - 0s 37us/step - loss: 0.8850 - acc: 0.8969 - val_loss: 0.8334 - val_acc: 0.8750
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:03<00:19,  1.82s/it]
Epoch 00028: loss did not improve from 0.77497
Epoch 00028: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.7140 - acc: 0.5312
223/223 [==============================] - 0s 1ms/step - loss: 1.7390 - acc: 0.7489 - val_loss: 1.2085 - val_acc: 0.6964

Epoch 00001: loss improved from inf to 1.73896, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6468 - acc: 0.5938
223/223 [==============================] - 0s 41us/step - loss: 1.4469 - acc: 0.7758 - val_loss: 1.1176 - val_acc: 0.7143

Epoch 00002: loss improved from 1.73896 to 1.44689, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4561 - acc: 0.7188
223/223 [==============================] - 0s 39us/step - loss: 1.3792 - acc: 0.8206 - val_loss: 1.1043 - val_acc: 0.7143

Epoch 00003: loss improved from 1.44689 to 1.37920, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4361 - acc: 0.6250
223/223 [==============================] - 0s 39us/step - loss: 1.3510 - acc: 0.8296 - val_loss: 0.9614 - val_acc: 0.7857

Epoch 00004: loss improved from 1.37920 to 1.35103, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2880 - acc: 0.7188
223/223 [==============================] - 0s 38us/step - loss: 1.3547 - acc: 0.8296 - val_loss: 1.0752 - val_acc: 0.7500

Epoch 00005: loss did not improve from 1.35103
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4693 - acc: 0.6875
223/223 [==============================] - 0s 38us/step - loss: 1.3366 - acc: 0.8117 - val_loss: 1.0918 - val_acc: 0.6964

Epoch 00006: loss improved from 1.35103 to 1.33658, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3293 - acc: 0.6875
223/223 [==============================] - 0s 38us/step - loss: 1.3122 - acc: 0.8341 - val_loss: 1.0516 - val_acc: 0.7321

Epoch 00007: loss improved from 1.33658 to 1.31217, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5271 - acc: 0.6562
223/223 [==============================] - 0s 38us/step - loss: 1.2914 - acc: 0.8206 - val_loss: 0.8894 - val_acc: 0.8214

Epoch 00008: loss improved from 1.31217 to 1.29141, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2068 - acc: 0.7188
223/223 [==============================] - 0s 38us/step - loss: 1.2927 - acc: 0.8251 - val_loss: 1.0487 - val_acc: 0.7143

Epoch 00009: loss did not improve from 1.29141
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2084 - acc: 0.7812
223/223 [==============================] - 0s 38us/step - loss: 1.1787 - acc: 0.8655 - val_loss: 1.0280 - val_acc: 0.7321

Epoch 00010: loss improved from 1.29141 to 1.17872, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3270 - acc: 0.6562
223/223 [==============================] - 0s 37us/step - loss: 1.2751 - acc: 0.8206 - val_loss: 1.0559 - val_acc: 0.7321

Epoch 00011: loss did not improve from 1.17872
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2718 - acc: 0.6875
223/223 [==============================] - 0s 37us/step - loss: 1.1268 - acc: 0.8520 - val_loss: 0.9707 - val_acc: 0.7679

Epoch 00012: loss improved from 1.17872 to 1.12677, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8883 - acc: 0.8438
223/223 [==============================] - 0s 38us/step - loss: 1.0577 - acc: 0.8744 - val_loss: 1.0021 - val_acc: 0.7321

Epoch 00013: loss improved from 1.12677 to 1.05773, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2070 - acc: 0.7188
223/223 [==============================] - 0s 38us/step - loss: 1.0105 - acc: 0.8924 - val_loss: 0.9462 - val_acc: 0.7679

Epoch 00014: loss improved from 1.05773 to 1.01053, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1635 - acc: 0.6562
223/223 [==============================] - 0s 38us/step - loss: 1.0519 - acc: 0.8834 - val_loss: 0.7485 - val_acc: 0.8393

Epoch 00015: loss did not improve from 1.01053
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9574 - acc: 0.8125
223/223 [==============================] - 0s 37us/step - loss: 1.1768 - acc: 0.8610 - val_loss: 0.7085 - val_acc: 0.9107

Epoch 00016: loss did not improve from 1.01053
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2322 - acc: 0.7500
223/223 [==============================] - 0s 38us/step - loss: 1.1698 - acc: 0.8700 - val_loss: 0.6862 - val_acc: 0.8929

Epoch 00017: loss did not improve from 1.01053
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1488 - acc: 0.7812
223/223 [==============================] - 0s 37us/step - loss: 1.0169 - acc: 0.8744 - val_loss: 0.7050 - val_acc: 0.8393

Epoch 00018: loss did not improve from 1.01053
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2200 - acc: 0.7188
223/223 [==============================] - 0s 37us/step - loss: 1.0243 - acc: 0.8655 - val_loss: 0.7592 - val_acc: 0.8036
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:05<00:17,  1.77s/it]
Epoch 00019: loss did not improve from 1.01053
Epoch 00019: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.5969 - acc: 0.5625
223/223 [==============================] - 0s 1ms/step - loss: 1.7080 - acc: 0.7130 - val_loss: 1.1074 - val_acc: 0.7679

Epoch 00001: loss improved from inf to 1.70805, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7267 - acc: 0.6875
223/223 [==============================] - 0s 41us/step - loss: 1.5726 - acc: 0.7803 - val_loss: 1.0582 - val_acc: 0.7143

Epoch 00002: loss improved from 1.70805 to 1.57261, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4242 - acc: 0.6562
223/223 [==============================] - 0s 39us/step - loss: 1.4644 - acc: 0.7848 - val_loss: 1.0662 - val_acc: 0.7321

Epoch 00003: loss improved from 1.57261 to 1.46436, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4847 - acc: 0.5625
223/223 [==============================] - 0s 39us/step - loss: 1.3604 - acc: 0.7892 - val_loss: 1.0415 - val_acc: 0.6964

Epoch 00004: loss improved from 1.46436 to 1.36043, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4391 - acc: 0.6875
223/223 [==============================] - 0s 39us/step - loss: 1.3412 - acc: 0.8072 - val_loss: 1.1094 - val_acc: 0.7143

Epoch 00005: loss improved from 1.36043 to 1.34115, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2986 - acc: 0.6562
223/223 [==============================] - 0s 39us/step - loss: 1.3240 - acc: 0.8027 - val_loss: 1.0829 - val_acc: 0.7143

Epoch 00006: loss improved from 1.34115 to 1.32401, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3159 - acc: 0.7188
223/223 [==============================] - 0s 39us/step - loss: 1.2317 - acc: 0.8430 - val_loss: 0.9985 - val_acc: 0.7321

Epoch 00007: loss improved from 1.32401 to 1.23167, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3488 - acc: 0.6875
223/223 [==============================] - 0s 38us/step - loss: 1.3390 - acc: 0.8430 - val_loss: 0.9903 - val_acc: 0.7500

Epoch 00008: loss did not improve from 1.23167
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2335 - acc: 0.8438
223/223 [==============================] - 0s 39us/step - loss: 1.1415 - acc: 0.8655 - val_loss: 0.8694 - val_acc: 0.8393

Epoch 00009: loss improved from 1.23167 to 1.14149, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1987 - acc: 0.6562
223/223 [==============================] - 0s 38us/step - loss: 1.1636 - acc: 0.8565 - val_loss: 0.8981 - val_acc: 0.7679

Epoch 00010: loss did not improve from 1.14149
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0871 - acc: 0.7812
223/223 [==============================] - 0s 39us/step - loss: 1.0972 - acc: 0.8565 - val_loss: 0.9976 - val_acc: 0.7321

Epoch 00011: loss improved from 1.14149 to 1.09716, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1638 - acc: 0.8125
223/223 [==============================] - 0s 38us/step - loss: 1.2250 - acc: 0.8565 - val_loss: 1.2178 - val_acc: 0.7143

Epoch 00012: loss did not improve from 1.09716
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4081 - acc: 0.7188
223/223 [==============================] - 0s 38us/step - loss: 1.1354 - acc: 0.8655 - val_loss: 1.1463 - val_acc: 0.7143

Epoch 00013: loss did not improve from 1.09716
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1690 - acc: 0.7812
223/223 [==============================] - 0s 38us/step - loss: 1.1363 - acc: 0.9283 - val_loss: 1.0410 - val_acc: 0.7321

Epoch 00014: loss did not improve from 1.09716
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0414 - acc: 0.7500
223/223 [==============================] - 0s 38us/step - loss: 1.0338 - acc: 0.8924 - val_loss: 0.8330 - val_acc: 0.8571

Epoch 00015: loss improved from 1.09716 to 1.03379, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9897 - acc: 0.8125
223/223 [==============================] - 0s 38us/step - loss: 1.1265 - acc: 0.8655 - val_loss: 0.9065 - val_acc: 0.8214

Epoch 00016: loss did not improve from 1.03379
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2547 - acc: 0.7812
223/223 [==============================] - 0s 37us/step - loss: 1.0305 - acc: 0.9148 - val_loss: 0.8009 - val_acc: 0.8750

Epoch 00017: loss improved from 1.03379 to 1.03054, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3089 - acc: 0.7188
223/223 [==============================] - 0s 37us/step - loss: 1.1427 - acc: 0.8879 - val_loss: 0.7849 - val_acc: 0.8750

Epoch 00018: loss did not improve from 1.03054
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0636 - acc: 0.7188
223/223 [==============================] - 0s 38us/step - loss: 1.0889 - acc: 0.8879 - val_loss: 0.8228 - val_acc: 0.8750

Epoch 00019: loss did not improve from 1.03054
Epoch 20/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2438 - acc: 0.7500
223/223 [==============================] - 0s 37us/step - loss: 1.2376 - acc: 0.8341 - val_loss: 0.8974 - val_acc: 0.8393

Epoch 00020: loss did not improve from 1.03054
Epoch 21/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0745 - acc: 0.7188
223/223 [==============================] - 0s 38us/step - loss: 0.9856 - acc: 0.8744 - val_loss: 0.8164 - val_acc: 0.8929

Epoch 00021: loss improved from 1.03054 to 0.98564, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_9.h5
Epoch 22/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1199 - acc: 0.7500
223/223 [==============================] - 0s 38us/step - loss: 1.0291 - acc: 0.8924 - val_loss: 0.8315 - val_acc: 0.8750

Epoch 00022: loss did not improve from 0.98564
Epoch 23/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1038 - acc: 0.8438
223/223 [==============================] - 0s 37us/step - loss: 1.0147 - acc: 0.9058 - val_loss: 0.7758 - val_acc: 0.8393

Epoch 00023: loss did not improve from 0.98564
Epoch 24/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3844 - acc: 0.7188
223/223 [==============================] - 0s 38us/step - loss: 1.1473 - acc: 0.8565 - val_loss: 0.8444 - val_acc: 0.8214

Epoch 00024: loss did not improve from 0.98564
Epoch 25/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4259 - acc: 0.7500
223/223 [==============================] - 0s 38us/step - loss: 1.0689 - acc: 0.8834 - val_loss: 0.7837 - val_acc: 0.8214

Epoch 00025: loss did not improve from 0.98564
Epoch 26/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1086 - acc: 0.7188
223/223 [==============================] - 0s 38us/step - loss: 1.0996 - acc: 0.8475 - val_loss: 0.7561 - val_acc: 0.8750
DeepAmes+ Weights:  31%|███       | 4/13 [00:07<00:15,  1.74s/it]
Epoch 00026: loss did not improve from 0.98564
Epoch 00026: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.7449 - acc: 0.5625
223/223 [==============================] - 0s 1ms/step - loss: 1.9755 - acc: 0.7399 - val_loss: 1.3914 - val_acc: 0.7500

Epoch 00001: loss improved from inf to 1.97549, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6758 - acc: 0.6250
223/223 [==============================] - 0s 42us/step - loss: 1.5277 - acc: 0.7713 - val_loss: 1.1657 - val_acc: 0.6786

Epoch 00002: loss improved from 1.97549 to 1.52773, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5577 - acc: 0.5312
223/223 [==============================] - 0s 39us/step - loss: 1.4801 - acc: 0.7803 - val_loss: 1.1546 - val_acc: 0.6964

Epoch 00003: loss improved from 1.52773 to 1.48012, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5473 - acc: 0.5938
223/223 [==============================] - 0s 39us/step - loss: 1.3565 - acc: 0.8027 - val_loss: 1.0330 - val_acc: 0.7679

Epoch 00004: loss improved from 1.48012 to 1.35652, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5423 - acc: 0.6562
223/223 [==============================] - 0s 39us/step - loss: 1.4656 - acc: 0.8027 - val_loss: 1.1253 - val_acc: 0.7321

Epoch 00005: loss did not improve from 1.35652
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4953 - acc: 0.6562
223/223 [==============================] - 0s 39us/step - loss: 1.3471 - acc: 0.8161 - val_loss: 1.0182 - val_acc: 0.7679

Epoch 00006: loss improved from 1.35652 to 1.34710, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5927 - acc: 0.6562
223/223 [==============================] - 0s 38us/step - loss: 1.3525 - acc: 0.8161 - val_loss: 1.0682 - val_acc: 0.7143

Epoch 00007: loss did not improve from 1.34710
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3606 - acc: 0.6562
223/223 [==============================] - 0s 39us/step - loss: 1.2481 - acc: 0.8296 - val_loss: 1.0314 - val_acc: 0.7679

Epoch 00008: loss improved from 1.34710 to 1.24806, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5039 - acc: 0.6250
223/223 [==============================] - 0s 38us/step - loss: 1.1954 - acc: 0.8296 - val_loss: 0.9540 - val_acc: 0.7857

Epoch 00009: loss improved from 1.24806 to 1.19544, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2452 - acc: 0.6562
223/223 [==============================] - 0s 38us/step - loss: 1.1952 - acc: 0.8296 - val_loss: 0.9190 - val_acc: 0.8036

Epoch 00010: loss improved from 1.19544 to 1.19515, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1533 - acc: 0.7188
223/223 [==============================] - 0s 39us/step - loss: 1.1730 - acc: 0.8700 - val_loss: 1.0020 - val_acc: 0.7500

Epoch 00011: loss improved from 1.19515 to 1.17305, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2504 - acc: 0.7188
223/223 [==============================] - 0s 39us/step - loss: 1.2867 - acc: 0.8161 - val_loss: 1.0187 - val_acc: 0.7679

Epoch 00012: loss did not improve from 1.17305
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1053 - acc: 0.7500
223/223 [==============================] - 0s 39us/step - loss: 1.2306 - acc: 0.8655 - val_loss: 1.0234 - val_acc: 0.7679

Epoch 00013: loss did not improve from 1.17305
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1463 - acc: 0.7188
223/223 [==============================] - 0s 39us/step - loss: 1.0577 - acc: 0.8924 - val_loss: 0.9427 - val_acc: 0.7679

Epoch 00014: loss improved from 1.17305 to 1.05767, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2411 - acc: 0.7500
223/223 [==============================] - 0s 37us/step - loss: 1.0678 - acc: 0.8744 - val_loss: 0.9862 - val_acc: 0.7679

Epoch 00015: loss did not improve from 1.05767
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2737 - acc: 0.6875
223/223 [==============================] - 0s 37us/step - loss: 1.1449 - acc: 0.8475 - val_loss: 1.0037 - val_acc: 0.7143

Epoch 00016: loss did not improve from 1.05767
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0740 - acc: 0.7500
223/223 [==============================] - 0s 38us/step - loss: 1.0486 - acc: 0.8879 - val_loss: 1.0139 - val_acc: 0.7321

Epoch 00017: loss improved from 1.05767 to 1.04860, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3511 - acc: 0.7188
223/223 [==============================] - 0s 37us/step - loss: 1.1901 - acc: 0.8655 - val_loss: 1.1565 - val_acc: 0.7143

Epoch 00018: loss did not improve from 1.04860
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4871 - acc: 0.6562
223/223 [==============================] - 0s 37us/step - loss: 1.1529 - acc: 0.8251 - val_loss: 1.0491 - val_acc: 0.7143

Epoch 00019: loss did not improve from 1.04860
Epoch 20/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2582 - acc: 0.7500
223/223 [==============================] - 0s 38us/step - loss: 1.0683 - acc: 0.8520 - val_loss: 1.0042 - val_acc: 0.7500

Epoch 00020: loss did not improve from 1.04860
Epoch 21/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3066 - acc: 0.6875
223/223 [==============================] - 0s 37us/step - loss: 0.9468 - acc: 0.8969 - val_loss: 0.8796 - val_acc: 0.7679

Epoch 00021: loss improved from 1.04860 to 0.94685, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 22/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9968 - acc: 0.7812
223/223 [==============================] - 0s 36us/step - loss: 0.9456 - acc: 0.9103 - val_loss: 0.9329 - val_acc: 0.7321

Epoch 00022: loss improved from 0.94685 to 0.94563, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 23/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7866 - acc: 0.9062
223/223 [==============================] - 0s 37us/step - loss: 0.8149 - acc: 0.9372 - val_loss: 0.7521 - val_acc: 0.8036

Epoch 00023: loss improved from 0.94563 to 0.81490, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 24/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7079 - acc: 0.9062
223/223 [==============================] - 0s 37us/step - loss: 0.7759 - acc: 0.9327 - val_loss: 0.7477 - val_acc: 0.8393

Epoch 00024: loss improved from 0.81490 to 0.77588, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 25/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.7947 - acc: 0.9062
223/223 [==============================] - 0s 31us/step - loss: 0.7621 - acc: 0.9507 - val_loss: 0.7515 - val_acc: 0.8750

Epoch 00025: loss improved from 0.77588 to 0.76213, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 26/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9629 - acc: 0.8438
223/223 [==============================] - 0s 29us/step - loss: 0.7388 - acc: 0.9372 - val_loss: 0.7788 - val_acc: 0.7857

Epoch 00026: loss improved from 0.76213 to 0.73879, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_10.h5
Epoch 27/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8084 - acc: 0.8750
223/223 [==============================] - 0s 29us/step - loss: 0.8124 - acc: 0.9238 - val_loss: 0.7915 - val_acc: 0.8036

Epoch 00027: loss did not improve from 0.73879
Epoch 28/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0863 - acc: 0.7812
223/223 [==============================] - 0s 29us/step - loss: 0.9791 - acc: 0.8879 - val_loss: 0.8766 - val_acc: 0.7679

Epoch 00028: loss did not improve from 0.73879
Epoch 29/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.8701 - acc: 0.8125
223/223 [==============================] - 0s 29us/step - loss: 0.8410 - acc: 0.8969 - val_loss: 0.7259 - val_acc: 0.8214

Epoch 00029: loss did not improve from 0.73879
Epoch 30/100

 32/223 [===>..........................] - ETA: 0s - loss: 0.9602 - acc: 0.8125
223/223 [==============================] - 0s 29us/step - loss: 1.0894 - acc: 0.8655 - val_loss: 0.7339 - val_acc: 0.9107

Epoch 00030: loss did not improve from 0.73879
Epoch 31/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2641 - acc: 0.7188
223/223 [==============================] - 0s 29us/step - loss: 1.0607 - acc: 0.8879 - val_loss: 0.7731 - val_acc: 0.8929
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:08<00:14,  1.79s/it]
Epoch 00031: loss did not improve from 0.73879
Epoch 00031: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.5611 - acc: 0.5938
223/223 [==============================] - 0s 1ms/step - loss: 1.9260 - acc: 0.7309 - val_loss: 2.0665 - val_acc: 0.6607

Epoch 00001: loss improved from inf to 1.92599, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8162 - acc: 0.5625
223/223 [==============================] - 0s 33us/step - loss: 1.7000 - acc: 0.7444 - val_loss: 1.3557 - val_acc: 0.6786

Epoch 00002: loss improved from 1.92599 to 1.69995, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8339 - acc: 0.5625
223/223 [==============================] - 0s 32us/step - loss: 1.5854 - acc: 0.7085 - val_loss: 1.2885 - val_acc: 0.6786

Epoch 00003: loss improved from 1.69995 to 1.58544, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5404 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.4723 - acc: 0.7668 - val_loss: 1.2406 - val_acc: 0.6964

Epoch 00004: loss improved from 1.58544 to 1.47225, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6716 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.5159 - acc: 0.7444 - val_loss: 1.0768 - val_acc: 0.7143

Epoch 00005: loss did not improve from 1.47225
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4855 - acc: 0.6562
223/223 [==============================] - 0s 31us/step - loss: 1.4221 - acc: 0.7937 - val_loss: 1.0433 - val_acc: 0.7143

Epoch 00006: loss improved from 1.47225 to 1.42212, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3435 - acc: 0.6875
223/223 [==============================] - 0s 31us/step - loss: 1.3636 - acc: 0.8027 - val_loss: 1.0404 - val_acc: 0.7143

Epoch 00007: loss improved from 1.42212 to 1.36362, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3176 - acc: 0.6875
223/223 [==============================] - 0s 31us/step - loss: 1.3194 - acc: 0.8161 - val_loss: 1.0984 - val_acc: 0.6964

Epoch 00008: loss improved from 1.36362 to 1.31942, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2311 - acc: 0.6875
223/223 [==============================] - 0s 31us/step - loss: 1.1644 - acc: 0.8386 - val_loss: 1.1327 - val_acc: 0.7321

Epoch 00009: loss improved from 1.31942 to 1.16445, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2169 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.1454 - acc: 0.8341 - val_loss: 1.0977 - val_acc: 0.7321

Epoch 00010: loss improved from 1.16445 to 1.14543, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4459 - acc: 0.6562
223/223 [==============================] - 0s 31us/step - loss: 1.1550 - acc: 0.8430 - val_loss: 1.0092 - val_acc: 0.7679

Epoch 00011: loss did not improve from 1.14543
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1394 - acc: 0.7812
223/223 [==============================] - 0s 30us/step - loss: 1.0462 - acc: 0.8700 - val_loss: 1.0042 - val_acc: 0.7500

Epoch 00012: loss improved from 1.14543 to 1.04620, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_11.h5
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0805 - acc: 0.7500
223/223 [==============================] - 0s 30us/step - loss: 1.1001 - acc: 0.8744 - val_loss: 1.0262 - val_acc: 0.7679

Epoch 00013: loss did not improve from 1.04620
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2229 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.1644 - acc: 0.8565 - val_loss: 0.9426 - val_acc: 0.8571

Epoch 00014: loss did not improve from 1.04620
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4671 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.2348 - acc: 0.8834 - val_loss: 0.8964 - val_acc: 0.8214

Epoch 00015: loss did not improve from 1.04620
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4202 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.2068 - acc: 0.8161 - val_loss: 0.8807 - val_acc: 0.8571

Epoch 00016: loss did not improve from 1.04620
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1261 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.1355 - acc: 0.8565 - val_loss: 0.8439 - val_acc: 0.8036
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:10<00:12,  1.75s/it]
Epoch 00017: loss did not improve from 1.04620
Epoch 00017: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.7071 - acc: 0.7188
223/223 [==============================] - 0s 1ms/step - loss: 1.8329 - acc: 0.7399 - val_loss: 1.3364 - val_acc: 0.7321

Epoch 00001: loss improved from inf to 1.83293, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8354 - acc: 0.5312
223/223 [==============================] - 0s 33us/step - loss: 1.7431 - acc: 0.6682 - val_loss: 1.2396 - val_acc: 0.6786

Epoch 00002: loss improved from 1.83293 to 1.74314, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8577 - acc: 0.5625
223/223 [==============================] - 0s 31us/step - loss: 1.5160 - acc: 0.6996 - val_loss: 1.1913 - val_acc: 0.6786

Epoch 00003: loss improved from 1.74314 to 1.51598, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4908 - acc: 0.6562
223/223 [==============================] - 0s 31us/step - loss: 1.5527 - acc: 0.7578 - val_loss: 1.2486 - val_acc: 0.6786

Epoch 00004: loss did not improve from 1.51598
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5838 - acc: 0.5938
223/223 [==============================] - 0s 30us/step - loss: 1.5583 - acc: 0.7309 - val_loss: 1.1112 - val_acc: 0.6786

Epoch 00005: loss did not improve from 1.51598
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4578 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.4539 - acc: 0.7713 - val_loss: 1.0996 - val_acc: 0.6786

Epoch 00006: loss improved from 1.51598 to 1.45390, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3999 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.3982 - acc: 0.7713 - val_loss: 1.1357 - val_acc: 0.6964

Epoch 00007: loss improved from 1.45390 to 1.39819, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3359 - acc: 0.6562
223/223 [==============================] - 0s 31us/step - loss: 1.4574 - acc: 0.7803 - val_loss: 1.0147 - val_acc: 0.7143

Epoch 00008: loss did not improve from 1.39819
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3354 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.2844 - acc: 0.7892 - val_loss: 0.9928 - val_acc: 0.7321

Epoch 00009: loss improved from 1.39819 to 1.28436, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3731 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.2370 - acc: 0.8027 - val_loss: 0.9456 - val_acc: 0.8036

Epoch 00010: loss improved from 1.28436 to 1.23701, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4352 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.1712 - acc: 0.8206 - val_loss: 0.8604 - val_acc: 0.8036

Epoch 00011: loss improved from 1.23701 to 1.17122, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1815 - acc: 0.7812
223/223 [==============================] - 0s 31us/step - loss: 1.7628 - acc: 0.8161 - val_loss: 1.2305 - val_acc: 0.7143

Epoch 00012: loss did not improve from 1.17122
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3764 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.3273 - acc: 0.8520 - val_loss: 1.2075 - val_acc: 0.6786

Epoch 00013: loss did not improve from 1.17122
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4617 - acc: 0.6875
223/223 [==============================] - 0s 29us/step - loss: 1.1953 - acc: 0.8341 - val_loss: 1.1455 - val_acc: 0.7143

Epoch 00014: loss did not improve from 1.17122
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2899 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.2358 - acc: 0.8430 - val_loss: 1.0351 - val_acc: 0.7321

Epoch 00015: loss did not improve from 1.17122
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1573 - acc: 0.6875
223/223 [==============================] - 0s 29us/step - loss: 1.1422 - acc: 0.8520 - val_loss: 1.0013 - val_acc: 0.7321

Epoch 00016: loss improved from 1.17122 to 1.14217, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_12.h5
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4660 - acc: 0.6875
223/223 [==============================] - 0s 29us/step - loss: 1.2271 - acc: 0.8341 - val_loss: 0.9419 - val_acc: 0.7679

Epoch 00017: loss did not improve from 1.14217
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0917 - acc: 0.6875
223/223 [==============================] - 0s 29us/step - loss: 1.2069 - acc: 0.8430 - val_loss: 0.9754 - val_acc: 0.7500

Epoch 00018: loss did not improve from 1.14217
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2381 - acc: 0.6562
223/223 [==============================] - 0s 29us/step - loss: 1.1989 - acc: 0.8341 - val_loss: 0.8915 - val_acc: 0.7500

Epoch 00019: loss did not improve from 1.14217
Epoch 20/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1625 - acc: 0.7500
223/223 [==============================] - 0s 29us/step - loss: 1.2884 - acc: 0.8520 - val_loss: 1.3486 - val_acc: 0.7679

Epoch 00020: loss did not improve from 1.14217
Epoch 21/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3533 - acc: 0.7500
223/223 [==============================] - 0s 29us/step - loss: 1.3750 - acc: 0.8296 - val_loss: 1.1502 - val_acc: 0.7500
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:12<00:10,  1.69s/it]
Epoch 00021: loss did not improve from 1.14217
Epoch 00021: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.7164 - acc: 0.6562
223/223 [==============================] - 0s 1ms/step - loss: 2.1281 - acc: 0.7220 - val_loss: 1.1751 - val_acc: 0.7321

Epoch 00001: loss improved from inf to 2.12809, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7737 - acc: 0.5312
223/223 [==============================] - 0s 33us/step - loss: 1.6397 - acc: 0.7085 - val_loss: 1.2100 - val_acc: 0.6786

Epoch 00002: loss improved from 2.12809 to 1.63967, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8307 - acc: 0.5625
223/223 [==============================] - 0s 32us/step - loss: 1.5900 - acc: 0.7578 - val_loss: 1.2503 - val_acc: 0.6786

Epoch 00003: loss improved from 1.63967 to 1.59004, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7447 - acc: 0.5938
223/223 [==============================] - 0s 32us/step - loss: 1.6612 - acc: 0.7668 - val_loss: 1.2479 - val_acc: 0.6786

Epoch 00004: loss did not improve from 1.59004
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6481 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.5353 - acc: 0.7444 - val_loss: 1.1804 - val_acc: 0.7143

Epoch 00005: loss improved from 1.59004 to 1.53534, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6810 - acc: 0.6875
223/223 [==============================] - 0s 31us/step - loss: 1.4440 - acc: 0.8027 - val_loss: 1.0563 - val_acc: 0.7143

Epoch 00006: loss improved from 1.53534 to 1.44396, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4461 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.3201 - acc: 0.8027 - val_loss: 1.0517 - val_acc: 0.7500

Epoch 00007: loss improved from 1.44396 to 1.32014, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3612 - acc: 0.7500
223/223 [==============================] - 0s 31us/step - loss: 1.3518 - acc: 0.8475 - val_loss: 1.2029 - val_acc: 0.6964

Epoch 00008: loss did not improve from 1.32014
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7399 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.5652 - acc: 0.8206 - val_loss: 1.1673 - val_acc: 0.7143

Epoch 00009: loss did not improve from 1.32014
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4727 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.4077 - acc: 0.7848 - val_loss: 1.1422 - val_acc: 0.7143

Epoch 00010: loss did not improve from 1.32014
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3995 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.2243 - acc: 0.8206 - val_loss: 1.0248 - val_acc: 0.7500

Epoch 00011: loss improved from 1.32014 to 1.22435, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2369 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.3199 - acc: 0.8251 - val_loss: 0.9149 - val_acc: 0.8036

Epoch 00012: loss did not improve from 1.22435
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3914 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.1748 - acc: 0.8206 - val_loss: 0.8892 - val_acc: 0.8214

Epoch 00013: loss improved from 1.22435 to 1.17479, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_13.h5
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0976 - acc: 0.7500
223/223 [==============================] - 0s 31us/step - loss: 1.3336 - acc: 0.8520 - val_loss: 0.7228 - val_acc: 0.9107

Epoch 00014: loss did not improve from 1.17479
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3304 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.2783 - acc: 0.8386 - val_loss: 0.7510 - val_acc: 0.8929

Epoch 00015: loss did not improve from 1.17479
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4873 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.3316 - acc: 0.8117 - val_loss: 1.1582 - val_acc: 0.8214

Epoch 00016: loss did not improve from 1.17479
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6085 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.2381 - acc: 0.8296 - val_loss: 0.8876 - val_acc: 0.7679

Epoch 00017: loss did not improve from 1.17479
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.0826 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.2458 - acc: 0.8430 - val_loss: 0.9536 - val_acc: 0.8214
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:13<00:08,  1.68s/it]
Epoch 00018: loss did not improve from 1.17479
Epoch 00018: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.7696 - acc: 0.5938
223/223 [==============================] - 0s 1ms/step - loss: 2.2680 - acc: 0.6906 - val_loss: 1.7112 - val_acc: 0.7500

Epoch 00001: loss improved from inf to 2.26804, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 2.0034 - acc: 0.5625
223/223 [==============================] - 0s 33us/step - loss: 1.9410 - acc: 0.6996 - val_loss: 1.4038 - val_acc: 0.6786

Epoch 00002: loss improved from 2.26804 to 1.94104, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8388 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.6723 - acc: 0.6951 - val_loss: 1.3212 - val_acc: 0.6786

Epoch 00003: loss improved from 1.94104 to 1.67226, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6980 - acc: 0.6250
223/223 [==============================] - 0s 36us/step - loss: 1.6756 - acc: 0.7175 - val_loss: 1.3527 - val_acc: 0.6964

Epoch 00004: loss did not improve from 1.67226
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6353 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.6601 - acc: 0.7578 - val_loss: 1.3592 - val_acc: 0.6786

Epoch 00005: loss improved from 1.67226 to 1.66007, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8766 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.6526 - acc: 0.7220 - val_loss: 1.2362 - val_acc: 0.6786

Epoch 00006: loss improved from 1.66007 to 1.65258, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7222 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.5402 - acc: 0.7489 - val_loss: 1.2374 - val_acc: 0.6786

Epoch 00007: loss improved from 1.65258 to 1.54018, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7160 - acc: 0.5938
223/223 [==============================] - 0s 30us/step - loss: 1.4506 - acc: 0.7354 - val_loss: 1.1197 - val_acc: 0.7143

Epoch 00008: loss improved from 1.54018 to 1.45059, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3331 - acc: 0.6562
223/223 [==============================] - 0s 30us/step - loss: 1.4435 - acc: 0.7803 - val_loss: 1.1849 - val_acc: 0.6786

Epoch 00009: loss improved from 1.45059 to 1.44353, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5181 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.3826 - acc: 0.7803 - val_loss: 1.0728 - val_acc: 0.7143

Epoch 00010: loss improved from 1.44353 to 1.38258, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3260 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.2959 - acc: 0.7937 - val_loss: 1.1048 - val_acc: 0.7143

Epoch 00011: loss improved from 1.38258 to 1.29592, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2978 - acc: 0.6562
223/223 [==============================] - 0s 30us/step - loss: 1.3878 - acc: 0.7803 - val_loss: 1.1191 - val_acc: 0.7143

Epoch 00012: loss did not improve from 1.29592
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4733 - acc: 0.6562
223/223 [==============================] - 0s 30us/step - loss: 1.3611 - acc: 0.7848 - val_loss: 1.0337 - val_acc: 0.7143

Epoch 00013: loss did not improve from 1.29592
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5235 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.2954 - acc: 0.7937 - val_loss: 0.9916 - val_acc: 0.7857

Epoch 00014: loss improved from 1.29592 to 1.29544, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5663 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.3819 - acc: 0.8296 - val_loss: 1.2768 - val_acc: 0.7500

Epoch 00015: loss did not improve from 1.29544
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6615 - acc: 0.6562
223/223 [==============================] - 0s 29us/step - loss: 1.5331 - acc: 0.7848 - val_loss: 1.1585 - val_acc: 0.7321

Epoch 00016: loss did not improve from 1.29544
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5745 - acc: 0.6250
223/223 [==============================] - 0s 29us/step - loss: 1.3411 - acc: 0.8296 - val_loss: 1.2254 - val_acc: 0.6964

Epoch 00017: loss did not improve from 1.29544
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7166 - acc: 0.5938
223/223 [==============================] - 0s 29us/step - loss: 1.3126 - acc: 0.7803 - val_loss: 1.1816 - val_acc: 0.6964

Epoch 00018: loss did not improve from 1.29544
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1673 - acc: 0.7188
223/223 [==============================] - 0s 29us/step - loss: 1.1071 - acc: 0.8565 - val_loss: 1.0076 - val_acc: 0.6964

Epoch 00019: loss improved from 1.29544 to 1.10714, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_14.h5
Epoch 20/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2721 - acc: 0.6562
223/223 [==============================] - 0s 29us/step - loss: 1.3815 - acc: 0.8027 - val_loss: 0.8791 - val_acc: 0.8571

Epoch 00020: loss did not improve from 1.10714
Epoch 21/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5316 - acc: 0.8125
223/223 [==============================] - 0s 29us/step - loss: 1.2239 - acc: 0.8565 - val_loss: 0.8241 - val_acc: 0.8571

Epoch 00021: loss did not improve from 1.10714
Epoch 22/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4257 - acc: 0.6875
223/223 [==============================] - 0s 29us/step - loss: 1.5253 - acc: 0.8161 - val_loss: 0.8060 - val_acc: 0.8393

Epoch 00022: loss did not improve from 1.10714
Epoch 23/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3328 - acc: 0.7188
223/223 [==============================] - 0s 29us/step - loss: 1.2283 - acc: 0.8296 - val_loss: 0.8465 - val_acc: 0.7857

Epoch 00023: loss did not improve from 1.10714
Epoch 24/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3233 - acc: 0.6562
223/223 [==============================] - 0s 29us/step - loss: 1.1786 - acc: 0.8430 - val_loss: 1.0758 - val_acc: 0.7500
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:15<00:06,  1.70s/it]
Epoch 00024: loss did not improve from 1.10714
Epoch 00024: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.7020 - acc: 0.5938
223/223 [==============================] - 0s 1ms/step - loss: 2.4523 - acc: 0.6816 - val_loss: 1.6294 - val_acc: 0.7143

Epoch 00001: loss improved from inf to 2.45233, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 2.2865 - acc: 0.6250
223/223 [==============================] - 0s 33us/step - loss: 1.9193 - acc: 0.6816 - val_loss: 1.4104 - val_acc: 0.6607

Epoch 00002: loss improved from 2.45233 to 1.91932, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7642 - acc: 0.5312
223/223 [==============================] - 0s 31us/step - loss: 1.7175 - acc: 0.7309 - val_loss: 1.3669 - val_acc: 0.6786

Epoch 00003: loss improved from 1.91932 to 1.71747, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6791 - acc: 0.5625
223/223 [==============================] - 0s 31us/step - loss: 1.7328 - acc: 0.7354 - val_loss: 1.4708 - val_acc: 0.6786

Epoch 00004: loss did not improve from 1.71747
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7407 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.6859 - acc: 0.7130 - val_loss: 1.3258 - val_acc: 0.6786

Epoch 00005: loss improved from 1.71747 to 1.68591, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5484 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.4925 - acc: 0.7848 - val_loss: 1.2780 - val_acc: 0.6786

Epoch 00006: loss improved from 1.68591 to 1.49248, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6700 - acc: 0.5625
223/223 [==============================] - 0s 30us/step - loss: 1.5920 - acc: 0.7668 - val_loss: 1.2577 - val_acc: 0.6964

Epoch 00007: loss did not improve from 1.49248
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6221 - acc: 0.5938
223/223 [==============================] - 0s 30us/step - loss: 1.5187 - acc: 0.7578 - val_loss: 1.2068 - val_acc: 0.6786

Epoch 00008: loss did not improve from 1.49248
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5704 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.4116 - acc: 0.7848 - val_loss: 1.1639 - val_acc: 0.6786

Epoch 00009: loss improved from 1.49248 to 1.41156, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6400 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.4839 - acc: 0.7937 - val_loss: 1.3083 - val_acc: 0.6607

Epoch 00010: loss did not improve from 1.41156
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5263 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.4550 - acc: 0.7892 - val_loss: 1.3434 - val_acc: 0.6607

Epoch 00011: loss did not improve from 1.41156
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6216 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.5719 - acc: 0.7848 - val_loss: 1.2080 - val_acc: 0.6964

Epoch 00012: loss did not improve from 1.41156
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3324 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.5173 - acc: 0.7982 - val_loss: 1.3241 - val_acc: 0.7321

Epoch 00013: loss did not improve from 1.41156
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7177 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.6100 - acc: 0.7982 - val_loss: 1.0660 - val_acc: 0.7857
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:17<00:05,  1.67s/it]
Epoch 00014: loss did not improve from 1.41156
Epoch 00014: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.5480 - acc: 0.6250
223/223 [==============================] - 0s 1ms/step - loss: 2.1600 - acc: 0.7175 - val_loss: 1.5254 - val_acc: 0.6607

Epoch 00001: loss improved from inf to 2.15995, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8936 - acc: 0.4375
223/223 [==============================] - 0s 33us/step - loss: 1.7678 - acc: 0.6233 - val_loss: 1.3377 - val_acc: 0.6786

Epoch 00002: loss improved from 2.15995 to 1.76783, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7177 - acc: 0.5312
223/223 [==============================] - 0s 32us/step - loss: 1.8218 - acc: 0.6996 - val_loss: 1.2099 - val_acc: 0.6786

Epoch 00003: loss did not improve from 1.76783
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6865 - acc: 0.5312
223/223 [==============================] - 0s 30us/step - loss: 1.9011 - acc: 0.6592 - val_loss: 1.2993 - val_acc: 0.6786

Epoch 00004: loss did not improve from 1.76783
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8899 - acc: 0.5000
223/223 [==============================] - 0s 30us/step - loss: 1.7534 - acc: 0.6816 - val_loss: 1.2442 - val_acc: 0.6786

Epoch 00005: loss improved from 1.76783 to 1.75337, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7960 - acc: 0.5625
223/223 [==============================] - 0s 31us/step - loss: 1.6671 - acc: 0.6996 - val_loss: 1.3357 - val_acc: 0.6786

Epoch 00006: loss improved from 1.75337 to 1.66711, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8497 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.5827 - acc: 0.7309 - val_loss: 1.1574 - val_acc: 0.7143

Epoch 00007: loss improved from 1.66711 to 1.58269, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8178 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.5912 - acc: 0.7265 - val_loss: 1.3035 - val_acc: 0.6607

Epoch 00008: loss did not improve from 1.58269
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6079 - acc: 0.5625
223/223 [==============================] - 0s 30us/step - loss: 1.4020 - acc: 0.7444 - val_loss: 1.1908 - val_acc: 0.7143

Epoch 00009: loss improved from 1.58269 to 1.40204, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5421 - acc: 0.5625
223/223 [==============================] - 0s 31us/step - loss: 1.3671 - acc: 0.8072 - val_loss: 1.1840 - val_acc: 0.6964

Epoch 00010: loss improved from 1.40204 to 1.36713, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8196 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.4528 - acc: 0.7892 - val_loss: 1.1434 - val_acc: 0.7143

Epoch 00011: loss did not improve from 1.36713
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5507 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.3772 - acc: 0.8117 - val_loss: 1.1529 - val_acc: 0.7143

Epoch 00012: loss did not improve from 1.36713
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5894 - acc: 0.6562
223/223 [==============================] - 0s 30us/step - loss: 1.3901 - acc: 0.8072 - val_loss: 1.1718 - val_acc: 0.7143

Epoch 00013: loss did not improve from 1.36713
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5152 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.6735 - acc: 0.7578 - val_loss: 1.3234 - val_acc: 0.7321

Epoch 00014: loss did not improve from 1.36713
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4438 - acc: 0.6562
223/223 [==============================] - 0s 30us/step - loss: 1.4809 - acc: 0.8117 - val_loss: 1.4704 - val_acc: 0.7143
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:18<00:03,  1.62s/it]
Epoch 00015: loss did not improve from 1.36713
Epoch 00015: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.4779 - acc: 0.6562
223/223 [==============================] - 0s 1ms/step - loss: 2.0495 - acc: 0.7265 - val_loss: 1.3368 - val_acc: 0.6964

Epoch 00001: loss improved from inf to 2.04954, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.9502 - acc: 0.4375
223/223 [==============================] - 0s 33us/step - loss: 2.0958 - acc: 0.6054 - val_loss: 1.2962 - val_acc: 0.7143

Epoch 00002: loss did not improve from 2.04954
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.9350 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.7753 - acc: 0.6502 - val_loss: 1.3496 - val_acc: 0.6786

Epoch 00003: loss improved from 2.04954 to 1.77533, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7656 - acc: 0.5625
223/223 [==============================] - 0s 32us/step - loss: 1.6569 - acc: 0.6771 - val_loss: 1.2658 - val_acc: 0.6786

Epoch 00004: loss improved from 1.77533 to 1.65689, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6843 - acc: 0.5625
223/223 [==============================] - 0s 31us/step - loss: 1.7080 - acc: 0.6996 - val_loss: 1.2338 - val_acc: 0.6786

Epoch 00005: loss did not improve from 1.65689
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5714 - acc: 0.6250
223/223 [==============================] - 0s 31us/step - loss: 1.6253 - acc: 0.7534 - val_loss: 1.3471 - val_acc: 0.6429

Epoch 00006: loss improved from 1.65689 to 1.62525, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7870 - acc: 0.5312
223/223 [==============================] - 0s 31us/step - loss: 1.6801 - acc: 0.6861 - val_loss: 1.2677 - val_acc: 0.6786

Epoch 00007: loss did not improve from 1.62525
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6775 - acc: 0.5938
223/223 [==============================] - 0s 30us/step - loss: 1.7056 - acc: 0.7130 - val_loss: 1.0971 - val_acc: 0.7143

Epoch 00008: loss did not improve from 1.62525
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6841 - acc: 0.5625
223/223 [==============================] - 0s 30us/step - loss: 1.5941 - acc: 0.7309 - val_loss: 1.1671 - val_acc: 0.6786

Epoch 00009: loss improved from 1.62525 to 1.59411, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8404 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.5273 - acc: 0.7534 - val_loss: 1.1669 - val_acc: 0.6786

Epoch 00010: loss improved from 1.59411 to 1.52729, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5442 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.2694 - acc: 0.8027 - val_loss: 1.0201 - val_acc: 0.7500

Epoch 00011: loss improved from 1.52729 to 1.26941, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3191 - acc: 0.6562
223/223 [==============================] - 0s 31us/step - loss: 1.2640 - acc: 0.8430 - val_loss: 1.1967 - val_acc: 0.6786

Epoch 00012: loss improved from 1.26941 to 1.26401, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4302 - acc: 0.7188
223/223 [==============================] - 0s 31us/step - loss: 1.4338 - acc: 0.8206 - val_loss: 1.1941 - val_acc: 0.6607

Epoch 00013: loss did not improve from 1.26401
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7412 - acc: 0.5938
223/223 [==============================] - 0s 30us/step - loss: 1.3327 - acc: 0.8206 - val_loss: 1.1142 - val_acc: 0.7321

Epoch 00014: loss did not improve from 1.26401
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4870 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.2068 - acc: 0.8161 - val_loss: 1.0685 - val_acc: 0.7500

Epoch 00015: loss improved from 1.26401 to 1.20679, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2416 - acc: 0.7188
223/223 [==============================] - 0s 30us/step - loss: 1.1304 - acc: 0.8341 - val_loss: 1.0525 - val_acc: 0.7500

Epoch 00016: loss improved from 1.20679 to 1.13042, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_17.h5
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2881 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.4007 - acc: 0.8117 - val_loss: 0.8775 - val_acc: 0.8036

Epoch 00017: loss did not improve from 1.13042
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3671 - acc: 0.6562
223/223 [==============================] - 0s 30us/step - loss: 1.6354 - acc: 0.7623 - val_loss: 0.9373 - val_acc: 0.8036

Epoch 00018: loss did not improve from 1.13042
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3967 - acc: 0.7500
223/223 [==============================] - 0s 30us/step - loss: 1.3422 - acc: 0.8430 - val_loss: 1.0120 - val_acc: 0.7857

Epoch 00019: loss did not improve from 1.13042
Epoch 20/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5289 - acc: 0.5625
223/223 [==============================] - 0s 29us/step - loss: 1.2564 - acc: 0.8117 - val_loss: 0.9076 - val_acc: 0.7857

Epoch 00020: loss did not improve from 1.13042
Epoch 21/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5367 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.2468 - acc: 0.8296 - val_loss: 0.9025 - val_acc: 0.8036
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:20<00:01,  1.66s/it]
Epoch 00021: loss did not improve from 1.13042
Epoch 00021: early stopping
Train on 223 samples, validate on 56 samples
Epoch 1/100

 32/223 [===>..........................] - ETA: 1s - loss: 1.7393 - acc: 0.5938
223/223 [==============================] - 0s 1ms/step - loss: 2.3743 - acc: 0.7040 - val_loss: 1.3463 - val_acc: 0.7321

Epoch 00001: loss improved from inf to 2.37430, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/223 [===>..........................] - ETA: 0s - loss: 2.1053 - acc: 0.5000
223/223 [==============================] - 0s 33us/step - loss: 2.0191 - acc: 0.6816 - val_loss: 1.5828 - val_acc: 0.6786

Epoch 00002: loss improved from 2.37430 to 2.01910, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/223 [===>..........................] - ETA: 0s - loss: 2.0410 - acc: 0.5000
223/223 [==============================] - 0s 31us/step - loss: 1.9232 - acc: 0.6457 - val_loss: 1.4729 - val_acc: 0.6786

Epoch 00003: loss improved from 2.01910 to 1.92319, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/223 [===>..........................] - ETA: 0s - loss: 2.2206 - acc: 0.5312
223/223 [==============================] - 0s 31us/step - loss: 2.0001 - acc: 0.6592 - val_loss: 1.4746 - val_acc: 0.6607

Epoch 00004: loss did not improve from 1.92319
Epoch 5/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8934 - acc: 0.5312
223/223 [==============================] - 0s 31us/step - loss: 1.7787 - acc: 0.6906 - val_loss: 1.4584 - val_acc: 0.6786

Epoch 00005: loss improved from 1.92319 to 1.77868, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/223 [===>..........................] - ETA: 0s - loss: 2.0408 - acc: 0.5312
223/223 [==============================] - 0s 30us/step - loss: 1.7473 - acc: 0.6951 - val_loss: 1.4842 - val_acc: 0.6250

Epoch 00006: loss improved from 1.77868 to 1.74729, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7290 - acc: 0.5625
223/223 [==============================] - 0s 31us/step - loss: 1.6782 - acc: 0.7220 - val_loss: 1.2749 - val_acc: 0.6964

Epoch 00007: loss improved from 1.74729 to 1.67820, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6303 - acc: 0.5625
223/223 [==============================] - 0s 31us/step - loss: 1.8379 - acc: 0.7354 - val_loss: 1.3053 - val_acc: 0.6964

Epoch 00008: loss did not improve from 1.67820
Epoch 9/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8327 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.6725 - acc: 0.7668 - val_loss: 1.2240 - val_acc: 0.6786

Epoch 00009: loss improved from 1.67820 to 1.67247, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6938 - acc: 0.5625
223/223 [==============================] - 0s 30us/step - loss: 1.5692 - acc: 0.7534 - val_loss: 1.4505 - val_acc: 0.6964

Epoch 00010: loss improved from 1.67247 to 1.56915, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.9794 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.5620 - acc: 0.7085 - val_loss: 1.3091 - val_acc: 0.6786

Epoch 00011: loss improved from 1.56915 to 1.56200, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5453 - acc: 0.5938
223/223 [==============================] - 0s 30us/step - loss: 1.7470 - acc: 0.7578 - val_loss: 1.1848 - val_acc: 0.7143

Epoch 00012: loss did not improve from 1.56200
Epoch 13/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7920 - acc: 0.6250
223/223 [==============================] - 0s 30us/step - loss: 1.5384 - acc: 0.7803 - val_loss: 1.0038 - val_acc: 0.7857

Epoch 00013: loss improved from 1.56200 to 1.53836, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 14/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6621 - acc: 0.5938
223/223 [==============================] - 0s 31us/step - loss: 1.4430 - acc: 0.7758 - val_loss: 1.0134 - val_acc: 0.7679

Epoch 00014: loss improved from 1.53836 to 1.44304, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 15/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5663 - acc: 0.6875
223/223 [==============================] - 0s 30us/step - loss: 1.2922 - acc: 0.7982 - val_loss: 1.0378 - val_acc: 0.7857

Epoch 00015: loss improved from 1.44304 to 1.29219, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.2332 - acc: 0.7500
223/223 [==============================] - 0s 30us/step - loss: 1.3524 - acc: 0.8072 - val_loss: 1.0806 - val_acc: 0.7500

Epoch 00016: loss did not improve from 1.29219
Epoch 17/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5377 - acc: 0.6250
223/223 [==============================] - 0s 29us/step - loss: 1.4983 - acc: 0.7848 - val_loss: 1.0653 - val_acc: 0.8036

Epoch 00017: loss did not improve from 1.29219
Epoch 18/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6354 - acc: 0.6250
223/223 [==============================] - 0s 29us/step - loss: 1.4171 - acc: 0.7982 - val_loss: 1.1849 - val_acc: 0.7500

Epoch 00018: loss did not improve from 1.29219
Epoch 19/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.8917 - acc: 0.6250
223/223 [==============================] - 0s 29us/step - loss: 1.4137 - acc: 0.8072 - val_loss: 1.3457 - val_acc: 0.6429

Epoch 00019: loss did not improve from 1.29219
Epoch 20/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.4287 - acc: 0.5312
223/223 [==============================] - 0s 29us/step - loss: 1.1860 - acc: 0.8027 - val_loss: 1.1004 - val_acc: 0.7679

Epoch 00020: loss improved from 1.29219 to 1.18596, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 21/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.6957 - acc: 0.6562
223/223 [==============================] - 0s 30us/step - loss: 1.1711 - acc: 0.8296 - val_loss: 1.1550 - val_acc: 0.7143

Epoch 00021: loss improved from 1.18596 to 1.17114, saving model to ./results_TA97_with_S9/DeepAmes_models/weight_18.h5
Epoch 22/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.1044 - acc: 0.7500
223/223 [==============================] - 0s 30us/step - loss: 1.2950 - acc: 0.8520 - val_loss: 1.1664 - val_acc: 0.7321

Epoch 00022: loss did not improve from 1.17114
Epoch 23/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.3380 - acc: 0.6562
223/223 [==============================] - 0s 29us/step - loss: 1.4249 - acc: 0.7668 - val_loss: 1.4189 - val_acc: 0.6964

Epoch 00023: loss did not improve from 1.17114
Epoch 24/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.7192 - acc: 0.5938
223/223 [==============================] - 0s 29us/step - loss: 1.3346 - acc: 0.8161 - val_loss: 1.2705 - val_acc: 0.7679

Epoch 00024: loss did not improve from 1.17114
Epoch 25/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.5097 - acc: 0.7500
223/223 [==============================] - 0s 29us/step - loss: 1.5256 - acc: 0.7803 - val_loss: 1.5453 - val_acc: 0.7321

Epoch 00025: loss did not improve from 1.17114
Epoch 26/100

 32/223 [===>..........................] - ETA: 0s - loss: 1.9394 - acc: 0.6250
223/223 [==============================] - 0s 29us/step - loss: 1.4890 - acc: 0.7848 - val_loss: 1.4228 - val_acc: 0.7143
DeepAmes+ Weights: 100%|██████████| 13/13 [00:22<00:00,  1.69s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:22<00:00,  1.71s/it]

Epoch 00026: loss did not improve from 1.17114
Epoch 00026: early stopping
--- 1257.0763120651245 seconds ---

Generating metrics report for TA97_with_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 134 samples.
Processing weight 7...
  Done. 134 samples.
Processing weight 8...
  Done. 134 samples.
Processing weight 9...
  Done. 134 samples.
Processing weight 10...
  Done. 134 samples.
Processing weight 11...
  Done. 134 samples.
Processing weight 12...
  Done. 134 samples.
Processing weight 13...
  Done. 134 samples.
Processing weight 14...
  Done. 134 samples.
Processing weight 15...
  Done. 134 samples.
Processing weight 16...
  Done. 134 samples.
Processing weight 17...
  Done. 134 samples.
Processing weight 18...
  Done. 134 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA97_with_S9/metrics_report_TA97_with_S9.txt

Done!

Completed TA97_with_S9 in 1257.08 seconds

================================================================================
[14/16] Processing: TA97_without_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA97_without_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA97_without_S9_Test_mold2.csv
(1457, 777)
(1165, 777)
(137, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:03<00:59,  3.13s/it]KNN Seeds:  10%|█         | 2/20 [00:06<00:55,  3.10s/it]KNN Seeds:  15%|█▌        | 3/20 [00:09<00:52,  3.11s/it]KNN Seeds:  20%|██        | 4/20 [00:12<00:50,  3.13s/it]KNN Seeds:  25%|██▌       | 5/20 [00:15<00:47,  3.14s/it]KNN Seeds:  30%|███       | 6/20 [00:18<00:44,  3.15s/it]KNN Seeds:  35%|███▌      | 7/20 [00:22<00:41,  3.17s/it]KNN Seeds:  40%|████      | 8/20 [00:25<00:37,  3.17s/it]KNN Seeds:  45%|████▌     | 9/20 [00:28<00:35,  3.19s/it]KNN Seeds:  50%|█████     | 10/20 [00:31<00:32,  3.21s/it]KNN Seeds:  55%|█████▌    | 11/20 [00:34<00:29,  3.22s/it]KNN Seeds:  60%|██████    | 12/20 [00:38<00:25,  3.22s/it]KNN Seeds:  65%|██████▌   | 13/20 [00:41<00:22,  3.23s/it]KNN Seeds:  70%|███████   | 14/20 [00:44<00:19,  3.25s/it]KNN Seeds:  75%|███████▌  | 15/20 [00:47<00:16,  3.26s/it]KNN Seeds:  80%|████████  | 16/20 [00:51<00:13,  3.27s/it]KNN Seeds:  85%|████████▌ | 17/20 [00:54<00:09,  3.27s/it]KNN Seeds:  90%|█████████ | 18/20 [00:57<00:06,  3.27s/it]KNN Seeds:  95%|█████████▌| 19/20 [01:01<00:03,  3.29s/it]KNN Seeds: 100%|██████████| 20/20 [01:04<00:00,  3.30s/it]KNN Seeds: 100%|██████████| 20/20 [01:04<00:00,  3.22s/it]
24
(100, None, 'lbfgs')
(1457, 777)
(1165, 777)
(137, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:01<00:33,  1.78s/it]LR Seeds:  10%|█         | 2/20 [00:03<00:32,  1.83s/it]LR Seeds:  15%|█▌        | 3/20 [00:05<00:31,  1.86s/it]LR Seeds:  20%|██        | 4/20 [00:07<00:30,  1.89s/it]LR Seeds:  25%|██▌       | 5/20 [00:09<00:28,  1.88s/it]LR Seeds:  30%|███       | 6/20 [00:11<00:26,  1.89s/it]LR Seeds:  35%|███▌      | 7/20 [00:13<00:24,  1.88s/it]LR Seeds:  40%|████      | 8/20 [00:15<00:22,  1.89s/it]LR Seeds:  45%|████▌     | 9/20 [00:16<00:20,  1.90s/it]LR Seeds:  50%|█████     | 10/20 [00:18<00:19,  1.92s/it]LR Seeds:  55%|█████▌    | 11/20 [00:20<00:17,  1.93s/it]LR Seeds:  60%|██████    | 12/20 [00:22<00:15,  1.94s/it]LR Seeds:  65%|██████▌   | 13/20 [00:24<00:13,  1.96s/it]LR Seeds:  70%|███████   | 14/20 [00:26<00:11,  1.97s/it]LR Seeds:  75%|███████▌  | 15/20 [00:28<00:09,  1.97s/it]LR Seeds:  80%|████████  | 16/20 [00:30<00:07,  1.98s/it]LR Seeds:  85%|████████▌ | 17/20 [00:32<00:05,  1.99s/it]LR Seeds:  90%|█████████ | 18/20 [00:34<00:03,  2.00s/it]LR Seeds:  95%|█████████▌| 19/20 [00:36<00:02,  2.01s/it]LR Seeds: 100%|██████████| 20/20 [00:39<00:00,  2.07s/it]LR Seeds: 100%|██████████| 20/20 [00:39<00:00,  1.95s/it]
96
('rbf', 1, 1)
(1457, 777)
(1165, 777)
(137, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [00:20<06:30, 20.53s/it]SVM Seeds:  10%|█         | 2/20 [00:40<06:08, 20.49s/it]SVM Seeds:  15%|█▌        | 3/20 [01:01<05:48, 20.52s/it]SVM Seeds:  20%|██        | 4/20 [01:22<05:28, 20.52s/it]SVM Seeds:  25%|██▌       | 5/20 [01:42<05:08, 20.54s/it]SVM Seeds:  30%|███       | 6/20 [02:03<04:47, 20.55s/it]SVM Seeds:  35%|███▌      | 7/20 [02:23<04:27, 20.56s/it]SVM Seeds:  40%|████      | 8/20 [02:44<04:06, 20.57s/it]SVM Seeds:  45%|████▌     | 9/20 [03:04<03:46, 20.58s/it]SVM Seeds:  50%|█████     | 10/20 [03:25<03:25, 20.59s/it]SVM Seeds:  55%|█████▌    | 11/20 [03:46<03:05, 20.60s/it]SVM Seeds:  60%|██████    | 12/20 [04:06<02:44, 20.61s/it]SVM Seeds:  65%|██████▌   | 13/20 [04:27<02:24, 20.63s/it]SVM Seeds:  70%|███████   | 14/20 [04:48<02:03, 20.64s/it]SVM Seeds:  75%|███████▌  | 15/20 [05:08<01:43, 20.64s/it]SVM Seeds:  80%|████████  | 16/20 [05:29<01:22, 20.65s/it]SVM Seeds:  85%|████████▌ | 17/20 [05:50<01:01, 20.67s/it]SVM Seeds:  90%|█████████ | 18/20 [06:10<00:41, 20.67s/it]SVM Seeds:  95%|█████████▌| 19/20 [06:31<00:20, 20.70s/it]SVM Seeds: 100%|██████████| 20/20 [06:52<00:00, 20.71s/it]SVM Seeds: 100%|██████████| 20/20 [06:52<00:00, 20.62s/it]
200
(500, None, 70, 1, 'balanced')
(1457, 777)
(1165, 777)
(137, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:04<01:16,  4.05s/it]RF Seeds:  10%|█         | 2/20 [00:08<01:12,  4.05s/it]RF Seeds:  15%|█▌        | 3/20 [00:12<01:09,  4.06s/it]RF Seeds:  20%|██        | 4/20 [00:16<01:05,  4.07s/it]RF Seeds:  25%|██▌       | 5/20 [00:20<01:01,  4.08s/it]RF Seeds:  30%|███       | 6/20 [00:24<00:57,  4.09s/it]RF Seeds:  35%|███▌      | 7/20 [00:28<00:53,  4.11s/it]RF Seeds:  40%|████      | 8/20 [00:32<00:49,  4.11s/it]RF Seeds:  45%|████▌     | 9/20 [00:36<00:45,  4.12s/it]RF Seeds:  50%|█████     | 10/20 [00:41<00:41,  4.13s/it]RF Seeds:  55%|█████▌    | 11/20 [00:45<00:37,  4.14s/it]RF Seeds:  60%|██████    | 12/20 [00:49<00:33,  4.15s/it]RF Seeds:  65%|██████▌   | 13/20 [00:53<00:29,  4.17s/it]RF Seeds:  70%|███████   | 14/20 [00:57<00:25,  4.18s/it]RF Seeds:  75%|███████▌  | 15/20 [01:01<00:20,  4.19s/it]RF Seeds:  80%|████████  | 16/20 [01:06<00:16,  4.20s/it]RF Seeds:  85%|████████▌ | 17/20 [01:10<00:12,  4.22s/it]RF Seeds:  90%|█████████ | 18/20 [01:14<00:08,  4.25s/it]RF Seeds:  95%|█████████▌| 19/20 [01:19<00:04,  4.26s/it]RF Seeds: 100%|██████████| 20/20 [01:23<00:00,  4.26s/it]RF Seeds: 100%|██████████| 20/20 [01:23<00:00,  4.17s/it]
400
(0.01, 900, 7, 0.8, 6)
(1457, 777)
(1165, 777)
(137, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [00:31<09:53, 31.21s/it]XGBoost Seeds:  10%|█         | 2/20 [01:02<09:21, 31.18s/it]XGBoost Seeds:  15%|█▌        | 3/20 [01:33<08:50, 31.20s/it]XGBoost Seeds:  20%|██        | 4/20 [02:04<08:18, 31.17s/it]XGBoost Seeds:  25%|██▌       | 5/20 [02:35<07:47, 31.17s/it]XGBoost Seeds:  30%|███       | 6/20 [03:07<07:16, 31.17s/it]XGBoost Seeds:  35%|███▌      | 7/20 [03:38<06:45, 31.19s/it]XGBoost Seeds:  40%|████      | 8/20 [04:09<06:13, 31.15s/it]XGBoost Seeds:  45%|████▌     | 9/20 [04:40<05:42, 31.14s/it]XGBoost Seeds:  50%|█████     | 10/20 [05:11<05:10, 31.10s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [05:42<04:40, 31.13s/it]XGBoost Seeds:  60%|██████    | 12/20 [06:13<04:09, 31.18s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [06:45<03:38, 31.19s/it]XGBoost Seeds:  70%|███████   | 14/20 [07:16<03:07, 31.20s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [07:47<02:36, 31.26s/it]XGBoost Seeds:  80%|████████  | 16/20 [08:19<02:05, 31.31s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [08:50<01:33, 31.32s/it]XGBoost Seeds:  90%|█████████ | 18/20 [09:22<01:02, 31.38s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [09:53<00:31, 31.42s/it]XGBoost Seeds: 100%|██████████| 20/20 [10:24<00:00, 31.41s/it]XGBoost Seeds: 100%|██████████| 20/20 [10:24<00:00, 31.25s/it]
knn:  86
lr:  87
svm:  91
rf:  99
xgboost:  76
Combining validation predictions is completed
knn:  86
lr:  87
svm:  91
rf:  99
xgboost:  76
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 1.8081 - acc: 0.6875
233/233 [==============================] - 0s 1ms/step - loss: 1.7257 - acc: 0.6910 - val_loss: 1.4379 - val_acc: 0.8305

Epoch 00001: loss improved from inf to 1.72565, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7313 - acc: 0.8438
233/233 [==============================] - 0s 35us/step - loss: 1.4035 - acc: 0.8798 - val_loss: 1.1564 - val_acc: 0.8644

Epoch 00002: loss improved from 1.72565 to 1.40351, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4957 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.2790 - acc: 0.8927 - val_loss: 1.2152 - val_acc: 0.8644

Epoch 00003: loss improved from 1.40351 to 1.27900, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5353 - acc: 0.8750
233/233 [==============================] - 0s 34us/step - loss: 1.1572 - acc: 0.9185 - val_loss: 1.0244 - val_acc: 0.8644

Epoch 00004: loss improved from 1.27900 to 1.15724, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2717 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 1.1594 - acc: 0.9270 - val_loss: 0.9761 - val_acc: 0.8644

Epoch 00005: loss did not improve from 1.15724
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2279 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 0.9773 - acc: 0.9614 - val_loss: 1.0490 - val_acc: 0.8644

Epoch 00006: loss improved from 1.15724 to 0.97733, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3994 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.0147 - acc: 0.9399 - val_loss: 1.5779 - val_acc: 0.8305

Epoch 00007: loss did not improve from 0.97733
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2275 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.9987 - acc: 0.9270 - val_loss: 0.9322 - val_acc: 0.8644

Epoch 00008: loss did not improve from 0.97733
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9842 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 0.8838 - acc: 0.9485 - val_loss: 0.8932 - val_acc: 0.8644

Epoch 00009: loss improved from 0.97733 to 0.88380, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1700 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 0.9028 - acc: 0.9442 - val_loss: 1.3980 - val_acc: 0.8136

Epoch 00010: loss did not improve from 0.88380
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4342 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 0.9435 - acc: 0.9399 - val_loss: 0.9717 - val_acc: 0.8644

Epoch 00011: loss did not improve from 0.88380
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0535 - acc: 0.9688
233/233 [==============================] - 0s 33us/step - loss: 0.9320 - acc: 0.9571 - val_loss: 1.3351 - val_acc: 0.8305

Epoch 00012: loss did not improve from 0.88380
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4132 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 0.9672 - acc: 0.9442 - val_loss: 0.9041 - val_acc: 0.8983

Epoch 00013: loss did not improve from 0.88380
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0158 - acc: 0.9688
233/233 [==============================] - 0s 32us/step - loss: 0.8864 - acc: 0.9571 - val_loss: 0.8646 - val_acc: 0.8644
DeepAmes+ Weights:   8%|▊         | 1/13 [00:01<00:18,  1.54s/it]
Epoch 00014: loss did not improve from 0.88380
Epoch 00014: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.0049 - acc: 0.6250
233/233 [==============================] - 0s 1ms/step - loss: 1.8298 - acc: 0.6652 - val_loss: 1.4859 - val_acc: 0.8305

Epoch 00001: loss improved from inf to 1.82985, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6856 - acc: 0.7812
233/233 [==============================] - 0s 36us/step - loss: 1.3834 - acc: 0.8455 - val_loss: 1.1212 - val_acc: 0.8644

Epoch 00002: loss improved from 1.82985 to 1.38344, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5856 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.2357 - acc: 0.8884 - val_loss: 1.1227 - val_acc: 0.8814

Epoch 00003: loss improved from 1.38344 to 1.23567, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5970 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.1799 - acc: 0.9227 - val_loss: 1.0913 - val_acc: 0.8644

Epoch 00004: loss improved from 1.23567 to 1.17991, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4385 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 1.1006 - acc: 0.9399 - val_loss: 1.0751 - val_acc: 0.8644

Epoch 00005: loss improved from 1.17991 to 1.10058, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4874 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.2358 - acc: 0.8970 - val_loss: 1.3811 - val_acc: 0.8814

Epoch 00006: loss did not improve from 1.10058
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7823 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.1882 - acc: 0.9099 - val_loss: 1.5791 - val_acc: 0.8305

Epoch 00007: loss did not improve from 1.10058
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4297 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1362 - acc: 0.9185 - val_loss: 1.3067 - val_acc: 0.8644

Epoch 00008: loss did not improve from 1.10058
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4446 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 1.1391 - acc: 0.9227 - val_loss: 1.1308 - val_acc: 0.8644

Epoch 00009: loss did not improve from 1.10058
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4156 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.0700 - acc: 0.9270 - val_loss: 0.9893 - val_acc: 0.8644

Epoch 00010: loss improved from 1.10058 to 1.07005, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0909 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 1.1432 - acc: 0.9142 - val_loss: 1.4885 - val_acc: 0.8305

Epoch 00011: loss did not improve from 1.07005
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8025 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1824 - acc: 0.9185 - val_loss: 1.0964 - val_acc: 0.8814

Epoch 00012: loss did not improve from 1.07005
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1847 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.0380 - acc: 0.9270 - val_loss: 1.1423 - val_acc: 0.8475

Epoch 00013: loss improved from 1.07005 to 1.03796, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_7.h5
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4324 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.0929 - acc: 0.9185 - val_loss: 0.8511 - val_acc: 0.8983

Epoch 00014: loss did not improve from 1.03796
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1827 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.0402 - acc: 0.9142 - val_loss: 1.1363 - val_acc: 0.8475

Epoch 00015: loss did not improve from 1.03796
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7909 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1216 - acc: 0.9185 - val_loss: 0.9190 - val_acc: 0.8644

Epoch 00016: loss did not improve from 1.03796
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0799 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8283 - acc: 0.9528 - val_loss: 1.0280 - val_acc: 0.8475

Epoch 00017: loss improved from 1.03796 to 0.82835, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_7.h5
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2355 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9261 - acc: 0.9356 - val_loss: 0.9187 - val_acc: 0.8814

Epoch 00018: loss did not improve from 0.82835
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0211 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8400 - acc: 0.9485 - val_loss: 1.0334 - val_acc: 0.8644

Epoch 00019: loss did not improve from 0.82835
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3118 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9773 - acc: 0.9399 - val_loss: 0.9602 - val_acc: 0.8644

Epoch 00020: loss did not improve from 0.82835
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2405 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9289 - acc: 0.9399 - val_loss: 1.0706 - val_acc: 0.8983

Epoch 00021: loss did not improve from 0.82835
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1211 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8520 - acc: 0.9528 - val_loss: 0.9113 - val_acc: 0.8644
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:03<00:17,  1.63s/it]
Epoch 00022: loss did not improve from 0.82835
Epoch 00022: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.2054 - acc: 0.5938
233/233 [==============================] - 0s 1ms/step - loss: 1.7226 - acc: 0.7039 - val_loss: 2.5353 - val_acc: 0.8305

Epoch 00001: loss improved from inf to 1.72257, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9054 - acc: 0.8438
233/233 [==============================] - 0s 35us/step - loss: 1.4385 - acc: 0.8627 - val_loss: 1.3232 - val_acc: 0.8644

Epoch 00002: loss improved from 1.72257 to 1.43853, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7335 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.4974 - acc: 0.8755 - val_loss: 1.4650 - val_acc: 0.8136

Epoch 00003: loss did not improve from 1.43853
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.5010 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.5694 - acc: 0.8627 - val_loss: 1.1727 - val_acc: 0.8644

Epoch 00004: loss did not improve from 1.43853
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4619 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1861 - acc: 0.9142 - val_loss: 1.0980 - val_acc: 0.8644

Epoch 00005: loss improved from 1.43853 to 1.18612, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3157 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.2250 - acc: 0.8927 - val_loss: 1.0817 - val_acc: 0.8475

Epoch 00006: loss did not improve from 1.18612
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6660 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1805 - acc: 0.9142 - val_loss: 0.9915 - val_acc: 0.8644

Epoch 00007: loss improved from 1.18612 to 1.18053, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5171 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 1.0630 - acc: 0.9399 - val_loss: 0.9886 - val_acc: 0.8644

Epoch 00008: loss improved from 1.18053 to 1.06301, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3823 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 1.0360 - acc: 0.9485 - val_loss: 0.9374 - val_acc: 0.8814

Epoch 00009: loss improved from 1.06301 to 1.03602, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0460 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 1.0355 - acc: 0.9528 - val_loss: 1.5541 - val_acc: 0.8136

Epoch 00010: loss improved from 1.03602 to 1.03551, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4175 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.1350 - acc: 0.8970 - val_loss: 1.0968 - val_acc: 0.8305

Epoch 00011: loss did not improve from 1.03551
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2126 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.0685 - acc: 0.9227 - val_loss: 1.1332 - val_acc: 0.8305

Epoch 00012: loss did not improve from 1.03551
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0525 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.9610 - acc: 0.9399 - val_loss: 1.0465 - val_acc: 0.8644

Epoch 00013: loss improved from 1.03551 to 0.96103, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3524 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.0589 - acc: 0.9142 - val_loss: 1.0936 - val_acc: 0.8644

Epoch 00014: loss did not improve from 0.96103
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0194 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 0.8658 - acc: 0.9227 - val_loss: 0.9799 - val_acc: 0.8644

Epoch 00015: loss improved from 0.96103 to 0.86583, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9956 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 0.8332 - acc: 0.9399 - val_loss: 0.9315 - val_acc: 0.8644

Epoch 00016: loss improved from 0.86583 to 0.83316, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9688 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.8791 - acc: 0.9313 - val_loss: 0.9976 - val_acc: 0.8644

Epoch 00017: loss did not improve from 0.83316
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0188 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 0.7876 - acc: 0.9528 - val_loss: 0.8612 - val_acc: 0.8475

Epoch 00018: loss improved from 0.83316 to 0.78759, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.8973 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8816 - acc: 0.9185 - val_loss: 1.2246 - val_acc: 0.8644

Epoch 00019: loss did not improve from 0.78759
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1707 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 0.9226 - acc: 0.9313 - val_loss: 1.1791 - val_acc: 0.8305

Epoch 00020: loss did not improve from 0.78759
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.7317 - acc: 0.9375
233/233 [==============================] - 0s 31us/step - loss: 0.7885 - acc: 0.9399 - val_loss: 1.1893 - val_acc: 0.7627

Epoch 00021: loss did not improve from 0.78759
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.7391 - acc: 0.9375
233/233 [==============================] - 0s 31us/step - loss: 0.6926 - acc: 0.9571 - val_loss: 0.9688 - val_acc: 0.8814

Epoch 00022: loss improved from 0.78759 to 0.69262, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 23/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3089 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.8618 - acc: 0.9399 - val_loss: 0.7370 - val_acc: 0.8644

Epoch 00023: loss did not improve from 0.69262
Epoch 24/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.6962 - acc: 1.0000
233/233 [==============================] - 0s 31us/step - loss: 0.6313 - acc: 0.9828 - val_loss: 0.7392 - val_acc: 0.8983

Epoch 00024: loss improved from 0.69262 to 0.63132, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 25/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.6626 - acc: 1.0000
233/233 [==============================] - 0s 32us/step - loss: 0.6721 - acc: 0.9742 - val_loss: 0.8546 - val_acc: 0.8475

Epoch 00025: loss did not improve from 0.63132
Epoch 26/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.5317 - acc: 1.0000
233/233 [==============================] - 0s 31us/step - loss: 0.6003 - acc: 0.9657 - val_loss: 1.1598 - val_acc: 0.8644

Epoch 00026: loss improved from 0.63132 to 0.60034, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 27/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0513 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.7709 - acc: 0.9270 - val_loss: 1.0131 - val_acc: 0.8305

Epoch 00027: loss did not improve from 0.60034
Epoch 28/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.5931 - acc: 0.9688
233/233 [==============================] - 0s 32us/step - loss: 0.5335 - acc: 0.9828 - val_loss: 0.9461 - val_acc: 0.8305

Epoch 00028: loss improved from 0.60034 to 0.53348, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_8.h5
Epoch 29/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.7014 - acc: 0.9688
233/233 [==============================] - 0s 32us/step - loss: 0.7006 - acc: 0.9657 - val_loss: 1.0041 - val_acc: 0.8644

Epoch 00029: loss did not improve from 0.53348
Epoch 30/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9947 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 0.7305 - acc: 0.9356 - val_loss: 1.2896 - val_acc: 0.6271

Epoch 00030: loss did not improve from 0.53348
Epoch 31/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.6612 - acc: 0.9688
233/233 [==============================] - 0s 31us/step - loss: 0.7224 - acc: 0.9571 - val_loss: 0.7292 - val_acc: 0.8644

Epoch 00031: loss did not improve from 0.53348
Epoch 32/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0145 - acc: 0.9375
233/233 [==============================] - 0s 31us/step - loss: 0.7864 - acc: 0.9313 - val_loss: 0.8273 - val_acc: 0.8475

Epoch 00032: loss did not improve from 0.53348
Epoch 33/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.7029 - acc: 0.9375
233/233 [==============================] - 0s 31us/step - loss: 0.6944 - acc: 0.9442 - val_loss: 1.0130 - val_acc: 0.8475
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:05<00:17,  1.72s/it]
Epoch 00033: loss did not improve from 0.53348
Epoch 00033: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.3439 - acc: 0.6250
233/233 [==============================] - 0s 1ms/step - loss: 2.0485 - acc: 0.6609 - val_loss: 2.0185 - val_acc: 0.7966

Epoch 00001: loss improved from inf to 2.04851, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8747 - acc: 0.8125
233/233 [==============================] - 0s 35us/step - loss: 1.6183 - acc: 0.7897 - val_loss: 1.2352 - val_acc: 0.7966

Epoch 00002: loss improved from 2.04851 to 1.61832, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7201 - acc: 0.7812
233/233 [==============================] - 0s 34us/step - loss: 1.3924 - acc: 0.8584 - val_loss: 1.1580 - val_acc: 0.8475

Epoch 00003: loss improved from 1.61832 to 1.39238, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6307 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.3856 - acc: 0.8670 - val_loss: 1.1312 - val_acc: 0.8814

Epoch 00004: loss improved from 1.39238 to 1.38565, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4583 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.3590 - acc: 0.8627 - val_loss: 1.1183 - val_acc: 0.8814

Epoch 00005: loss improved from 1.38565 to 1.35897, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5974 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.2239 - acc: 0.9142 - val_loss: 1.0707 - val_acc: 0.8814

Epoch 00006: loss improved from 1.35897 to 1.22387, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3083 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.1452 - acc: 0.9185 - val_loss: 1.0217 - val_acc: 0.8814

Epoch 00007: loss improved from 1.22387 to 1.14523, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2050 - acc: 0.9375
233/233 [==============================] - 0s 33us/step - loss: 1.2504 - acc: 0.9013 - val_loss: 1.0593 - val_acc: 0.8475

Epoch 00008: loss did not improve from 1.14523
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4375 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.2310 - acc: 0.8798 - val_loss: 1.1582 - val_acc: 0.8475

Epoch 00009: loss did not improve from 1.14523
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4777 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.1930 - acc: 0.8970 - val_loss: 0.9453 - val_acc: 0.8814

Epoch 00010: loss did not improve from 1.14523
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9572 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 1.0525 - acc: 0.9056 - val_loss: 0.9431 - val_acc: 0.8305

Epoch 00011: loss improved from 1.14523 to 1.05246, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3706 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.1633 - acc: 0.8970 - val_loss: 1.0174 - val_acc: 0.8136

Epoch 00012: loss did not improve from 1.05246
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4320 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.0721 - acc: 0.9099 - val_loss: 0.7966 - val_acc: 0.8983

Epoch 00013: loss did not improve from 1.05246
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0286 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 0.9302 - acc: 0.9056 - val_loss: 1.1486 - val_acc: 0.8475

Epoch 00014: loss improved from 1.05246 to 0.93022, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1570 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 1.1443 - acc: 0.9056 - val_loss: 1.0844 - val_acc: 0.8644

Epoch 00015: loss did not improve from 0.93022
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.8079 - acc: 1.0000
233/233 [==============================] - 0s 31us/step - loss: 0.8505 - acc: 0.9614 - val_loss: 1.0771 - val_acc: 0.8644

Epoch 00016: loss improved from 0.93022 to 0.85051, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9978 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8168 - acc: 0.9528 - val_loss: 0.8852 - val_acc: 0.8814

Epoch 00017: loss improved from 0.85051 to 0.81684, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.8301 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 0.8177 - acc: 0.9614 - val_loss: 1.2647 - val_acc: 0.8644

Epoch 00018: loss did not improve from 0.81684
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1824 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 1.0688 - acc: 0.9056 - val_loss: 1.2546 - val_acc: 0.8644

Epoch 00019: loss did not improve from 0.81684
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0918 - acc: 0.8438
233/233 [==============================] - 0s 31us/step - loss: 0.9198 - acc: 0.9227 - val_loss: 1.0894 - val_acc: 0.8644

Epoch 00020: loss did not improve from 0.81684
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0404 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8818 - acc: 0.9056 - val_loss: 1.2315 - val_acc: 0.8475

Epoch 00021: loss did not improve from 0.81684
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9413 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 0.7959 - acc: 0.9227 - val_loss: 1.1961 - val_acc: 0.8644

Epoch 00022: loss improved from 0.81684 to 0.79586, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_9.h5
Epoch 23/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4116 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 0.8512 - acc: 0.9270 - val_loss: 0.9285 - val_acc: 0.8814

Epoch 00023: loss did not improve from 0.79586
Epoch 24/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1330 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8976 - acc: 0.9270 - val_loss: 1.1572 - val_acc: 0.8814

Epoch 00024: loss did not improve from 0.79586
Epoch 25/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9061 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8582 - acc: 0.9270 - val_loss: 1.0034 - val_acc: 0.8814

Epoch 00025: loss did not improve from 0.79586
Epoch 26/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1930 - acc: 0.9688
233/233 [==============================] - 0s 32us/step - loss: 0.8875 - acc: 0.9313 - val_loss: 1.2022 - val_acc: 0.8644

Epoch 00026: loss did not improve from 0.79586
Epoch 27/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0209 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9321 - acc: 0.9185 - val_loss: 1.0716 - val_acc: 0.8475
DeepAmes+ Weights:  31%|███       | 4/13 [00:06<00:15,  1.70s/it]
Epoch 00027: loss did not improve from 0.79586
Epoch 00027: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.0774 - acc: 0.6562
233/233 [==============================] - 0s 1ms/step - loss: 1.9840 - acc: 0.6524 - val_loss: 1.5306 - val_acc: 0.7627

Epoch 00001: loss improved from inf to 1.98404, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8848 - acc: 0.8125
233/233 [==============================] - 0s 35us/step - loss: 1.6184 - acc: 0.8283 - val_loss: 1.4349 - val_acc: 0.8305

Epoch 00002: loss improved from 1.98404 to 1.61841, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1402 - acc: 0.7812
233/233 [==============================] - 0s 34us/step - loss: 1.5225 - acc: 0.8455 - val_loss: 1.4459 - val_acc: 0.8136

Epoch 00003: loss improved from 1.61841 to 1.52246, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0060 - acc: 0.8125
233/233 [==============================] - 0s 34us/step - loss: 1.3723 - acc: 0.8584 - val_loss: 1.1842 - val_acc: 0.8475

Epoch 00004: loss improved from 1.52246 to 1.37231, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6390 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.4395 - acc: 0.8541 - val_loss: 1.4323 - val_acc: 0.8475

Epoch 00005: loss did not improve from 1.37231
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1475 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.4265 - acc: 0.8970 - val_loss: 1.0619 - val_acc: 0.8644

Epoch 00006: loss did not improve from 1.37231
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0081 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.2451 - acc: 0.9185 - val_loss: 0.9374 - val_acc: 0.8983

Epoch 00007: loss improved from 1.37231 to 1.24510, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3645 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 1.2472 - acc: 0.8927 - val_loss: 1.0294 - val_acc: 0.8644

Epoch 00008: loss did not improve from 1.24510
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3610 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.1271 - acc: 0.9099 - val_loss: 1.1391 - val_acc: 0.8814

Epoch 00009: loss improved from 1.24510 to 1.12706, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0880 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.1973 - acc: 0.8755 - val_loss: 1.4197 - val_acc: 0.8644

Epoch 00010: loss did not improve from 1.12706
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7252 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1345 - acc: 0.9227 - val_loss: 1.0061 - val_acc: 0.8644

Epoch 00011: loss did not improve from 1.12706
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8382 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1894 - acc: 0.9013 - val_loss: 0.9831 - val_acc: 0.8644

Epoch 00012: loss did not improve from 1.12706
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3860 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9947 - acc: 0.9399 - val_loss: 0.8741 - val_acc: 0.8814

Epoch 00013: loss improved from 1.12706 to 0.99473, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0700 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 0.9238 - acc: 0.9356 - val_loss: 0.8628 - val_acc: 0.8644

Epoch 00014: loss improved from 0.99473 to 0.92383, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_10.h5
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1436 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.9532 - acc: 0.9399 - val_loss: 1.2330 - val_acc: 0.8305

Epoch 00015: loss did not improve from 0.92383
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5247 - acc: 0.8438
233/233 [==============================] - 0s 31us/step - loss: 1.0267 - acc: 0.9142 - val_loss: 1.8504 - val_acc: 0.8305

Epoch 00016: loss did not improve from 0.92383
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6140 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.2333 - acc: 0.9142 - val_loss: 1.4609 - val_acc: 0.8475

Epoch 00017: loss did not improve from 0.92383
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1819 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9264 - acc: 0.9013 - val_loss: 1.3057 - val_acc: 0.8305

Epoch 00018: loss did not improve from 0.92383
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6930 - acc: 0.9062
233/233 [==============================] - 0s 31us/step - loss: 1.0077 - acc: 0.9270 - val_loss: 1.2974 - val_acc: 0.8305
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:08<00:13,  1.70s/it]
Epoch 00019: loss did not improve from 0.92383
Epoch 00019: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.5970 - acc: 0.6562
233/233 [==============================] - 0s 1ms/step - loss: 2.2822 - acc: 0.6609 - val_loss: 1.4903 - val_acc: 0.7627

Epoch 00001: loss improved from inf to 2.28215, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0811 - acc: 0.7812
233/233 [==============================] - 0s 38us/step - loss: 1.5766 - acc: 0.8069 - val_loss: 1.4670 - val_acc: 0.7966

Epoch 00002: loss improved from 2.28215 to 1.57658, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9589 - acc: 0.8438
233/233 [==============================] - 0s 36us/step - loss: 1.4963 - acc: 0.8369 - val_loss: 1.1706 - val_acc: 0.8475

Epoch 00003: loss improved from 1.57658 to 1.49631, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7298 - acc: 0.8438
233/233 [==============================] - 0s 35us/step - loss: 1.4070 - acc: 0.8541 - val_loss: 1.2308 - val_acc: 0.8475

Epoch 00004: loss improved from 1.49631 to 1.40701, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9802 - acc: 0.8125
233/233 [==============================] - 0s 36us/step - loss: 1.6330 - acc: 0.8627 - val_loss: 1.2699 - val_acc: 0.8644

Epoch 00005: loss did not improve from 1.40701
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.5721 - acc: 0.7812
233/233 [==============================] - 0s 35us/step - loss: 1.5829 - acc: 0.8841 - val_loss: 1.0236 - val_acc: 0.8814

Epoch 00006: loss did not improve from 1.40701
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0098 - acc: 0.8125
233/233 [==============================] - 0s 35us/step - loss: 1.4147 - acc: 0.8970 - val_loss: 0.9888 - val_acc: 0.8814

Epoch 00007: loss did not improve from 1.40701
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7332 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.3105 - acc: 0.8841 - val_loss: 1.1524 - val_acc: 0.8814

Epoch 00008: loss improved from 1.40701 to 1.31053, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0806 - acc: 0.8125
233/233 [==============================] - 0s 35us/step - loss: 1.3319 - acc: 0.8798 - val_loss: 1.0037 - val_acc: 0.8644

Epoch 00009: loss did not improve from 1.31053
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3711 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.1981 - acc: 0.8712 - val_loss: 1.0803 - val_acc: 0.8814

Epoch 00010: loss improved from 1.31053 to 1.19812, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6456 - acc: 0.8125
233/233 [==============================] - 0s 35us/step - loss: 1.2612 - acc: 0.8927 - val_loss: 1.1077 - val_acc: 0.8644

Epoch 00011: loss did not improve from 1.19812
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7119 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.2897 - acc: 0.8798 - val_loss: 1.0040 - val_acc: 0.8814

Epoch 00012: loss did not improve from 1.19812
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2555 - acc: 0.8125
233/233 [==============================] - 0s 34us/step - loss: 1.1543 - acc: 0.8584 - val_loss: 0.9238 - val_acc: 0.9153

Epoch 00013: loss improved from 1.19812 to 1.15431, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4893 - acc: 0.8750
233/233 [==============================] - 0s 34us/step - loss: 1.1168 - acc: 0.9142 - val_loss: 0.8348 - val_acc: 0.8983

Epoch 00014: loss improved from 1.15431 to 1.11684, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1696 - acc: 0.8750
233/233 [==============================] - 0s 34us/step - loss: 0.8883 - acc: 0.9356 - val_loss: 0.8475 - val_acc: 0.8814

Epoch 00015: loss improved from 1.11684 to 0.88831, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_11.h5
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5993 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 0.9816 - acc: 0.9056 - val_loss: 1.0977 - val_acc: 0.8814

Epoch 00016: loss did not improve from 0.88831
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4931 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.1129 - acc: 0.9142 - val_loss: 1.5119 - val_acc: 0.8644

Epoch 00017: loss did not improve from 0.88831
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1718 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.1952 - acc: 0.9056 - val_loss: 1.3352 - val_acc: 0.8475

Epoch 00018: loss did not improve from 0.88831
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3431 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.1223 - acc: 0.9013 - val_loss: 1.0462 - val_acc: 0.8475

Epoch 00019: loss did not improve from 0.88831
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4792 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.0524 - acc: 0.8970 - val_loss: 1.1174 - val_acc: 0.8644
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:10<00:11,  1.70s/it]
Epoch 00020: loss did not improve from 0.88831
Epoch 00020: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.3379 - acc: 0.5938
233/233 [==============================] - 0s 1ms/step - loss: 2.0851 - acc: 0.6695 - val_loss: 1.6325 - val_acc: 0.8136

Epoch 00001: loss improved from inf to 2.08514, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.5403 - acc: 0.8125
233/233 [==============================] - 0s 36us/step - loss: 1.7642 - acc: 0.8069 - val_loss: 1.2791 - val_acc: 0.8644

Epoch 00002: loss improved from 2.08514 to 1.76419, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8368 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.5488 - acc: 0.8541 - val_loss: 1.2360 - val_acc: 0.8644

Epoch 00003: loss improved from 1.76419 to 1.54878, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8964 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.5230 - acc: 0.8498 - val_loss: 1.1148 - val_acc: 0.8644

Epoch 00004: loss improved from 1.54878 to 1.52302, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8849 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.5808 - acc: 0.8498 - val_loss: 1.1334 - val_acc: 0.8475

Epoch 00005: loss did not improve from 1.52302
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7146 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.5018 - acc: 0.8326 - val_loss: 1.1258 - val_acc: 0.8644

Epoch 00006: loss improved from 1.52302 to 1.50178, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1614 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.4444 - acc: 0.8498 - val_loss: 1.0514 - val_acc: 0.8814

Epoch 00007: loss improved from 1.50178 to 1.44437, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4996 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.2343 - acc: 0.8755 - val_loss: 0.9669 - val_acc: 0.8814

Epoch 00008: loss improved from 1.44437 to 1.23426, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9638 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.3389 - acc: 0.8798 - val_loss: 1.0332 - val_acc: 0.8814

Epoch 00009: loss did not improve from 1.23426
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5789 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.3177 - acc: 0.8755 - val_loss: 0.9842 - val_acc: 0.8475

Epoch 00010: loss did not improve from 1.23426
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3772 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1403 - acc: 0.8970 - val_loss: 0.8980 - val_acc: 0.8814

Epoch 00011: loss improved from 1.23426 to 1.14035, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6431 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.1123 - acc: 0.9227 - val_loss: 1.0649 - val_acc: 0.8475

Epoch 00012: loss improved from 1.14035 to 1.11230, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3391 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9747 - acc: 0.9313 - val_loss: 0.9813 - val_acc: 0.8475

Epoch 00013: loss improved from 1.11230 to 0.97468, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0392 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.0479 - acc: 0.9227 - val_loss: 0.8197 - val_acc: 0.8814

Epoch 00014: loss did not improve from 0.97468
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0788 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.9431 - acc: 0.9313 - val_loss: 0.7495 - val_acc: 0.8983

Epoch 00015: loss improved from 0.97468 to 0.94311, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4270 - acc: 0.9688
233/233 [==============================] - 0s 32us/step - loss: 0.9720 - acc: 0.9356 - val_loss: 0.8803 - val_acc: 0.8644

Epoch 00016: loss did not improve from 0.94311
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2358 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.0862 - acc: 0.9185 - val_loss: 1.7347 - val_acc: 0.8136

Epoch 00017: loss did not improve from 0.94311
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.6704 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.2290 - acc: 0.9142 - val_loss: 1.0239 - val_acc: 0.8475

Epoch 00018: loss did not improve from 0.94311
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4027 - acc: 0.9375
233/233 [==============================] - 0s 31us/step - loss: 1.1686 - acc: 0.9056 - val_loss: 1.2768 - val_acc: 0.8644

Epoch 00019: loss did not improve from 0.94311
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0235 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 0.8369 - acc: 0.9099 - val_loss: 1.0009 - val_acc: 0.8644

Epoch 00020: loss improved from 0.94311 to 0.83689, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_12.h5
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7977 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.2319 - acc: 0.8798 - val_loss: 1.6617 - val_acc: 0.8475

Epoch 00021: loss did not improve from 0.83689
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5216 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.0913 - acc: 0.9056 - val_loss: 1.1875 - val_acc: 0.8814

Epoch 00022: loss did not improve from 0.83689
Epoch 23/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.8396 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.1234 - acc: 0.9056 - val_loss: 1.5855 - val_acc: 0.5763

Epoch 00023: loss did not improve from 0.83689
Epoch 24/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.0087 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9750 - acc: 0.8798 - val_loss: 1.3635 - val_acc: 0.8814

Epoch 00024: loss did not improve from 0.83689
Epoch 25/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3497 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1638 - acc: 0.8970 - val_loss: 1.5179 - val_acc: 0.7966
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:11<00:10,  1.68s/it]
Epoch 00025: loss did not improve from 0.83689
Epoch 00025: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.5384 - acc: 0.6562
233/233 [==============================] - 0s 1ms/step - loss: 2.6938 - acc: 0.6996 - val_loss: 2.1469 - val_acc: 0.8305

Epoch 00001: loss improved from inf to 2.69382, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 3.0735 - acc: 0.7812
233/233 [==============================] - 0s 36us/step - loss: 1.9130 - acc: 0.8283 - val_loss: 1.5748 - val_acc: 0.8305

Epoch 00002: loss improved from 2.69382 to 1.91305, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.5344 - acc: 0.8125
233/233 [==============================] - 0s 34us/step - loss: 1.6901 - acc: 0.8498 - val_loss: 1.3355 - val_acc: 0.8644

Epoch 00003: loss improved from 1.91305 to 1.69014, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2422 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.6461 - acc: 0.8455 - val_loss: 1.2776 - val_acc: 0.8644

Epoch 00004: loss improved from 1.69014 to 1.64614, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0535 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.4633 - acc: 0.8798 - val_loss: 1.2624 - val_acc: 0.8475

Epoch 00005: loss improved from 1.64614 to 1.46335, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8743 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.4213 - acc: 0.8755 - val_loss: 1.1020 - val_acc: 0.8644

Epoch 00006: loss improved from 1.46335 to 1.42126, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8490 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.4904 - acc: 0.8584 - val_loss: 1.0885 - val_acc: 0.8475

Epoch 00007: loss did not improve from 1.42126
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8971 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.2645 - acc: 0.8841 - val_loss: 1.0062 - val_acc: 0.8644

Epoch 00008: loss improved from 1.42126 to 1.26449, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2510 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.4314 - acc: 0.8712 - val_loss: 1.2940 - val_acc: 0.8644

Epoch 00009: loss did not improve from 1.26449
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5978 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.3652 - acc: 0.9013 - val_loss: 1.1111 - val_acc: 0.8475

Epoch 00010: loss did not improve from 1.26449
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8707 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.2596 - acc: 0.9270 - val_loss: 1.0429 - val_acc: 0.8475

Epoch 00011: loss improved from 1.26449 to 1.25957, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7874 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.2048 - acc: 0.9185 - val_loss: 1.1319 - val_acc: 0.8644

Epoch 00012: loss improved from 1.25957 to 1.20483, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6411 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.2335 - acc: 0.9185 - val_loss: 1.0746 - val_acc: 0.8644

Epoch 00013: loss did not improve from 1.20483
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1221 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.4980 - acc: 0.9099 - val_loss: 1.2648 - val_acc: 0.8814

Epoch 00014: loss did not improve from 1.20483
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2970 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.4885 - acc: 0.8884 - val_loss: 0.9105 - val_acc: 0.8983

Epoch 00015: loss did not improve from 1.20483
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8437 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.2502 - acc: 0.8927 - val_loss: 0.9969 - val_acc: 0.8983

Epoch 00016: loss did not improve from 1.20483
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5989 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1626 - acc: 0.8498 - val_loss: 0.8433 - val_acc: 0.8983

Epoch 00017: loss improved from 1.20483 to 1.16260, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6251 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.4250 - acc: 0.8712 - val_loss: 1.1842 - val_acc: 0.8814

Epoch 00018: loss did not improve from 1.16260
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0272 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.2676 - acc: 0.8755 - val_loss: 1.0518 - val_acc: 0.8814

Epoch 00019: loss did not improve from 1.16260
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2908 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1388 - acc: 0.9142 - val_loss: 2.1455 - val_acc: 0.8475

Epoch 00020: loss improved from 1.16260 to 1.13876, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.5035 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.3754 - acc: 0.8541 - val_loss: 1.2867 - val_acc: 0.8644

Epoch 00021: loss did not improve from 1.13876
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6149 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1535 - acc: 0.9099 - val_loss: 1.3402 - val_acc: 0.8644

Epoch 00022: loss did not improve from 1.13876
Epoch 23/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4286 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.0883 - acc: 0.8884 - val_loss: 1.2614 - val_acc: 0.8475

Epoch 00023: loss improved from 1.13876 to 1.08832, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 24/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2314 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.1925 - acc: 0.8627 - val_loss: 1.4668 - val_acc: 0.8644

Epoch 00024: loss did not improve from 1.08832
Epoch 25/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.3026 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.1841 - acc: 0.9227 - val_loss: 1.0363 - val_acc: 0.8814

Epoch 00025: loss did not improve from 1.08832
Epoch 26/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3071 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.0505 - acc: 0.8970 - val_loss: 1.1105 - val_acc: 0.8814

Epoch 00026: loss improved from 1.08832 to 1.05054, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 27/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3581 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.8940 - acc: 0.9013 - val_loss: 1.0195 - val_acc: 0.8814

Epoch 00027: loss improved from 1.05054 to 0.89403, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 28/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1560 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.9135 - acc: 0.9313 - val_loss: 0.9510 - val_acc: 0.8644

Epoch 00028: loss did not improve from 0.89403
Epoch 29/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9887 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.7996 - acc: 0.9313 - val_loss: 0.9194 - val_acc: 0.8814

Epoch 00029: loss improved from 0.89403 to 0.79964, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_13.h5
Epoch 30/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2288 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.1277 - acc: 0.9185 - val_loss: 0.9461 - val_acc: 0.8814

Epoch 00030: loss did not improve from 0.79964
Epoch 31/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3677 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 0.9351 - acc: 0.8884 - val_loss: 0.9792 - val_acc: 0.8136

Epoch 00031: loss did not improve from 0.79964
Epoch 32/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3967 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9855 - acc: 0.9013 - val_loss: 1.3082 - val_acc: 0.8475

Epoch 00032: loss did not improve from 0.79964
Epoch 33/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4625 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 0.9249 - acc: 0.8970 - val_loss: 0.8859 - val_acc: 0.8814

Epoch 00033: loss did not improve from 0.79964
Epoch 34/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9499 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 0.9675 - acc: 0.8841 - val_loss: 0.8792 - val_acc: 0.8983
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:13<00:08,  1.74s/it]
Epoch 00034: loss did not improve from 0.79964
Epoch 00034: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.4858 - acc: 0.6875
233/233 [==============================] - 0s 1ms/step - loss: 2.3532 - acc: 0.6223 - val_loss: 1.5880 - val_acc: 0.7627

Epoch 00001: loss improved from inf to 2.35323, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 3.1421 - acc: 0.7500
233/233 [==============================] - 0s 36us/step - loss: 1.8991 - acc: 0.8155 - val_loss: 1.5720 - val_acc: 0.8305

Epoch 00002: loss improved from 2.35323 to 1.89909, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.5325 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.6743 - acc: 0.8240 - val_loss: 1.2098 - val_acc: 0.8136

Epoch 00003: loss improved from 1.89909 to 1.67433, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1185 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.5458 - acc: 0.8627 - val_loss: 2.5671 - val_acc: 0.8136

Epoch 00004: loss improved from 1.67433 to 1.54575, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.4617 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.6227 - acc: 0.8455 - val_loss: 1.3221 - val_acc: 0.8305

Epoch 00005: loss did not improve from 1.54575
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.7343 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.6833 - acc: 0.8197 - val_loss: 1.5398 - val_acc: 0.8136

Epoch 00006: loss did not improve from 1.54575
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2019 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.5065 - acc: 0.8498 - val_loss: 1.5017 - val_acc: 0.8305

Epoch 00007: loss improved from 1.54575 to 1.50650, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2065 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.5524 - acc: 0.8584 - val_loss: 1.4090 - val_acc: 0.8305

Epoch 00008: loss did not improve from 1.50650
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.4758 - acc: 0.7812
233/233 [==============================] - 0s 32us/step - loss: 1.5286 - acc: 0.8240 - val_loss: 1.1345 - val_acc: 0.8475

Epoch 00009: loss did not improve from 1.50650
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9625 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.4006 - acc: 0.8584 - val_loss: 1.1811 - val_acc: 0.8136

Epoch 00010: loss improved from 1.50650 to 1.40064, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0332 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.3525 - acc: 0.8627 - val_loss: 1.0868 - val_acc: 0.8814

Epoch 00011: loss improved from 1.40064 to 1.35249, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5594 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.4468 - acc: 0.8712 - val_loss: 1.3404 - val_acc: 0.8814

Epoch 00012: loss did not improve from 1.35249
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.3437 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.4575 - acc: 0.8712 - val_loss: 1.1862 - val_acc: 0.8814

Epoch 00013: loss did not improve from 1.35249
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2795 - acc: 0.8438
233/233 [==============================] - 0s 31us/step - loss: 1.4290 - acc: 0.8627 - val_loss: 0.9732 - val_acc: 0.8814

Epoch 00014: loss did not improve from 1.35249
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5464 - acc: 0.9375
233/233 [==============================] - 0s 31us/step - loss: 1.1611 - acc: 0.9185 - val_loss: 1.6075 - val_acc: 0.8475

Epoch 00015: loss improved from 1.35249 to 1.16109, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5785 - acc: 0.8125
233/233 [==============================] - 0s 37us/step - loss: 1.2859 - acc: 0.8927 - val_loss: 2.3339 - val_acc: 0.7966

Epoch 00016: loss did not improve from 1.16109
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.5727 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.6008 - acc: 0.8498 - val_loss: 1.5454 - val_acc: 0.8305

Epoch 00017: loss did not improve from 1.16109
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5855 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1018 - acc: 0.8927 - val_loss: 1.5714 - val_acc: 0.8644

Epoch 00018: loss improved from 1.16109 to 1.10176, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5372 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1472 - acc: 0.8841 - val_loss: 1.2070 - val_acc: 0.8644

Epoch 00019: loss did not improve from 1.10176
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3526 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 1.0479 - acc: 0.8627 - val_loss: 1.1941 - val_acc: 0.8814

Epoch 00020: loss improved from 1.10176 to 1.04789, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5333 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.1989 - acc: 0.9013 - val_loss: 1.2068 - val_acc: 0.8644

Epoch 00021: loss did not improve from 1.04789
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4141 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 1.0728 - acc: 0.8627 - val_loss: 1.2618 - val_acc: 0.8814

Epoch 00022: loss did not improve from 1.04789
Epoch 23/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2077 - acc: 0.9062
233/233 [==============================] - 0s 31us/step - loss: 0.9669 - acc: 0.9185 - val_loss: 1.4414 - val_acc: 0.8644

Epoch 00023: loss improved from 1.04789 to 0.96693, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 24/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3093 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.0371 - acc: 0.8841 - val_loss: 1.1788 - val_acc: 0.8644

Epoch 00024: loss did not improve from 0.96693
Epoch 25/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1424 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 1.1469 - acc: 0.8584 - val_loss: 1.1332 - val_acc: 0.8644

Epoch 00025: loss did not improve from 0.96693
Epoch 26/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.8828 - acc: 0.9375
233/233 [==============================] - 0s 31us/step - loss: 0.8778 - acc: 0.9099 - val_loss: 0.9703 - val_acc: 0.8644

Epoch 00026: loss improved from 0.96693 to 0.87780, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 27/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.8606 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 0.8494 - acc: 0.9185 - val_loss: 1.0576 - val_acc: 0.8475

Epoch 00027: loss improved from 0.87780 to 0.84938, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_14.h5
Epoch 28/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9966 - acc: 0.7812
233/233 [==============================] - 0s 32us/step - loss: 1.2060 - acc: 0.8627 - val_loss: 1.7212 - val_acc: 0.8305

Epoch 00028: loss did not improve from 0.84938
Epoch 29/100

 32/233 [===>..........................] - ETA: 0s - loss: 3.4403 - acc: 0.8125
233/233 [==============================] - 0s 31us/step - loss: 1.3725 - acc: 0.8712 - val_loss: 1.0467 - val_acc: 0.8814

Epoch 00029: loss did not improve from 0.84938
Epoch 30/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6756 - acc: 0.8125
233/233 [==============================] - 0s 31us/step - loss: 0.9786 - acc: 0.9099 - val_loss: 1.4577 - val_acc: 0.8644

Epoch 00030: loss did not improve from 0.84938
Epoch 31/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2335 - acc: 0.8125
233/233 [==============================] - 0s 31us/step - loss: 1.2312 - acc: 0.8970 - val_loss: 1.3495 - val_acc: 0.8644

Epoch 00031: loss did not improve from 0.84938
Epoch 32/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3595 - acc: 0.8438
233/233 [==============================] - 0s 31us/step - loss: 1.0283 - acc: 0.8584 - val_loss: 1.1687 - val_acc: 0.8644
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:15<00:07,  1.76s/it]
Epoch 00032: loss did not improve from 0.84938
Epoch 00032: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.8353 - acc: 0.6250
233/233 [==============================] - 0s 1ms/step - loss: 1.9899 - acc: 0.6824 - val_loss: 1.3570 - val_acc: 0.7797

Epoch 00001: loss improved from inf to 1.98993, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9553 - acc: 0.7812
233/233 [==============================] - 0s 35us/step - loss: 1.7598 - acc: 0.7811 - val_loss: 1.3138 - val_acc: 0.7797

Epoch 00002: loss improved from 1.98993 to 1.75980, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0121 - acc: 0.7812
233/233 [==============================] - 0s 33us/step - loss: 1.7407 - acc: 0.7639 - val_loss: 1.3973 - val_acc: 0.7797

Epoch 00003: loss improved from 1.75980 to 1.74067, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1310 - acc: 0.7500
233/233 [==============================] - 0s 33us/step - loss: 1.7043 - acc: 0.7597 - val_loss: 1.2340 - val_acc: 0.8136

Epoch 00004: loss improved from 1.74067 to 1.70432, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2771 - acc: 0.7812
233/233 [==============================] - 0s 33us/step - loss: 1.5652 - acc: 0.8240 - val_loss: 1.1705 - val_acc: 0.8305

Epoch 00005: loss improved from 1.70432 to 1.56515, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6524 - acc: 0.7812
233/233 [==============================] - 0s 33us/step - loss: 1.6246 - acc: 0.8455 - val_loss: 2.0609 - val_acc: 0.7458

Epoch 00006: loss did not improve from 1.56515
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 3.1537 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.8459 - acc: 0.8455 - val_loss: 1.4262 - val_acc: 0.7966

Epoch 00007: loss did not improve from 1.56515
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9439 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.4842 - acc: 0.8283 - val_loss: 1.2411 - val_acc: 0.8475

Epoch 00008: loss improved from 1.56515 to 1.48421, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6859 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.4505 - acc: 0.8498 - val_loss: 1.2227 - val_acc: 0.8644

Epoch 00009: loss improved from 1.48421 to 1.45054, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8919 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.4379 - acc: 0.7983 - val_loss: 1.1522 - val_acc: 0.8814

Epoch 00010: loss improved from 1.45054 to 1.43791, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9462 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.3259 - acc: 0.8970 - val_loss: 1.0677 - val_acc: 0.8644

Epoch 00011: loss improved from 1.43791 to 1.32592, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3564 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.2075 - acc: 0.8627 - val_loss: 1.2062 - val_acc: 0.8305

Epoch 00012: loss improved from 1.32592 to 1.20750, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5391 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.2649 - acc: 0.8283 - val_loss: 1.1379 - val_acc: 0.8644

Epoch 00013: loss did not improve from 1.20750
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5457 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.3389 - acc: 0.8627 - val_loss: 1.1989 - val_acc: 0.8475

Epoch 00014: loss did not improve from 1.20750
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6248 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1461 - acc: 0.8798 - val_loss: 1.1474 - val_acc: 0.8136

Epoch 00015: loss improved from 1.20750 to 1.14613, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3198 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.2178 - acc: 0.8541 - val_loss: 2.1308 - val_acc: 0.8136

Epoch 00016: loss did not improve from 1.14613
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0766 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.1294 - acc: 0.9056 - val_loss: 1.3747 - val_acc: 0.7966

Epoch 00017: loss improved from 1.14613 to 1.12936, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_15.h5
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2372 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.4583 - acc: 0.8412 - val_loss: 4.5370 - val_acc: 0.7966

Epoch 00018: loss did not improve from 1.12936
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 5.5776 - acc: 0.7812
233/233 [==============================] - 0s 32us/step - loss: 3.2772 - acc: 0.7725 - val_loss: 3.4390 - val_acc: 0.7966

Epoch 00019: loss did not improve from 1.12936
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.9572 - acc: 0.8438
233/233 [==============================] - 0s 31us/step - loss: 2.6244 - acc: 0.8240 - val_loss: 3.3897 - val_acc: 0.7797

Epoch 00020: loss did not improve from 1.12936
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 3.3000 - acc: 0.7500
233/233 [==============================] - 0s 31us/step - loss: 2.8311 - acc: 0.8369 - val_loss: 3.2219 - val_acc: 0.8136

Epoch 00021: loss did not improve from 1.12936
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 3.6241 - acc: 0.8125
233/233 [==============================] - 0s 31us/step - loss: 2.5302 - acc: 0.8541 - val_loss: 2.5153 - val_acc: 0.8475
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:17<00:05,  1.75s/it]
Epoch 00022: loss did not improve from 1.12936
Epoch 00022: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.8902 - acc: 0.6875
233/233 [==============================] - 0s 1ms/step - loss: 2.4004 - acc: 0.6309 - val_loss: 1.3929 - val_acc: 0.7797

Epoch 00001: loss improved from inf to 2.40038, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.4949 - acc: 0.8125
233/233 [==============================] - 0s 35us/step - loss: 2.0265 - acc: 0.7253 - val_loss: 1.4198 - val_acc: 0.7966

Epoch 00002: loss improved from 2.40038 to 2.02648, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.4944 - acc: 0.7812
233/233 [==============================] - 0s 33us/step - loss: 1.8218 - acc: 0.8155 - val_loss: 1.3496 - val_acc: 0.8475

Epoch 00003: loss improved from 2.02648 to 1.82180, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8320 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.6613 - acc: 0.8112 - val_loss: 1.3009 - val_acc: 0.8305

Epoch 00004: loss improved from 1.82180 to 1.66128, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1171 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.7010 - acc: 0.8026 - val_loss: 1.2863 - val_acc: 0.8305

Epoch 00005: loss did not improve from 1.66128
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1288 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.4295 - acc: 0.8584 - val_loss: 1.3103 - val_acc: 0.8305

Epoch 00006: loss improved from 1.66128 to 1.42948, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.3157 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.7192 - acc: 0.7811 - val_loss: 1.1151 - val_acc: 0.8305

Epoch 00007: loss did not improve from 1.42948
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8784 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.5018 - acc: 0.8412 - val_loss: 1.4118 - val_acc: 0.8475

Epoch 00008: loss did not improve from 1.42948
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8767 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.5706 - acc: 0.8326 - val_loss: 1.3209 - val_acc: 0.8305

Epoch 00009: loss did not improve from 1.42948
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4468 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.3763 - acc: 0.8627 - val_loss: 1.5017 - val_acc: 0.8136

Epoch 00010: loss improved from 1.42948 to 1.37634, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7992 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.3038 - acc: 0.8455 - val_loss: 1.2033 - val_acc: 0.8305

Epoch 00011: loss improved from 1.37634 to 1.30378, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2237 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 1.3150 - acc: 0.8369 - val_loss: 1.6949 - val_acc: 0.8136

Epoch 00012: loss did not improve from 1.30378
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4195 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.2753 - acc: 0.8798 - val_loss: 1.2918 - val_acc: 0.8136

Epoch 00013: loss improved from 1.30378 to 1.27530, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0076 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.6702 - acc: 0.8498 - val_loss: 1.0989 - val_acc: 0.8305

Epoch 00014: loss did not improve from 1.27530
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7879 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.2381 - acc: 0.8627 - val_loss: 1.0723 - val_acc: 0.8644

Epoch 00015: loss improved from 1.27530 to 1.23810, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6165 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.2237 - acc: 0.8541 - val_loss: 1.0718 - val_acc: 0.8644

Epoch 00016: loss improved from 1.23810 to 1.22365, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4055 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.0775 - acc: 0.8927 - val_loss: 1.1076 - val_acc: 0.8644

Epoch 00017: loss improved from 1.22365 to 1.07749, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3267 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 0.9634 - acc: 0.9185 - val_loss: 0.9844 - val_acc: 0.8475

Epoch 00018: loss improved from 1.07749 to 0.96336, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_16.h5
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9640 - acc: 0.9062
233/233 [==============================] - 0s 32us/step - loss: 1.1016 - acc: 0.8884 - val_loss: 1.1097 - val_acc: 0.8475

Epoch 00019: loss did not improve from 0.96336
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6122 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.1682 - acc: 0.8755 - val_loss: 1.1202 - val_acc: 0.8475

Epoch 00020: loss did not improve from 0.96336
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 0.9335 - acc: 0.9688
233/233 [==============================] - 0s 32us/step - loss: 1.2773 - acc: 0.8755 - val_loss: 1.2182 - val_acc: 0.8644

Epoch 00021: loss did not improve from 0.96336
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9216 - acc: 0.8438
233/233 [==============================] - 0s 31us/step - loss: 1.4993 - acc: 0.8283 - val_loss: 0.9510 - val_acc: 0.8644

Epoch 00022: loss did not improve from 0.96336
Epoch 23/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5293 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 1.0589 - acc: 0.9056 - val_loss: 1.6008 - val_acc: 0.8475
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:18<00:03,  1.72s/it]
Epoch 00023: loss did not improve from 0.96336
Epoch 00023: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.4921 - acc: 0.7188
233/233 [==============================] - 0s 1ms/step - loss: 2.0601 - acc: 0.6781 - val_loss: 1.4595 - val_acc: 0.7458

Epoch 00001: loss improved from inf to 2.06011, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.3870 - acc: 0.7500
233/233 [==============================] - 0s 36us/step - loss: 1.9468 - acc: 0.6695 - val_loss: 1.6837 - val_acc: 0.7627

Epoch 00002: loss improved from 2.06011 to 1.94684, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.3752 - acc: 0.7812
233/233 [==============================] - 0s 34us/step - loss: 1.7750 - acc: 0.7382 - val_loss: 1.3614 - val_acc: 0.8136

Epoch 00003: loss improved from 1.94684 to 1.77499, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0968 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.6481 - acc: 0.8026 - val_loss: 1.5525 - val_acc: 0.7627

Epoch 00004: loss improved from 1.77499 to 1.64809, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.6301 - acc: 0.7812
233/233 [==============================] - 0s 34us/step - loss: 1.7653 - acc: 0.7983 - val_loss: 1.1922 - val_acc: 0.8136

Epoch 00005: loss did not improve from 1.64809
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7469 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.4713 - acc: 0.8455 - val_loss: 1.1093 - val_acc: 0.8475

Epoch 00006: loss improved from 1.64809 to 1.47127, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3793 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.3884 - acc: 0.8670 - val_loss: 1.6027 - val_acc: 0.7966

Epoch 00007: loss improved from 1.47127 to 1.38836, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.3187 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.6906 - acc: 0.8026 - val_loss: 1.2257 - val_acc: 0.8136

Epoch 00008: loss did not improve from 1.38836
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0609 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.4296 - acc: 0.8455 - val_loss: 1.1890 - val_acc: 0.8305

Epoch 00009: loss did not improve from 1.38836
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.3075 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.5624 - acc: 0.8240 - val_loss: 1.3628 - val_acc: 0.8475

Epoch 00010: loss did not improve from 1.38836
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.4772 - acc: 0.7812
233/233 [==============================] - 0s 33us/step - loss: 1.4151 - acc: 0.8755 - val_loss: 1.2132 - val_acc: 0.8475

Epoch 00011: loss did not improve from 1.38836
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7838 - acc: 0.8750
233/233 [==============================] - 0s 32us/step - loss: 1.3399 - acc: 0.8412 - val_loss: 1.2461 - val_acc: 0.8644

Epoch 00012: loss improved from 1.38836 to 1.33992, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1948 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.3023 - acc: 0.8498 - val_loss: 1.1743 - val_acc: 0.8475

Epoch 00013: loss improved from 1.33992 to 1.30232, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.2084 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.0918 - acc: 0.9099 - val_loss: 1.0879 - val_acc: 0.8475

Epoch 00014: loss improved from 1.30232 to 1.09182, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_17.h5
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3930 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.1525 - acc: 0.8369 - val_loss: 1.3983 - val_acc: 0.6102

Epoch 00015: loss did not improve from 1.09182
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3283 - acc: 0.9375
233/233 [==============================] - 0s 32us/step - loss: 1.1104 - acc: 0.8841 - val_loss: 1.3254 - val_acc: 0.8475

Epoch 00016: loss did not improve from 1.09182
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.4408 - acc: 0.9062
233/233 [==============================] - 0s 33us/step - loss: 1.1939 - acc: 0.8841 - val_loss: 1.3802 - val_acc: 0.8475

Epoch 00017: loss did not improve from 1.09182
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9843 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.3737 - acc: 0.8326 - val_loss: 1.2447 - val_acc: 0.8475

Epoch 00018: loss did not improve from 1.09182
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.6222 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.6631 - acc: 0.7768 - val_loss: 1.5517 - val_acc: 0.5424
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:20<00:01,  1.72s/it]
Epoch 00019: loss did not improve from 1.09182
Epoch 00019: early stopping
Train on 233 samples, validate on 59 samples
Epoch 1/100

 32/233 [===>..........................] - ETA: 1s - loss: 2.1643 - acc: 0.6562
233/233 [==============================] - 0s 1ms/step - loss: 2.4887 - acc: 0.5837 - val_loss: 1.8187 - val_acc: 0.7797

Epoch 00001: loss improved from inf to 2.48872, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/233 [===>..........................] - ETA: 0s - loss: 3.1375 - acc: 0.7812
233/233 [==============================] - 0s 35us/step - loss: 1.9213 - acc: 0.7597 - val_loss: 1.3605 - val_acc: 0.8305

Epoch 00002: loss improved from 2.48872 to 1.92129, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.6446 - acc: 0.8125
233/233 [==============================] - 0s 34us/step - loss: 1.8245 - acc: 0.7725 - val_loss: 1.5533 - val_acc: 0.8136

Epoch 00003: loss improved from 1.92129 to 1.82446, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.9501 - acc: 0.7500
233/233 [==============================] - 0s 33us/step - loss: 1.7689 - acc: 0.7768 - val_loss: 1.2293 - val_acc: 0.8644

Epoch 00004: loss improved from 1.82446 to 1.76885, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9576 - acc: 0.8438
233/233 [==============================] - 0s 33us/step - loss: 1.5483 - acc: 0.8283 - val_loss: 1.2410 - val_acc: 0.8814

Epoch 00005: loss improved from 1.76885 to 1.54834, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2711 - acc: 0.8750
233/233 [==============================] - 0s 33us/step - loss: 1.5572 - acc: 0.8369 - val_loss: 1.5734 - val_acc: 0.8305

Epoch 00006: loss did not improve from 1.54834
Epoch 7/100

 32/233 [===>..........................] - ETA: 0s - loss: 3.1603 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.7732 - acc: 0.8455 - val_loss: 1.1720 - val_acc: 0.8814

Epoch 00007: loss did not improve from 1.54834
Epoch 8/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1189 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.7488 - acc: 0.8197 - val_loss: 1.2973 - val_acc: 0.8814

Epoch 00008: loss did not improve from 1.54834
Epoch 9/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.1272 - acc: 0.8438
233/233 [==============================] - 0s 34us/step - loss: 1.6066 - acc: 0.7725 - val_loss: 1.0726 - val_acc: 0.8644

Epoch 00009: loss did not improve from 1.54834
Epoch 10/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3582 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.5304 - acc: 0.7468 - val_loss: 1.2246 - val_acc: 0.8644

Epoch 00010: loss improved from 1.54834 to 1.53036, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9791 - acc: 0.8125
233/233 [==============================] - 0s 32us/step - loss: 1.3394 - acc: 0.7940 - val_loss: 1.1015 - val_acc: 0.8814

Epoch 00011: loss improved from 1.53036 to 1.33935, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0191 - acc: 0.7812
233/233 [==============================] - 0s 32us/step - loss: 1.2890 - acc: 0.8112 - val_loss: 1.2391 - val_acc: 0.8814

Epoch 00012: loss improved from 1.33935 to 1.28904, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 13/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.2023 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.4458 - acc: 0.8326 - val_loss: 1.1895 - val_acc: 0.8814

Epoch 00013: loss did not improve from 1.28904
Epoch 14/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.8325 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.3183 - acc: 0.8369 - val_loss: 1.4446 - val_acc: 0.8305

Epoch 00014: loss did not improve from 1.28904
Epoch 15/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.3915 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 1.2987 - acc: 0.8798 - val_loss: 1.7501 - val_acc: 0.8475

Epoch 00015: loss did not improve from 1.28904
Epoch 16/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0155 - acc: 0.8125
233/233 [==============================] - 0s 31us/step - loss: 1.4144 - acc: 0.8455 - val_loss: 1.6575 - val_acc: 0.8136

Epoch 00016: loss did not improve from 1.28904
Epoch 17/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.1525 - acc: 0.9375
233/233 [==============================] - 0s 31us/step - loss: 1.2070 - acc: 0.8841 - val_loss: 1.8080 - val_acc: 0.8305

Epoch 00017: loss improved from 1.28904 to 1.20703, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 18/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.4422 - acc: 0.8438
233/233 [==============================] - 0s 32us/step - loss: 1.3508 - acc: 0.8670 - val_loss: 1.2217 - val_acc: 0.8475

Epoch 00018: loss did not improve from 1.20703
Epoch 19/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.7739 - acc: 0.8750
233/233 [==============================] - 0s 31us/step - loss: 1.3957 - acc: 0.8541 - val_loss: 1.2387 - val_acc: 0.8644

Epoch 00019: loss did not improve from 1.20703
Epoch 20/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.6380 - acc: 0.8438
233/233 [==============================] - 0s 31us/step - loss: 1.1923 - acc: 0.8970 - val_loss: 3.0403 - val_acc: 0.8136

Epoch 00020: loss improved from 1.20703 to 1.19226, saving model to ./results_TA97_without_S9/DeepAmes_models/weight_18.h5
Epoch 21/100

 32/233 [===>..........................] - ETA: 0s - loss: 4.4150 - acc: 0.8125
233/233 [==============================] - 0s 35us/step - loss: 2.2617 - acc: 0.7554 - val_loss: 2.3761 - val_acc: 0.5254

Epoch 00021: loss did not improve from 1.19226
Epoch 22/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.0846 - acc: 0.8125
233/233 [==============================] - 0s 34us/step - loss: 1.4010 - acc: 0.7768 - val_loss: 1.4596 - val_acc: 0.8475

Epoch 00022: loss did not improve from 1.19226
Epoch 23/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.5829 - acc: 0.8750
233/233 [==============================] - 0s 34us/step - loss: 1.2884 - acc: 0.8240 - val_loss: 1.5703 - val_acc: 0.8475

Epoch 00023: loss did not improve from 1.19226
Epoch 24/100

 32/233 [===>..........................] - ETA: 0s - loss: 1.9818 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.8905 - acc: 0.7983 - val_loss: 2.2496 - val_acc: 0.8136

Epoch 00024: loss did not improve from 1.19226
Epoch 25/100

 32/233 [===>..........................] - ETA: 0s - loss: 2.9984 - acc: 0.8125
233/233 [==============================] - 0s 33us/step - loss: 1.7212 - acc: 0.8197 - val_loss: 1.8916 - val_acc: 0.8475
DeepAmes+ Weights: 100%|██████████| 13/13 [00:22<00:00,  1.72s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:22<00:00,  1.71s/it]

Epoch 00025: loss did not improve from 1.19226
Epoch 00025: early stopping
--- 1294.4037821292877 seconds ---

Generating metrics report for TA97_without_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 137 samples.
Processing weight 7...
  Done. 137 samples.
Processing weight 8...
  Done. 137 samples.
Processing weight 9...
  Done. 137 samples.
Processing weight 10...
  Done. 137 samples.
Processing weight 11...
  Done. 137 samples.
Processing weight 12...
  Done. 137 samples.
Processing weight 13...
  Done. 137 samples.
Processing weight 14...
  Done. 137 samples.
Processing weight 15...
  Done. 137 samples.
Processing weight 16...
  Done. 137 samples.
Processing weight 17...
  Done. 137 samples.
Processing weight 18...
  Done. 137 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA97_without_S9/metrics_report_TA97_without_S9.txt

Done!

Completed TA97_without_S9 in 1294.40 seconds

================================================================================
[15/16] Processing: TA98_with_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA98_with_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA98_with_S9_Test_mold2.csv
(4588, 777)
(3670, 777)
(538, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:30<09:43, 30.69s/it]KNN Seeds:  10%|█         | 2/20 [01:01<09:10, 30.60s/it]KNN Seeds:  15%|█▌        | 3/20 [01:33<08:49, 31.17s/it]KNN Seeds:  20%|██        | 4/20 [02:04<08:18, 31.16s/it]KNN Seeds:  25%|██▌       | 5/20 [02:35<07:49, 31.33s/it]KNN Seeds:  30%|███       | 6/20 [03:06<07:17, 31.25s/it]KNN Seeds:  35%|███▌      | 7/20 [03:37<06:44, 31.13s/it]KNN Seeds:  40%|████      | 8/20 [04:09<06:14, 31.19s/it]KNN Seeds:  45%|████▌     | 9/20 [04:39<05:41, 31.07s/it]KNN Seeds:  50%|█████     | 10/20 [05:11<05:11, 31.14s/it]KNN Seeds:  55%|█████▌    | 11/20 [05:42<04:40, 31.11s/it]KNN Seeds:  60%|██████    | 12/20 [06:13<04:08, 31.11s/it]KNN Seeds:  65%|██████▌   | 13/20 [06:44<03:37, 31.11s/it]KNN Seeds:  70%|███████   | 14/20 [07:15<03:05, 30.98s/it]KNN Seeds:  75%|███████▌  | 15/20 [07:46<02:35, 31.05s/it]KNN Seeds:  80%|████████  | 16/20 [08:17<02:04, 31.15s/it]KNN Seeds:  85%|████████▌ | 17/20 [08:48<01:33, 31.10s/it]KNN Seeds:  90%|█████████ | 18/20 [09:19<01:02, 31.05s/it]KNN Seeds:  95%|█████████▌| 19/20 [09:51<00:31, 31.14s/it]KNN Seeds: 100%|██████████| 20/20 [10:22<00:00, 31.22s/it]KNN Seeds: 100%|██████████| 20/20 [10:22<00:00, 31.12s/it]
24
(100, None, 'lbfgs')
(4588, 777)
(3670, 777)
(538, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:02<00:53,  2.82s/it]LR Seeds:  10%|█         | 2/20 [00:05<00:50,  2.80s/it]LR Seeds:  15%|█▌        | 3/20 [00:08<00:47,  2.81s/it]LR Seeds:  20%|██        | 4/20 [00:11<00:45,  2.82s/it]LR Seeds:  25%|██▌       | 5/20 [00:14<00:42,  2.83s/it]LR Seeds:  30%|███       | 6/20 [00:16<00:39,  2.84s/it]LR Seeds:  35%|███▌      | 7/20 [00:19<00:37,  2.85s/it]LR Seeds:  40%|████      | 8/20 [00:22<00:34,  2.86s/it]LR Seeds:  45%|████▌     | 9/20 [00:25<00:31,  2.87s/it]LR Seeds:  50%|█████     | 10/20 [00:28<00:28,  2.87s/it]LR Seeds:  55%|█████▌    | 11/20 [00:31<00:25,  2.87s/it]LR Seeds:  60%|██████    | 12/20 [00:34<00:23,  2.88s/it]LR Seeds:  65%|██████▌   | 13/20 [00:37<00:20,  2.89s/it]LR Seeds:  70%|███████   | 14/20 [00:40<00:17,  2.91s/it]LR Seeds:  75%|███████▌  | 15/20 [00:43<00:14,  2.92s/it]LR Seeds:  80%|████████  | 16/20 [00:46<00:11,  2.94s/it]LR Seeds:  85%|████████▌ | 17/20 [00:49<00:08,  2.95s/it]LR Seeds:  90%|█████████ | 18/20 [00:52<00:05,  3.00s/it]LR Seeds:  95%|█████████▌| 19/20 [00:55<00:03,  3.00s/it]LR Seeds: 100%|██████████| 20/20 [00:58<00:00,  3.00s/it]LR Seeds: 100%|██████████| 20/20 [00:58<00:00,  2.91s/it]
96
('rbf', 1, 1)
(4588, 777)
(3670, 777)
(538, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [03:19<1:03:05, 199.23s/it]SVM Seeds:  10%|█         | 2/20 [06:37<59:38, 198.83s/it]  SVM Seeds:  15%|█▌        | 3/20 [09:56<56:16, 198.62s/it]SVM Seeds:  20%|██        | 4/20 [13:15<53:00, 198.80s/it]SVM Seeds:  25%|██▌       | 5/20 [16:34<49:44, 198.93s/it]SVM Seeds:  30%|███       | 6/20 [19:53<46:26, 199.03s/it]SVM Seeds:  35%|███▌      | 7/20 [23:12<43:05, 198.90s/it]SVM Seeds:  40%|████      | 8/20 [26:31<39:46, 198.90s/it]SVM Seeds:  45%|████▌     | 9/20 [29:49<36:27, 198.85s/it]SVM Seeds:  50%|█████     | 10/20 [33:08<33:06, 198.69s/it]SVM Seeds:  55%|█████▌    | 11/20 [36:27<29:48, 198.73s/it]SVM Seeds:  60%|██████    | 12/20 [39:45<26:29, 198.64s/it]SVM Seeds:  65%|██████▌   | 13/20 [43:03<23:09, 198.56s/it]SVM Seeds:  70%|███████   | 14/20 [46:21<19:50, 198.44s/it]SVM Seeds:  75%|███████▌  | 15/20 [49:40<16:31, 198.36s/it]SVM Seeds:  80%|████████  | 16/20 [52:58<13:13, 198.27s/it]SVM Seeds:  85%|████████▌ | 17/20 [56:16<09:54, 198.32s/it]SVM Seeds:  90%|█████████ | 18/20 [59:34<06:36, 198.32s/it]SVM Seeds:  95%|█████████▌| 19/20 [1:02:53<03:18, 198.42s/it]SVM Seeds: 100%|██████████| 20/20 [1:06:12<00:00, 198.42s/it]SVM Seeds: 100%|██████████| 20/20 [1:06:12<00:00, 198.60s/it]
200
(500, None, 70, 1, 'balanced')
(4588, 777)
(3670, 777)
(538, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:15<04:52, 15.41s/it]RF Seeds:  10%|█         | 2/20 [00:30<04:37, 15.42s/it]RF Seeds:  15%|█▌        | 3/20 [00:46<04:22, 15.44s/it]RF Seeds:  20%|██        | 4/20 [01:01<04:07, 15.44s/it]RF Seeds:  25%|██▌       | 5/20 [01:17<03:51, 15.45s/it]RF Seeds:  30%|███       | 6/20 [01:32<03:36, 15.47s/it]RF Seeds:  35%|███▌      | 7/20 [01:48<03:21, 15.49s/it]RF Seeds:  40%|████      | 8/20 [02:03<03:05, 15.50s/it]RF Seeds:  45%|████▌     | 9/20 [02:19<02:50, 15.50s/it]RF Seeds:  50%|█████     | 10/20 [02:34<02:35, 15.51s/it]RF Seeds:  55%|█████▌    | 11/20 [02:50<02:19, 15.52s/it]RF Seeds:  60%|██████    | 12/20 [03:05<02:04, 15.52s/it]RF Seeds:  65%|██████▌   | 13/20 [03:21<01:48, 15.53s/it]RF Seeds:  70%|███████   | 14/20 [03:36<01:33, 15.53s/it]RF Seeds:  75%|███████▌  | 15/20 [03:52<01:17, 15.53s/it]RF Seeds:  80%|████████  | 16/20 [04:08<01:02, 15.55s/it]RF Seeds:  85%|████████▌ | 17/20 [04:23<00:46, 15.59s/it]RF Seeds:  90%|█████████ | 18/20 [04:39<00:31, 15.60s/it]RF Seeds:  95%|█████████▌| 19/20 [04:54<00:15, 15.60s/it]RF Seeds: 100%|██████████| 20/20 [05:10<00:00, 15.60s/it]RF Seeds: 100%|██████████| 20/20 [05:10<00:00, 15.53s/it]
400
(0.01, 900, 7, 0.8, 6)
(4588, 777)
(3670, 777)
(538, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [01:01<19:25, 61.34s/it]XGBoost Seeds:  10%|█         | 2/20 [02:02<18:21, 61.22s/it]XGBoost Seeds:  15%|█▌        | 3/20 [03:03<17:21, 61.26s/it]XGBoost Seeds:  20%|██        | 4/20 [04:05<16:21, 61.36s/it]XGBoost Seeds:  25%|██▌       | 5/20 [05:06<15:20, 61.37s/it]XGBoost Seeds:  30%|███       | 6/20 [06:08<14:19, 61.39s/it]XGBoost Seeds:  35%|███▌      | 7/20 [07:09<13:18, 61.44s/it]XGBoost Seeds:  40%|████      | 8/20 [08:11<12:17, 61.49s/it]XGBoost Seeds:  45%|████▌     | 9/20 [09:12<11:16, 61.53s/it]XGBoost Seeds:  50%|█████     | 10/20 [10:14<10:15, 61.52s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [11:16<09:14, 61.57s/it]XGBoost Seeds:  60%|██████    | 12/20 [12:17<08:12, 61.59s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [13:19<07:10, 61.56s/it]XGBoost Seeds:  70%|███████   | 14/20 [14:20<06:09, 61.52s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [15:22<05:07, 61.52s/it]XGBoost Seeds:  80%|████████  | 16/20 [16:23<04:06, 61.51s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [17:25<03:04, 61.51s/it]XGBoost Seeds:  90%|█████████ | 18/20 [18:26<02:02, 61.46s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [19:27<01:01, 61.45s/it]XGBoost Seeds: 100%|██████████| 20/20 [20:29<00:00, 61.45s/it]XGBoost Seeds: 100%|██████████| 20/20 [20:29<00:00, 61.47s/it]
knn:  96
lr:  93
svm:  90
rf:  83
xgboost:  87
Combining validation predictions is completed
knn:  96
lr:  93
svm:  90
rf:  83
xgboost:  87
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.3389 - acc: 0.8125
734/734 [==============================] - 0s 400us/step - loss: 1.6108 - acc: 0.7766 - val_loss: 1.1161 - val_acc: 0.7989

Epoch 00001: loss improved from inf to 1.61081, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3063 - acc: 0.9062
734/734 [==============================] - 0s 31us/step - loss: 1.4646 - acc: 0.7956 - val_loss: 1.0405 - val_acc: 0.8098

Epoch 00002: loss improved from 1.61081 to 1.46455, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1842 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.3940 - acc: 0.8065 - val_loss: 1.0284 - val_acc: 0.8098

Epoch 00003: loss improved from 1.46455 to 1.39403, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1696 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.3391 - acc: 0.8093 - val_loss: 1.0202 - val_acc: 0.7772

Epoch 00004: loss improved from 1.39403 to 1.33912, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0511 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.2588 - acc: 0.8011 - val_loss: 0.9595 - val_acc: 0.7826

Epoch 00005: loss improved from 1.33912 to 1.25884, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9327 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.2141 - acc: 0.8161 - val_loss: 0.8853 - val_acc: 0.8207

Epoch 00006: loss improved from 1.25884 to 1.21405, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9504 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1698 - acc: 0.8079 - val_loss: 0.9297 - val_acc: 0.8370

Epoch 00007: loss improved from 1.21405 to 1.16981, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9807 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1170 - acc: 0.8270 - val_loss: 0.8322 - val_acc: 0.8207

Epoch 00008: loss improved from 1.16981 to 1.11703, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8924 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1117 - acc: 0.8147 - val_loss: 0.8430 - val_acc: 0.8152

Epoch 00009: loss improved from 1.11703 to 1.11170, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8622 - acc: 0.9375
734/734 [==============================] - 0s 29us/step - loss: 1.0680 - acc: 0.8106 - val_loss: 0.8256 - val_acc: 0.8370

Epoch 00010: loss improved from 1.11170 to 1.06799, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9947 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0542 - acc: 0.8243 - val_loss: 0.7556 - val_acc: 0.8370

Epoch 00011: loss improved from 1.06799 to 1.05424, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8793 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0278 - acc: 0.8270 - val_loss: 0.6465 - val_acc: 0.8315

Epoch 00012: loss improved from 1.05424 to 1.02780, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9179 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0266 - acc: 0.8270 - val_loss: 0.6491 - val_acc: 0.8424

Epoch 00013: loss improved from 1.02780 to 1.02660, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0757 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0197 - acc: 0.8338 - val_loss: 0.6659 - val_acc: 0.8152

Epoch 00014: loss improved from 1.02660 to 1.01975, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8846 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9886 - acc: 0.8202 - val_loss: 0.6695 - val_acc: 0.8261

Epoch 00015: loss improved from 1.01975 to 0.98856, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8514 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9742 - acc: 0.8079 - val_loss: 0.6509 - val_acc: 0.8261

Epoch 00016: loss improved from 0.98856 to 0.97415, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7612 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9559 - acc: 0.8311 - val_loss: 0.6871 - val_acc: 0.7717

Epoch 00017: loss improved from 0.97415 to 0.95589, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9362 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 0.9245 - acc: 0.8202 - val_loss: 0.5811 - val_acc: 0.8152

Epoch 00018: loss improved from 0.95589 to 0.92448, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7657 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9092 - acc: 0.8256 - val_loss: 0.5677 - val_acc: 0.8370

Epoch 00019: loss improved from 0.92448 to 0.90921, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7502 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9163 - acc: 0.8256 - val_loss: 0.5674 - val_acc: 0.8315

Epoch 00020: loss did not improve from 0.90921
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7481 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.8876 - acc: 0.8392 - val_loss: 0.7073 - val_acc: 0.8152

Epoch 00021: loss improved from 0.90921 to 0.88760, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7890 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 0.8878 - acc: 0.8420 - val_loss: 0.7384 - val_acc: 0.7663

Epoch 00022: loss did not improve from 0.88760
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8147 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 0.9051 - acc: 0.8270 - val_loss: 0.6799 - val_acc: 0.7880

Epoch 00023: loss did not improve from 0.88760
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8802 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 0.8977 - acc: 0.8324 - val_loss: 0.6772 - val_acc: 0.8152

Epoch 00024: loss did not improve from 0.88760
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 0.6937 - acc: 0.9375
734/734 [==============================] - 0s 29us/step - loss: 0.8566 - acc: 0.8597 - val_loss: 0.6562 - val_acc: 0.7989

Epoch 00025: loss improved from 0.88760 to 0.85665, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 26/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7365 - acc: 0.9375
734/734 [==============================] - 0s 29us/step - loss: 0.8938 - acc: 0.8433 - val_loss: 0.6196 - val_acc: 0.7989

Epoch 00026: loss did not improve from 0.85665
Epoch 27/100

 32/734 [>.............................] - ETA: 0s - loss: 0.6675 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.8446 - acc: 0.8270 - val_loss: 0.6127 - val_acc: 0.8315

Epoch 00027: loss improved from 0.85665 to 0.84458, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_6.h5
Epoch 28/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7212 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.8745 - acc: 0.8202 - val_loss: 0.5687 - val_acc: 0.8207

Epoch 00028: loss did not improve from 0.84458
Epoch 29/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8005 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.8865 - acc: 0.8270 - val_loss: 0.5130 - val_acc: 0.8043

Epoch 00029: loss did not improve from 0.84458
Epoch 30/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7149 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9043 - acc: 0.8243 - val_loss: 0.5562 - val_acc: 0.8424

Epoch 00030: loss did not improve from 0.84458
Epoch 31/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9309 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 0.9156 - acc: 0.8229 - val_loss: 0.7274 - val_acc: 0.8261

Epoch 00031: loss did not improve from 0.84458
Epoch 32/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7319 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.8681 - acc: 0.8270 - val_loss: 0.6173 - val_acc: 0.8152
DeepAmes+ Weights:   8%|▊         | 1/13 [00:02<00:28,  2.38s/it]
Epoch 00032: loss did not improve from 0.84458
Epoch 00032: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.3093 - acc: 0.9062
734/734 [==============================] - 0s 382us/step - loss: 1.6687 - acc: 0.7779 - val_loss: 1.1548 - val_acc: 0.7989

Epoch 00001: loss improved from inf to 1.66872, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2053 - acc: 0.8750
734/734 [==============================] - 0s 31us/step - loss: 1.4964 - acc: 0.7725 - val_loss: 1.0751 - val_acc: 0.7880

Epoch 00002: loss improved from 1.66872 to 1.49642, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2857 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.4399 - acc: 0.7766 - val_loss: 1.0208 - val_acc: 0.7935

Epoch 00003: loss improved from 1.49642 to 1.43992, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1779 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.3738 - acc: 0.7943 - val_loss: 0.9293 - val_acc: 0.8098

Epoch 00004: loss improved from 1.43992 to 1.37382, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9477 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.3286 - acc: 0.7888 - val_loss: 0.9753 - val_acc: 0.7609

Epoch 00005: loss improved from 1.37382 to 1.32862, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0889 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2792 - acc: 0.7970 - val_loss: 1.0295 - val_acc: 0.7391

Epoch 00006: loss improved from 1.32862 to 1.27918, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0130 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2282 - acc: 0.8120 - val_loss: 0.9450 - val_acc: 0.8098

Epoch 00007: loss improved from 1.27918 to 1.22819, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1117 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1887 - acc: 0.8025 - val_loss: 0.8585 - val_acc: 0.8098

Epoch 00008: loss improved from 1.22819 to 1.18865, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9027 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1995 - acc: 0.7888 - val_loss: 0.8236 - val_acc: 0.7935

Epoch 00009: loss did not improve from 1.18865
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8369 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1687 - acc: 0.7929 - val_loss: 0.7702 - val_acc: 0.8207

Epoch 00010: loss improved from 1.18865 to 1.16873, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9074 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1442 - acc: 0.8093 - val_loss: 0.8994 - val_acc: 0.7500

Epoch 00011: loss improved from 1.16873 to 1.14420, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8910 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1416 - acc: 0.8174 - val_loss: 0.7957 - val_acc: 0.8098

Epoch 00012: loss improved from 1.14420 to 1.14164, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9550 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0774 - acc: 0.8025 - val_loss: 0.7721 - val_acc: 0.8098

Epoch 00013: loss improved from 1.14164 to 1.07735, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0745 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.0560 - acc: 0.8215 - val_loss: 0.6661 - val_acc: 0.8152

Epoch 00014: loss improved from 1.07735 to 1.05601, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8259 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0538 - acc: 0.8106 - val_loss: 0.7355 - val_acc: 0.7989

Epoch 00015: loss improved from 1.05601 to 1.05377, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8868 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9889 - acc: 0.8188 - val_loss: 0.6534 - val_acc: 0.8370

Epoch 00016: loss improved from 1.05377 to 0.98889, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9059 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0344 - acc: 0.8215 - val_loss: 0.7301 - val_acc: 0.7935

Epoch 00017: loss did not improve from 0.98889
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9903 - acc: 0.8750
734/734 [==============================] - 0s 28us/step - loss: 1.0158 - acc: 0.8270 - val_loss: 0.6815 - val_acc: 0.8152

Epoch 00018: loss did not improve from 0.98889
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 0.6787 - acc: 0.9062
734/734 [==============================] - 0s 28us/step - loss: 0.9497 - acc: 0.8106 - val_loss: 0.7948 - val_acc: 0.7609

Epoch 00019: loss improved from 0.98889 to 0.94974, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8102 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9946 - acc: 0.8229 - val_loss: 0.7668 - val_acc: 0.7500

Epoch 00020: loss did not improve from 0.94974
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 0.6804 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.8995 - acc: 0.8392 - val_loss: 0.6349 - val_acc: 0.7935

Epoch 00021: loss improved from 0.94974 to 0.89955, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 0.6804 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9427 - acc: 0.8311 - val_loss: 0.7433 - val_acc: 0.7717

Epoch 00022: loss did not improve from 0.89955
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7073 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.8863 - acc: 0.8406 - val_loss: 0.6632 - val_acc: 0.7663

Epoch 00023: loss improved from 0.89955 to 0.88628, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_7.h5
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 0.6761 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 0.9403 - acc: 0.8297 - val_loss: 0.6886 - val_acc: 0.7717

Epoch 00024: loss did not improve from 0.88628
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7834 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 0.9291 - acc: 0.8270 - val_loss: 0.7043 - val_acc: 0.8207

Epoch 00025: loss did not improve from 0.88628
Epoch 26/100

 32/734 [>.............................] - ETA: 0s - loss: 0.6906 - acc: 0.9375
734/734 [==============================] - 0s 29us/step - loss: 0.9899 - acc: 0.8311 - val_loss: 0.7445 - val_acc: 0.7935

Epoch 00026: loss did not improve from 0.88628
Epoch 27/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7231 - acc: 0.8438
734/734 [==============================] - 0s 28us/step - loss: 0.9880 - acc: 0.8065 - val_loss: 0.6319 - val_acc: 0.8152

Epoch 00027: loss did not improve from 0.88628
Epoch 28/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9845 - acc: 0.8750
734/734 [==============================] - 0s 28us/step - loss: 0.9208 - acc: 0.8324 - val_loss: 0.6370 - val_acc: 0.8152
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:04<00:25,  2.34s/it]
Epoch 00028: loss did not improve from 0.88628
Epoch 00028: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.4964 - acc: 0.8750
734/734 [==============================] - 0s 380us/step - loss: 1.7644 - acc: 0.7548 - val_loss: 1.1491 - val_acc: 0.8098

Epoch 00001: loss improved from inf to 1.76440, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3313 - acc: 0.8438
734/734 [==============================] - 0s 32us/step - loss: 1.5704 - acc: 0.7657 - val_loss: 1.1334 - val_acc: 0.7880

Epoch 00002: loss improved from 1.76440 to 1.57036, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3729 - acc: 0.8438
734/734 [==============================] - 0s 31us/step - loss: 1.4889 - acc: 0.7684 - val_loss: 1.0771 - val_acc: 0.7717

Epoch 00003: loss improved from 1.57036 to 1.48891, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1176 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.4501 - acc: 0.7752 - val_loss: 1.0025 - val_acc: 0.7989

Epoch 00004: loss improved from 1.48891 to 1.45013, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2837 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.4159 - acc: 0.7738 - val_loss: 0.9493 - val_acc: 0.8043

Epoch 00005: loss improved from 1.45013 to 1.41589, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1522 - acc: 0.9062
734/734 [==============================] - 0s 31us/step - loss: 1.3375 - acc: 0.7916 - val_loss: 0.8707 - val_acc: 0.8315

Epoch 00006: loss improved from 1.41589 to 1.33748, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1322 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.3220 - acc: 0.7847 - val_loss: 0.9191 - val_acc: 0.8043

Epoch 00007: loss improved from 1.33748 to 1.32201, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0600 - acc: 0.9062
734/734 [==============================] - 0s 31us/step - loss: 1.2720 - acc: 0.7752 - val_loss: 0.8809 - val_acc: 0.7935

Epoch 00008: loss improved from 1.32201 to 1.27196, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0311 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.2382 - acc: 0.8093 - val_loss: 0.8679 - val_acc: 0.7989

Epoch 00009: loss improved from 1.27196 to 1.23819, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9896 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.2153 - acc: 0.7902 - val_loss: 0.8717 - val_acc: 0.7989

Epoch 00010: loss improved from 1.23819 to 1.21526, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9034 - acc: 0.9062
734/734 [==============================] - 0s 31us/step - loss: 1.2002 - acc: 0.7970 - val_loss: 1.0581 - val_acc: 0.6413

Epoch 00011: loss improved from 1.21526 to 1.20021, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0901 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.1602 - acc: 0.8038 - val_loss: 0.8264 - val_acc: 0.8098

Epoch 00012: loss improved from 1.20021 to 1.16016, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8978 - acc: 0.9375
734/734 [==============================] - 0s 30us/step - loss: 1.1478 - acc: 0.7956 - val_loss: 0.7901 - val_acc: 0.7989

Epoch 00013: loss improved from 1.16016 to 1.14778, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9410 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.1467 - acc: 0.7970 - val_loss: 0.8493 - val_acc: 0.7880

Epoch 00014: loss improved from 1.14778 to 1.14670, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8612 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.0989 - acc: 0.8134 - val_loss: 0.7465 - val_acc: 0.7826

Epoch 00015: loss improved from 1.14670 to 1.09891, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9594 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.0939 - acc: 0.8011 - val_loss: 0.6734 - val_acc: 0.8152

Epoch 00016: loss improved from 1.09891 to 1.09391, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9266 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.0965 - acc: 0.8065 - val_loss: 0.6880 - val_acc: 0.7989

Epoch 00017: loss did not improve from 1.09391
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0377 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.0704 - acc: 0.8038 - val_loss: 0.6701 - val_acc: 0.8315

Epoch 00018: loss improved from 1.09391 to 1.07039, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9227 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.0113 - acc: 0.8229 - val_loss: 0.7480 - val_acc: 0.8315

Epoch 00019: loss improved from 1.07039 to 1.01128, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8665 - acc: 0.9375
734/734 [==============================] - 0s 30us/step - loss: 1.0328 - acc: 0.8229 - val_loss: 0.8016 - val_acc: 0.7772

Epoch 00020: loss did not improve from 1.01128
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8244 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.0028 - acc: 0.8270 - val_loss: 0.8150 - val_acc: 0.7772

Epoch 00021: loss improved from 1.01128 to 1.00283, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8070 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 0.9663 - acc: 0.8297 - val_loss: 0.8596 - val_acc: 0.7337

Epoch 00022: loss improved from 1.00283 to 0.96635, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_8.h5
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8725 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.0236 - acc: 0.8134 - val_loss: 1.2103 - val_acc: 0.3261

Epoch 00023: loss did not improve from 0.96635
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9348 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 0.9728 - acc: 0.8147 - val_loss: 0.7482 - val_acc: 0.7609

Epoch 00024: loss did not improve from 0.96635
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7583 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 0.9877 - acc: 0.8174 - val_loss: 0.6700 - val_acc: 0.8261

Epoch 00025: loss did not improve from 0.96635
Epoch 26/100

 32/734 [>.............................] - ETA: 0s - loss: 0.6319 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.0382 - acc: 0.8093 - val_loss: 0.7059 - val_acc: 0.8043

Epoch 00026: loss did not improve from 0.96635
Epoch 27/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7551 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.0497 - acc: 0.8052 - val_loss: 0.7231 - val_acc: 0.8098
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:07<00:23,  2.34s/it]
Epoch 00027: loss did not improve from 0.96635
Epoch 00027: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.5410 - acc: 0.8125
734/734 [==============================] - 0s 381us/step - loss: 1.8626 - acc: 0.7357 - val_loss: 1.2189 - val_acc: 0.7772

Epoch 00001: loss improved from inf to 1.86263, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4102 - acc: 0.8125
734/734 [==============================] - 0s 31us/step - loss: 1.6223 - acc: 0.7507 - val_loss: 1.1591 - val_acc: 0.7609

Epoch 00002: loss improved from 1.86263 to 1.62235, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2700 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.5478 - acc: 0.7657 - val_loss: 1.0859 - val_acc: 0.7826

Epoch 00003: loss improved from 1.62235 to 1.54779, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3501 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.4894 - acc: 0.7711 - val_loss: 1.0478 - val_acc: 0.7880

Epoch 00004: loss improved from 1.54779 to 1.48941, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0720 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.4466 - acc: 0.7711 - val_loss: 1.0193 - val_acc: 0.7989

Epoch 00005: loss improved from 1.48941 to 1.44664, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1960 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.3918 - acc: 0.7807 - val_loss: 0.9461 - val_acc: 0.7826

Epoch 00006: loss improved from 1.44664 to 1.39181, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9870 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.3291 - acc: 0.7698 - val_loss: 0.9440 - val_acc: 0.7663

Epoch 00007: loss improved from 1.39181 to 1.32909, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0612 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.3261 - acc: 0.7752 - val_loss: 0.9187 - val_acc: 0.7717

Epoch 00008: loss improved from 1.32909 to 1.32610, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0569 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.2943 - acc: 0.7752 - val_loss: 0.8129 - val_acc: 0.8098

Epoch 00009: loss improved from 1.32610 to 1.29427, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0553 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2227 - acc: 0.7807 - val_loss: 0.9625 - val_acc: 0.7554

Epoch 00010: loss improved from 1.29427 to 1.22269, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0238 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2068 - acc: 0.7929 - val_loss: 0.8098 - val_acc: 0.8152

Epoch 00011: loss improved from 1.22269 to 1.20678, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9561 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1903 - acc: 0.7820 - val_loss: 0.8082 - val_acc: 0.8098

Epoch 00012: loss improved from 1.20678 to 1.19025, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0151 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1732 - acc: 0.7984 - val_loss: 0.8468 - val_acc: 0.8098

Epoch 00013: loss improved from 1.19025 to 1.17321, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8186 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1384 - acc: 0.8079 - val_loss: 0.7656 - val_acc: 0.8098

Epoch 00014: loss improved from 1.17321 to 1.13836, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0407 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.0771 - acc: 0.7997 - val_loss: 0.8225 - val_acc: 0.7500

Epoch 00015: loss improved from 1.13836 to 1.07708, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_9.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1543 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.1373 - acc: 0.7956 - val_loss: 0.8918 - val_acc: 0.7772

Epoch 00016: loss did not improve from 1.07708
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9032 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1375 - acc: 0.7997 - val_loss: 0.7569 - val_acc: 0.8043

Epoch 00017: loss did not improve from 1.07708
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1461 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1188 - acc: 0.7997 - val_loss: 0.8256 - val_acc: 0.7880

Epoch 00018: loss did not improve from 1.07708
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8078 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1083 - acc: 0.7997 - val_loss: 0.7905 - val_acc: 0.7772

Epoch 00019: loss did not improve from 1.07708
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8202 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1158 - acc: 0.7902 - val_loss: 1.0120 - val_acc: 0.7065
DeepAmes+ Weights:  31%|███       | 4/13 [00:09<00:19,  2.22s/it]
Epoch 00020: loss did not improve from 1.07708
Epoch 00020: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.7495 - acc: 0.8125
734/734 [==============================] - 0s 386us/step - loss: 1.9023 - acc: 0.7439 - val_loss: 1.2413 - val_acc: 0.7554

Epoch 00001: loss improved from inf to 1.90230, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3803 - acc: 0.8438
734/734 [==============================] - 0s 33us/step - loss: 1.7251 - acc: 0.7384 - val_loss: 1.1312 - val_acc: 0.7826

Epoch 00002: loss improved from 1.90230 to 1.72512, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2802 - acc: 0.8438
734/734 [==============================] - 0s 32us/step - loss: 1.6047 - acc: 0.7629 - val_loss: 1.1278 - val_acc: 0.7717

Epoch 00003: loss improved from 1.72512 to 1.60465, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1816 - acc: 0.8750
734/734 [==============================] - 0s 32us/step - loss: 1.5051 - acc: 0.7657 - val_loss: 1.0955 - val_acc: 0.7663

Epoch 00004: loss improved from 1.60465 to 1.50508, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1006 - acc: 0.8750
734/734 [==============================] - 0s 32us/step - loss: 1.5037 - acc: 0.7548 - val_loss: 1.0623 - val_acc: 0.7554

Epoch 00005: loss improved from 1.50508 to 1.50368, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3992 - acc: 0.8438
734/734 [==============================] - 0s 31us/step - loss: 1.4657 - acc: 0.7670 - val_loss: 1.0075 - val_acc: 0.7554

Epoch 00006: loss improved from 1.50368 to 1.46572, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2311 - acc: 0.8750
734/734 [==============================] - 0s 31us/step - loss: 1.3458 - acc: 0.7984 - val_loss: 0.9151 - val_acc: 0.7826

Epoch 00007: loss improved from 1.46572 to 1.34578, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3478 - acc: 0.8750
734/734 [==============================] - 0s 31us/step - loss: 1.3489 - acc: 0.7766 - val_loss: 0.9463 - val_acc: 0.7663

Epoch 00008: loss did not improve from 1.34578
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2259 - acc: 0.9062
734/734 [==============================] - 0s 31us/step - loss: 1.3091 - acc: 0.7684 - val_loss: 0.8816 - val_acc: 0.7935

Epoch 00009: loss improved from 1.34578 to 1.30913, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2068 - acc: 0.8750
734/734 [==============================] - 0s 31us/step - loss: 1.2899 - acc: 0.7820 - val_loss: 0.9022 - val_acc: 0.7663

Epoch 00010: loss improved from 1.30913 to 1.28986, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0773 - acc: 0.9062
734/734 [==============================] - 0s 31us/step - loss: 1.3100 - acc: 0.7738 - val_loss: 0.8911 - val_acc: 0.7935

Epoch 00011: loss did not improve from 1.28986
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0112 - acc: 0.9062
734/734 [==============================] - 0s 31us/step - loss: 1.2873 - acc: 0.7766 - val_loss: 0.8763 - val_acc: 0.7663

Epoch 00012: loss improved from 1.28986 to 1.28734, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0616 - acc: 0.8750
734/734 [==============================] - 0s 31us/step - loss: 1.2487 - acc: 0.7684 - val_loss: 0.8782 - val_acc: 0.7609

Epoch 00013: loss improved from 1.28734 to 1.24865, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9528 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2779 - acc: 0.7629 - val_loss: 1.0362 - val_acc: 0.7717

Epoch 00014: loss did not improve from 1.24865
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1996 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.2478 - acc: 0.7711 - val_loss: 0.9684 - val_acc: 0.7446

Epoch 00015: loss improved from 1.24865 to 1.24778, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9454 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2009 - acc: 0.7766 - val_loss: 0.9428 - val_acc: 0.7554

Epoch 00016: loss improved from 1.24778 to 1.20088, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0327 - acc: 0.9062
734/734 [==============================] - 0s 30us/step - loss: 1.2182 - acc: 0.7698 - val_loss: 0.8564 - val_acc: 0.7609

Epoch 00017: loss did not improve from 1.20088
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7561 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1640 - acc: 0.7943 - val_loss: 0.7337 - val_acc: 0.7880

Epoch 00018: loss improved from 1.20088 to 1.16395, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8516 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1635 - acc: 0.7902 - val_loss: 0.7614 - val_acc: 0.7880

Epoch 00019: loss improved from 1.16395 to 1.16354, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9240 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1905 - acc: 0.7629 - val_loss: 0.7672 - val_acc: 0.7500

Epoch 00020: loss did not improve from 1.16354
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8047 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1414 - acc: 0.7725 - val_loss: 0.7115 - val_acc: 0.7826

Epoch 00021: loss improved from 1.16354 to 1.14145, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8387 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1012 - acc: 0.7916 - val_loss: 0.7325 - val_acc: 0.7554

Epoch 00022: loss improved from 1.14145 to 1.10119, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8461 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1435 - acc: 0.7752 - val_loss: 0.7558 - val_acc: 0.7500

Epoch 00023: loss did not improve from 1.10119
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8351 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.1670 - acc: 0.7847 - val_loss: 0.7427 - val_acc: 0.7554

Epoch 00024: loss did not improve from 1.10119
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9074 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.0506 - acc: 0.8120 - val_loss: 0.7142 - val_acc: 0.8207

Epoch 00025: loss improved from 1.10119 to 1.05056, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_10.h5
Epoch 26/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9907 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.1220 - acc: 0.7902 - val_loss: 0.8837 - val_acc: 0.7772

Epoch 00026: loss did not improve from 1.05056
Epoch 27/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7588 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.0515 - acc: 0.8025 - val_loss: 0.6878 - val_acc: 0.7772

Epoch 00027: loss did not improve from 1.05056
Epoch 28/100

 32/734 [>.............................] - ETA: 0s - loss: 0.7991 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0606 - acc: 0.8025 - val_loss: 0.6947 - val_acc: 0.7772

Epoch 00028: loss did not improve from 1.05056
Epoch 29/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8189 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.1027 - acc: 0.7902 - val_loss: 0.7063 - val_acc: 0.7663

Epoch 00029: loss did not improve from 1.05056
Epoch 30/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8780 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.0729 - acc: 0.7997 - val_loss: 0.8177 - val_acc: 0.8261
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:11<00:18,  2.29s/it]
Epoch 00030: loss did not improve from 1.05056
Epoch 00030: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 4s - loss: 1.7334 - acc: 0.8125
734/734 [==============================] - 0s 379us/step - loss: 2.0065 - acc: 0.7357 - val_loss: 1.2835 - val_acc: 0.7391

Epoch 00001: loss improved from inf to 2.00647, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6099 - acc: 0.8125
734/734 [==============================] - 0s 31us/step - loss: 1.7470 - acc: 0.7357 - val_loss: 1.2775 - val_acc: 0.7065

Epoch 00002: loss improved from 2.00647 to 1.74695, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6784 - acc: 0.7500
734/734 [==============================] - 0s 31us/step - loss: 1.6910 - acc: 0.7316 - val_loss: 1.1298 - val_acc: 0.7717

Epoch 00003: loss improved from 1.74695 to 1.69096, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2658 - acc: 0.8438
734/734 [==============================] - 0s 30us/step - loss: 1.6069 - acc: 0.7275 - val_loss: 1.1299 - val_acc: 0.7228

Epoch 00004: loss improved from 1.69096 to 1.60686, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2623 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.5455 - acc: 0.7629 - val_loss: 1.0621 - val_acc: 0.7609

Epoch 00005: loss improved from 1.60686 to 1.54553, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2454 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.5188 - acc: 0.7507 - val_loss: 1.0332 - val_acc: 0.7391

Epoch 00006: loss improved from 1.54553 to 1.51882, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2676 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.4453 - acc: 0.7534 - val_loss: 0.9851 - val_acc: 0.7446

Epoch 00007: loss improved from 1.51882 to 1.44529, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1890 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.4072 - acc: 0.7452 - val_loss: 0.8759 - val_acc: 0.8043

Epoch 00008: loss improved from 1.44529 to 1.40721, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1205 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3948 - acc: 0.7548 - val_loss: 0.8894 - val_acc: 0.7554

Epoch 00009: loss improved from 1.40721 to 1.39478, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2583 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3751 - acc: 0.7548 - val_loss: 0.9268 - val_acc: 0.7446

Epoch 00010: loss improved from 1.39478 to 1.37509, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1725 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3310 - acc: 0.7452 - val_loss: 0.9707 - val_acc: 0.7391

Epoch 00011: loss improved from 1.37509 to 1.33100, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0546 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.2977 - acc: 0.7793 - val_loss: 0.8976 - val_acc: 0.7826

Epoch 00012: loss improved from 1.33100 to 1.29770, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9670 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.2654 - acc: 0.7738 - val_loss: 0.9397 - val_acc: 0.7337

Epoch 00013: loss improved from 1.29770 to 1.26540, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1761 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.2768 - acc: 0.7411 - val_loss: 0.7389 - val_acc: 0.8043

Epoch 00014: loss did not improve from 1.26540
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9477 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2265 - acc: 0.7711 - val_loss: 0.8144 - val_acc: 0.7609

Epoch 00015: loss improved from 1.26540 to 1.22651, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9318 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.1767 - acc: 0.7738 - val_loss: 1.1691 - val_acc: 0.4565

Epoch 00016: loss improved from 1.22651 to 1.17673, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0341 - acc: 0.9375
734/734 [==============================] - 0s 30us/step - loss: 1.2392 - acc: 0.7670 - val_loss: 0.9960 - val_acc: 0.7065

Epoch 00017: loss did not improve from 1.17673
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9663 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.2490 - acc: 0.7520 - val_loss: 0.9141 - val_acc: 0.7174

Epoch 00018: loss did not improve from 1.17673
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9176 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2217 - acc: 0.7711 - val_loss: 0.9480 - val_acc: 0.6902

Epoch 00019: loss did not improve from 1.17673
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9729 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2134 - acc: 0.7807 - val_loss: 0.7792 - val_acc: 0.7446

Epoch 00020: loss did not improve from 1.17673
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8484 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1727 - acc: 0.7847 - val_loss: 0.8351 - val_acc: 0.7337

Epoch 00021: loss improved from 1.17673 to 1.17273, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9814 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.1200 - acc: 0.7684 - val_loss: 0.7988 - val_acc: 0.7500

Epoch 00022: loss improved from 1.17273 to 1.11999, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_11.h5
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8987 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.2154 - acc: 0.7752 - val_loss: 0.8624 - val_acc: 0.7989

Epoch 00023: loss did not improve from 1.11999
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2127 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.2476 - acc: 0.7643 - val_loss: 0.8175 - val_acc: 0.8043

Epoch 00024: loss did not improve from 1.11999
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 0.8317 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.1404 - acc: 0.7670 - val_loss: 0.8395 - val_acc: 0.7228

Epoch 00025: loss did not improve from 1.11999
Epoch 26/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3974 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.2053 - acc: 0.7698 - val_loss: 0.7755 - val_acc: 0.8043

Epoch 00026: loss did not improve from 1.11999
Epoch 27/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1714 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.1849 - acc: 0.7670 - val_loss: 0.9045 - val_acc: 0.7500
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:13<00:16,  2.29s/it]
Epoch 00027: loss did not improve from 1.11999
Epoch 00027: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 4s - loss: 1.8427 - acc: 0.7812
734/734 [==============================] - 0s 379us/step - loss: 2.0705 - acc: 0.7425 - val_loss: 1.2914 - val_acc: 0.7880

Epoch 00001: loss improved from inf to 2.07049, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4132 - acc: 0.9062
734/734 [==============================] - 0s 31us/step - loss: 1.8037 - acc: 0.7330 - val_loss: 1.2419 - val_acc: 0.7174

Epoch 00002: loss improved from 2.07049 to 1.80368, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5963 - acc: 0.7812
734/734 [==============================] - 0s 30us/step - loss: 1.7472 - acc: 0.7057 - val_loss: 1.1852 - val_acc: 0.7283

Epoch 00003: loss improved from 1.80368 to 1.74721, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5341 - acc: 0.8125
734/734 [==============================] - 0s 30us/step - loss: 1.6785 - acc: 0.7153 - val_loss: 1.1490 - val_acc: 0.7283

Epoch 00004: loss improved from 1.74721 to 1.67848, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3399 - acc: 0.8438
734/734 [==============================] - 0s 30us/step - loss: 1.5861 - acc: 0.7357 - val_loss: 1.0341 - val_acc: 0.7717

Epoch 00005: loss improved from 1.67848 to 1.58615, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3247 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.5542 - acc: 0.7275 - val_loss: 1.0035 - val_acc: 0.7663

Epoch 00006: loss improved from 1.58615 to 1.55419, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3271 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.4825 - acc: 0.7466 - val_loss: 0.9767 - val_acc: 0.7717

Epoch 00007: loss improved from 1.55419 to 1.48253, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2319 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.4488 - acc: 0.7411 - val_loss: 0.9142 - val_acc: 0.8043

Epoch 00008: loss improved from 1.48253 to 1.44882, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1726 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.4416 - acc: 0.7411 - val_loss: 0.9669 - val_acc: 0.7554

Epoch 00009: loss improved from 1.44882 to 1.44161, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2945 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.4213 - acc: 0.7493 - val_loss: 0.9908 - val_acc: 0.6957

Epoch 00010: loss improved from 1.44161 to 1.42126, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1660 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3233 - acc: 0.7616 - val_loss: 0.8281 - val_acc: 0.7989

Epoch 00011: loss improved from 1.42126 to 1.32329, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0248 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.3012 - acc: 0.7684 - val_loss: 0.8827 - val_acc: 0.7772

Epoch 00012: loss improved from 1.32329 to 1.30123, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0475 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3476 - acc: 0.7425 - val_loss: 0.9797 - val_acc: 0.7391

Epoch 00013: loss did not improve from 1.30123
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0049 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.3549 - acc: 0.7439 - val_loss: 0.7667 - val_acc: 0.7772

Epoch 00014: loss did not improve from 1.30123
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1275 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.3005 - acc: 0.7548 - val_loss: 0.8724 - val_acc: 0.8043

Epoch 00015: loss improved from 1.30123 to 1.30046, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9928 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.3357 - acc: 0.7466 - val_loss: 0.8297 - val_acc: 0.7717

Epoch 00016: loss did not improve from 1.30046
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0628 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.2531 - acc: 0.7629 - val_loss: 0.9271 - val_acc: 0.6848

Epoch 00017: loss improved from 1.30046 to 1.25310, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2047 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.2364 - acc: 0.7561 - val_loss: 0.7776 - val_acc: 0.7337

Epoch 00018: loss improved from 1.25310 to 1.23635, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0587 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.1843 - acc: 0.7643 - val_loss: 0.7934 - val_acc: 0.7446

Epoch 00019: loss improved from 1.23635 to 1.18427, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_12.h5
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4730 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.2502 - acc: 0.7466 - val_loss: 0.7496 - val_acc: 0.7935

Epoch 00020: loss did not improve from 1.18427
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0867 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.2373 - acc: 0.7493 - val_loss: 0.6548 - val_acc: 0.8098

Epoch 00021: loss did not improve from 1.18427
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0340 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.2056 - acc: 0.7725 - val_loss: 1.0893 - val_acc: 0.3370

Epoch 00022: loss did not improve from 1.18427
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2286 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.1855 - acc: 0.7725 - val_loss: 0.9310 - val_acc: 0.7609

Epoch 00023: loss did not improve from 1.18427
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9468 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.2138 - acc: 0.7575 - val_loss: 0.9247 - val_acc: 0.7283
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:15<00:13,  2.24s/it]
Epoch 00024: loss did not improve from 1.18427
Epoch 00024: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.7859 - acc: 0.8125
734/734 [==============================] - 0s 387us/step - loss: 2.1066 - acc: 0.7207 - val_loss: 1.2691 - val_acc: 0.7337

Epoch 00001: loss improved from inf to 2.10659, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5294 - acc: 0.7812
734/734 [==============================] - 0s 31us/step - loss: 1.8207 - acc: 0.7275 - val_loss: 1.2162 - val_acc: 0.7554

Epoch 00002: loss improved from 2.10659 to 1.82074, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3858 - acc: 0.8125
734/734 [==============================] - 0s 30us/step - loss: 1.7740 - acc: 0.7057 - val_loss: 1.2339 - val_acc: 0.7120

Epoch 00003: loss improved from 1.82074 to 1.77398, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4751 - acc: 0.7500
734/734 [==============================] - 0s 30us/step - loss: 1.6836 - acc: 0.7262 - val_loss: 1.3042 - val_acc: 0.6576

Epoch 00004: loss improved from 1.77398 to 1.68365, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3448 - acc: 0.8125
734/734 [==============================] - 0s 30us/step - loss: 1.6288 - acc: 0.7207 - val_loss: 1.1514 - val_acc: 0.7174

Epoch 00005: loss improved from 1.68365 to 1.62880, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4049 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.5950 - acc: 0.7166 - val_loss: 1.2083 - val_acc: 0.6848

Epoch 00006: loss improved from 1.62880 to 1.59500, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3273 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.5602 - acc: 0.7262 - val_loss: 1.1776 - val_acc: 0.6739

Epoch 00007: loss improved from 1.59500 to 1.56017, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3226 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.5091 - acc: 0.7180 - val_loss: 1.0487 - val_acc: 0.7337

Epoch 00008: loss improved from 1.56017 to 1.50911, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1615 - acc: 0.8438
734/734 [==============================] - 0s 30us/step - loss: 1.5083 - acc: 0.7343 - val_loss: 0.9932 - val_acc: 0.7337

Epoch 00009: loss improved from 1.50911 to 1.50832, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3797 - acc: 0.8125
734/734 [==============================] - 0s 30us/step - loss: 1.4251 - acc: 0.7330 - val_loss: 0.9762 - val_acc: 0.7391

Epoch 00010: loss improved from 1.50832 to 1.42505, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1206 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.3701 - acc: 0.7411 - val_loss: 0.9258 - val_acc: 0.7609

Epoch 00011: loss improved from 1.42505 to 1.37014, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0011 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3802 - acc: 0.7398 - val_loss: 0.8334 - val_acc: 0.8207

Epoch 00012: loss did not improve from 1.37014
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0843 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.3676 - acc: 0.7534 - val_loss: 0.8471 - val_acc: 0.7826

Epoch 00013: loss improved from 1.37014 to 1.36764, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1894 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.3125 - acc: 0.7439 - val_loss: 0.8827 - val_acc: 0.7772

Epoch 00014: loss improved from 1.36764 to 1.31251, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0706 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3125 - acc: 0.7316 - val_loss: 0.7393 - val_acc: 0.7989

Epoch 00015: loss improved from 1.31251 to 1.31250, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0196 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.3274 - acc: 0.7452 - val_loss: 0.8837 - val_acc: 0.7717

Epoch 00016: loss did not improve from 1.31250
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9518 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.2971 - acc: 0.7548 - val_loss: 0.8224 - val_acc: 0.7609

Epoch 00017: loss improved from 1.31250 to 1.29709, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_13.h5
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0819 - acc: 0.7812
734/734 [==============================] - 0s 30us/step - loss: 1.3027 - acc: 0.7289 - val_loss: 0.7536 - val_acc: 0.7717

Epoch 00018: loss did not improve from 1.29709
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0887 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.3191 - acc: 0.7221 - val_loss: 0.8808 - val_acc: 0.6957

Epoch 00019: loss did not improve from 1.29709
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9332 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3055 - acc: 0.7330 - val_loss: 0.7703 - val_acc: 0.7446

Epoch 00020: loss did not improve from 1.29709
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0538 - acc: 0.6875
734/734 [==============================] - 0s 29us/step - loss: 1.3502 - acc: 0.7302 - val_loss: 0.7703 - val_acc: 0.7880

Epoch 00021: loss did not improve from 1.29709
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1715 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.3115 - acc: 0.7343 - val_loss: 0.9811 - val_acc: 0.7391
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:18<00:11,  2.23s/it]
Epoch 00022: loss did not improve from 1.29709
Epoch 00022: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 2.0336 - acc: 0.7500
734/734 [==============================] - 0s 391us/step - loss: 2.2435 - acc: 0.7153 - val_loss: 1.3118 - val_acc: 0.7391

Epoch 00001: loss improved from inf to 2.24352, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4492 - acc: 0.8125
734/734 [==============================] - 0s 31us/step - loss: 1.8542 - acc: 0.6989 - val_loss: 1.3435 - val_acc: 0.6957

Epoch 00002: loss improved from 2.24352 to 1.85423, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5879 - acc: 0.7812
734/734 [==============================] - 0s 30us/step - loss: 1.8032 - acc: 0.6948 - val_loss: 1.2990 - val_acc: 0.7065

Epoch 00003: loss improved from 1.85423 to 1.80322, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6551 - acc: 0.7812
734/734 [==============================] - 0s 30us/step - loss: 1.7278 - acc: 0.7071 - val_loss: 1.3365 - val_acc: 0.5326

Epoch 00004: loss improved from 1.80322 to 1.72775, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6746 - acc: 0.8125
734/734 [==============================] - 0s 30us/step - loss: 1.7448 - acc: 0.7057 - val_loss: 1.1005 - val_acc: 0.7609

Epoch 00005: loss did not improve from 1.72775
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3271 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.6191 - acc: 0.7234 - val_loss: 1.1627 - val_acc: 0.6902

Epoch 00006: loss improved from 1.72775 to 1.61907, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2881 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.6260 - acc: 0.7044 - val_loss: 1.0588 - val_acc: 0.7228

Epoch 00007: loss did not improve from 1.61907
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2681 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.5226 - acc: 0.7016 - val_loss: 1.1003 - val_acc: 0.6902

Epoch 00008: loss improved from 1.61907 to 1.52262, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1583 - acc: 0.8125
734/734 [==============================] - 0s 30us/step - loss: 1.5033 - acc: 0.7166 - val_loss: 1.0557 - val_acc: 0.6848

Epoch 00009: loss improved from 1.52262 to 1.50330, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2701 - acc: 0.7812
734/734 [==============================] - 0s 30us/step - loss: 1.4693 - acc: 0.7044 - val_loss: 1.1234 - val_acc: 0.5652

Epoch 00010: loss improved from 1.50330 to 1.46926, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1737 - acc: 0.8125
734/734 [==============================] - 0s 30us/step - loss: 1.4704 - acc: 0.7166 - val_loss: 1.2277 - val_acc: 0.6522

Epoch 00011: loss did not improve from 1.46926
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4033 - acc: 0.8750
734/734 [==============================] - 0s 30us/step - loss: 1.5225 - acc: 0.7003 - val_loss: 1.0868 - val_acc: 0.6359

Epoch 00012: loss did not improve from 1.46926
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3172 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.4437 - acc: 0.6921 - val_loss: 1.2928 - val_acc: 0.2609

Epoch 00013: loss improved from 1.46926 to 1.44368, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1429 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.4383 - acc: 0.7057 - val_loss: 1.0654 - val_acc: 0.6576

Epoch 00014: loss improved from 1.44368 to 1.43835, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1199 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.3674 - acc: 0.7262 - val_loss: 0.8270 - val_acc: 0.7609

Epoch 00015: loss improved from 1.43835 to 1.36743, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0975 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.3850 - acc: 0.7262 - val_loss: 0.7840 - val_acc: 0.8043

Epoch 00016: loss did not improve from 1.36743
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1260 - acc: 0.8438
734/734 [==============================] - 0s 30us/step - loss: 1.3739 - acc: 0.7330 - val_loss: 0.9245 - val_acc: 0.7011

Epoch 00017: loss did not improve from 1.36743
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1054 - acc: 0.8438
734/734 [==============================] - 0s 30us/step - loss: 1.3219 - acc: 0.7398 - val_loss: 1.0900 - val_acc: 0.5652

Epoch 00018: loss improved from 1.36743 to 1.32187, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0318 - acc: 0.8125
734/734 [==============================] - 0s 30us/step - loss: 1.3338 - acc: 0.7221 - val_loss: 0.9122 - val_acc: 0.7283

Epoch 00019: loss did not improve from 1.32187
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 0.9465 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.2263 - acc: 0.7411 - val_loss: 0.7149 - val_acc: 0.7880

Epoch 00020: loss improved from 1.32187 to 1.22633, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_14.h5
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0567 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.3853 - acc: 0.7112 - val_loss: 0.7335 - val_acc: 0.7772

Epoch 00021: loss did not improve from 1.22633
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1028 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.3784 - acc: 0.7425 - val_loss: 0.9981 - val_acc: 0.7120

Epoch 00022: loss did not improve from 1.22633
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1256 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3557 - acc: 0.7357 - val_loss: 0.8935 - val_acc: 0.7174

Epoch 00023: loss did not improve from 1.22633
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0407 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.3517 - acc: 0.7153 - val_loss: 0.7624 - val_acc: 0.7880

Epoch 00024: loss did not improve from 1.22633
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2924 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.2876 - acc: 0.7466 - val_loss: 0.8393 - val_acc: 0.7554
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:20<00:08,  2.23s/it]
Epoch 00025: loss did not improve from 1.22633
Epoch 00025: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 4s - loss: 1.6256 - acc: 0.8438
734/734 [==============================] - 0s 380us/step - loss: 2.2802 - acc: 0.7180 - val_loss: 1.3697 - val_acc: 0.7011

Epoch 00001: loss improved from inf to 2.28020, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5869 - acc: 0.7188
734/734 [==============================] - 0s 31us/step - loss: 1.9322 - acc: 0.6703 - val_loss: 1.2926 - val_acc: 0.7011

Epoch 00002: loss improved from 2.28020 to 1.93217, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5651 - acc: 0.7500
734/734 [==============================] - 0s 30us/step - loss: 1.8197 - acc: 0.6744 - val_loss: 1.2498 - val_acc: 0.7011

Epoch 00003: loss improved from 1.93217 to 1.81973, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5009 - acc: 0.7500
734/734 [==============================] - 0s 30us/step - loss: 1.7619 - acc: 0.6894 - val_loss: 1.2067 - val_acc: 0.6902

Epoch 00004: loss improved from 1.81973 to 1.76189, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3872 - acc: 0.7188
734/734 [==============================] - 0s 30us/step - loss: 1.7033 - acc: 0.6866 - val_loss: 1.1718 - val_acc: 0.7065

Epoch 00005: loss improved from 1.76189 to 1.70326, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5140 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.6771 - acc: 0.6826 - val_loss: 1.2906 - val_acc: 0.5163

Epoch 00006: loss improved from 1.70326 to 1.67705, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3833 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.6208 - acc: 0.6730 - val_loss: 1.2678 - val_acc: 0.5435

Epoch 00007: loss improved from 1.67705 to 1.62083, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2410 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.5933 - acc: 0.6975 - val_loss: 0.9382 - val_acc: 0.7880

Epoch 00008: loss improved from 1.62083 to 1.59329, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2162 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.5431 - acc: 0.7071 - val_loss: 1.0013 - val_acc: 0.7228

Epoch 00009: loss improved from 1.59329 to 1.54310, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1947 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.4759 - acc: 0.7193 - val_loss: 1.0343 - val_acc: 0.6739

Epoch 00010: loss improved from 1.54310 to 1.47589, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0916 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.4549 - acc: 0.7248 - val_loss: 1.0895 - val_acc: 0.6467

Epoch 00011: loss improved from 1.47589 to 1.45487, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3442 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.4281 - acc: 0.7357 - val_loss: 0.8657 - val_acc: 0.7772

Epoch 00012: loss improved from 1.45487 to 1.42806, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3163 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.4380 - acc: 0.7125 - val_loss: 0.9756 - val_acc: 0.7283

Epoch 00013: loss did not improve from 1.42806
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3828 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.3993 - acc: 0.6948 - val_loss: 0.8764 - val_acc: 0.7609

Epoch 00014: loss improved from 1.42806 to 1.39931, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1337 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.4270 - acc: 0.7234 - val_loss: 0.9591 - val_acc: 0.7228

Epoch 00015: loss did not improve from 1.39931
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2209 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.4408 - acc: 0.7139 - val_loss: 0.9579 - val_acc: 0.7065

Epoch 00016: loss did not improve from 1.39931
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3390 - acc: 0.5938
734/734 [==============================] - 0s 29us/step - loss: 1.3288 - acc: 0.7262 - val_loss: 1.0284 - val_acc: 0.6250

Epoch 00017: loss improved from 1.39931 to 1.32883, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1070 - acc: 0.8750
734/734 [==============================] - 0s 29us/step - loss: 1.3512 - acc: 0.7425 - val_loss: 0.8045 - val_acc: 0.7391

Epoch 00018: loss did not improve from 1.32883
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1193 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.3128 - acc: 0.7411 - val_loss: 0.8482 - val_acc: 0.7554

Epoch 00019: loss improved from 1.32883 to 1.31280, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0727 - acc: 0.9062
734/734 [==============================] - 0s 29us/step - loss: 1.2895 - acc: 0.7548 - val_loss: 0.9631 - val_acc: 0.7554

Epoch 00020: loss improved from 1.31280 to 1.28949, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_15.h5
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0700 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.4156 - acc: 0.7275 - val_loss: 0.9293 - val_acc: 0.7500

Epoch 00021: loss did not improve from 1.28949
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0351 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3593 - acc: 0.7153 - val_loss: 0.9865 - val_acc: 0.7120

Epoch 00022: loss did not improve from 1.28949
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1132 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.3098 - acc: 0.7316 - val_loss: 0.9982 - val_acc: 0.6467

Epoch 00023: loss did not improve from 1.28949
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0293 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.3323 - acc: 0.7425 - val_loss: 0.7102 - val_acc: 0.7989

Epoch 00024: loss did not improve from 1.28949
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3716 - acc: 0.6562
734/734 [==============================] - 0s 29us/step - loss: 1.3597 - acc: 0.7166 - val_loss: 0.7642 - val_acc: 0.7772
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:22<00:06,  2.23s/it]
Epoch 00025: loss did not improve from 1.28949
Epoch 00025: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.8110 - acc: 0.8750
734/734 [==============================] - 0s 383us/step - loss: 2.3354 - acc: 0.6757 - val_loss: 1.4499 - val_acc: 0.7283

Epoch 00001: loss improved from inf to 2.33540, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5999 - acc: 0.7500
734/734 [==============================] - 0s 31us/step - loss: 2.0153 - acc: 0.6717 - val_loss: 1.3757 - val_acc: 0.6957

Epoch 00002: loss improved from 2.33540 to 2.01527, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6633 - acc: 0.6875
734/734 [==============================] - 0s 30us/step - loss: 1.9597 - acc: 0.6458 - val_loss: 1.3669 - val_acc: 0.6685

Epoch 00003: loss improved from 2.01527 to 1.95969, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6172 - acc: 0.7500
734/734 [==============================] - 0s 30us/step - loss: 1.8593 - acc: 0.6540 - val_loss: 1.2592 - val_acc: 0.6848

Epoch 00004: loss improved from 1.95969 to 1.85926, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4182 - acc: 0.7812
734/734 [==============================] - 0s 30us/step - loss: 1.7684 - acc: 0.6880 - val_loss: 1.2872 - val_acc: 0.6793

Epoch 00005: loss improved from 1.85926 to 1.76843, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3380 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.7780 - acc: 0.6771 - val_loss: 1.2422 - val_acc: 0.6630

Epoch 00006: loss did not improve from 1.76843
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6799 - acc: 0.6562
734/734 [==============================] - 0s 29us/step - loss: 1.7330 - acc: 0.6662 - val_loss: 1.2360 - val_acc: 0.6685

Epoch 00007: loss improved from 1.76843 to 1.73300, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3659 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.6705 - acc: 0.6894 - val_loss: 1.2233 - val_acc: 0.6522

Epoch 00008: loss improved from 1.73300 to 1.67051, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3937 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.6457 - acc: 0.6989 - val_loss: 1.1650 - val_acc: 0.6522

Epoch 00009: loss improved from 1.67051 to 1.64574, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2795 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.5633 - acc: 0.7125 - val_loss: 1.0324 - val_acc: 0.7228

Epoch 00010: loss improved from 1.64574 to 1.56333, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4341 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.5657 - acc: 0.6662 - val_loss: 0.9036 - val_acc: 0.7717

Epoch 00011: loss did not improve from 1.56333
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4037 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.5328 - acc: 0.6962 - val_loss: 1.0308 - val_acc: 0.7011

Epoch 00012: loss improved from 1.56333 to 1.53279, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0948 - acc: 0.8438
734/734 [==============================] - 0s 29us/step - loss: 1.5851 - acc: 0.6744 - val_loss: 0.9469 - val_acc: 0.7717

Epoch 00013: loss did not improve from 1.53279
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4040 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.5392 - acc: 0.6785 - val_loss: 1.0932 - val_acc: 0.6576

Epoch 00014: loss did not improve from 1.53279
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4161 - acc: 0.6875
734/734 [==============================] - 0s 29us/step - loss: 1.5350 - acc: 0.6771 - val_loss: 1.1698 - val_acc: 0.3804

Epoch 00015: loss did not improve from 1.53279
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4157 - acc: 0.6250
734/734 [==============================] - 0s 29us/step - loss: 1.4930 - acc: 0.6853 - val_loss: 0.8273 - val_acc: 0.7663

Epoch 00016: loss improved from 1.53279 to 1.49299, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2661 - acc: 0.6250
734/734 [==============================] - 0s 29us/step - loss: 1.3886 - acc: 0.7112 - val_loss: 0.9116 - val_acc: 0.7609

Epoch 00017: loss improved from 1.49299 to 1.38859, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3857 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.4221 - acc: 0.6989 - val_loss: 0.8343 - val_acc: 0.7717

Epoch 00018: loss did not improve from 1.38859
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4116 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.5213 - acc: 0.6785 - val_loss: 0.9058 - val_acc: 0.7663

Epoch 00019: loss did not improve from 1.38859
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4808 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.4500 - acc: 0.7003 - val_loss: 1.1442 - val_acc: 0.4022

Epoch 00020: loss did not improve from 1.38859
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2274 - acc: 0.6562
734/734 [==============================] - 0s 29us/step - loss: 1.3643 - acc: 0.6975 - val_loss: 0.9471 - val_acc: 0.7065

Epoch 00021: loss improved from 1.38859 to 1.36427, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_16.h5
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1838 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.3943 - acc: 0.7180 - val_loss: 0.9509 - val_acc: 0.7337

Epoch 00022: loss did not improve from 1.36427
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1727 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.4192 - acc: 0.7398 - val_loss: 0.8668 - val_acc: 0.7337

Epoch 00023: loss did not improve from 1.36427
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3615 - acc: 0.6562
734/734 [==============================] - 0s 29us/step - loss: 1.4466 - acc: 0.6866 - val_loss: 0.9509 - val_acc: 0.7011

Epoch 00024: loss did not improve from 1.36427
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0380 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.3858 - acc: 0.7153 - val_loss: 0.8717 - val_acc: 0.7500

Epoch 00025: loss did not improve from 1.36427
Epoch 26/100

 32/734 [>.............................] - ETA: 0s - loss: 1.0109 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.4025 - acc: 0.6880 - val_loss: 0.9089 - val_acc: 0.7446
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:24<00:04,  2.21s/it]
Epoch 00026: loss did not improve from 1.36427
Epoch 00026: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.5588 - acc: 0.8750
734/734 [==============================] - 0s 388us/step - loss: 2.4400 - acc: 0.6744 - val_loss: 1.3526 - val_acc: 0.7120

Epoch 00001: loss improved from inf to 2.43997, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6034 - acc: 0.6250
734/734 [==============================] - 0s 31us/step - loss: 1.9837 - acc: 0.6580 - val_loss: 1.3458 - val_acc: 0.6902

Epoch 00002: loss improved from 2.43997 to 1.98365, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5012 - acc: 0.7188
734/734 [==============================] - 0s 30us/step - loss: 1.8889 - acc: 0.6608 - val_loss: 1.3460 - val_acc: 0.6522

Epoch 00003: loss improved from 1.98365 to 1.88894, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4607 - acc: 0.7500
734/734 [==============================] - 0s 30us/step - loss: 1.7690 - acc: 0.6907 - val_loss: 1.3449 - val_acc: 0.6848

Epoch 00004: loss improved from 1.88894 to 1.76900, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6028 - acc: 0.7812
734/734 [==============================] - 0s 30us/step - loss: 1.7823 - acc: 0.6894 - val_loss: 1.2346 - val_acc: 0.6848

Epoch 00005: loss did not improve from 1.76900
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3236 - acc: 0.6562
734/734 [==============================] - 0s 29us/step - loss: 1.7006 - acc: 0.6853 - val_loss: 1.0119 - val_acc: 0.7880

Epoch 00006: loss improved from 1.76900 to 1.70058, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4560 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.6723 - acc: 0.6948 - val_loss: 1.0709 - val_acc: 0.7500

Epoch 00007: loss improved from 1.70058 to 1.67227, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3145 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.6324 - acc: 0.7084 - val_loss: 1.0102 - val_acc: 0.7391

Epoch 00008: loss improved from 1.67227 to 1.63240, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2666 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.5663 - acc: 0.7166 - val_loss: 0.9115 - val_acc: 0.7880

Epoch 00009: loss improved from 1.63240 to 1.56628, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4542 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.5445 - acc: 0.7084 - val_loss: 0.9838 - val_acc: 0.7663

Epoch 00010: loss improved from 1.56628 to 1.54450, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_17.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4631 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.6173 - acc: 0.6744 - val_loss: 1.0380 - val_acc: 0.7065

Epoch 00011: loss did not improve from 1.54450
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3112 - acc: 0.7812
734/734 [==============================] - 0s 29us/step - loss: 1.5714 - acc: 0.7139 - val_loss: 1.1971 - val_acc: 0.6902

Epoch 00012: loss did not improve from 1.54450
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1697 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.5480 - acc: 0.6866 - val_loss: 1.5542 - val_acc: 0.2609

Epoch 00013: loss did not improve from 1.54450
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6576 - acc: 0.5000
734/734 [==============================] - 0s 29us/step - loss: 1.6089 - acc: 0.6362 - val_loss: 1.2520 - val_acc: 0.4511

Epoch 00014: loss did not improve from 1.54450
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3973 - acc: 0.8125
734/734 [==============================] - 0s 29us/step - loss: 1.5772 - acc: 0.6512 - val_loss: 1.1626 - val_acc: 0.5761
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:26<00:02,  2.15s/it]
Epoch 00015: loss did not improve from 1.54450
Epoch 00015: early stopping
Train on 734 samples, validate on 184 samples
Epoch 1/100

 32/734 [>.............................] - ETA: 5s - loss: 1.5989 - acc: 0.8438
734/734 [==============================] - 0s 381us/step - loss: 2.4496 - acc: 0.6812 - val_loss: 1.4024 - val_acc: 0.7011

Epoch 00001: loss improved from inf to 2.44961, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6813 - acc: 0.6875
734/734 [==============================] - 0s 31us/step - loss: 2.0815 - acc: 0.6294 - val_loss: 1.3785 - val_acc: 0.6902

Epoch 00002: loss improved from 2.44961 to 2.08148, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/734 [>.............................] - ETA: 0s - loss: 1.7544 - acc: 0.6562
734/734 [==============================] - 0s 30us/step - loss: 1.9505 - acc: 0.6526 - val_loss: 1.3129 - val_acc: 0.6522

Epoch 00003: loss improved from 2.08148 to 1.95055, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6748 - acc: 0.5938
734/734 [==============================] - 0s 30us/step - loss: 1.8718 - acc: 0.6281 - val_loss: 1.3533 - val_acc: 0.6522

Epoch 00004: loss improved from 1.95055 to 1.87183, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4777 - acc: 0.5938
734/734 [==============================] - 0s 29us/step - loss: 1.8097 - acc: 0.6499 - val_loss: 1.2889 - val_acc: 0.6522

Epoch 00005: loss improved from 1.87183 to 1.80970, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4140 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.7458 - acc: 0.6526 - val_loss: 1.4418 - val_acc: 0.3641

Epoch 00006: loss improved from 1.80970 to 1.74582, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4296 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.7389 - acc: 0.6771 - val_loss: 1.1396 - val_acc: 0.6793

Epoch 00007: loss improved from 1.74582 to 1.73894, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 8/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5102 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.6975 - acc: 0.6785 - val_loss: 1.2199 - val_acc: 0.6467

Epoch 00008: loss improved from 1.73894 to 1.69754, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4381 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.6564 - acc: 0.6580 - val_loss: 0.9934 - val_acc: 0.7554

Epoch 00009: loss improved from 1.69754 to 1.65637, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3748 - acc: 0.6562
734/734 [==============================] - 0s 29us/step - loss: 1.6198 - acc: 0.6567 - val_loss: 1.0018 - val_acc: 0.7337

Epoch 00010: loss improved from 1.65637 to 1.61978, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 11/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3049 - acc: 0.7500
734/734 [==============================] - 0s 29us/step - loss: 1.6033 - acc: 0.6594 - val_loss: 1.0796 - val_acc: 0.6630

Epoch 00011: loss improved from 1.61978 to 1.60326, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 12/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2658 - acc: 0.6562
734/734 [==============================] - 0s 29us/step - loss: 1.6088 - acc: 0.6594 - val_loss: 1.0926 - val_acc: 0.6467

Epoch 00012: loss did not improve from 1.60326
Epoch 13/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1517 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.5185 - acc: 0.6621 - val_loss: 1.5192 - val_acc: 0.2609

Epoch 00013: loss improved from 1.60326 to 1.51846, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 14/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3959 - acc: 0.5312
734/734 [==============================] - 0s 29us/step - loss: 1.5334 - acc: 0.6403 - val_loss: 1.0291 - val_acc: 0.7065

Epoch 00014: loss did not improve from 1.51846
Epoch 15/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1582 - acc: 0.7812
734/734 [==============================] - 0s 28us/step - loss: 1.5124 - acc: 0.6812 - val_loss: 1.0072 - val_acc: 0.6630

Epoch 00015: loss improved from 1.51846 to 1.51239, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2931 - acc: 0.6875
734/734 [==============================] - 0s 29us/step - loss: 1.5736 - acc: 0.6812 - val_loss: 1.2154 - val_acc: 0.2663

Epoch 00016: loss did not improve from 1.51239
Epoch 17/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3876 - acc: 0.6875
734/734 [==============================] - 0s 29us/step - loss: 1.5273 - acc: 0.6757 - val_loss: 1.5135 - val_acc: 0.2609

Epoch 00017: loss did not improve from 1.51239
Epoch 18/100

 32/734 [>.............................] - ETA: 0s - loss: 1.5578 - acc: 0.4688
734/734 [==============================] - 0s 28us/step - loss: 1.4877 - acc: 0.6580 - val_loss: 0.7842 - val_acc: 0.7826

Epoch 00018: loss improved from 1.51239 to 1.48772, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 19/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3272 - acc: 0.6562
734/734 [==============================] - 0s 29us/step - loss: 1.4919 - acc: 0.6812 - val_loss: 0.8588 - val_acc: 0.7337

Epoch 00019: loss did not improve from 1.48772
Epoch 20/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3063 - acc: 0.5312
734/734 [==============================] - 0s 28us/step - loss: 1.4447 - acc: 0.6894 - val_loss: 1.2970 - val_acc: 0.2609

Epoch 00020: loss improved from 1.48772 to 1.44469, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 21/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3440 - acc: 0.5312
734/734 [==============================] - 0s 29us/step - loss: 1.5405 - acc: 0.6676 - val_loss: 1.3600 - val_acc: 0.2663

Epoch 00021: loss did not improve from 1.44469
Epoch 22/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2076 - acc: 0.7500
734/734 [==============================] - 0s 28us/step - loss: 1.5508 - acc: 0.6826 - val_loss: 0.8912 - val_acc: 0.7772

Epoch 00022: loss did not improve from 1.44469
Epoch 23/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4590 - acc: 0.7188
734/734 [==============================] - 0s 29us/step - loss: 1.5734 - acc: 0.6431 - val_loss: 1.1696 - val_acc: 0.4674

Epoch 00023: loss did not improve from 1.44469
Epoch 24/100

 32/734 [>.............................] - ETA: 0s - loss: 1.3201 - acc: 0.5625
734/734 [==============================] - 0s 28us/step - loss: 1.4970 - acc: 0.6662 - val_loss: 1.1909 - val_acc: 0.4946

Epoch 00024: loss did not improve from 1.44469
Epoch 25/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1467 - acc: 0.7812
734/734 [==============================] - 0s 28us/step - loss: 1.3868 - acc: 0.7071 - val_loss: 1.0434 - val_acc: 0.5109

Epoch 00025: loss improved from 1.44469 to 1.38681, saving model to ./results_TA98_with_S9/DeepAmes_models/weight_18.h5
Epoch 26/100

 32/734 [>.............................] - ETA: 0s - loss: 1.1771 - acc: 0.5625
734/734 [==============================] - 0s 29us/step - loss: 1.5136 - acc: 0.6540 - val_loss: 1.2508 - val_acc: 0.3913

Epoch 00026: loss did not improve from 1.38681
Epoch 27/100

 32/734 [>.............................] - ETA: 0s - loss: 1.4676 - acc: 0.6250
734/734 [==============================] - 0s 29us/step - loss: 1.5423 - acc: 0.6757 - val_loss: 1.0614 - val_acc: 0.2880

Epoch 00027: loss did not improve from 1.38681
Epoch 28/100

 32/734 [>.............................] - ETA: 0s - loss: 1.6128 - acc: 0.5000
734/734 [==============================] - 0s 28us/step - loss: 1.5479 - acc: 0.6812 - val_loss: 1.1073 - val_acc: 0.4565

Epoch 00028: loss did not improve from 1.38681
Epoch 29/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2940 - acc: 0.6562
734/734 [==============================] - 0s 28us/step - loss: 1.4683 - acc: 0.6798 - val_loss: 1.0714 - val_acc: 0.6141

Epoch 00029: loss did not improve from 1.38681
Epoch 30/100

 32/734 [>.............................] - ETA: 0s - loss: 1.2450 - acc: 0.6250
734/734 [==============================] - 0s 28us/step - loss: 1.4250 - acc: 0.6894 - val_loss: 1.1788 - val_acc: 0.2880
DeepAmes+ Weights: 100%|██████████| 13/13 [00:29<00:00,  2.21s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:29<00:00,  2.24s/it]

Epoch 00030: loss did not improve from 1.38681
Epoch 00030: early stopping
--- 6273.951404571533 seconds ---

Generating metrics report for TA98_with_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 538 samples.
Processing weight 7...
  Done. 538 samples.
Processing weight 8...
  Done. 538 samples.
Processing weight 9...
  Done. 538 samples.
Processing weight 10...
  Done. 538 samples.
Processing weight 11...
  Done. 538 samples.
Processing weight 12...
  Done. 538 samples.
Processing weight 13...
  Done. 538 samples.
Processing weight 14...
  Done. 538 samples.
Processing weight 15...
  Done. 538 samples.
Processing weight 16...
  Done. 538 samples.
Processing weight 17...
  Done. 538 samples.
Processing weight 18...
  Done. 538 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA98_with_S9/metrics_report_TA98_with_S9.txt

Done!

Completed TA98_with_S9 in 6273.95 seconds

================================================================================
[16/16] Processing: TA98_without_S9
================================================================================
  Train: ./Ready_Data/Train_Data_Featurized/TA98_without_S9_Train_Val_mold2.csv
  Test:  ./Ready_Data/Test_Data_Featurized/TA98_without_S9_Test_mold2.csv
(4979, 777)
(3983, 777)
(567, 777)
KNN Seeds:   0%|          | 0/20 [00:00<?, ?it/s]KNN Seeds:   5%|▌         | 1/20 [00:36<11:31, 36.39s/it]KNN Seeds:  10%|█         | 2/20 [01:12<10:57, 36.52s/it]KNN Seeds:  15%|█▌        | 3/20 [01:49<10:23, 36.65s/it]KNN Seeds:  20%|██        | 4/20 [02:26<09:48, 36.80s/it]KNN Seeds:  25%|██▌       | 5/20 [03:03<09:11, 36.76s/it]KNN Seeds:  30%|███       | 6/20 [03:39<08:30, 36.44s/it]KNN Seeds:  35%|███▌      | 7/20 [04:16<07:54, 36.53s/it]KNN Seeds:  40%|████      | 8/20 [04:52<07:19, 36.65s/it]KNN Seeds:  45%|████▌     | 9/20 [05:28<06:40, 36.45s/it]KNN Seeds:  50%|█████     | 10/20 [06:05<06:04, 36.44s/it]KNN Seeds:  55%|█████▌    | 11/20 [06:42<05:29, 36.57s/it]KNN Seeds:  60%|██████    | 12/20 [07:18<04:51, 36.42s/it]KNN Seeds:  65%|██████▌   | 13/20 [07:55<04:15, 36.54s/it]KNN Seeds:  70%|███████   | 14/20 [08:31<03:38, 36.48s/it]KNN Seeds:  75%|███████▌  | 15/20 [09:08<03:02, 36.58s/it]KNN Seeds:  80%|████████  | 16/20 [09:43<02:24, 36.14s/it]KNN Seeds:  85%|████████▌ | 17/20 [10:18<01:47, 35.97s/it]KNN Seeds:  90%|█████████ | 18/20 [10:55<01:12, 36.07s/it]KNN Seeds:  95%|█████████▌| 19/20 [11:31<00:36, 36.02s/it]KNN Seeds: 100%|██████████| 20/20 [12:08<00:00, 36.26s/it]KNN Seeds: 100%|██████████| 20/20 [12:08<00:00, 36.40s/it]
24
(100, None, 'lbfgs')
(4979, 777)
(3983, 777)
(567, 777)
LR Seeds:   0%|          | 0/20 [00:00<?, ?it/s]LR Seeds:   5%|▌         | 1/20 [00:02<00:54,  2.85s/it]LR Seeds:  10%|█         | 2/20 [00:05<00:51,  2.85s/it]LR Seeds:  15%|█▌        | 3/20 [00:08<00:48,  2.87s/it]LR Seeds:  20%|██        | 4/20 [00:11<00:45,  2.86s/it]LR Seeds:  25%|██▌       | 5/20 [00:14<00:42,  2.86s/it]LR Seeds:  30%|███       | 6/20 [00:17<00:40,  2.87s/it]LR Seeds:  35%|███▌      | 7/20 [00:20<00:37,  2.87s/it]LR Seeds:  40%|████      | 8/20 [00:22<00:34,  2.87s/it]LR Seeds:  45%|████▌     | 9/20 [00:25<00:31,  2.88s/it]LR Seeds:  50%|█████     | 10/20 [00:28<00:29,  2.90s/it]LR Seeds:  55%|█████▌    | 11/20 [00:31<00:26,  2.92s/it]LR Seeds:  60%|██████    | 12/20 [00:34<00:23,  2.93s/it]LR Seeds:  65%|██████▌   | 13/20 [00:37<00:20,  2.93s/it]LR Seeds:  70%|███████   | 14/20 [00:40<00:17,  2.94s/it]LR Seeds:  75%|███████▌  | 15/20 [00:43<00:14,  2.97s/it]LR Seeds:  80%|████████  | 16/20 [00:46<00:11,  2.97s/it]LR Seeds:  85%|████████▌ | 17/20 [00:49<00:08,  2.99s/it]LR Seeds:  90%|█████████ | 18/20 [00:52<00:06,  3.01s/it]LR Seeds:  95%|█████████▌| 19/20 [00:55<00:03,  3.04s/it]LR Seeds: 100%|██████████| 20/20 [00:58<00:00,  3.04s/it]LR Seeds: 100%|██████████| 20/20 [00:58<00:00,  2.94s/it]
96
('rbf', 1, 1)
(4979, 777)
(3983, 777)
(567, 777)
SVM Seeds:   0%|          | 0/20 [00:00<?, ?it/s]SVM Seeds:   5%|▌         | 1/20 [03:46<1:11:39, 226.31s/it]SVM Seeds:  10%|█         | 2/20 [07:32<1:07:52, 226.24s/it]SVM Seeds:  15%|█▌        | 3/20 [11:19<1:04:10, 226.48s/it]SVM Seeds:  20%|██        | 4/20 [15:05<1:00:24, 226.54s/it]SVM Seeds:  25%|██▌       | 5/20 [18:52<56:36, 226.42s/it]  SVM Seeds:  30%|███       | 6/20 [22:39<52:56, 226.86s/it]SVM Seeds:  35%|███▌      | 7/20 [26:26<49:07, 226.72s/it]SVM Seeds:  40%|████      | 8/20 [30:12<45:19, 226.66s/it]SVM Seeds:  45%|████▌     | 9/20 [33:58<41:31, 226.52s/it]SVM Seeds:  50%|█████     | 10/20 [37:46<37:49, 226.94s/it]SVM Seeds:  55%|█████▌    | 11/20 [41:33<34:00, 226.74s/it]SVM Seeds:  60%|██████    | 12/20 [45:20<30:15, 226.90s/it]SVM Seeds:  65%|██████▌   | 13/20 [49:06<26:25, 226.57s/it]SVM Seeds:  70%|███████   | 14/20 [52:52<22:38, 226.44s/it]SVM Seeds:  75%|███████▌  | 15/20 [56:38<18:51, 226.36s/it]SVM Seeds:  80%|████████  | 16/20 [1:00:25<15:06, 226.50s/it]SVM Seeds:  85%|████████▌ | 17/20 [1:04:12<11:19, 226.65s/it]SVM Seeds:  90%|█████████ | 18/20 [1:08:00<07:33, 226.96s/it]SVM Seeds:  95%|█████████▌| 19/20 [1:11:47<03:47, 227.20s/it]SVM Seeds: 100%|██████████| 20/20 [1:15:33<00:00, 226.84s/it]SVM Seeds: 100%|██████████| 20/20 [1:15:33<00:00, 226.69s/it]
200
(500, None, 70, 1, 'balanced')
(4979, 777)
(3983, 777)
(567, 777)
RF Seeds:   0%|          | 0/20 [00:00<?, ?it/s]RF Seeds:   5%|▌         | 1/20 [00:17<05:27, 17.21s/it]RF Seeds:  10%|█         | 2/20 [00:34<05:10, 17.24s/it]RF Seeds:  15%|█▌        | 3/20 [00:51<04:53, 17.24s/it]RF Seeds:  20%|██        | 4/20 [01:08<04:36, 17.26s/it]RF Seeds:  25%|██▌       | 5/20 [01:26<04:18, 17.25s/it]RF Seeds:  30%|███       | 6/20 [01:43<04:01, 17.25s/it]RF Seeds:  35%|███▌      | 7/20 [02:00<03:44, 17.25s/it]RF Seeds:  40%|████      | 8/20 [02:17<03:26, 17.23s/it]RF Seeds:  45%|████▌     | 9/20 [02:35<03:09, 17.25s/it]RF Seeds:  50%|█████     | 10/20 [02:52<02:52, 17.26s/it]RF Seeds:  55%|█████▌    | 11/20 [03:09<02:35, 17.26s/it]RF Seeds:  60%|██████    | 12/20 [03:27<02:18, 17.29s/it]RF Seeds:  65%|██████▌   | 13/20 [03:44<02:01, 17.29s/it]RF Seeds:  70%|███████   | 14/20 [04:01<01:43, 17.31s/it]RF Seeds:  75%|███████▌  | 15/20 [04:19<01:26, 17.33s/it]RF Seeds:  80%|████████  | 16/20 [04:36<01:09, 17.33s/it]RF Seeds:  85%|████████▌ | 17/20 [04:53<00:52, 17.37s/it]RF Seeds:  90%|█████████ | 18/20 [05:11<00:34, 17.37s/it]RF Seeds:  95%|█████████▌| 19/20 [05:28<00:17, 17.39s/it]RF Seeds: 100%|██████████| 20/20 [05:46<00:00, 17.39s/it]RF Seeds: 100%|██████████| 20/20 [05:46<00:00, 17.31s/it]
400
(0.01, 900, 7, 0.8, 6)
(4979, 777)
(3983, 777)
(567, 777)
XGBoost Seeds:   0%|          | 0/20 [00:00<?, ?it/s]XGBoost Seeds:   5%|▌         | 1/20 [01:04<20:29, 64.73s/it]XGBoost Seeds:  10%|█         | 2/20 [02:09<19:24, 64.69s/it]XGBoost Seeds:  15%|█▌        | 3/20 [03:13<18:17, 64.56s/it]XGBoost Seeds:  20%|██        | 4/20 [04:18<17:13, 64.57s/it]XGBoost Seeds:  25%|██▌       | 5/20 [05:22<16:08, 64.56s/it]XGBoost Seeds:  30%|███       | 6/20 [06:27<15:03, 64.53s/it]XGBoost Seeds:  35%|███▌      | 7/20 [07:31<13:59, 64.54s/it]XGBoost Seeds:  40%|████      | 8/20 [08:36<12:54, 64.54s/it]XGBoost Seeds:  45%|████▌     | 9/20 [09:41<11:50, 64.56s/it]XGBoost Seeds:  50%|█████     | 10/20 [10:45<10:45, 64.59s/it]XGBoost Seeds:  55%|█████▌    | 11/20 [11:50<09:41, 64.56s/it]XGBoost Seeds:  60%|██████    | 12/20 [12:54<08:36, 64.59s/it]XGBoost Seeds:  65%|██████▌   | 13/20 [13:59<07:32, 64.58s/it]XGBoost Seeds:  70%|███████   | 14/20 [15:04<06:27, 64.58s/it]XGBoost Seeds:  75%|███████▌  | 15/20 [16:08<05:22, 64.58s/it]XGBoost Seeds:  80%|████████  | 16/20 [17:13<04:18, 64.59s/it]XGBoost Seeds:  85%|████████▌ | 17/20 [18:18<03:14, 64.72s/it]XGBoost Seeds:  90%|█████████ | 18/20 [19:23<02:09, 64.78s/it]XGBoost Seeds:  95%|█████████▌| 19/20 [20:28<01:04, 64.84s/it]XGBoost Seeds: 100%|██████████| 20/20 [21:33<00:00, 64.86s/it]XGBoost Seeds: 100%|██████████| 20/20 [21:33<00:00, 64.65s/it]
knn:  96
lr:  82
svm:  99
rf:  97
xgboost:  73
Combining validation predictions is completed
knn:  96
lr:  82
svm:  99
rf:  97
xgboost:  73
Combining test predictions is completed
DeepAmes+ Weights:   0%|          | 0/13 [00:00<?, ?it/s]Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.3775 - acc: 0.7812
796/796 [==============================] - 0s 362us/step - loss: 1.5928 - acc: 0.8040 - val_loss: 1.1176 - val_acc: 0.8350

Epoch 00001: loss improved from inf to 1.59280, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0278 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.3741 - acc: 0.8392 - val_loss: 1.0486 - val_acc: 0.8400

Epoch 00002: loss improved from 1.59280 to 1.37407, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9870 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.3067 - acc: 0.8392 - val_loss: 0.9869 - val_acc: 0.8400

Epoch 00003: loss improved from 1.37407 to 1.30668, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0066 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.2686 - acc: 0.8379 - val_loss: 0.9404 - val_acc: 0.8400

Epoch 00004: loss improved from 1.30668 to 1.26858, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7705 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1820 - acc: 0.8430 - val_loss: 0.8725 - val_acc: 0.8400

Epoch 00005: loss improved from 1.26858 to 1.18204, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7675 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1443 - acc: 0.8492 - val_loss: 0.8659 - val_acc: 0.8450

Epoch 00006: loss improved from 1.18204 to 1.14433, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7113 - acc: 0.9062
796/796 [==============================] - 0s 30us/step - loss: 1.0935 - acc: 0.8530 - val_loss: 0.8182 - val_acc: 0.8350

Epoch 00007: loss improved from 1.14433 to 1.09348, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6575 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0563 - acc: 0.8442 - val_loss: 0.7876 - val_acc: 0.8450

Epoch 00008: loss improved from 1.09348 to 1.05635, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6379 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0158 - acc: 0.8455 - val_loss: 0.8340 - val_acc: 0.8450

Epoch 00009: loss improved from 1.05635 to 1.01583, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6341 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.9730 - acc: 0.8518 - val_loss: 0.8648 - val_acc: 0.8150

Epoch 00010: loss improved from 1.01583 to 0.97297, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5534 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 1.0214 - acc: 0.8467 - val_loss: 0.7269 - val_acc: 0.8500

Epoch 00011: loss did not improve from 0.97297
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5604 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.9368 - acc: 0.8580 - val_loss: 0.6858 - val_acc: 0.8600

Epoch 00012: loss improved from 0.97297 to 0.93675, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5262 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.9740 - acc: 0.8342 - val_loss: 0.7249 - val_acc: 0.8450

Epoch 00013: loss did not improve from 0.93675
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5605 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 0.9435 - acc: 0.8417 - val_loss: 0.7853 - val_acc: 0.8350

Epoch 00014: loss did not improve from 0.93675
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5316 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.9128 - acc: 0.8543 - val_loss: 0.7014 - val_acc: 0.8500

Epoch 00015: loss improved from 0.93675 to 0.91283, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5225 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8886 - acc: 0.8518 - val_loss: 0.6292 - val_acc: 0.8600

Epoch 00016: loss improved from 0.91283 to 0.88863, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5288 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.8920 - acc: 0.8719 - val_loss: 0.6072 - val_acc: 0.8550

Epoch 00017: loss did not improve from 0.88863
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4466 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.8590 - acc: 0.8580 - val_loss: 0.8110 - val_acc: 0.8450

Epoch 00018: loss improved from 0.88863 to 0.85895, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5377 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8795 - acc: 0.8555 - val_loss: 0.6439 - val_acc: 0.8500

Epoch 00019: loss did not improve from 0.85895
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4884 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8676 - acc: 0.8543 - val_loss: 0.5822 - val_acc: 0.8550

Epoch 00020: loss did not improve from 0.85895
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4743 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8626 - acc: 0.8505 - val_loss: 0.6081 - val_acc: 0.8500

Epoch 00021: loss did not improve from 0.85895
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4699 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8681 - acc: 0.8530 - val_loss: 0.6709 - val_acc: 0.8350

Epoch 00022: loss did not improve from 0.85895
Epoch 23/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5056 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8182 - acc: 0.8693 - val_loss: 0.6161 - val_acc: 0.8600

Epoch 00023: loss improved from 0.85895 to 0.81817, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 24/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5190 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.8777 - acc: 0.8530 - val_loss: 0.5514 - val_acc: 0.8750

Epoch 00024: loss did not improve from 0.81817
Epoch 25/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5614 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8748 - acc: 0.8543 - val_loss: 0.6117 - val_acc: 0.8550

Epoch 00025: loss did not improve from 0.81817
Epoch 26/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5688 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 0.8677 - acc: 0.8480 - val_loss: 0.5097 - val_acc: 0.8700

Epoch 00026: loss did not improve from 0.81817
Epoch 27/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5331 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 0.7926 - acc: 0.8555 - val_loss: 0.5086 - val_acc: 0.8700

Epoch 00027: loss improved from 0.81817 to 0.79261, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 28/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5170 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8127 - acc: 0.8606 - val_loss: 0.5744 - val_acc: 0.8600

Epoch 00028: loss did not improve from 0.79261
Epoch 29/100

 32/796 [>.............................] - ETA: 0s - loss: 0.3963 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.8126 - acc: 0.8606 - val_loss: 0.5310 - val_acc: 0.8600

Epoch 00029: loss did not improve from 0.79261
Epoch 30/100

 32/796 [>.............................] - ETA: 0s - loss: 0.3639 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.8206 - acc: 0.8492 - val_loss: 0.5465 - val_acc: 0.8500

Epoch 00030: loss did not improve from 0.79261
Epoch 31/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4503 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.7917 - acc: 0.8706 - val_loss: 0.5076 - val_acc: 0.8650

Epoch 00031: loss improved from 0.79261 to 0.79173, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 32/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4476 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.7884 - acc: 0.8530 - val_loss: 0.6340 - val_acc: 0.8550

Epoch 00032: loss improved from 0.79173 to 0.78843, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 33/100

 32/796 [>.............................] - ETA: 0s - loss: 0.3422 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.7931 - acc: 0.8668 - val_loss: 0.5833 - val_acc: 0.8450

Epoch 00033: loss did not improve from 0.78843
Epoch 34/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4125 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 0.8693 - acc: 0.8593 - val_loss: 0.5459 - val_acc: 0.8450

Epoch 00034: loss did not improve from 0.78843
Epoch 35/100

 32/796 [>.............................] - ETA: 0s - loss: 0.3808 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.8189 - acc: 0.8693 - val_loss: 0.6453 - val_acc: 0.8600

Epoch 00035: loss did not improve from 0.78843
Epoch 36/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4489 - acc: 0.9688
796/796 [==============================] - 0s 29us/step - loss: 0.7954 - acc: 0.8555 - val_loss: 0.5823 - val_acc: 0.8350

Epoch 00036: loss did not improve from 0.78843
Epoch 37/100

 32/796 [>.............................] - ETA: 0s - loss: 0.3775 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.7339 - acc: 0.8656 - val_loss: 0.7339 - val_acc: 0.8600

Epoch 00037: loss improved from 0.78843 to 0.73392, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_6.h5
Epoch 38/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4002 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.8317 - acc: 0.8681 - val_loss: 0.5398 - val_acc: 0.8550

Epoch 00038: loss did not improve from 0.73392
Epoch 39/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4334 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.8405 - acc: 0.8668 - val_loss: 0.5756 - val_acc: 0.8500

Epoch 00039: loss did not improve from 0.73392
Epoch 40/100

 32/796 [>.............................] - ETA: 0s - loss: 0.3974 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.8345 - acc: 0.8618 - val_loss: 0.5511 - val_acc: 0.8550

Epoch 00040: loss did not improve from 0.73392
Epoch 41/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4078 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.7572 - acc: 0.8668 - val_loss: 0.5271 - val_acc: 0.8650

Epoch 00041: loss did not improve from 0.73392
Epoch 42/100

 32/796 [>.............................] - ETA: 0s - loss: 0.3077 - acc: 0.9688
796/796 [==============================] - 0s 29us/step - loss: 0.8301 - acc: 0.8492 - val_loss: 0.4567 - val_acc: 0.8700
DeepAmes+ Weights:   8%|▊         | 1/13 [00:02<00:31,  2.64s/it]
Epoch 00042: loss did not improve from 0.73392
Epoch 00042: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.1674 - acc: 0.8125
796/796 [==============================] - 0s 361us/step - loss: 1.6457 - acc: 0.7877 - val_loss: 1.1477 - val_acc: 0.8150

Epoch 00001: loss improved from inf to 1.64566, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0378 - acc: 0.9062
796/796 [==============================] - 0s 30us/step - loss: 1.4461 - acc: 0.8204 - val_loss: 1.0911 - val_acc: 0.8300

Epoch 00002: loss improved from 1.64566 to 1.44615, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9508 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.3741 - acc: 0.8204 - val_loss: 1.0260 - val_acc: 0.8350

Epoch 00003: loss improved from 1.44615 to 1.37406, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9892 - acc: 0.8438
796/796 [==============================] - 0s 32us/step - loss: 1.3088 - acc: 0.8191 - val_loss: 0.9252 - val_acc: 0.8400

Epoch 00004: loss improved from 1.37406 to 1.30881, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8634 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.2433 - acc: 0.8304 - val_loss: 0.8951 - val_acc: 0.8300

Epoch 00005: loss improved from 1.30881 to 1.24327, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8907 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.2181 - acc: 0.8329 - val_loss: 0.8715 - val_acc: 0.8300

Epoch 00006: loss improved from 1.24327 to 1.21806, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8191 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.1634 - acc: 0.8329 - val_loss: 0.8842 - val_acc: 0.8350

Epoch 00007: loss improved from 1.21806 to 1.16340, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7242 - acc: 0.9375
796/796 [==============================] - 0s 31us/step - loss: 1.1155 - acc: 0.8342 - val_loss: 0.8140 - val_acc: 0.8450

Epoch 00008: loss improved from 1.16340 to 1.11552, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8416 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.1218 - acc: 0.8367 - val_loss: 0.7441 - val_acc: 0.8450

Epoch 00009: loss did not improve from 1.11552
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6617 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.1041 - acc: 0.8430 - val_loss: 0.7360 - val_acc: 0.8350

Epoch 00010: loss improved from 1.11552 to 1.10406, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6458 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.0741 - acc: 0.8392 - val_loss: 0.8174 - val_acc: 0.8350

Epoch 00011: loss improved from 1.10406 to 1.07414, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6885 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.0444 - acc: 0.8254 - val_loss: 0.7788 - val_acc: 0.8450

Epoch 00012: loss improved from 1.07414 to 1.04444, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6443 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.0027 - acc: 0.8329 - val_loss: 0.7820 - val_acc: 0.8350

Epoch 00013: loss improved from 1.04444 to 1.00275, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5738 - acc: 0.9375
796/796 [==============================] - 0s 31us/step - loss: 0.9797 - acc: 0.8392 - val_loss: 0.8398 - val_acc: 0.7800

Epoch 00014: loss improved from 1.00275 to 0.97971, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5932 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 0.9560 - acc: 0.8455 - val_loss: 0.8699 - val_acc: 0.8200

Epoch 00015: loss improved from 0.97971 to 0.95599, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_7.h5
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5391 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 0.9611 - acc: 0.8593 - val_loss: 0.7475 - val_acc: 0.8500

Epoch 00016: loss did not improve from 0.95599
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5314 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 0.9780 - acc: 0.8518 - val_loss: 0.6843 - val_acc: 0.8450

Epoch 00017: loss did not improve from 0.95599
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5803 - acc: 0.9062
796/796 [==============================] - 0s 30us/step - loss: 0.9993 - acc: 0.8379 - val_loss: 0.6432 - val_acc: 0.8450

Epoch 00018: loss did not improve from 0.95599
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6033 - acc: 0.9062
796/796 [==============================] - 0s 30us/step - loss: 0.9711 - acc: 0.8379 - val_loss: 0.6574 - val_acc: 0.8350

Epoch 00019: loss did not improve from 0.95599
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5243 - acc: 0.9688
796/796 [==============================] - 0s 30us/step - loss: 0.9887 - acc: 0.8379 - val_loss: 0.6781 - val_acc: 0.8100
DeepAmes+ Weights:  15%|█▌        | 2/13 [00:04<00:26,  2.38s/it]
Epoch 00020: loss did not improve from 0.95599
Epoch 00020: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.3560 - acc: 0.8438
796/796 [==============================] - 0s 345us/step - loss: 1.6725 - acc: 0.7877 - val_loss: 1.1376 - val_acc: 0.8050

Epoch 00001: loss improved from inf to 1.67249, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0485 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.5133 - acc: 0.8090 - val_loss: 1.0403 - val_acc: 0.8500

Epoch 00002: loss improved from 1.67249 to 1.51333, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9645 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.4255 - acc: 0.8103 - val_loss: 0.9867 - val_acc: 0.8350

Epoch 00003: loss improved from 1.51333 to 1.42554, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9279 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.3537 - acc: 0.8153 - val_loss: 0.9929 - val_acc: 0.8400

Epoch 00004: loss improved from 1.42554 to 1.35369, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8982 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3020 - acc: 0.8241 - val_loss: 0.9140 - val_acc: 0.8400

Epoch 00005: loss improved from 1.35369 to 1.30203, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8227 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2590 - acc: 0.8266 - val_loss: 0.9049 - val_acc: 0.8400

Epoch 00006: loss improved from 1.30203 to 1.25901, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7912 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2292 - acc: 0.8241 - val_loss: 0.9657 - val_acc: 0.8050

Epoch 00007: loss improved from 1.25901 to 1.22915, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6945 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 1.1854 - acc: 0.8379 - val_loss: 0.9293 - val_acc: 0.8100

Epoch 00008: loss improved from 1.22915 to 1.18543, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6403 - acc: 0.9062
796/796 [==============================] - 0s 28us/step - loss: 1.1583 - acc: 0.8304 - val_loss: 0.8331 - val_acc: 0.8200

Epoch 00009: loss improved from 1.18543 to 1.15827, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6907 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1372 - acc: 0.8153 - val_loss: 0.8464 - val_acc: 0.8300

Epoch 00010: loss improved from 1.15827 to 1.13721, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7982 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.1071 - acc: 0.8191 - val_loss: 0.7556 - val_acc: 0.8300

Epoch 00011: loss improved from 1.13721 to 1.10707, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7116 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.0462 - acc: 0.8379 - val_loss: 0.7975 - val_acc: 0.8450

Epoch 00012: loss improved from 1.10707 to 1.04619, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5996 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0069 - acc: 0.8379 - val_loss: 0.7319 - val_acc: 0.8400

Epoch 00013: loss improved from 1.04619 to 1.00691, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5496 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0534 - acc: 0.8392 - val_loss: 0.7059 - val_acc: 0.8550

Epoch 00014: loss did not improve from 1.00691
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5592 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 1.0605 - acc: 0.8342 - val_loss: 0.7742 - val_acc: 0.8450

Epoch 00015: loss did not improve from 1.00691
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5383 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0767 - acc: 0.8392 - val_loss: 0.7074 - val_acc: 0.8450

Epoch 00016: loss did not improve from 1.00691
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5775 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0577 - acc: 0.8467 - val_loss: 0.7092 - val_acc: 0.8400

Epoch 00017: loss did not improve from 1.00691
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5375 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 0.9984 - acc: 0.8367 - val_loss: 0.8597 - val_acc: 0.8550

Epoch 00018: loss improved from 1.00691 to 0.99841, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6174 - acc: 0.9062
796/796 [==============================] - 0s 28us/step - loss: 0.9835 - acc: 0.8254 - val_loss: 0.5990 - val_acc: 0.8550

Epoch 00019: loss improved from 0.99841 to 0.98346, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6970 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.0223 - acc: 0.8467 - val_loss: 0.7928 - val_acc: 0.8400

Epoch 00020: loss did not improve from 0.98346
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5119 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.9559 - acc: 0.8304 - val_loss: 0.6642 - val_acc: 0.8550

Epoch 00021: loss improved from 0.98346 to 0.95591, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5754 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 0.9398 - acc: 0.8455 - val_loss: 0.6403 - val_acc: 0.8450

Epoch 00022: loss improved from 0.95591 to 0.93984, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_8.h5
Epoch 23/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4624 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0323 - acc: 0.8153 - val_loss: 0.7707 - val_acc: 0.8400

Epoch 00023: loss did not improve from 0.93984
Epoch 24/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5741 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0354 - acc: 0.8266 - val_loss: 0.6494 - val_acc: 0.8400

Epoch 00024: loss did not improve from 0.93984
Epoch 25/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6379 - acc: 0.8750
796/796 [==============================] - 0s 28us/step - loss: 1.0448 - acc: 0.8103 - val_loss: 0.6679 - val_acc: 0.8450

Epoch 00025: loss did not improve from 0.93984
Epoch 26/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5483 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 1.0371 - acc: 0.8254 - val_loss: 0.7841 - val_acc: 0.8400

Epoch 00026: loss did not improve from 0.93984
Epoch 27/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4922 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0084 - acc: 0.8279 - val_loss: 0.7791 - val_acc: 0.8150
DeepAmes+ Weights:  23%|██▎       | 3/13 [00:07<00:23,  2.36s/it]
Epoch 00027: loss did not improve from 0.93984
Epoch 00027: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.4579 - acc: 0.8125
796/796 [==============================] - 0s 357us/step - loss: 1.7562 - acc: 0.7739 - val_loss: 1.1648 - val_acc: 0.8050

Epoch 00001: loss improved from inf to 1.75621, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0935 - acc: 0.8438
796/796 [==============================] - 0s 33us/step - loss: 1.5586 - acc: 0.7965 - val_loss: 1.0868 - val_acc: 0.8200

Epoch 00002: loss improved from 1.75621 to 1.55858, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0595 - acc: 0.8438
796/796 [==============================] - 0s 33us/step - loss: 1.4930 - acc: 0.8090 - val_loss: 1.0609 - val_acc: 0.8200

Epoch 00003: loss improved from 1.55858 to 1.49300, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9397 - acc: 0.8750
796/796 [==============================] - 0s 32us/step - loss: 1.3665 - acc: 0.8015 - val_loss: 1.0969 - val_acc: 0.7750

Epoch 00004: loss improved from 1.49300 to 1.36649, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9821 - acc: 0.8125
796/796 [==============================] - 0s 32us/step - loss: 1.3574 - acc: 0.8116 - val_loss: 1.0229 - val_acc: 0.8000

Epoch 00005: loss improved from 1.36649 to 1.35736, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8592 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2824 - acc: 0.8178 - val_loss: 0.9473 - val_acc: 0.8200

Epoch 00006: loss improved from 1.35736 to 1.28244, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9353 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2975 - acc: 0.8191 - val_loss: 1.0814 - val_acc: 0.8300

Epoch 00007: loss did not improve from 1.28244
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7743 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2412 - acc: 0.8266 - val_loss: 1.0411 - val_acc: 0.7700

Epoch 00008: loss improved from 1.28244 to 1.24117, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7691 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2411 - acc: 0.8116 - val_loss: 0.9635 - val_acc: 0.8450

Epoch 00009: loss improved from 1.24117 to 1.24113, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6998 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 1.1884 - acc: 0.8241 - val_loss: 0.8174 - val_acc: 0.8300

Epoch 00010: loss improved from 1.24113 to 1.18837, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8111 - acc: 0.9375
796/796 [==============================] - 0s 30us/step - loss: 1.1682 - acc: 0.8241 - val_loss: 0.7722 - val_acc: 0.8200

Epoch 00011: loss improved from 1.18837 to 1.16822, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6267 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1204 - acc: 0.8329 - val_loss: 0.7553 - val_acc: 0.8400

Epoch 00012: loss improved from 1.16822 to 1.12037, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6286 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1376 - acc: 0.8279 - val_loss: 0.8582 - val_acc: 0.8350

Epoch 00013: loss did not improve from 1.12037
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5956 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1339 - acc: 0.8241 - val_loss: 0.9412 - val_acc: 0.7300

Epoch 00014: loss did not improve from 1.12037
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7052 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1295 - acc: 0.8266 - val_loss: 0.7935 - val_acc: 0.8100

Epoch 00015: loss did not improve from 1.12037
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5440 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0359 - acc: 0.8229 - val_loss: 0.7124 - val_acc: 0.8250

Epoch 00016: loss improved from 1.12037 to 1.03591, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5808 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.0935 - acc: 0.8216 - val_loss: 0.6970 - val_acc: 0.8400

Epoch 00017: loss did not improve from 1.03591
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5583 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 0.9955 - acc: 0.8266 - val_loss: 0.6332 - val_acc: 0.8350

Epoch 00018: loss improved from 1.03591 to 0.99554, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_9.h5
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5214 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0019 - acc: 0.8304 - val_loss: 0.6680 - val_acc: 0.8300

Epoch 00019: loss did not improve from 0.99554
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5638 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.0294 - acc: 0.8329 - val_loss: 0.7051 - val_acc: 0.8450

Epoch 00020: loss did not improve from 0.99554
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6254 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0490 - acc: 0.8367 - val_loss: 0.6694 - val_acc: 0.8400

Epoch 00021: loss did not improve from 0.99554
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5408 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 1.0471 - acc: 0.8291 - val_loss: 0.6840 - val_acc: 0.8300

Epoch 00022: loss did not improve from 0.99554
Epoch 23/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5601 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0073 - acc: 0.8367 - val_loss: 0.7400 - val_acc: 0.8350
DeepAmes+ Weights:  31%|███       | 4/13 [00:09<00:20,  2.27s/it]
Epoch 00023: loss did not improve from 0.99554
Epoch 00023: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.2930 - acc: 0.7812
796/796 [==============================] - 0s 363us/step - loss: 1.7954 - acc: 0.7550 - val_loss: 1.2365 - val_acc: 0.7900

Epoch 00001: loss improved from inf to 1.79540, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2195 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.5783 - acc: 0.7915 - val_loss: 1.1343 - val_acc: 0.7900

Epoch 00002: loss improved from 1.79540 to 1.57829, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.1320 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.5384 - acc: 0.7927 - val_loss: 1.0520 - val_acc: 0.8100

Epoch 00003: loss improved from 1.57829 to 1.53844, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 1.1180 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.4791 - acc: 0.7952 - val_loss: 1.0065 - val_acc: 0.8200

Epoch 00004: loss improved from 1.53844 to 1.47910, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9696 - acc: 0.9062
796/796 [==============================] - 0s 30us/step - loss: 1.3990 - acc: 0.8065 - val_loss: 0.9453 - val_acc: 0.8300

Epoch 00005: loss improved from 1.47910 to 1.39895, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0275 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.3850 - acc: 0.8015 - val_loss: 1.0298 - val_acc: 0.7750

Epoch 00006: loss improved from 1.39895 to 1.38501, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7998 - acc: 0.9062
796/796 [==============================] - 0s 30us/step - loss: 1.3486 - acc: 0.8103 - val_loss: 0.8993 - val_acc: 0.8250

Epoch 00007: loss improved from 1.38501 to 1.34863, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9005 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.3134 - acc: 0.7990 - val_loss: 0.8138 - val_acc: 0.8250

Epoch 00008: loss improved from 1.34863 to 1.31341, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8627 - acc: 0.9375
796/796 [==============================] - 0s 30us/step - loss: 1.2554 - acc: 0.8103 - val_loss: 0.8697 - val_acc: 0.8100

Epoch 00009: loss improved from 1.31341 to 1.25540, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8195 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2796 - acc: 0.8040 - val_loss: 0.8478 - val_acc: 0.7950

Epoch 00010: loss did not improve from 1.25540
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7137 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2124 - acc: 0.8153 - val_loss: 0.7542 - val_acc: 0.8400

Epoch 00011: loss improved from 1.25540 to 1.21238, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7533 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.2762 - acc: 0.8003 - val_loss: 0.7803 - val_acc: 0.8350

Epoch 00012: loss did not improve from 1.21238
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6983 - acc: 0.9062
796/796 [==============================] - 0s 30us/step - loss: 1.1292 - acc: 0.8178 - val_loss: 0.7837 - val_acc: 0.8300

Epoch 00013: loss improved from 1.21238 to 1.12923, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6511 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.1549 - acc: 0.8078 - val_loss: 0.7908 - val_acc: 0.8250

Epoch 00014: loss did not improve from 1.12923
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6566 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.1655 - acc: 0.8028 - val_loss: 0.7303 - val_acc: 0.8400

Epoch 00015: loss did not improve from 1.12923
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6879 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.1397 - acc: 0.8103 - val_loss: 1.1905 - val_acc: 0.4650

Epoch 00016: loss did not improve from 1.12923
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7125 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.1220 - acc: 0.8241 - val_loss: 0.9152 - val_acc: 0.7350

Epoch 00017: loss improved from 1.12923 to 1.12203, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6068 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.1617 - acc: 0.8003 - val_loss: 0.7563 - val_acc: 0.8250

Epoch 00018: loss did not improve from 1.12203
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5998 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.1518 - acc: 0.8053 - val_loss: 0.7589 - val_acc: 0.8350

Epoch 00019: loss did not improve from 1.12203
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6787 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.1016 - acc: 0.8166 - val_loss: 0.6936 - val_acc: 0.8400

Epoch 00020: loss improved from 1.12203 to 1.10164, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6755 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.1098 - acc: 0.8204 - val_loss: 0.7016 - val_acc: 0.8450

Epoch 00021: loss did not improve from 1.10164
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5597 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.0672 - acc: 0.8053 - val_loss: 0.6161 - val_acc: 0.8500

Epoch 00022: loss improved from 1.10164 to 1.06720, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 23/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6147 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.1037 - acc: 0.8078 - val_loss: 0.6428 - val_acc: 0.8400

Epoch 00023: loss did not improve from 1.06720
Epoch 24/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5008 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.0514 - acc: 0.8229 - val_loss: 0.6353 - val_acc: 0.8300

Epoch 00024: loss improved from 1.06720 to 1.05138, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 25/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6286 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.0282 - acc: 0.8241 - val_loss: 0.6521 - val_acc: 0.8450

Epoch 00025: loss improved from 1.05138 to 1.02818, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 26/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5691 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.0080 - acc: 0.8304 - val_loss: 0.6553 - val_acc: 0.8450

Epoch 00026: loss improved from 1.02818 to 1.00801, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_10.h5
Epoch 27/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4809 - acc: 0.9375
796/796 [==============================] - 0s 31us/step - loss: 1.0520 - acc: 0.8354 - val_loss: 0.7586 - val_acc: 0.8400

Epoch 00027: loss did not improve from 1.00801
Epoch 28/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5540 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.0794 - acc: 0.8317 - val_loss: 0.8121 - val_acc: 0.8450

Epoch 00028: loss did not improve from 1.00801
Epoch 29/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5704 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.0257 - acc: 0.8191 - val_loss: 0.8049 - val_acc: 0.8250

Epoch 00029: loss did not improve from 1.00801
Epoch 30/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6075 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.0687 - acc: 0.8078 - val_loss: 0.7947 - val_acc: 0.8000

Epoch 00030: loss did not improve from 1.00801
Epoch 31/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5695 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.0432 - acc: 0.8291 - val_loss: 0.7289 - val_acc: 0.8100
DeepAmes+ Weights:  38%|███▊      | 5/13 [00:11<00:18,  2.36s/it]
Epoch 00031: loss did not improve from 1.00801
Epoch 00031: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.3202 - acc: 0.7812
796/796 [==============================] - 0s 352us/step - loss: 1.9267 - acc: 0.7462 - val_loss: 1.2576 - val_acc: 0.7950

Epoch 00001: loss improved from inf to 1.92672, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.1664 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.6596 - acc: 0.7776 - val_loss: 1.1766 - val_acc: 0.8000

Epoch 00002: loss improved from 1.92672 to 1.65960, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2189 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.6128 - acc: 0.7789 - val_loss: 1.0592 - val_acc: 0.8150

Epoch 00003: loss improved from 1.65960 to 1.61279, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9736 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.5252 - acc: 0.7789 - val_loss: 1.0711 - val_acc: 0.7950

Epoch 00004: loss improved from 1.61279 to 1.52519, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0705 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4359 - acc: 0.7927 - val_loss: 1.0273 - val_acc: 0.8000

Epoch 00005: loss improved from 1.52519 to 1.43588, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9689 - acc: 0.7812
796/796 [==============================] - 0s 29us/step - loss: 1.3828 - acc: 0.7864 - val_loss: 0.9387 - val_acc: 0.8000

Epoch 00006: loss improved from 1.43588 to 1.38280, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8908 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.4261 - acc: 0.7789 - val_loss: 1.5133 - val_acc: 0.3600

Epoch 00007: loss did not improve from 1.38280
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9118 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.3893 - acc: 0.7915 - val_loss: 0.9840 - val_acc: 0.8050

Epoch 00008: loss did not improve from 1.38280
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9920 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.3516 - acc: 0.7839 - val_loss: 0.9163 - val_acc: 0.8150

Epoch 00009: loss improved from 1.38280 to 1.35165, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8690 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2825 - acc: 0.7977 - val_loss: 0.9327 - val_acc: 0.7950

Epoch 00010: loss improved from 1.35165 to 1.28251, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7582 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2516 - acc: 0.8053 - val_loss: 0.7934 - val_acc: 0.8100

Epoch 00011: loss improved from 1.28251 to 1.25163, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8409 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.2721 - acc: 0.8028 - val_loss: 0.7859 - val_acc: 0.8400

Epoch 00012: loss did not improve from 1.25163
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7216 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2019 - acc: 0.8078 - val_loss: 0.8754 - val_acc: 0.7950

Epoch 00013: loss improved from 1.25163 to 1.20190, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6538 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2349 - acc: 0.7977 - val_loss: 0.7797 - val_acc: 0.8200

Epoch 00014: loss did not improve from 1.20190
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7954 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.2057 - acc: 0.7940 - val_loss: 0.9508 - val_acc: 0.8200

Epoch 00015: loss did not improve from 1.20190
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7294 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1966 - acc: 0.8053 - val_loss: 0.7627 - val_acc: 0.8200

Epoch 00016: loss improved from 1.20190 to 1.19656, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7201 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1170 - acc: 0.8128 - val_loss: 0.7409 - val_acc: 0.8400

Epoch 00017: loss improved from 1.19656 to 1.11698, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6347 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.1014 - acc: 0.8229 - val_loss: 0.7476 - val_acc: 0.8400

Epoch 00018: loss improved from 1.11698 to 1.10138, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6685 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1392 - acc: 0.8015 - val_loss: 0.7430 - val_acc: 0.8300

Epoch 00019: loss did not improve from 1.10138
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6673 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 1.0608 - acc: 0.8317 - val_loss: 0.8428 - val_acc: 0.7750

Epoch 00020: loss improved from 1.10138 to 1.06082, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6824 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.1898 - acc: 0.8053 - val_loss: 0.7398 - val_acc: 0.8300

Epoch 00021: loss did not improve from 1.06082
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5633 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1547 - acc: 0.8003 - val_loss: 0.7578 - val_acc: 0.8500

Epoch 00022: loss did not improve from 1.06082
Epoch 23/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6518 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1097 - acc: 0.8053 - val_loss: 0.7601 - val_acc: 0.8150

Epoch 00023: loss did not improve from 1.06082
Epoch 24/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6583 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.0525 - acc: 0.8153 - val_loss: 0.8308 - val_acc: 0.7900

Epoch 00024: loss improved from 1.06082 to 1.05250, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 25/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6360 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.1163 - acc: 0.8078 - val_loss: 0.7212 - val_acc: 0.8250

Epoch 00025: loss did not improve from 1.05250
Epoch 26/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6221 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.1023 - acc: 0.8116 - val_loss: 0.7431 - val_acc: 0.8300

Epoch 00026: loss did not improve from 1.05250
Epoch 27/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6307 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.0824 - acc: 0.8003 - val_loss: 0.7734 - val_acc: 0.8450

Epoch 00027: loss did not improve from 1.05250
Epoch 28/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5523 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0771 - acc: 0.8204 - val_loss: 0.6818 - val_acc: 0.8400

Epoch 00028: loss did not improve from 1.05250
Epoch 29/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6152 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.0024 - acc: 0.8191 - val_loss: 0.6904 - val_acc: 0.8350

Epoch 00029: loss improved from 1.05250 to 1.00240, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_11.h5
Epoch 30/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5144 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.1134 - acc: 0.8078 - val_loss: 0.6686 - val_acc: 0.8350

Epoch 00030: loss did not improve from 1.00240
Epoch 31/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5632 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.1833 - acc: 0.7915 - val_loss: 0.7545 - val_acc: 0.8400

Epoch 00031: loss did not improve from 1.00240
Epoch 32/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4855 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.0993 - acc: 0.8128 - val_loss: 0.6746 - val_acc: 0.8400

Epoch 00032: loss did not improve from 1.00240
Epoch 33/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5706 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.0439 - acc: 0.8329 - val_loss: 0.6617 - val_acc: 0.8350

Epoch 00033: loss did not improve from 1.00240
Epoch 34/100

 32/796 [>.............................] - ETA: 0s - loss: 0.4935 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.0324 - acc: 0.8279 - val_loss: 0.8268 - val_acc: 0.8200
DeepAmes+ Weights:  46%|████▌     | 6/13 [00:14<00:16,  2.41s/it]
Epoch 00034: loss did not improve from 1.00240
Epoch 00034: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.3596 - acc: 0.8750
796/796 [==============================] - 0s 355us/step - loss: 1.8828 - acc: 0.7450 - val_loss: 1.2513 - val_acc: 0.8100

Epoch 00001: loss improved from inf to 1.88280, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9691 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.6402 - acc: 0.7676 - val_loss: 1.1635 - val_acc: 0.8000

Epoch 00002: loss improved from 1.88280 to 1.64019, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0701 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.5719 - acc: 0.7739 - val_loss: 1.1916 - val_acc: 0.7700

Epoch 00003: loss improved from 1.64019 to 1.57187, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9461 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.6072 - acc: 0.7651 - val_loss: 1.0440 - val_acc: 0.7900

Epoch 00004: loss did not improve from 1.57187
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0126 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.4922 - acc: 0.7902 - val_loss: 1.1550 - val_acc: 0.7400

Epoch 00005: loss improved from 1.57187 to 1.49221, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9411 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.4418 - acc: 0.7789 - val_loss: 1.0168 - val_acc: 0.8000

Epoch 00006: loss improved from 1.49221 to 1.44178, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9438 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3846 - acc: 0.7852 - val_loss: 1.0050 - val_acc: 0.7600

Epoch 00007: loss improved from 1.44178 to 1.38461, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9278 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.3772 - acc: 0.7839 - val_loss: 0.8577 - val_acc: 0.8250

Epoch 00008: loss improved from 1.38461 to 1.37716, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8348 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3333 - acc: 0.7827 - val_loss: 1.0349 - val_acc: 0.7700

Epoch 00009: loss improved from 1.37716 to 1.33332, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7737 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2664 - acc: 0.7952 - val_loss: 0.8703 - val_acc: 0.8200

Epoch 00010: loss improved from 1.33332 to 1.26637, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_12.h5
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9289 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.3643 - acc: 0.7814 - val_loss: 0.9954 - val_acc: 0.8350

Epoch 00011: loss did not improve from 1.26637
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7627 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.3175 - acc: 0.7739 - val_loss: 0.8904 - val_acc: 0.8200

Epoch 00012: loss did not improve from 1.26637
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7020 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2716 - acc: 0.7965 - val_loss: 0.8032 - val_acc: 0.8400

Epoch 00013: loss did not improve from 1.26637
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7163 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.2988 - acc: 0.8003 - val_loss: 0.8916 - val_acc: 0.7900

Epoch 00014: loss did not improve from 1.26637
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7327 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.3076 - acc: 0.7764 - val_loss: 0.8814 - val_acc: 0.8150
DeepAmes+ Weights:  54%|█████▍    | 7/13 [00:16<00:13,  2.24s/it]
Epoch 00015: loss did not improve from 1.26637
Epoch 00015: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.6176 - acc: 0.7812
796/796 [==============================] - 0s 361us/step - loss: 1.9228 - acc: 0.7412 - val_loss: 1.2433 - val_acc: 0.7750

Epoch 00001: loss improved from inf to 1.92283, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2468 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.7431 - acc: 0.7500 - val_loss: 1.2369 - val_acc: 0.7700

Epoch 00002: loss improved from 1.92283 to 1.74306, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2782 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.6694 - acc: 0.7513 - val_loss: 1.1393 - val_acc: 0.8000

Epoch 00003: loss improved from 1.74306 to 1.66941, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0264 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.6023 - acc: 0.7563 - val_loss: 1.1368 - val_acc: 0.7650

Epoch 00004: loss improved from 1.66941 to 1.60228, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0858 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.5281 - acc: 0.7475 - val_loss: 1.0734 - val_acc: 0.7550

Epoch 00005: loss improved from 1.60228 to 1.52811, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9824 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.4949 - acc: 0.7663 - val_loss: 0.9898 - val_acc: 0.7850

Epoch 00006: loss improved from 1.52811 to 1.49489, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9186 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.4417 - acc: 0.7839 - val_loss: 1.0627 - val_acc: 0.7300

Epoch 00007: loss improved from 1.49489 to 1.44165, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8132 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.4116 - acc: 0.7726 - val_loss: 0.9880 - val_acc: 0.7800

Epoch 00008: loss improved from 1.44165 to 1.41162, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8681 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.3626 - acc: 0.7864 - val_loss: 1.1236 - val_acc: 0.4600

Epoch 00009: loss improved from 1.41162 to 1.36263, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9036 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.4681 - acc: 0.7387 - val_loss: 0.9392 - val_acc: 0.7650

Epoch 00010: loss did not improve from 1.36263
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7891 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.3656 - acc: 0.7487 - val_loss: 0.8318 - val_acc: 0.8100

Epoch 00011: loss did not improve from 1.36263
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7334 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2978 - acc: 0.7902 - val_loss: 0.8726 - val_acc: 0.8050

Epoch 00012: loss improved from 1.36263 to 1.29785, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9038 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.2704 - acc: 0.7852 - val_loss: 0.8003 - val_acc: 0.8250

Epoch 00013: loss improved from 1.29785 to 1.27045, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7206 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.3194 - acc: 0.7915 - val_loss: 0.7900 - val_acc: 0.8150

Epoch 00014: loss did not improve from 1.27045
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8168 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2684 - acc: 0.7751 - val_loss: 0.9814 - val_acc: 0.7350

Epoch 00015: loss improved from 1.27045 to 1.26838, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9919 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.3195 - acc: 0.7601 - val_loss: 0.7623 - val_acc: 0.8200

Epoch 00016: loss did not improve from 1.26838
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7623 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3010 - acc: 0.7726 - val_loss: 0.7848 - val_acc: 0.8100

Epoch 00017: loss did not improve from 1.26838
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9101 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.2112 - acc: 0.7802 - val_loss: 0.7144 - val_acc: 0.8250

Epoch 00018: loss improved from 1.26838 to 1.21117, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_13.h5
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6538 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.2404 - acc: 0.7827 - val_loss: 0.7391 - val_acc: 0.8450

Epoch 00019: loss did not improve from 1.21117
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8349 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.2130 - acc: 0.7663 - val_loss: 0.7876 - val_acc: 0.8200

Epoch 00020: loss did not improve from 1.21117
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7940 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2492 - acc: 0.7776 - val_loss: 0.7552 - val_acc: 0.8150

Epoch 00021: loss did not improve from 1.21117
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6654 - acc: 0.7812
796/796 [==============================] - 0s 29us/step - loss: 1.2250 - acc: 0.7563 - val_loss: 0.7046 - val_acc: 0.8400

Epoch 00022: loss did not improve from 1.21117
Epoch 23/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5720 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.2113 - acc: 0.7827 - val_loss: 0.7328 - val_acc: 0.8400
DeepAmes+ Weights:  62%|██████▏   | 8/13 [00:18<00:11,  2.25s/it]
Epoch 00023: loss did not improve from 1.21117
Epoch 00023: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.6037 - acc: 0.7812
796/796 [==============================] - 0s 352us/step - loss: 2.0869 - acc: 0.7111 - val_loss: 1.2377 - val_acc: 0.8000

Epoch 00001: loss improved from inf to 2.08693, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.3025 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.7751 - acc: 0.7563 - val_loss: 1.2253 - val_acc: 0.7700

Epoch 00002: loss improved from 2.08693 to 1.77510, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.1098 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.7403 - acc: 0.7487 - val_loss: 1.1695 - val_acc: 0.7650

Epoch 00003: loss improved from 1.77510 to 1.74032, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 1.1587 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.6148 - acc: 0.7563 - val_loss: 1.1425 - val_acc: 0.7450

Epoch 00004: loss improved from 1.74032 to 1.61478, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0249 - acc: 0.8125
796/796 [==============================] - 0s 30us/step - loss: 1.5209 - acc: 0.7588 - val_loss: 1.0158 - val_acc: 0.8200

Epoch 00005: loss improved from 1.61478 to 1.52089, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9559 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.4926 - acc: 0.7751 - val_loss: 1.0143 - val_acc: 0.7850

Epoch 00006: loss improved from 1.52089 to 1.49255, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9354 - acc: 0.8438
796/796 [==============================] - 0s 30us/step - loss: 1.4745 - acc: 0.7601 - val_loss: 0.9811 - val_acc: 0.8300

Epoch 00007: loss improved from 1.49255 to 1.47452, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8416 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.4508 - acc: 0.7776 - val_loss: 0.9782 - val_acc: 0.7850

Epoch 00008: loss improved from 1.47452 to 1.45083, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8640 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.4545 - acc: 0.7575 - val_loss: 0.9380 - val_acc: 0.7850

Epoch 00009: loss did not improve from 1.45083
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8211 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4181 - acc: 0.7613 - val_loss: 1.0305 - val_acc: 0.7500

Epoch 00010: loss improved from 1.45083 to 1.41811, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7821 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.3781 - acc: 0.7739 - val_loss: 0.9070 - val_acc: 0.7900

Epoch 00011: loss improved from 1.41811 to 1.37810, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7972 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.2915 - acc: 0.7789 - val_loss: 0.9871 - val_acc: 0.7550

Epoch 00012: loss improved from 1.37810 to 1.29150, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7199 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2495 - acc: 0.7864 - val_loss: 1.1655 - val_acc: 0.4350

Epoch 00013: loss improved from 1.29150 to 1.24953, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6209 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2284 - acc: 0.7802 - val_loss: 1.0523 - val_acc: 0.7250

Epoch 00014: loss improved from 1.24953 to 1.22840, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7004 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.2199 - acc: 0.7827 - val_loss: 1.0970 - val_acc: 0.6400

Epoch 00015: loss improved from 1.22840 to 1.21990, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_14.h5
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7747 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3342 - acc: 0.7802 - val_loss: 1.0481 - val_acc: 0.7850

Epoch 00016: loss did not improve from 1.21990
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7286 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4185 - acc: 0.7425 - val_loss: 0.9736 - val_acc: 0.7450

Epoch 00017: loss did not improve from 1.21990
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7659 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.3197 - acc: 0.7877 - val_loss: 0.8281 - val_acc: 0.8400

Epoch 00018: loss did not improve from 1.21990
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7151 - acc: 0.8438
796/796 [==============================] - 0s 28us/step - loss: 1.3064 - acc: 0.7915 - val_loss: 0.9594 - val_acc: 0.7800

Epoch 00019: loss did not improve from 1.21990
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7422 - acc: 0.8438
796/796 [==============================] - 0s 28us/step - loss: 1.2623 - acc: 0.7940 - val_loss: 0.9836 - val_acc: 0.7900
DeepAmes+ Weights:  69%|██████▉   | 9/13 [00:20<00:08,  2.22s/it]
Epoch 00020: loss did not improve from 1.21990
Epoch 00020: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.4067 - acc: 0.8125
796/796 [==============================] - 0s 345us/step - loss: 2.0522 - acc: 0.7198 - val_loss: 1.2770 - val_acc: 0.7850

Epoch 00001: loss improved from inf to 2.05220, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.3107 - acc: 0.8125
796/796 [==============================] - 0s 31us/step - loss: 1.8233 - acc: 0.7337 - val_loss: 1.2496 - val_acc: 0.7700

Epoch 00002: loss improved from 2.05220 to 1.82327, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0673 - acc: 0.8125
796/796 [==============================] - 0s 30us/step - loss: 1.7229 - acc: 0.7437 - val_loss: 1.2309 - val_acc: 0.7600

Epoch 00003: loss improved from 1.82327 to 1.72291, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 1.1775 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.6553 - acc: 0.7362 - val_loss: 1.1266 - val_acc: 0.7750

Epoch 00004: loss improved from 1.72291 to 1.65533, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0298 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.6656 - acc: 0.7425 - val_loss: 1.0064 - val_acc: 0.8150

Epoch 00005: loss did not improve from 1.65533
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9959 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.6446 - acc: 0.7349 - val_loss: 1.0544 - val_acc: 0.7600

Epoch 00006: loss improved from 1.65533 to 1.64460, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0217 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.5355 - acc: 0.7475 - val_loss: 1.0748 - val_acc: 0.7550

Epoch 00007: loss improved from 1.64460 to 1.53547, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9261 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4952 - acc: 0.7437 - val_loss: 1.0122 - val_acc: 0.7750

Epoch 00008: loss improved from 1.53547 to 1.49517, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8668 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4502 - acc: 0.7487 - val_loss: 0.9869 - val_acc: 0.7450

Epoch 00009: loss improved from 1.49517 to 1.45021, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9540 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.4954 - acc: 0.7462 - val_loss: 0.9142 - val_acc: 0.8350

Epoch 00010: loss did not improve from 1.45021
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7470 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.4327 - acc: 0.7588 - val_loss: 0.9635 - val_acc: 0.8000

Epoch 00011: loss improved from 1.45021 to 1.43267, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8473 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.3895 - acc: 0.7425 - val_loss: 0.9128 - val_acc: 0.7900

Epoch 00012: loss improved from 1.43267 to 1.38951, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8277 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3832 - acc: 0.7563 - val_loss: 0.8497 - val_acc: 0.8150

Epoch 00013: loss improved from 1.38951 to 1.38321, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7313 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3681 - acc: 0.7751 - val_loss: 0.8321 - val_acc: 0.8300

Epoch 00014: loss improved from 1.38321 to 1.36814, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8170 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3008 - acc: 0.7563 - val_loss: 0.8357 - val_acc: 0.7950

Epoch 00015: loss improved from 1.36814 to 1.30084, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6533 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2904 - acc: 0.7726 - val_loss: 0.9329 - val_acc: 0.7700

Epoch 00016: loss improved from 1.30084 to 1.29041, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7256 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.2740 - acc: 0.7425 - val_loss: 0.8100 - val_acc: 0.8150

Epoch 00017: loss improved from 1.29041 to 1.27400, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7047 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3131 - acc: 0.7663 - val_loss: 0.8237 - val_acc: 0.8350

Epoch 00018: loss did not improve from 1.27400
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6662 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2948 - acc: 0.7764 - val_loss: 0.7212 - val_acc: 0.8350

Epoch 00019: loss did not improve from 1.27400
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7784 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.2711 - acc: 0.7613 - val_loss: 0.7943 - val_acc: 0.7950

Epoch 00020: loss improved from 1.27400 to 1.27114, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_15.h5
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6449 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.5993 - acc: 0.7362 - val_loss: 1.1453 - val_acc: 0.8150

Epoch 00021: loss did not improve from 1.27114
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7517 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.3274 - acc: 0.7538 - val_loss: 0.8759 - val_acc: 0.7850

Epoch 00022: loss did not improve from 1.27114
Epoch 23/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7993 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3246 - acc: 0.7538 - val_loss: 0.8200 - val_acc: 0.8050

Epoch 00023: loss did not improve from 1.27114
Epoch 24/100

 32/796 [>.............................] - ETA: 0s - loss: 0.5373 - acc: 0.9375
796/796 [==============================] - 0s 29us/step - loss: 1.2914 - acc: 0.7638 - val_loss: 0.7787 - val_acc: 0.8200

Epoch 00024: loss did not improve from 1.27114
Epoch 25/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6250 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3400 - acc: 0.7701 - val_loss: 0.7228 - val_acc: 0.8200
DeepAmes+ Weights:  77%|███████▋  | 10/13 [00:22<00:06,  2.24s/it]
Epoch 00025: loss did not improve from 1.27114
Epoch 00025: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.6959 - acc: 0.7500
796/796 [==============================] - 0s 354us/step - loss: 2.1681 - acc: 0.6834 - val_loss: 1.3200 - val_acc: 0.7800

Epoch 00001: loss improved from inf to 2.16812, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.3035 - acc: 0.8125
796/796 [==============================] - 0s 33us/step - loss: 1.8704 - acc: 0.7023 - val_loss: 1.2524 - val_acc: 0.7800

Epoch 00002: loss improved from 2.16812 to 1.87042, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.3131 - acc: 0.8125
796/796 [==============================] - 0s 32us/step - loss: 1.7536 - acc: 0.7148 - val_loss: 1.1881 - val_acc: 0.7750

Epoch 00003: loss improved from 1.87042 to 1.75362, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2009 - acc: 0.7812
796/796 [==============================] - 0s 32us/step - loss: 1.6911 - acc: 0.7236 - val_loss: 1.1813 - val_acc: 0.7500

Epoch 00004: loss improved from 1.75362 to 1.69114, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0375 - acc: 0.8125
796/796 [==============================] - 0s 31us/step - loss: 1.6260 - acc: 0.7249 - val_loss: 1.1975 - val_acc: 0.7200

Epoch 00005: loss improved from 1.69114 to 1.62595, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0378 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.5783 - acc: 0.7286 - val_loss: 1.1622 - val_acc: 0.7400

Epoch 00006: loss improved from 1.62595 to 1.57830, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9257 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.5210 - acc: 0.7538 - val_loss: 1.0550 - val_acc: 0.7650

Epoch 00007: loss improved from 1.57830 to 1.52101, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8716 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.5701 - acc: 0.7337 - val_loss: 0.9786 - val_acc: 0.7750

Epoch 00008: loss did not improve from 1.52101
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0148 - acc: 0.8125
796/796 [==============================] - 0s 31us/step - loss: 1.5509 - acc: 0.7374 - val_loss: 1.0948 - val_acc: 0.7600

Epoch 00009: loss did not improve from 1.52101
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8028 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.5125 - acc: 0.7299 - val_loss: 1.1193 - val_acc: 0.7050

Epoch 00010: loss improved from 1.52101 to 1.51250, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9074 - acc: 0.8125
796/796 [==============================] - 0s 31us/step - loss: 1.4801 - acc: 0.7500 - val_loss: 1.1308 - val_acc: 0.5750

Epoch 00011: loss improved from 1.51250 to 1.48009, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8878 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.4304 - acc: 0.7412 - val_loss: 0.9747 - val_acc: 0.7800

Epoch 00012: loss improved from 1.48009 to 1.43045, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8353 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.4542 - acc: 0.7337 - val_loss: 0.9732 - val_acc: 0.8400

Epoch 00013: loss did not improve from 1.43045
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8195 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.4747 - acc: 0.7123 - val_loss: 0.8673 - val_acc: 0.8000

Epoch 00014: loss did not improve from 1.43045
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8363 - acc: 0.8125
796/796 [==============================] - 0s 31us/step - loss: 1.3939 - acc: 0.7312 - val_loss: 0.8008 - val_acc: 0.8400

Epoch 00015: loss improved from 1.43045 to 1.39395, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7633 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.4174 - acc: 0.7487 - val_loss: 0.9319 - val_acc: 0.8350

Epoch 00016: loss did not improve from 1.39395
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7921 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.3421 - acc: 0.7337 - val_loss: 1.1811 - val_acc: 0.8250

Epoch 00017: loss improved from 1.39395 to 1.34214, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_16.h5
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7023 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.4427 - acc: 0.7324 - val_loss: 1.0099 - val_acc: 0.7600

Epoch 00018: loss did not improve from 1.34214
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7839 - acc: 0.8750
796/796 [==============================] - 0s 31us/step - loss: 1.4156 - acc: 0.7437 - val_loss: 0.9315 - val_acc: 0.8250

Epoch 00019: loss did not improve from 1.34214
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7981 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.5269 - acc: 0.6910 - val_loss: 0.9504 - val_acc: 0.7950

Epoch 00020: loss did not improve from 1.34214
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9072 - acc: 0.8438
796/796 [==============================] - 0s 31us/step - loss: 1.4694 - acc: 0.7098 - val_loss: 0.9789 - val_acc: 0.7650

Epoch 00021: loss did not improve from 1.34214
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8413 - acc: 0.9062
796/796 [==============================] - 0s 31us/step - loss: 1.3700 - acc: 0.7173 - val_loss: 0.9681 - val_acc: 0.7500
DeepAmes+ Weights:  85%|████████▍ | 11/13 [00:25<00:04,  2.21s/it]
Epoch 00022: loss did not improve from 1.34214
Epoch 00022: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.6370 - acc: 0.8750
796/796 [==============================] - 0s 363us/step - loss: 2.2150 - acc: 0.6935 - val_loss: 1.3450 - val_acc: 0.7750

Epoch 00001: loss improved from inf to 2.21504, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2957 - acc: 0.8125
796/796 [==============================] - 0s 31us/step - loss: 1.8845 - acc: 0.6922 - val_loss: 1.2921 - val_acc: 0.7350

Epoch 00002: loss improved from 2.21504 to 1.88446, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.3004 - acc: 0.7500
796/796 [==============================] - 0s 30us/step - loss: 1.7981 - acc: 0.7236 - val_loss: 1.1927 - val_acc: 0.7800

Epoch 00003: loss improved from 1.88446 to 1.79806, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2466 - acc: 0.8125
796/796 [==============================] - 0s 30us/step - loss: 1.7575 - acc: 0.7048 - val_loss: 1.1987 - val_acc: 0.7550

Epoch 00004: loss improved from 1.79806 to 1.75749, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 1.1723 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.6903 - acc: 0.7286 - val_loss: 1.1787 - val_acc: 0.7400

Epoch 00005: loss improved from 1.75749 to 1.69032, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0357 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.5990 - acc: 0.7249 - val_loss: 1.2517 - val_acc: 0.6800

Epoch 00006: loss improved from 1.69032 to 1.59897, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9521 - acc: 0.7812
796/796 [==============================] - 0s 30us/step - loss: 1.6446 - acc: 0.7148 - val_loss: 1.1016 - val_acc: 0.7350

Epoch 00007: loss did not improve from 1.59897
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0747 - acc: 0.7812
796/796 [==============================] - 0s 29us/step - loss: 1.6042 - acc: 0.7224 - val_loss: 1.1174 - val_acc: 0.7500

Epoch 00008: loss did not improve from 1.59897
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9195 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4695 - acc: 0.7525 - val_loss: 1.1693 - val_acc: 0.5900

Epoch 00009: loss improved from 1.59897 to 1.46946, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9333 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.6069 - acc: 0.7550 - val_loss: 0.9807 - val_acc: 0.7850

Epoch 00010: loss did not improve from 1.46946
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9609 - acc: 0.7812
796/796 [==============================] - 0s 29us/step - loss: 1.4717 - acc: 0.7412 - val_loss: 0.9067 - val_acc: 0.8300

Epoch 00011: loss did not improve from 1.46946
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8585 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.4530 - acc: 0.7563 - val_loss: 0.8633 - val_acc: 0.8250

Epoch 00012: loss improved from 1.46946 to 1.45298, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8830 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4848 - acc: 0.7362 - val_loss: 0.8978 - val_acc: 0.8050

Epoch 00013: loss did not improve from 1.45298
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8504 - acc: 0.7812
796/796 [==============================] - 0s 29us/step - loss: 1.4672 - acc: 0.7249 - val_loss: 1.0327 - val_acc: 0.7550

Epoch 00014: loss did not improve from 1.45298
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8285 - acc: 0.7812
796/796 [==============================] - 0s 29us/step - loss: 1.4556 - acc: 0.7161 - val_loss: 1.1605 - val_acc: 0.4900

Epoch 00015: loss did not improve from 1.45298
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7409 - acc: 0.9062
796/796 [==============================] - 0s 29us/step - loss: 1.4078 - acc: 0.7525 - val_loss: 1.0713 - val_acc: 0.7750

Epoch 00016: loss improved from 1.45298 to 1.40783, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8185 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.4089 - acc: 0.7224 - val_loss: 0.8527 - val_acc: 0.8250

Epoch 00017: loss did not improve from 1.40783
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8712 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4154 - acc: 0.7286 - val_loss: 0.8282 - val_acc: 0.8050

Epoch 00018: loss did not improve from 1.40783
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9378 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.5045 - acc: 0.7236 - val_loss: 0.8374 - val_acc: 0.8150

Epoch 00019: loss did not improve from 1.40783
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8517 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.3764 - acc: 0.7224 - val_loss: 0.8198 - val_acc: 0.7950

Epoch 00020: loss improved from 1.40783 to 1.37636, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 21/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7531 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3112 - acc: 0.7563 - val_loss: 0.8742 - val_acc: 0.7850

Epoch 00021: loss improved from 1.37636 to 1.31119, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_17.h5
Epoch 22/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8426 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4907 - acc: 0.7412 - val_loss: 0.8371 - val_acc: 0.8100

Epoch 00022: loss did not improve from 1.31119
Epoch 23/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7717 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.3229 - acc: 0.7563 - val_loss: 0.9907 - val_acc: 0.7100

Epoch 00023: loss did not improve from 1.31119
Epoch 24/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6409 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4713 - acc: 0.7450 - val_loss: 1.0153 - val_acc: 0.8150

Epoch 00024: loss did not improve from 1.31119
Epoch 25/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7947 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.3931 - acc: 0.7324 - val_loss: 0.9497 - val_acc: 0.7700

Epoch 00025: loss did not improve from 1.31119
Epoch 26/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7454 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4179 - acc: 0.7211 - val_loss: 0.8320 - val_acc: 0.8050
DeepAmes+ Weights:  92%|█████████▏| 12/13 [00:27<00:02,  2.24s/it]
Epoch 00026: loss did not improve from 1.31119
Epoch 00026: early stopping
Train on 796 samples, validate on 200 samples
Epoch 1/100

 32/796 [>.............................] - ETA: 5s - loss: 1.4242 - acc: 0.7500
796/796 [==============================] - 0s 348us/step - loss: 2.2773 - acc: 0.6595 - val_loss: 1.3491 - val_acc: 0.7600

Epoch 00001: loss improved from inf to 2.27727, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 2/100

 32/796 [>.............................] - ETA: 0s - loss: 1.3773 - acc: 0.8750
796/796 [==============================] - 0s 30us/step - loss: 1.9682 - acc: 0.6671 - val_loss: 1.3674 - val_acc: 0.7650

Epoch 00002: loss improved from 2.27727 to 1.96822, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 3/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2092 - acc: 0.8125
796/796 [==============================] - 0s 30us/step - loss: 1.8720 - acc: 0.6960 - val_loss: 1.3066 - val_acc: 0.7450

Epoch 00003: loss improved from 1.96822 to 1.87199, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 4/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2416 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.7997 - acc: 0.7035 - val_loss: 1.1565 - val_acc: 0.7650

Epoch 00004: loss improved from 1.87199 to 1.79973, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 5/100

 32/796 [>.............................] - ETA: 0s - loss: 1.2542 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.7119 - acc: 0.7286 - val_loss: 1.2050 - val_acc: 0.7400

Epoch 00005: loss improved from 1.79973 to 1.71187, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 6/100

 32/796 [>.............................] - ETA: 0s - loss: 1.1178 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.6221 - acc: 0.7236 - val_loss: 1.0988 - val_acc: 0.7450

Epoch 00006: loss improved from 1.71187 to 1.62205, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 7/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0512 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.6664 - acc: 0.7312 - val_loss: 1.0982 - val_acc: 0.7600

Epoch 00007: loss did not improve from 1.62205
Epoch 8/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9331 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.5708 - acc: 0.7198 - val_loss: 1.1285 - val_acc: 0.7300

Epoch 00008: loss improved from 1.62205 to 1.57081, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 9/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0276 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4939 - acc: 0.7261 - val_loss: 0.9994 - val_acc: 0.7900

Epoch 00009: loss improved from 1.57081 to 1.49394, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 10/100

 32/796 [>.............................] - ETA: 0s - loss: 0.9542 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.6316 - acc: 0.7186 - val_loss: 1.1772 - val_acc: 0.8150

Epoch 00010: loss did not improve from 1.49394
Epoch 11/100

 32/796 [>.............................] - ETA: 0s - loss: 1.0018 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.6734 - acc: 0.6709 - val_loss: 1.1543 - val_acc: 0.7650

Epoch 00011: loss did not improve from 1.49394
Epoch 12/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8868 - acc: 0.7812
796/796 [==============================] - 0s 29us/step - loss: 1.4833 - acc: 0.6884 - val_loss: 1.1177 - val_acc: 0.6150

Epoch 00012: loss improved from 1.49394 to 1.48335, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 13/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8713 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4549 - acc: 0.7161 - val_loss: 1.1850 - val_acc: 0.5500

Epoch 00013: loss improved from 1.48335 to 1.45490, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 14/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8559 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4697 - acc: 0.7224 - val_loss: 1.0085 - val_acc: 0.7750

Epoch 00014: loss did not improve from 1.45490
Epoch 15/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7620 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.4033 - acc: 0.7374 - val_loss: 0.7882 - val_acc: 0.8250

Epoch 00015: loss improved from 1.45490 to 1.40333, saving model to ./results_TA98_without_S9/DeepAmes_models/weight_18.h5
Epoch 16/100

 32/796 [>.............................] - ETA: 0s - loss: 0.6731 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.4954 - acc: 0.7010 - val_loss: 0.8436 - val_acc: 0.7950

Epoch 00016: loss did not improve from 1.40333
Epoch 17/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8543 - acc: 0.8125
796/796 [==============================] - 0s 29us/step - loss: 1.4238 - acc: 0.7312 - val_loss: 0.8429 - val_acc: 0.8050

Epoch 00017: loss did not improve from 1.40333
Epoch 18/100

 32/796 [>.............................] - ETA: 0s - loss: 0.8775 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.5053 - acc: 0.7538 - val_loss: 0.9072 - val_acc: 0.8050

Epoch 00018: loss did not improve from 1.40333
Epoch 19/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7380 - acc: 0.8438
796/796 [==============================] - 0s 29us/step - loss: 1.5125 - acc: 0.6960 - val_loss: 0.8739 - val_acc: 0.8100

Epoch 00019: loss did not improve from 1.40333
Epoch 20/100

 32/796 [>.............................] - ETA: 0s - loss: 0.7804 - acc: 0.8750
796/796 [==============================] - 0s 29us/step - loss: 1.4224 - acc: 0.7274 - val_loss: 1.0434 - val_acc: 0.7900
DeepAmes+ Weights: 100%|██████████| 13/13 [00:29<00:00,  2.21s/it]DeepAmes+ Weights: 100%|██████████| 13/13 [00:29<00:00,  2.27s/it]

Epoch 00020: loss did not improve from 1.40333
Epoch 00020: early stopping
--- 7041.4184403419495 seconds ---

Generating metrics report for TA98_without_S9...
Processing models with 1000 bootstrap iterations...
================================================================================
Processing weight 6...
  Done. 567 samples.
Processing weight 7...
  Done. 567 samples.
Processing weight 8...
  Done. 567 samples.
Processing weight 9...
  Done. 567 samples.
Processing weight 10...
  Done. 567 samples.
Processing weight 11...
  Done. 567 samples.
Processing weight 12...
  Done. 567 samples.
Processing weight 13...
  Done. 567 samples.
Processing weight 14...
  Done. 567 samples.
Processing weight 15...
  Done. 567 samples.
Processing weight 16...
  Done. 567 samples.
Processing weight 17...
  Done. 567 samples.
Processing weight 18...
  Done. 567 samples.
================================================================================
All models processed. Generating report...

Report saved to: ./results_TA98_without_S9/metrics_report_TA98_without_S9.txt

Done!

Completed TA98_without_S9 in 7041.42 seconds

================================================================================
PIPELINE SUMMARY
================================================================================

Total datasets: 16
Successful: 16
Failed: 0
Total time: 50464.57 seconds (841.08 minutes)

Detailed Results:
--------------------------------------------------------------------------------
  ✓ TA100_with_S9
      Time: 7052.41s
      Output: ./results_TA100_with_S9
      Report: ./results_TA100_with_S9/metrics_report_TA100_with_S9.txt
  ✓ TA100_without_S9
      Time: 8159.43s
      Output: ./results_TA100_without_S9
      Report: ./results_TA100_without_S9/metrics_report_TA100_without_S9.txt
  ✓ TA102_with_S9
      Time: 851.86s
      Output: ./results_TA102_with_S9
      Report: ./results_TA102_with_S9/metrics_report_TA102_with_S9.txt
  ✓ TA102_without_S9
      Time: 934.30s
      Output: ./results_TA102_without_S9
      Report: ./results_TA102_without_S9/metrics_report_TA102_without_S9.txt
  ✓ TA104_with_S9
      Time: 630.74s
      Output: ./results_TA104_with_S9
      Report: ./results_TA104_with_S9/metrics_report_TA104_with_S9.txt
  ✓ TA104_without_S9
      Time: 669.66s
      Output: ./results_TA104_without_S9
      Report: ./results_TA104_without_S9/metrics_report_TA104_without_S9.txt
  ✓ TA1535_with_S9
      Time: 3270.74s
      Output: ./results_TA1535_with_S9
      Report: ./results_TA1535_with_S9/metrics_report_TA1535_with_S9.txt
  ✓ TA1535_without_S9
      Time: 3553.87s
      Output: ./results_TA1535_without_S9
      Report: ./results_TA1535_without_S9/metrics_report_TA1535_without_S9.txt
  ✓ TA1537_with_S9
      Time: 2845.62s
      Output: ./results_TA1537_with_S9
      Report: ./results_TA1537_with_S9/metrics_report_TA1537_with_S9.txt
  ✓ TA1537_without_S9
      Time: 2947.44s
      Output: ./results_TA1537_without_S9
      Report: ./results_TA1537_without_S9/metrics_report_TA1537_without_S9.txt
  ✓ TA1538_with_S9
      Time: 1457.53s
      Output: ./results_TA1538_with_S9
      Report: ./results_TA1538_with_S9/metrics_report_TA1538_with_S9.txt
  ✓ TA1538_without_S9
      Time: 1554.77s
      Output: ./results_TA1538_without_S9
      Report: ./results_TA1538_without_S9/metrics_report_TA1538_without_S9.txt
  ✓ TA97_with_S9
      Time: 1257.08s
      Output: ./results_TA97_with_S9
      Report: ./results_TA97_with_S9/metrics_report_TA97_with_S9.txt
  ✓ TA97_without_S9
      Time: 1294.40s
      Output: ./results_TA97_without_S9
      Report: ./results_TA97_without_S9/metrics_report_TA97_without_S9.txt
  ✓ TA98_with_S9
      Time: 6273.95s
      Output: ./results_TA98_with_S9
      Report: ./results_TA98_with_S9/metrics_report_TA98_with_S9.txt
  ✓ TA98_without_S9
      Time: 7041.42s
      Output: ./results_TA98_without_S9
      Report: ./results_TA98_without_S9/metrics_report_TA98_without_S9.txt
